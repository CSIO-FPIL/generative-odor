{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import multiprocessing\n",
    "   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv , TransformerConv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "class DeepChemToPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        \"\"\"\n",
    "        Converts a list of PyG `Data` objects into an InMemoryDataset.\n",
    "        \n",
    "        Args:\n",
    "            data_list (list of Data): List of PyG Data objects.\n",
    "            transform (callable, optional): Optional transform applied to each data object.\n",
    "        \"\"\"\n",
    "        super(DeepChemToPyGDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data object at the specified index.\n",
    "        \"\"\"\n",
    "        return super().get(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_26876\\3827785572.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load('../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "pyg_dataset = torch.load('../../data/curated dataset/cleaned_frag_pyg_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = pyg_dataset[0].x.shape[1]  # Should be 134 based on your description\n",
    "edge_features = pyg_dataset[0].edge_attr.shape[1]  # Should be 6 based on your description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformer Encoder\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        # Adjust input dimension of the TransformerConv based on the combined feature size\n",
    "        self.transformer1 = TransformerConv(node_features + edge_features, hidden_dim, heads=4)\n",
    "        self.transformer2 = TransformerConv(hidden_dim * 4, hidden_dim, heads=4)  # Adjusted input dimension\n",
    "        self.transformer3 = TransformerConv(hidden_dim * 4, hidden_dim, heads=4)  # Adjusted input dimension\n",
    "        self.fc_mu = nn.Linear(hidden_dim * 4, latent_dim)  # Output dimension must match hidden_dim * heads\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_attr_expanded = torch.zeros((x.size(0), edge_features)).to(x.device)\n",
    "        edge_attr_expanded[edge_index[0]] = edge_attr\n",
    "        x = torch.cat([x, edge_attr_expanded], dim=1)\n",
    "\n",
    "        x = F.relu(self.transformer1(x, edge_index))\n",
    "        x = F.relu(self.transformer2(x, edge_index))\n",
    "        x = F.relu(self.transformer3(x, edge_index))\n",
    "        return self.fc_mu(x), None  # Return mu and None for logvar\n",
    "\n",
    "# Define Transformer Decoder\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, node_features, edge_features):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.node_decoder = nn.Linear(hidden_dim, node_features)\n",
    "        self.edge_decoder = nn.Linear(hidden_dim * 2, edge_features)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        h = F.relu(self.fc(z))\n",
    "        reconstructed_x = self.node_decoder(h)\n",
    "\n",
    "        # Edge reconstruction\n",
    "        row, col = edge_index\n",
    "        edge_h = torch.cat([h[row], h[col]], dim=1)\n",
    "        reconstructed_edge_attr = self.edge_decoder(edge_h)\n",
    "\n",
    "        return reconstructed_x, reconstructed_edge_attr\n",
    "\n",
    "# Define Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = TransformerEncoder(node_features, edge_features, hidden_dim, latent_dim)\n",
    "        self.decoder = TransformerDecoder(latent_dim, hidden_dim, node_features, edge_features)\n",
    "\n",
    "    def encode(self, x, edge_index, edge_attr):\n",
    "        return self.encoder(x, edge_index, edge_attr)\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return self.decoder(z, edge_index)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        z, _ = self.encode(x, edge_index, edge_attr)  # Ignore logvar\n",
    "        reconstructed_x, reconstructed_edge_attr = self.decode(z, edge_index)\n",
    "        return reconstructed_x, reconstructed_edge_attr\n",
    "\n",
    "    def generate_multiple_outputs(self, x, edge_index, edge_attr, num_samples=5):\n",
    "        outputs = []\n",
    "        with torch.no_grad():\n",
    "            z, _ = self.encode(x, edge_index, edge_attr)\n",
    "            for _ in range(num_samples):\n",
    "                # Add noise to z (sampling from normal distribution)\n",
    "                z_noisy = z + torch.randn_like(z) * 0.5  # Adjust std deviation for noise level\n",
    "                reconstructed_x, reconstructed_edge_attr = self.decode(z_noisy, edge_index)\n",
    "                outputs.append((reconstructed_x, reconstructed_edge_attr, edge_index))\n",
    "        return outputs\n",
    "\n",
    "    def generate_molecule(self, num_nodes):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Sample from the latent space\n",
    "            z = torch.randn(num_nodes, latent_dim)\n",
    "\n",
    "            # Create a fully connected edge_index\n",
    "            edge_index = torch.combinations(torch.arange(num_nodes), 2).t()\n",
    "\n",
    "            # Decode\n",
    "            reconstructed_x, reconstructed_edge_attr = self.decode(z, edge_index)\n",
    "\n",
    "            return reconstructed_x, edge_index, reconstructed_edge_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the reconstruction loss. It is MSE for GAE\n",
    "def loss_function(recon_x, x, recon_edge_attr, edge_attr):\n",
    "    # Reconstruction losses\n",
    "    node_recon_loss = F.mse_loss(recon_x, x)\n",
    "    edge_recon_loss = F.mse_loss(recon_edge_attr, edge_attr)\n",
    "\n",
    "    return node_recon_loss + edge_recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Fixed hyperparameter\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import optuna\n",
    "import multiprocessing\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from torch.utils.data import random_split\n",
    "import optuna.visualization as vis\n",
    "import plotly.graph_objects as go\n",
    "from multiprocessing import cpu_count\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune with specified ranges\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512, step=64)\n",
    "    latent_dim = trial.suggest_int(\"latent_dim\", 32, 128, step=32)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10)\n",
    "    \n",
    "    # Fixed hyperparameter\n",
    "    epochs = 60\n",
    "    print(f\"\\n[Trial {trial.number}] Starting with parameters: {trial.params}\")\n",
    "    # Split dataset\n",
    "    train_ratio = 0.8\n",
    "    num_train = int(len(pyg_dataset) * train_ratio)\n",
    "    num_valid = len(pyg_dataset) - num_train\n",
    "    train_dataset, valid_dataset = random_split(pyg_dataset, [num_train, num_valid])\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = PyGDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = PyGDataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Autoencoder(node_features, edge_features, hidden_dim, latent_dim)\n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Optimizer and Scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=False)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x = batch.x.to(device)\n",
    "            edge_index = batch.edge_index.to(device)\n",
    "            edge_attr = batch.edge_attr.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            recon_x, recon_edge_attr = model(x, edge_index, edge_attr)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_function(recon_x, x, recon_edge_attr, edge_attr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        avg_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                x_val = val_batch.x.to(device)\n",
    "                edge_index_val = val_batch.edge_index.to(device)\n",
    "                edge_attr_val = val_batch.edge_attr.to(device)\n",
    "                \n",
    "                recon_x_val, recon_edge_attr_val = model(x_val, edge_index_val, edge_attr_val)\n",
    "                val_loss += loss_function(recon_x_val, x_val, recon_edge_attr_val, edge_attr_val).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Print detailed trial information\n",
    "        print(f\"[Trial {trial.number}] Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"[Trial {trial.number}] Early stopping after {epoch + 1} epochs.\")\n",
    "            break\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "def run_hyperparameter_tuning():\n",
    "\n",
    "    num_jobs = min(multiprocessing.cpu_count()-1, 7)  # Use up to 4 cores\n",
    "\n",
    "    \n",
    "    \n",
    "    # Create a study object \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    # Run optimization\n",
    "    study.optimize(objective, n_trials=200, n_jobs=num_jobs)\n",
    "    \n",
    "    # Print best trial details\n",
    "    best_trial = study.best_trial\n",
    "    print(\"\\nBest Trial Details:\")\n",
    "    print(f\"Best Trial Number: {best_trial.number}\")\n",
    "    print(\"Best Parameters:\", best_trial.params)\n",
    "    print(\"Best Value (Objective):\", best_trial.value)\n",
    "    \n",
    "    # Save best hyperparameters\n",
    "    with open('best_hyperparameters.json', 'w') as f:\n",
    "        json.dump(best_trial.params, f, indent=4)\n",
    "    \n",
    "    return study, best_trial\n",
    "study, best_trial = run_hyperparameter_tuning()\n",
    "\n",
    "# Optional: Visualization (requires plotly)\n",
    "try:\n",
    "    import optuna.visualization as vis\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    # Parallel Coordinate Plot\n",
    "    fig = vis.plot_parallel_coordinate(study)\n",
    "    fig.show()\n",
    "    \n",
    "    # Contour Plot\n",
    "    fig = vis.plot_contour(study)\n",
    "    fig.show()\n",
    "    \n",
    "    # Optimization History Plot\n",
    "    fig = vis.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "except ImportError:\n",
    "    print(\"Plotly or optuna visualization not available. Skipping visualization.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
