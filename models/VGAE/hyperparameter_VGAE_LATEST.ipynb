{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "class DeepChemToPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        \"\"\"\n",
    "        Converts a list of PyG `Data` objects into an InMemoryDataset.\n",
    "        \n",
    "        Args:\n",
    "            data_list (list of Data): List of PyG Data objects.\n",
    "            transform (callable, optional): Optional transform applied to each data object.\n",
    "        \"\"\"\n",
    "        super(DeepChemToPyGDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data object at the specified index.\n",
    "        \"\"\"\n",
    "        return super().get(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_15888\\3827785572.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load('../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "pyg_dataset = torch.load('../../data/curated dataset/cleaned_frag_pyg_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = pyg_dataset[0].x.shape[1]  # Should be 134 based on your description\n",
    "edge_features = pyg_dataset[0].edge_attr.shape[1]  # Should be 6 based on your description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import SAGEConv, GINConv, GATConv\n",
    "\n",
    "class VGAE(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(VGAE, self).__init__()\n",
    "        self.encoder = VGEncoder(node_features, edge_features, hidden_dim, latent_dim)\n",
    "        self.decoder = VGDecoder(latent_dim, hidden_dim, node_features, edge_features)\n",
    "\n",
    "    def encode(self, x, edge_index, edge_attr):\n",
    "        return self.encoder(x, edge_index, edge_attr)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * torch.clamp(logvar, -10, 10))\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        mu, logvar = self.encoder(x, edge_index, edge_attr)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed_x, reconstructed_edge_attr = self.decoder(z, edge_index)\n",
    "        return reconstructed_x, reconstructed_edge_attr, mu, logvar\n",
    "\n",
    "    def generate_multiple_outputs(self, x, edge_index, edge_attr, variator, num_samples=5):\n",
    "        outputs = []\n",
    "        with torch.no_grad():\n",
    "            z, _ = self.encoder(x, edge_index, edge_attr)\n",
    "            for _ in range(num_samples):\n",
    "                mixed_noise = torch.randn_like(z) * variator\n",
    "                z_noisy = z + mixed_noise\n",
    "                outputs.append((*self.decoder(z_noisy, edge_index), edge_index))\n",
    "        return outputs\n",
    "\n",
    "class VGEncoder(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(VGEncoder, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = GINConv(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(node_features + edge_features, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = GINConv(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Variational layers\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Combine node and edge features\n",
    "        edge_attr_expanded = torch.zeros((x.size(0), edge_attr.size(1))).to(x.device)\n",
    "        edge_attr_expanded[edge_index[0]] = edge_attr\n",
    "        x = torch.cat([x, edge_attr_expanded], dim=1)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return self.fc_mu(x), self.fc_logvar(x)\n",
    "\n",
    "class VGDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, node_features, edge_features):\n",
    "        super(VGDecoder, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(latent_dim, hidden_dim)\n",
    "        \n",
    "        self.node_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, node_features)\n",
    "        )\n",
    "        \n",
    "        self.edge_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, edge_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        h = F.leaky_relu(self.fc(z), 0.2)\n",
    "        row, col = edge_index\n",
    "        edge_h = torch.cat([h[row], h[col]], dim=1)\n",
    "        return self.node_decoder(h), self.edge_decoder(edge_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, recon_edge_attr, edge_attr, mu, logvar):\n",
    "    # Reconstruction losses\n",
    "    node_recon_loss = F.mse_loss(recon_x, x)\n",
    "    edge_recon_loss = F.mse_loss(recon_edge_attr, edge_attr)\n",
    "\n",
    "    # KL divergence\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return node_recon_loss + edge_recon_loss + kl_divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-01-06 01:19:12,930] A new study created in memory with name: no-name-97390be0-3d5d-447f-a8a0-03d201be3dd3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 7] Epoch 1/60, Training Loss: 33.1071, Validation Loss: 14.2785\n",
      "[Trial 13] Epoch 1/60, Training Loss: 7.2208, Validation Loss: 2.8039\n",
      "[Trial 15] Epoch 1/60, Training Loss: 13.0652, Validation Loss: 3.6644\n",
      "[Trial 10] Epoch 1/60, Training Loss: 26.9631, Validation Loss: 9.8618\n",
      "[Trial 3] Epoch 1/60, Training Loss: 9.3004, Validation Loss: 2.9619\n",
      "[Trial 14] Epoch 1/60, Training Loss: 5.1470, Validation Loss: 1.8761\n",
      "[Trial 1] Epoch 1/60, Training Loss: 12634.7619, Validation Loss: 13.1371\n",
      "[Trial 11] Epoch 1/60, Training Loss: 17.3311, Validation Loss: 5.4767\n",
      "[Trial 2] Epoch 1/60, Training Loss: 4321.6092, Validation Loss: 7.7899\n",
      "[Trial 7] Epoch 2/60, Training Loss: 25.3690, Validation Loss: 12.4665\n",
      "[Trial 13] Epoch 2/60, Training Loss: 2.4619, Validation Loss: 2.2166\n",
      "[Trial 15] Epoch 2/60, Training Loss: 4.2538, Validation Loss: 2.6850\n",
      "[Trial 0] Epoch 1/60, Training Loss: 6.8310, Validation Loss: 2.3344\n",
      "[Trial 10] Epoch 2/60, Training Loss: 13.9464, Validation Loss: 7.1698\n",
      "[Trial 7] Epoch 3/60, Training Loss: 19.6477, Validation Loss: 10.7011\n",
      "[Trial 12] Epoch 1/60, Training Loss: 23.1603, Validation Loss: 8.5245\n",
      "[Trial 6] Epoch 1/60, Training Loss: 6.8743, Validation Loss: 2.6991\n",
      "[Trial 4] Epoch 1/60, Training Loss: 5.4134, Validation Loss: 3.6449\n",
      "[Trial 14] Epoch 2/60, Training Loss: 2.0074, Validation Loss: 1.2909\n",
      "[Trial 3] Epoch 2/60, Training Loss: 3.1989, Validation Loss: 2.2949\n",
      "[Trial 13] Epoch 3/60, Training Loss: 2.0758, Validation Loss: 1.8576\n",
      "[Trial 15] Epoch 3/60, Training Loss: 3.2825, Validation Loss: 2.2250\n",
      "[Trial 11] Epoch 2/60, Training Loss: 5.9294, Validation Loss: 3.3720\n",
      "[Trial 1] Epoch 2/60, Training Loss: 10.3948, Validation Loss: 8.5329\n",
      "[Trial 7] Epoch 4/60, Training Loss: 15.3623, Validation Loss: 9.2081\n",
      "[Trial 2] Epoch 2/60, Training Loss: 6.2482, Validation Loss: 4.6555\n",
      "[Trial 10] Epoch 3/60, Training Loss: 8.9527, Validation Loss: 5.3531\n",
      "[Trial 7] Epoch 5/60, Training Loss: 12.2884, Validation Loss: 7.7833\n",
      "[Trial 13] Epoch 4/60, Training Loss: 1.8594, Validation Loss: 1.6553\n",
      "[Trial 15] Epoch 4/60, Training Loss: 2.8007, Validation Loss: 2.0719\n",
      "[Trial 14] Epoch 3/60, Training Loss: 1.5497, Validation Loss: 1.1617\n",
      "[Trial 3] Epoch 3/60, Training Loss: 2.6965, Validation Loss: 1.9502\n",
      "[Trial 0] Epoch 2/60, Training Loss: 2.5595, Validation Loss: 1.7535\n",
      "[Trial 9] Epoch 1/60, Training Loss: 19.9921, Validation Loss: 3.4346\n",
      "[Trial 10] Epoch 4/60, Training Loss: 6.8768, Validation Loss: 4.4303\n",
      "[Trial 11] Epoch 3/60, Training Loss: 4.3566, Validation Loss: 2.8264\n",
      "[Trial 1] Epoch 3/60, Training Loss: 8.2233, Validation Loss: 9.1285\n",
      "[Trial 5] Epoch 1/60, Training Loss: 1710282.8385, Validation Loss: 166.3056\n",
      "[Trial 7] Epoch 6/60, Training Loss: 10.2187, Validation Loss: 7.0240\n",
      "[Trial 2] Epoch 3/60, Training Loss: 4.5839, Validation Loss: 3.5959\n",
      "[Trial 12] Epoch 2/60, Training Loss: 8.5683, Validation Loss: 5.3273\n",
      "[Trial 8] Epoch 1/60, Training Loss: 292337.6374, Validation Loss: 29.1660\n",
      "[Trial 13] Epoch 5/60, Training Loss: 1.7745, Validation Loss: 1.4212\n",
      "[Trial 15] Epoch 5/60, Training Loss: 2.4855, Validation Loss: 1.9446\n",
      "[Trial 6] Epoch 2/60, Training Loss: 2.5338, Validation Loss: 1.6391\n",
      "[Trial 4] Epoch 2/60, Training Loss: 2.3354, Validation Loss: 1.8273\n",
      "[Trial 10] Epoch 5/60, Training Loss: 5.8199, Validation Loss: 3.8430\n",
      "[Trial 14] Epoch 4/60, Training Loss: 1.2203, Validation Loss: 0.9950\n",
      "[Trial 3] Epoch 4/60, Training Loss: 2.4306, Validation Loss: 1.8020\n",
      "[Trial 7] Epoch 7/60, Training Loss: 8.7953, Validation Loss: 6.0891\n",
      "[Trial 13] Epoch 6/60, Training Loss: 1.6871, Validation Loss: 1.2371\n",
      "[Trial 15] Epoch 6/60, Training Loss: 2.2758, Validation Loss: 1.8267\n",
      "[Trial 11] Epoch 4/60, Training Loss: 3.7240, Validation Loss: 2.4735\n",
      "[Trial 1] Epoch 4/60, Training Loss: 7.0977, Validation Loss: 6.3794\n",
      "[Trial 0] Epoch 3/60, Training Loss: 2.1740, Validation Loss: 1.4443\n",
      "[Trial 7] Epoch 8/60, Training Loss: 7.7867, Validation Loss: 5.5256\n",
      "[Trial 2] Epoch 4/60, Training Loss: 3.9584, Validation Loss: 3.3239\n",
      "[Trial 10] Epoch 6/60, Training Loss: 5.1504, Validation Loss: 3.4784\n",
      "[Trial 14] Epoch 5/60, Training Loss: 1.1237, Validation Loss: 0.8312\n",
      "[Trial 3] Epoch 5/60, Training Loss: 2.2510, Validation Loss: 1.5644\n",
      "[Trial 13] Epoch 7/60, Training Loss: 1.5928, Validation Loss: 1.2767\n",
      "[Trial 7] Epoch 9/60, Training Loss: 6.9718, Validation Loss: 5.1413\n",
      "[Trial 15] Epoch 7/60, Training Loss: 2.1468, Validation Loss: 1.8039\n",
      "[Trial 12] Epoch 3/60, Training Loss: 5.7062, Validation Loss: 3.9876\n",
      "[Trial 10] Epoch 7/60, Training Loss: 4.6897, Validation Loss: 3.2753\n",
      "[Trial 11] Epoch 5/60, Training Loss: 3.2952, Validation Loss: 2.2250\n",
      "[Trial 6] Epoch 3/60, Training Loss: 2.1441, Validation Loss: 1.9258\n",
      "[Trial 1] Epoch 5/60, Training Loss: 6.3206, Validation Loss: 5.8895\n",
      "[Trial 2] Epoch 5/60, Training Loss: 3.5491, Validation Loss: 3.1074\n",
      "[Trial 7] Epoch 10/60, Training Loss: 6.3597, Validation Loss: 4.7494\n",
      "[Trial 4] Epoch 3/60, Training Loss: 1.7482, Validation Loss: 1.7830\n",
      "[Trial 13] Epoch 8/60, Training Loss: 1.4860, Validation Loss: 1.2731\n",
      "[Trial 14] Epoch 6/60, Training Loss: 1.0388, Validation Loss: 0.8053\n",
      "[Trial 3] Epoch 6/60, Training Loss: 2.0874, Validation Loss: 1.4764\n",
      "[Trial 15] Epoch 8/60, Training Loss: 2.0575, Validation Loss: 1.6483\n",
      "[Trial 0] Epoch 4/60, Training Loss: 1.9955, Validation Loss: 1.3974\n",
      "[Trial 9] Epoch 2/60, Training Loss: 3.6116, Validation Loss: 3.2911\n",
      "[Trial 10] Epoch 8/60, Training Loss: 4.3008, Validation Loss: 2.9858\n",
      "[Trial 7] Epoch 11/60, Training Loss: 5.8367, Validation Loss: 4.3084\n",
      "[Trial 13] Epoch 9/60, Training Loss: 1.3903, Validation Loss: 1.0617\n",
      "[Trial 11] Epoch 6/60, Training Loss: 2.9834, Validation Loss: 2.1146\n",
      "[Trial 15] Epoch 9/60, Training Loss: 1.9560, Validation Loss: 1.6248\n",
      "[Trial 1] Epoch 6/60, Training Loss: 6.9871, Validation Loss: 7.4610\n",
      "[Trial 5] Epoch 2/60, Training Loss: 322.2088, Validation Loss: 54.8349\n",
      "[Trial 14] Epoch 7/60, Training Loss: 0.9526, Validation Loss: 0.7809\n",
      "[Trial 3] Epoch 7/60, Training Loss: 2.0017, Validation Loss: 1.4131\n",
      "[Trial 2] Epoch 6/60, Training Loss: 3.3336, Validation Loss: 3.0224\n",
      "[Trial 7] Epoch 12/60, Training Loss: 5.4206, Validation Loss: 4.0618\n",
      "[Trial 10] Epoch 9/60, Training Loss: 4.0075, Validation Loss: 2.8417\n",
      "[Trial 8] Epoch 2/60, Training Loss: 19.6665, Validation Loss: 19.1731\n",
      "[Trial 12] Epoch 4/60, Training Loss: 4.8136, Validation Loss: 3.4704\n",
      "[Trial 13] Epoch 10/60, Training Loss: 1.2863, Validation Loss: 1.0483\n",
      "[Trial 15] Epoch 10/60, Training Loss: 1.8969, Validation Loss: 1.5178\n",
      "[Trial 7] Epoch 13/60, Training Loss: 5.1129, Validation Loss: 3.9443\n",
      "[Trial 6] Epoch 4/60, Training Loss: 1.7317, Validation Loss: 1.1400\n",
      "[Trial 0] Epoch 5/60, Training Loss: 1.8693, Validation Loss: 1.3039\n",
      "[Trial 4] Epoch 4/60, Training Loss: 1.3991, Validation Loss: 1.0907\n",
      "[Trial 11] Epoch 7/60, Training Loss: 2.7407, Validation Loss: 1.9980\n",
      "[Trial 10] Epoch 10/60, Training Loss: 3.7634, Validation Loss: 2.6730\n",
      "[Trial 1] Epoch 7/60, Training Loss: 7.1958, Validation Loss: 6.8337\n",
      "[Trial 3] Epoch 8/60, Training Loss: 1.9018, Validation Loss: 1.3893\n",
      "[Trial 14] Epoch 8/60, Training Loss: 0.9220, Validation Loss: 0.7461\n",
      "[Trial 13] Epoch 11/60, Training Loss: 1.1934, Validation Loss: 0.9899\n",
      "[Trial 2] Epoch 7/60, Training Loss: 3.0621, Validation Loss: 2.6837\n",
      "[Trial 7] Epoch 14/60, Training Loss: 4.8316, Validation Loss: 3.7948\n",
      "[Trial 15] Epoch 11/60, Training Loss: 1.8514, Validation Loss: 1.5421\n",
      "[Trial 10] Epoch 11/60, Training Loss: 3.5502, Validation Loss: 2.5873\n",
      "[Trial 7] Epoch 15/60, Training Loss: 4.6076, Validation Loss: 3.4515\n",
      "[Trial 13] Epoch 12/60, Training Loss: 1.1580, Validation Loss: 1.0428\n",
      "[Trial 11] Epoch 8/60, Training Loss: 2.5745, Validation Loss: 1.8930\n",
      "[Trial 3] Epoch 9/60, Training Loss: 1.8673, Validation Loss: 1.3492\n",
      "[Trial 15] Epoch 12/60, Training Loss: 1.8059, Validation Loss: 1.5343\n",
      "[Trial 14] Epoch 9/60, Training Loss: 0.9058, Validation Loss: 0.7178\n",
      "[Trial 1] Epoch 8/60, Training Loss: 5.6431, Validation Loss: 5.4577\n",
      "[Trial 12] Epoch 5/60, Training Loss: 4.2165, Validation Loss: 2.9497\n",
      "[Trial 0] Epoch 6/60, Training Loss: 1.8000, Validation Loss: 1.1991\n",
      "[Trial 2] Epoch 8/60, Training Loss: 2.8083, Validation Loss: 2.2506\n",
      "[Trial 7] Epoch 16/60, Training Loss: 4.4251, Validation Loss: 3.3469\n",
      "[Trial 9] Epoch 3/60, Training Loss: 3.2769, Validation Loss: 2.8618\n",
      "[Trial 10] Epoch 12/60, Training Loss: 3.3770, Validation Loss: 2.5163\n",
      "[Trial 6] Epoch 5/60, Training Loss: 1.4871, Validation Loss: 1.1724\n",
      "[Trial 13] Epoch 13/60, Training Loss: 1.1103, Validation Loss: 1.0394\n",
      "[Trial 15] Epoch 13/60, Training Loss: 1.7606, Validation Loss: 1.3991\n",
      "[Trial 4] Epoch 5/60, Training Loss: 1.1750, Validation Loss: 2.2193\n",
      "[Trial 7] Epoch 17/60, Training Loss: 4.2526, Validation Loss: 3.3097\n",
      "[Trial 3] Epoch 10/60, Training Loss: 1.8344, Validation Loss: 1.3848\n",
      "[Trial 14] Epoch 10/60, Training Loss: 0.8651, Validation Loss: 0.7319\n",
      "[Trial 11] Epoch 9/60, Training Loss: 2.4139, Validation Loss: 1.8646\n",
      "[Trial 1] Epoch 9/60, Training Loss: 5.0338, Validation Loss: 4.9263\n",
      "[Trial 10] Epoch 13/60, Training Loss: 3.2197, Validation Loss: 2.4606\n",
      "[Trial 13] Epoch 14/60, Training Loss: 1.0613, Validation Loss: 0.8410\n",
      "[Trial 2] Epoch 9/60, Training Loss: 2.6706, Validation Loss: 2.4472\n",
      "[Trial 5] Epoch 3/60, Training Loss: 80.9209, Validation Loss: 72.0695\n",
      "[Trial 15] Epoch 14/60, Training Loss: 1.7295, Validation Loss: 1.3901\n",
      "[Trial 7] Epoch 18/60, Training Loss: 4.1339, Validation Loss: 3.1586\n",
      "[Trial 0] Epoch 7/60, Training Loss: 1.7194, Validation Loss: 1.1393\n",
      "[Trial 3] Epoch 11/60, Training Loss: 1.7699, Validation Loss: 1.2538\n",
      "[Trial 8] Epoch 3/60, Training Loss: 312829.0650, Validation Loss: 24.0620\n",
      "[Trial 12] Epoch 6/60, Training Loss: 3.8073, Validation Loss: 2.6366\n",
      "[Trial 14] Epoch 11/60, Training Loss: 0.8475, Validation Loss: 0.6951\n",
      "[Trial 10] Epoch 14/60, Training Loss: 3.1074, Validation Loss: 2.4057\n",
      "[Trial 7] Epoch 19/60, Training Loss: 4.0029, Validation Loss: 3.0529\n",
      "[Trial 13] Epoch 15/60, Training Loss: 1.0001, Validation Loss: 0.8734\n",
      "[Trial 11] Epoch 10/60, Training Loss: 2.3189, Validation Loss: 1.7584\n",
      "[Trial 15] Epoch 15/60, Training Loss: 1.6996, Validation Loss: 1.2980\n",
      "[Trial 1] Epoch 10/60, Training Loss: 4.6178, Validation Loss: 4.1610\n",
      "[Trial 6] Epoch 6/60, Training Loss: 1.2056, Validation Loss: 0.9119\n",
      "[Trial 2] Epoch 10/60, Training Loss: 2.5107, Validation Loss: 2.0651\n",
      "[Trial 7] Epoch 20/60, Training Loss: 3.8790, Validation Loss: 2.9795\n",
      "[Trial 4] Epoch 6/60, Training Loss: 1.1486, Validation Loss: 3.0145\n",
      "[Trial 13] Epoch 16/60, Training Loss: 0.9728, Validation Loss: 0.7879\n",
      "[Trial 10] Epoch 15/60, Training Loss: 2.9949, Validation Loss: 2.3923\n",
      "[Trial 3] Epoch 12/60, Training Loss: 1.7187, Validation Loss: 1.2920\n",
      "[Trial 15] Epoch 16/60, Training Loss: 1.6727, Validation Loss: 1.2862\n",
      "[Trial 14] Epoch 12/60, Training Loss: 0.8360, Validation Loss: 0.6941\n",
      "[Trial 11] Epoch 11/60, Training Loss: 2.2258, Validation Loss: 1.7720\n",
      "[Trial 7] Epoch 21/60, Training Loss: 3.7846, Validation Loss: 2.9486\n",
      "[Trial 0] Epoch 8/60, Training Loss: 1.6627, Validation Loss: 1.1153\n",
      "[Trial 1] Epoch 11/60, Training Loss: 4.3385, Validation Loss: 4.1724\n",
      "[Trial 9] Epoch 4/60, Training Loss: 2.9833, Validation Loss: 2.0387\n",
      "[Trial 13] Epoch 17/60, Training Loss: 0.9351, Validation Loss: 0.8049\n",
      "[Trial 10] Epoch 16/60, Training Loss: 2.8887, Validation Loss: 2.3988\n",
      "[Trial 2] Epoch 11/60, Training Loss: 2.5644, Validation Loss: 2.1589\n",
      "[Trial 15] Epoch 17/60, Training Loss: 1.6457, Validation Loss: 1.2709\n",
      "[Trial 12] Epoch 7/60, Training Loss: 3.4999, Validation Loss: 2.4664\n",
      "[Trial 3] Epoch 13/60, Training Loss: 1.6697, Validation Loss: 1.2182\n",
      "[Trial 7] Epoch 22/60, Training Loss: 3.6755, Validation Loss: 2.8478\n",
      "[Trial 14] Epoch 13/60, Training Loss: 0.8379, Validation Loss: 0.7719\n",
      "[Trial 11] Epoch 12/60, Training Loss: 2.1447, Validation Loss: 1.6652\n",
      "[Trial 6] Epoch 7/60, Training Loss: 1.0559, Validation Loss: 0.9618\n",
      "[Trial 13] Epoch 18/60, Training Loss: 0.9078, Validation Loss: 0.7711\n",
      "[Trial 10] Epoch 17/60, Training Loss: 2.7931, Validation Loss: 2.3325\n",
      "[Trial 7] Epoch 23/60, Training Loss: 3.6069, Validation Loss: 2.7668\n",
      "[Trial 15] Epoch 18/60, Training Loss: 1.6247, Validation Loss: 1.2129\n",
      "[Trial 1] Epoch 12/60, Training Loss: 5.2833, Validation Loss: 7.1810\n",
      "[Trial 4] Epoch 7/60, Training Loss: 1.0773, Validation Loss: 0.7675\n",
      "[Trial 2] Epoch 12/60, Training Loss: 2.4717, Validation Loss: 2.1093\n",
      "[Trial 0] Epoch 9/60, Training Loss: 1.6165, Validation Loss: 1.0881\n",
      "[Trial 5] Epoch 4/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 3] Epoch 14/60, Training Loss: 1.6490, Validation Loss: 1.1367\n",
      "[Trial 14] Epoch 14/60, Training Loss: 0.7894, Validation Loss: 0.7230\n",
      "[Trial 7] Epoch 24/60, Training Loss: 3.5163, Validation Loss: 2.7286\n",
      "[Trial 13] Epoch 19/60, Training Loss: 0.8936, Validation Loss: 0.7469\n",
      "[Trial 15] Epoch 19/60, Training Loss: 1.6047, Validation Loss: 1.1727\n",
      "[Trial 10] Epoch 18/60, Training Loss: 2.7186, Validation Loss: 2.3071\n",
      "[Trial 11] Epoch 13/60, Training Loss: 2.0753, Validation Loss: 1.5892\n",
      "[Trial 8] Epoch 4/60, Training Loss: 71.9974, Validation Loss: 14.4015\n",
      "[Trial 12] Epoch 8/60, Training Loss: 3.2260, Validation Loss: 2.4104\n",
      "[Trial 7] Epoch 25/60, Training Loss: 3.4612, Validation Loss: 2.6826\n",
      "[Trial 1] Epoch 13/60, Training Loss: 4.3235, Validation Loss: 3.3886\n",
      "[Trial 13] Epoch 20/60, Training Loss: 0.8614, Validation Loss: 0.7540\n",
      "[Trial 3] Epoch 15/60, Training Loss: 1.6165, Validation Loss: 1.1408\n",
      "[Trial 14] Epoch 15/60, Training Loss: 0.7944, Validation Loss: 0.6843\n",
      "[Trial 2] Epoch 13/60, Training Loss: 2.4192, Validation Loss: 1.7794\n",
      "[Trial 15] Epoch 20/60, Training Loss: 1.5735, Validation Loss: 1.2093\n",
      "[Trial 10] Epoch 19/60, Training Loss: 2.6425, Validation Loss: 2.3491\n",
      "[Trial 6] Epoch 8/60, Training Loss: 1.0137, Validation Loss: 0.8564\n",
      "[Trial 7] Epoch 26/60, Training Loss: 3.3851, Validation Loss: 2.6025\n",
      "[Trial 0] Epoch 10/60, Training Loss: 1.5456, Validation Loss: 1.0176\n",
      "[Trial 11] Epoch 14/60, Training Loss: 2.0388, Validation Loss: 1.5481\n",
      "[Trial 13] Epoch 21/60, Training Loss: 0.8469, Validation Loss: 0.7175\n",
      "[Trial 4] Epoch 8/60, Training Loss: 0.9398, Validation Loss: 1.0184\n",
      "[Trial 9] Epoch 5/60, Training Loss: 2.6873, Validation Loss: 2.4102\n",
      "[Trial 15] Epoch 21/60, Training Loss: 1.5497, Validation Loss: 1.1839\n",
      "[Trial 7] Epoch 27/60, Training Loss: 3.3216, Validation Loss: 2.5515\n",
      "[Trial 3] Epoch 16/60, Training Loss: 1.5532, Validation Loss: 1.0889\n",
      "[Trial 1] Epoch 14/60, Training Loss: 13027.3238, Validation Loss: 300.1361\n",
      "[Trial 10] Epoch 20/60, Training Loss: 2.5618, Validation Loss: 2.3026\n",
      "[Trial 14] Epoch 16/60, Training Loss: 0.7649, Validation Loss: 0.6393\n",
      "[Trial 2] Epoch 14/60, Training Loss: 2.2044, Validation Loss: 1.7778\n",
      "[Trial 13] Epoch 22/60, Training Loss: 0.8425, Validation Loss: 0.6579\n",
      "[Trial 7] Epoch 28/60, Training Loss: 3.2473, Validation Loss: 2.5066\n",
      "[Trial 12] Epoch 9/60, Training Loss: 3.0285, Validation Loss: 2.2608\n",
      "[Trial 15] Epoch 22/60, Training Loss: 1.5395, Validation Loss: 1.1645\n",
      "[Trial 11] Epoch 15/60, Training Loss: 1.9899, Validation Loss: 1.5045\n",
      "[Trial 10] Epoch 21/60, Training Loss: 2.5164, Validation Loss: 2.2811\n",
      "[Trial 3] Epoch 17/60, Training Loss: 1.4724, Validation Loss: 1.0491\n",
      "[Trial 0] Epoch 11/60, Training Loss: 1.4580, Validation Loss: 0.9794\n",
      "[Trial 14] Epoch 17/60, Training Loss: 0.7513, Validation Loss: 0.6134\n",
      "[Trial 1] Epoch 15/60, Training Loss: 63502.9375, Validation Loss: 617.9113\n",
      "[Trial 7] Epoch 29/60, Training Loss: 3.1884, Validation Loss: 2.4524\n",
      "[Trial 13] Epoch 23/60, Training Loss: 0.8254, Validation Loss: 0.6862\n",
      "[Trial 6] Epoch 9/60, Training Loss: 0.9546, Validation Loss: 0.7297\n",
      "[Trial 15] Epoch 23/60, Training Loss: 1.5216, Validation Loss: 1.1193\n",
      "[Trial 2] Epoch 15/60, Training Loss: 2.1477, Validation Loss: 1.5666\n",
      "[Trial 5] Epoch 5/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 10] Epoch 22/60, Training Loss: 2.4411, Validation Loss: 2.2632\n",
      "[Trial 4] Epoch 9/60, Training Loss: 0.9323, Validation Loss: 0.7219\n",
      "[Trial 7] Epoch 30/60, Training Loss: 3.1261, Validation Loss: 2.4024\n",
      "[Trial 11] Epoch 16/60, Training Loss: 1.9394, Validation Loss: 1.4529\n",
      "[Trial 3] Epoch 18/60, Training Loss: 1.4222, Validation Loss: 1.0120\n",
      "[Trial 13] Epoch 24/60, Training Loss: 0.8235, Validation Loss: 0.7410\n",
      "[Trial 14] Epoch 18/60, Training Loss: 0.7784, Validation Loss: 0.6871\n",
      "[Trial 15] Epoch 24/60, Training Loss: 1.4997, Validation Loss: 1.1897\n",
      "[Trial 1] Epoch 16/60, Training Loss: 962.7733, Validation Loss: 653.3845\n",
      "[Trial 8] Epoch 5/60, Training Loss: 61.1125, Validation Loss: 19.9524\n",
      "[Trial 7] Epoch 31/60, Training Loss: 3.0708, Validation Loss: 2.3645\n",
      "[Trial 10] Epoch 23/60, Training Loss: 2.3844, Validation Loss: 2.2784\n",
      "[Trial 12] Epoch 10/60, Training Loss: 2.8711, Validation Loss: 2.1142\n",
      "[Trial 2] Epoch 16/60, Training Loss: 2.1301, Validation Loss: 1.9397\n",
      "[Trial 0] Epoch 12/60, Training Loss: 1.4212, Validation Loss: 0.9623\n",
      "[Trial 13] Epoch 25/60, Training Loss: 0.8125, Validation Loss: 0.6910\n",
      "[Trial 9] Epoch 6/60, Training Loss: 2.3285, Validation Loss: 1.9771\n",
      "[Trial 11] Epoch 17/60, Training Loss: 1.9108, Validation Loss: 1.4323\n",
      "[Trial 15] Epoch 25/60, Training Loss: 1.4969, Validation Loss: 1.1321\n",
      "[Trial 3] Epoch 19/60, Training Loss: 1.3671, Validation Loss: 0.9813\n",
      "[Trial 7] Epoch 32/60, Training Loss: 3.0190, Validation Loss: 2.3281\n",
      "[Trial 14] Epoch 19/60, Training Loss: 0.7812, Validation Loss: 0.6597\n",
      "[Trial 10] Epoch 24/60, Training Loss: 2.3284, Validation Loss: 2.2737\n",
      "[Trial 6] Epoch 10/60, Training Loss: 0.8962, Validation Loss: 0.8689\n",
      "[Trial 1] Epoch 17/60, Training Loss: 621.2188, Validation Loss: 598.3872\n",
      "[Trial 13] Epoch 26/60, Training Loss: 0.7824, Validation Loss: 0.6806\n",
      "[Trial 7] Epoch 33/60, Training Loss: 2.9625, Validation Loss: 2.2705\n",
      "[Trial 2] Epoch 17/60, Training Loss: 2.0975, Validation Loss: 1.7104\n",
      "[Trial 15] Epoch 26/60, Training Loss: 1.4778, Validation Loss: 1.1223\n",
      "[Trial 4] Epoch 10/60, Training Loss: 0.8883, Validation Loss: 1.1442\n",
      "[Trial 3] Epoch 20/60, Training Loss: 1.3032, Validation Loss: 1.0172\n",
      "[Trial 10] Epoch 25/60, Training Loss: 2.2956, Validation Loss: 2.2218\n",
      "[Trial 11] Epoch 18/60, Training Loss: 1.8725, Validation Loss: 1.4229\n",
      "[Trial 14] Epoch 20/60, Training Loss: 0.7424, Validation Loss: 0.6247\n",
      "[Trial 0] Epoch 13/60, Training Loss: 1.3442, Validation Loss: 0.9753\n",
      "[Trial 7] Epoch 34/60, Training Loss: 2.9346, Validation Loss: 2.2348\n",
      "[Trial 13] Epoch 27/60, Training Loss: 0.8026, Validation Loss: 0.6768\n",
      "[Trial 12] Epoch 11/60, Training Loss: 2.7100, Validation Loss: 2.0989\n",
      "[Trial 15] Epoch 27/60, Training Loss: 1.4555, Validation Loss: 1.0442\n",
      "[Trial 1] Epoch 18/60, Training Loss: 470117.1749, Validation Loss: 9391954.4733\n",
      "[Trial 10] Epoch 26/60, Training Loss: 2.2561, Validation Loss: 2.1919\n",
      "[Trial 7] Epoch 35/60, Training Loss: 2.8729, Validation Loss: 2.2069\n",
      "[Trial 2] Epoch 18/60, Training Loss: 2.2023, Validation Loss: 1.7334\n",
      "[Trial 3] Epoch 21/60, Training Loss: 1.2719, Validation Loss: 0.9304\n",
      "[Trial 13] Epoch 28/60, Training Loss: 0.7253, Validation Loss: 0.6275\n",
      "[Trial 5] Epoch 6/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 14] Epoch 21/60, Training Loss: 0.7272, Validation Loss: 0.6161\n",
      "[Trial 11] Epoch 19/60, Training Loss: 1.8401, Validation Loss: 1.3512\n",
      "[Trial 15] Epoch 28/60, Training Loss: 1.4279, Validation Loss: 1.0649\n",
      "[Trial 6] Epoch 11/60, Training Loss: 0.8597, Validation Loss: 0.8484\n",
      "[Trial 7] Epoch 36/60, Training Loss: 2.8453, Validation Loss: 2.1759\n",
      "[Trial 10] Epoch 27/60, Training Loss: 2.2132, Validation Loss: 2.2335\n",
      "[Trial 4] Epoch 11/60, Training Loss: 0.8841, Validation Loss: 0.8666\n",
      "[Trial 1] Epoch 19/60, Training Loss: 872.3571, Validation Loss: 2242.4902\n",
      "[Trial 0] Epoch 14/60, Training Loss: 1.2703, Validation Loss: 0.9127\n",
      "[Trial 13] Epoch 29/60, Training Loss: 0.7162, Validation Loss: 0.5971\n",
      "[Trial 15] Epoch 29/60, Training Loss: 1.4354, Validation Loss: 1.0551\n",
      "[Trial 3] Epoch 22/60, Training Loss: 1.2255, Validation Loss: 0.9112\n",
      "[Trial 7] Epoch 37/60, Training Loss: 2.7972, Validation Loss: 2.1359\n",
      "[Trial 2] Epoch 19/60, Training Loss: 2.1584, Validation Loss: 1.5880\n",
      "[Trial 8] Epoch 6/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 9] Epoch 7/60, Training Loss: 2.1052, Validation Loss: 1.6697\n",
      "[Trial 14] Epoch 22/60, Training Loss: 0.6654, Validation Loss: 0.5658\n",
      "[Trial 12] Epoch 12/60, Training Loss: 2.6043, Validation Loss: 2.0116\n",
      "[Trial 11] Epoch 20/60, Training Loss: 1.7991, Validation Loss: 1.3207\n",
      "[Trial 10] Epoch 28/60, Training Loss: 2.1933, Validation Loss: 2.1976\n",
      "[Trial 13] Epoch 30/60, Training Loss: 0.7043, Validation Loss: 0.6134\n",
      "[Trial 7] Epoch 38/60, Training Loss: 2.7429, Validation Loss: 2.0984\n",
      "[Trial 15] Epoch 30/60, Training Loss: 1.4161, Validation Loss: 1.0389\n",
      "[Trial 1] Epoch 20/60, Training Loss: 2043.2127, Validation Loss: 776.1019\n",
      "[Trial 3] Epoch 23/60, Training Loss: 1.1845, Validation Loss: 0.8937\n",
      "[Trial 6] Epoch 12/60, Training Loss: 0.8854, Validation Loss: 1.0547\n",
      "[Trial 14] Epoch 23/60, Training Loss: 0.6563, Validation Loss: 0.5487\n",
      "[Trial 2] Epoch 20/60, Training Loss: 1.6203, Validation Loss: 1.3379\n",
      "[Trial 7] Epoch 39/60, Training Loss: 2.7122, Validation Loss: 2.0550\n",
      "[Trial 10] Epoch 29/60, Training Loss: 2.1310, Validation Loss: 2.1970\n",
      "[Trial 13] Epoch 31/60, Training Loss: 0.7017, Validation Loss: 0.6161\n",
      "[Trial 0] Epoch 15/60, Training Loss: 1.2182, Validation Loss: 0.9488\n",
      "[Trial 11] Epoch 21/60, Training Loss: 1.7566, Validation Loss: 1.2878\n",
      "[Trial 15] Epoch 31/60, Training Loss: 1.4098, Validation Loss: 1.0621\n",
      "[Trial 4] Epoch 12/60, Training Loss: 0.8616, Validation Loss: 1.0126\n",
      "[Trial 7] Epoch 40/60, Training Loss: 2.6789, Validation Loss: 2.0333\n",
      "[Trial 10] Epoch 30/60, Training Loss: 2.1164, Validation Loss: 2.1267\n",
      "[Trial 12] Epoch 13/60, Training Loss: 2.4973, Validation Loss: 1.9682\n",
      "[Trial 3] Epoch 24/60, Training Loss: 1.1475, Validation Loss: 0.8660\n",
      "[Trial 13] Epoch 32/60, Training Loss: 0.7030, Validation Loss: 0.6002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:34:48,459] Trial 1 finished with value: 3.3885840733846027 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.03191582793146093, 'batch_size': 32, 'patience': 8}. Best is trial 1 with value: 3.3885840733846027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 1] Epoch 21/60, Training Loss: 734.2060, Validation Loss: 6972.2233\n",
      "[Trial 1] Early stopping after 21 epochs.\n",
      "[Trial 14] Epoch 24/60, Training Loss: 0.6666, Validation Loss: 0.5901\n",
      "[Trial 15] Epoch 32/60, Training Loss: 1.4089, Validation Loss: 1.0302\n",
      "[Trial 2] Epoch 21/60, Training Loss: 1.6166, Validation Loss: 1.2377\n",
      "[Trial 7] Epoch 41/60, Training Loss: 2.6198, Validation Loss: 1.9769\n",
      "[Trial 11] Epoch 22/60, Training Loss: 1.7635, Validation Loss: 1.2682\n",
      "[Trial 5] Epoch 7/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 16] Epoch 1/60, Training Loss: 1356360.7908, Validation Loss: 15.6516\n",
      "[Trial 10] Epoch 31/60, Training Loss: 2.1026, Validation Loss: 2.1605\n",
      "[Trial 13] Epoch 33/60, Training Loss: 0.6963, Validation Loss: 0.6178\n",
      "[Trial 0] Epoch 16/60, Training Loss: 1.1537, Validation Loss: 0.8258\n",
      "[Trial 7] Epoch 42/60, Training Loss: 2.5841, Validation Loss: 1.9594\n",
      "[Trial 15] Epoch 33/60, Training Loss: 1.3971, Validation Loss: 1.0197\n",
      "[Trial 3] Epoch 25/60, Training Loss: 1.1057, Validation Loss: 0.8222\n",
      "[Trial 6] Epoch 13/60, Training Loss: 0.9133, Validation Loss: 1.1557\n",
      "[Trial 14] Epoch 25/60, Training Loss: 0.6590, Validation Loss: 0.5560\n",
      "[Trial 9] Epoch 8/60, Training Loss: 1.9816, Validation Loss: 1.3810\n",
      "[Trial 16] Epoch 2/60, Training Loss: 13.2554, Validation Loss: 11.5142\n",
      "[Trial 2] Epoch 22/60, Training Loss: 1.5365, Validation Loss: 1.2769\n",
      "[Trial 13] Epoch 34/60, Training Loss: 0.6876, Validation Loss: 0.6149\n",
      "[Trial 7] Epoch 43/60, Training Loss: 2.5380, Validation Loss: 1.9371\n",
      "[Trial 10] Epoch 32/60, Training Loss: 2.0877, Validation Loss: 2.1145\n",
      "[Trial 4] Epoch 13/60, Training Loss: 0.7763, Validation Loss: 0.6492\n",
      "[Trial 8] Epoch 7/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 11] Epoch 23/60, Training Loss: 1.7257, Validation Loss: 1.2586\n",
      "[Trial 15] Epoch 34/60, Training Loss: 1.3864, Validation Loss: 1.0274\n",
      "[Trial 12] Epoch 14/60, Training Loss: 2.3999, Validation Loss: 1.9053\n",
      "[Trial 3] Epoch 26/60, Training Loss: 1.0773, Validation Loss: 0.7999\n",
      "[Trial 16] Epoch 3/60, Training Loss: 12.1293, Validation Loss: 11.3465\n",
      "[Trial 14] Epoch 26/60, Training Loss: 0.6518, Validation Loss: 0.5456\n",
      "[Trial 7] Epoch 44/60, Training Loss: 2.5147, Validation Loss: 1.8949\n",
      "[Trial 13] Epoch 35/60, Training Loss: 0.6727, Validation Loss: 0.5794\n",
      "[Trial 10] Epoch 33/60, Training Loss: 2.0819, Validation Loss: 2.0920\n",
      "[Trial 0] Epoch 17/60, Training Loss: 1.0915, Validation Loss: 0.7935\n",
      "[Trial 15] Epoch 35/60, Training Loss: 1.3795, Validation Loss: 1.0277\n",
      "[Trial 2] Epoch 23/60, Training Loss: 1.5644, Validation Loss: 1.2810\n",
      "[Trial 16] Epoch 4/60, Training Loss: 11.4025, Validation Loss: 11.3324\n",
      "[Trial 7] Epoch 45/60, Training Loss: 2.4968, Validation Loss: 1.8869\n",
      "[Trial 11] Epoch 24/60, Training Loss: 1.7197, Validation Loss: 1.2115\n",
      "[Trial 6] Epoch 14/60, Training Loss: 0.8868, Validation Loss: 0.7661\n",
      "[Trial 3] Epoch 27/60, Training Loss: 1.0431, Validation Loss: 0.7842\n",
      "[Trial 13] Epoch 36/60, Training Loss: 0.6691, Validation Loss: 0.5888\n",
      "[Trial 14] Epoch 27/60, Training Loss: 0.6461, Validation Loss: 0.5613\n",
      "[Trial 10] Epoch 34/60, Training Loss: 2.0496, Validation Loss: 2.1084\n",
      "[Trial 15] Epoch 36/60, Training Loss: 1.3756, Validation Loss: 1.0335\n",
      "[Trial 7] Epoch 46/60, Training Loss: 2.4655, Validation Loss: 1.8533\n",
      "[Trial 16] Epoch 5/60, Training Loss: 11.0317, Validation Loss: 11.6911\n",
      "[Trial 4] Epoch 14/60, Training Loss: 0.7388, Validation Loss: 0.6884\n",
      "[Trial 12] Epoch 15/60, Training Loss: 2.3324, Validation Loss: 1.8684\n",
      "[Trial 13] Epoch 37/60, Training Loss: 0.6712, Validation Loss: 0.5710\n",
      "[Trial 2] Epoch 24/60, Training Loss: 1.5466, Validation Loss: 1.2768\n",
      "[Trial 7] Epoch 47/60, Training Loss: 2.4278, Validation Loss: 1.8215\n",
      "[Trial 0] Epoch 18/60, Training Loss: 1.0488, Validation Loss: 0.7819\n",
      "[Trial 11] Epoch 25/60, Training Loss: 1.6892, Validation Loss: 1.2389\n",
      "[Trial 3] Epoch 28/60, Training Loss: 1.0150, Validation Loss: 0.7850\n",
      "[Trial 16] Epoch 6/60, Training Loss: 10.6550, Validation Loss: 9.5117\n",
      "[Trial 15] Epoch 37/60, Training Loss: 1.3626, Validation Loss: 1.0284\n",
      "[Trial 10] Epoch 35/60, Training Loss: 2.0474, Validation Loss: 2.0641\n",
      "[Trial 5] Epoch 8/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 14] Epoch 28/60, Training Loss: 0.6396, Validation Loss: 0.5833\n",
      "[Trial 9] Epoch 9/60, Training Loss: 1.7917, Validation Loss: 1.3808\n",
      "[Trial 7] Epoch 48/60, Training Loss: 2.3983, Validation Loss: 1.8166\n",
      "[Trial 13] Epoch 38/60, Training Loss: 0.6643, Validation Loss: 0.5717\n",
      "[Trial 16] Epoch 7/60, Training Loss: 9.9496, Validation Loss: 10.0942\n",
      "[Trial 15] Epoch 38/60, Training Loss: 1.3560, Validation Loss: 1.0032\n",
      "[Trial 6] Epoch 15/60, Training Loss: 0.7336, Validation Loss: 0.7265\n",
      "[Trial 10] Epoch 36/60, Training Loss: 2.0266, Validation Loss: 2.0297\n",
      "[Trial 3] Epoch 29/60, Training Loss: 0.9810, Validation Loss: 0.7523\n",
      "[Trial 2] Epoch 25/60, Training Loss: 1.4999, Validation Loss: 1.1597\n",
      "[Trial 7] Epoch 49/60, Training Loss: 2.3838, Validation Loss: 1.7737\n",
      "[Trial 14] Epoch 29/60, Training Loss: 0.6431, Validation Loss: 0.5480\n",
      "[Trial 11] Epoch 26/60, Training Loss: 1.6553, Validation Loss: 1.1911\n",
      "[Trial 13] Epoch 39/60, Training Loss: 0.6669, Validation Loss: 0.5736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:38:15,462] Trial 8 finished with value: 14.401457917690276 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.02570593674949771, 'batch_size': 8, 'patience': 4}. Best is trial 1 with value: 3.3885840733846027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 16] Epoch 8/60, Training Loss: 9.9797, Validation Loss: 9.4354\n",
      "[Trial 8] Epoch 8/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 8] Early stopping after 8 epochs.\n",
      "[Trial 12] Epoch 16/60, Training Loss: 2.2700, Validation Loss: 1.7643\n",
      "[Trial 0] Epoch 19/60, Training Loss: 1.0166, Validation Loss: 0.7569\n",
      "[Trial 15] Epoch 39/60, Training Loss: 1.3622, Validation Loss: 0.9861\n",
      "[Trial 4] Epoch 15/60, Training Loss: 0.7554, Validation Loss: 0.6592\n",
      "[Trial 10] Epoch 37/60, Training Loss: 2.0069, Validation Loss: 2.0239\n",
      "[Trial 7] Epoch 50/60, Training Loss: 2.3321, Validation Loss: 1.7455\n",
      "[Trial 3] Epoch 30/60, Training Loss: 0.9456, Validation Loss: 0.7227\n",
      "[Trial 16] Epoch 9/60, Training Loss: 9.1406, Validation Loss: 8.4219\n",
      "[Trial 13] Epoch 40/60, Training Loss: 0.6587, Validation Loss: 0.5795\n",
      "[Trial 14] Epoch 30/60, Training Loss: 0.6381, Validation Loss: 0.5126\n",
      "[Trial 2] Epoch 26/60, Training Loss: 1.5151, Validation Loss: 1.2881\n",
      "[Trial 11] Epoch 27/60, Training Loss: 1.6362, Validation Loss: 1.1812\n",
      "[Trial 15] Epoch 40/60, Training Loss: 1.3563, Validation Loss: 1.0011\n",
      "[Trial 7] Epoch 51/60, Training Loss: 2.3073, Validation Loss: 1.7382\n",
      "[Trial 17] Epoch 1/60, Training Loss: 15.9196, Validation Loss: 2.5752\n",
      "[Trial 10] Epoch 38/60, Training Loss: 1.9834, Validation Loss: 2.0190\n",
      "[Trial 16] Epoch 10/60, Training Loss: 8.7310, Validation Loss: 9.7345\n",
      "[Trial 6] Epoch 16/60, Training Loss: 0.7213, Validation Loss: 0.6862\n",
      "[Trial 13] Epoch 41/60, Training Loss: 0.6562, Validation Loss: 0.5729\n",
      "[Trial 7] Epoch 52/60, Training Loss: 2.2969, Validation Loss: 1.7115\n",
      "[Trial 3] Epoch 31/60, Training Loss: 0.9418, Validation Loss: 0.7388\n",
      "[Trial 15] Epoch 41/60, Training Loss: 1.3448, Validation Loss: 0.9825\n",
      "[Trial 0] Epoch 20/60, Training Loss: 0.9868, Validation Loss: 0.7532\n",
      "[Trial 14] Epoch 31/60, Training Loss: 0.6369, Validation Loss: 0.5697\n",
      "[Trial 10] Epoch 39/60, Training Loss: 1.9876, Validation Loss: 2.0351\n",
      "[Trial 16] Epoch 11/60, Training Loss: 8.4189, Validation Loss: 7.9775\n",
      "[Trial 12] Epoch 17/60, Training Loss: 2.2133, Validation Loss: 1.7443\n",
      "[Trial 2] Epoch 27/60, Training Loss: 1.4333, Validation Loss: 1.0908\n",
      "[Trial 11] Epoch 28/60, Training Loss: 1.6362, Validation Loss: 1.1796\n",
      "[Trial 7] Epoch 53/60, Training Loss: 2.2725, Validation Loss: 1.7024\n",
      "[Trial 4] Epoch 16/60, Training Loss: 0.7501, Validation Loss: 0.6642\n",
      "[Trial 17] Epoch 2/60, Training Loss: 2.4206, Validation Loss: 1.9418\n",
      "[Trial 13] Epoch 42/60, Training Loss: 0.6519, Validation Loss: 0.5738\n",
      "[Trial 5] Epoch 9/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 9] Epoch 10/60, Training Loss: 1.7421, Validation Loss: 1.5678\n",
      "[Trial 15] Epoch 42/60, Training Loss: 1.3422, Validation Loss: 1.0005\n",
      "[Trial 16] Epoch 12/60, Training Loss: 8.0477, Validation Loss: 7.8966\n",
      "[Trial 3] Epoch 32/60, Training Loss: 0.9213, Validation Loss: 0.7001\n",
      "[Trial 7] Epoch 54/60, Training Loss: 2.2550, Validation Loss: 1.6807\n",
      "[Trial 10] Epoch 40/60, Training Loss: 1.9626, Validation Loss: 1.9750\n",
      "[Trial 14] Epoch 32/60, Training Loss: 0.6541, Validation Loss: 0.5454\n",
      "[Trial 13] Epoch 43/60, Training Loss: 0.6427, Validation Loss: 0.5584\n",
      "[Trial 2] Epoch 28/60, Training Loss: 1.4704, Validation Loss: 1.0958\n",
      "[Trial 11] Epoch 29/60, Training Loss: 1.6169, Validation Loss: 1.1537\n",
      "[Trial 15] Epoch 43/60, Training Loss: 1.3276, Validation Loss: 0.9763\n",
      "[Trial 16] Epoch 13/60, Training Loss: 7.7953, Validation Loss: 7.7392\n",
      "[Trial 17] Epoch 3/60, Training Loss: 2.0018, Validation Loss: 1.4768\n",
      "[Trial 0] Epoch 21/60, Training Loss: 0.9563, Validation Loss: 0.7579\n",
      "[Trial 7] Epoch 55/60, Training Loss: 2.2111, Validation Loss: 1.6656\n",
      "[Trial 6] Epoch 17/60, Training Loss: 0.7025, Validation Loss: 0.6671\n",
      "[Trial 10] Epoch 41/60, Training Loss: 1.9688, Validation Loss: 1.9911\n",
      "[Trial 3] Epoch 33/60, Training Loss: 0.9027, Validation Loss: 0.7146\n",
      "[Trial 13] Epoch 44/60, Training Loss: 0.6430, Validation Loss: 0.5572\n",
      "[Trial 14] Epoch 33/60, Training Loss: 0.6543, Validation Loss: 0.5887\n",
      "[Trial 12] Epoch 18/60, Training Loss: 2.2028, Validation Loss: 1.7002\n",
      "[Trial 7] Epoch 56/60, Training Loss: 2.2166, Validation Loss: 1.6389\n",
      "[Trial 16] Epoch 14/60, Training Loss: 7.6286, Validation Loss: 7.0283\n",
      "[Trial 15] Epoch 44/60, Training Loss: 1.3411, Validation Loss: 0.9772\n",
      "[Trial 4] Epoch 17/60, Training Loss: 0.7099, Validation Loss: 0.6296\n",
      "[Trial 2] Epoch 29/60, Training Loss: 1.4112, Validation Loss: 1.0361\n",
      "[Trial 10] Epoch 42/60, Training Loss: 1.9563, Validation Loss: 1.9447\n",
      "[Trial 11] Epoch 30/60, Training Loss: 1.6070, Validation Loss: 1.1469\n",
      "[Trial 17] Epoch 4/60, Training Loss: 1.8013, Validation Loss: 1.3462\n",
      "[Trial 7] Epoch 57/60, Training Loss: 2.1774, Validation Loss: 1.6295\n",
      "[Trial 13] Epoch 45/60, Training Loss: 0.6313, Validation Loss: 0.5506\n",
      "[Trial 16] Epoch 15/60, Training Loss: 7.8592, Validation Loss: 8.5226\n",
      "[Trial 3] Epoch 34/60, Training Loss: 0.8781, Validation Loss: 0.7079\n",
      "[Trial 15] Epoch 45/60, Training Loss: 1.3288, Validation Loss: 0.9846\n",
      "[Trial 14] Epoch 34/60, Training Loss: 0.6379, Validation Loss: 0.5765\n",
      "[Trial 0] Epoch 22/60, Training Loss: 0.9375, Validation Loss: 0.7159\n",
      "[Trial 10] Epoch 43/60, Training Loss: 1.9373, Validation Loss: 1.9269\n",
      "[Trial 7] Epoch 58/60, Training Loss: 2.1623, Validation Loss: 1.6392\n",
      "[Trial 13] Epoch 46/60, Training Loss: 0.6370, Validation Loss: 0.5543\n",
      "[Trial 16] Epoch 16/60, Training Loss: 102.4321, Validation Loss: 4150.2977\n",
      "[Trial 6] Epoch 18/60, Training Loss: 0.7185, Validation Loss: 0.7033\n",
      "[Trial 9] Epoch 11/60, Training Loss: 1.8505, Validation Loss: 1.3695\n",
      "[Trial 2] Epoch 30/60, Training Loss: 1.4575, Validation Loss: 1.0474\n",
      "[Trial 17] Epoch 5/60, Training Loss: 1.5322, Validation Loss: 1.3619\n",
      "[Trial 11] Epoch 31/60, Training Loss: 1.5802, Validation Loss: 1.1287\n",
      "[Trial 15] Epoch 46/60, Training Loss: 1.3173, Validation Loss: 0.9890\n",
      "[Trial 3] Epoch 35/60, Training Loss: 0.8749, Validation Loss: 0.6992\n",
      "[Trial 7] Epoch 59/60, Training Loss: 2.1550, Validation Loss: 1.5894\n",
      "[Trial 12] Epoch 19/60, Training Loss: 2.1293, Validation Loss: 1.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:42:01,848] Trial 5 finished with value: 54.83493784268697 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'learning_rate': 0.0485057538222762, 'batch_size': 8, 'patience': 8}. Best is trial 1 with value: 3.3885840733846027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5] Epoch 10/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 5] Early stopping after 10 epochs.\n",
      "[Trial 14] Epoch 35/60, Training Loss: 0.5998, Validation Loss: 0.5126\n",
      "[Trial 10] Epoch 44/60, Training Loss: 1.9198, Validation Loss: 1.9125\n",
      "[Trial 16] Epoch 17/60, Training Loss: 37.6927, Validation Loss: 19.8528\n",
      "[Trial 13] Epoch 47/60, Training Loss: 0.6339, Validation Loss: 0.5446\n",
      "[Trial 4] Epoch 18/60, Training Loss: 0.7050, Validation Loss: 0.6200\n",
      "[Trial 15] Epoch 47/60, Training Loss: 1.3077, Validation Loss: 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:42:20,115] Trial 7 finished with value: 1.5645146369934082 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 2.720114447949522e-05, 'batch_size': 64, 'patience': 4}. Best is trial 7 with value: 1.5645146369934082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 7] Epoch 60/60, Training Loss: 2.1170, Validation Loss: 1.5645\n",
      "[Trial 0] Epoch 23/60, Training Loss: 0.9358, Validation Loss: 0.7366\n",
      "[Trial 17] Epoch 6/60, Training Loss: 1.3770, Validation Loss: 1.2843\n",
      "[Trial 2] Epoch 31/60, Training Loss: 1.4533, Validation Loss: 1.1730\n",
      "[Trial 16] Epoch 18/60, Training Loss: 469197784047176525048027545600.0000, Validation Loss: 2650.2999\n",
      "[Trial 3] Epoch 36/60, Training Loss: 0.8617, Validation Loss: 0.6955\n",
      "[Trial 11] Epoch 32/60, Training Loss: 1.5728, Validation Loss: 1.1129\n",
      "[Trial 10] Epoch 45/60, Training Loss: 1.9146, Validation Loss: 1.8877\n",
      "[Trial 13] Epoch 48/60, Training Loss: 0.6299, Validation Loss: 0.5526\n",
      "[Trial 14] Epoch 36/60, Training Loss: 0.5916, Validation Loss: 0.5340\n",
      "[Trial 15] Epoch 48/60, Training Loss: 1.3075, Validation Loss: 0.9686\n",
      "[Trial 6] Epoch 19/60, Training Loss: 0.7228, Validation Loss: 0.7660\n",
      "[Trial 16] Epoch 19/60, Training Loss: 3994450099188475323942210371584.0000, Validation Loss: 3575.4753\n",
      "[Trial 19] Epoch 1/60, Training Loss: 1039762.8259, Validation Loss: 289.8701\n",
      "[Trial 10] Epoch 46/60, Training Loss: 1.9067, Validation Loss: 1.8647\n",
      "[Trial 13] Epoch 49/60, Training Loss: 0.6302, Validation Loss: 0.5622\n",
      "[Trial 12] Epoch 20/60, Training Loss: 2.0964, Validation Loss: 1.6560\n",
      "[Trial 3] Epoch 37/60, Training Loss: 0.8466, Validation Loss: 0.6546\n",
      "[Trial 17] Epoch 7/60, Training Loss: 1.3187, Validation Loss: 0.9748\n",
      "[Trial 2] Epoch 32/60, Training Loss: 1.3896, Validation Loss: 1.2406\n",
      "[Trial 11] Epoch 33/60, Training Loss: 1.5612, Validation Loss: 1.1529\n",
      "[Trial 15] Epoch 49/60, Training Loss: 1.3009, Validation Loss: 0.9574\n",
      "[Trial 14] Epoch 37/60, Training Loss: 0.5883, Validation Loss: 0.5184\n",
      "[Trial 0] Epoch 24/60, Training Loss: 0.9366, Validation Loss: 0.7195\n",
      "[Trial 16] Epoch 20/60, Training Loss: 323911007345537539147386847232.0000, Validation Loss: 4451.3403\n",
      "[Trial 4] Epoch 19/60, Training Loss: 0.6984, Validation Loss: 0.6465\n",
      "[Trial 13] Epoch 50/60, Training Loss: 0.6336, Validation Loss: 0.5550\n",
      "[Trial 10] Epoch 47/60, Training Loss: 1.8943, Validation Loss: 1.8711\n",
      "[Trial 15] Epoch 50/60, Training Loss: 1.3000, Validation Loss: 0.9559\n",
      "[Trial 19] Epoch 2/60, Training Loss: 280.4934, Validation Loss: 254.9191\n",
      "[Trial 18] Epoch 1/60, Training Loss: 2.9094, Validation Loss: 1.2195\n",
      "[Trial 9] Epoch 12/60, Training Loss: 1.6511, Validation Loss: 1.6900\n",
      "[Trial 3] Epoch 38/60, Training Loss: 0.8429, Validation Loss: 0.6701\n",
      "[Trial 16] Epoch 21/60, Training Loss: 1223061769074619307724701171712.0000, Validation Loss: 3254.5228\n",
      "[Trial 17] Epoch 8/60, Training Loss: 1.1041, Validation Loss: 0.9701\n",
      "[Trial 14] Epoch 38/60, Training Loss: 0.5970, Validation Loss: 0.5286\n",
      "[Trial 2] Epoch 33/60, Training Loss: 1.3778, Validation Loss: 1.3127\n",
      "[Trial 11] Epoch 34/60, Training Loss: 1.5467, Validation Loss: 1.1046\n",
      "[Trial 13] Epoch 51/60, Training Loss: 0.6381, Validation Loss: 0.5654\n",
      "[Trial 6] Epoch 20/60, Training Loss: 0.7094, Validation Loss: 0.8436\n",
      "[Trial 10] Epoch 48/60, Training Loss: 1.8832, Validation Loss: 1.8313\n",
      "[Trial 15] Epoch 51/60, Training Loss: 1.3063, Validation Loss: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:44:17,885] Trial 16 finished with value: 7.028286616007487 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'learning_rate': 0.050275107745076826, 'batch_size': 64, 'patience': 8}. Best is trial 7 with value: 1.5645146369934082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 16] Epoch 22/60, Training Loss: 1246506900692824581611892768768.0000, Validation Loss: 4060.0855\n",
      "[Trial 16] Early stopping after 22 epochs.\n",
      "[Trial 12] Epoch 21/60, Training Loss: 2.0504, Validation Loss: 1.5970\n",
      "[Trial 0] Epoch 25/60, Training Loss: 0.9055, Validation Loss: 0.6957\n",
      "[Trial 3] Epoch 39/60, Training Loss: 0.8280, Validation Loss: 0.6593\n",
      "[Trial 19] Epoch 3/60, Training Loss: 243.0446, Validation Loss: 227.5414\n",
      "[Trial 13] Epoch 52/60, Training Loss: 0.6289, Validation Loss: 0.5648\n",
      "[Trial 17] Epoch 9/60, Training Loss: 1.0609, Validation Loss: 1.0299\n",
      "[Trial 14] Epoch 39/60, Training Loss: 0.5761, Validation Loss: 0.5172\n",
      "[Trial 10] Epoch 49/60, Training Loss: 1.8644, Validation Loss: 1.8224\n",
      "[Trial 11] Epoch 35/60, Training Loss: 1.5307, Validation Loss: 1.0879\n",
      "[Trial 2] Epoch 34/60, Training Loss: 1.2726, Validation Loss: 0.9210\n",
      "[Trial 15] Epoch 52/60, Training Loss: 1.3004, Validation Loss: 0.9627\n",
      "[Trial 4] Epoch 20/60, Training Loss: 0.7077, Validation Loss: 0.5723\n",
      "[Trial 20] Epoch 1/60, Training Loss: 5.4696, Validation Loss: 2.0656\n",
      "[Trial 13] Epoch 53/60, Training Loss: 0.6168, Validation Loss: 0.5483\n",
      "[Trial 3] Epoch 40/60, Training Loss: 0.8286, Validation Loss: 0.6591\n",
      "[Trial 10] Epoch 50/60, Training Loss: 1.8602, Validation Loss: 1.8104\n",
      "[Trial 15] Epoch 53/60, Training Loss: 1.3041, Validation Loss: 0.9696\n",
      "[Trial 14] Epoch 40/60, Training Loss: 0.5758, Validation Loss: 0.4948\n",
      "[Trial 19] Epoch 4/60, Training Loss: 213.2035, Validation Loss: 197.7350\n",
      "[Trial 17] Epoch 10/60, Training Loss: 1.0700, Validation Loss: 0.8861\n",
      "[Trial 6] Epoch 21/60, Training Loss: 0.6987, Validation Loss: 0.5748\n",
      "[Trial 0] Epoch 26/60, Training Loss: 0.8927, Validation Loss: 0.6926\n",
      "[Trial 11] Epoch 36/60, Training Loss: 1.5303, Validation Loss: 1.0729\n",
      "[Trial 2] Epoch 35/60, Training Loss: 1.2131, Validation Loss: 0.9754\n",
      "[Trial 12] Epoch 22/60, Training Loss: 2.0316, Validation Loss: 1.6231\n",
      "[Trial 13] Epoch 54/60, Training Loss: 0.6188, Validation Loss: 0.5416\n",
      "[Trial 18] Epoch 2/60, Training Loss: 1.6614, Validation Loss: 1.7758\n",
      "[Trial 10] Epoch 51/60, Training Loss: 1.8449, Validation Loss: 1.7944\n",
      "[Trial 15] Epoch 54/60, Training Loss: 1.2997, Validation Loss: 0.9612\n",
      "[Trial 3] Epoch 41/60, Training Loss: 0.8232, Validation Loss: 0.6418\n",
      "[Trial 20] Epoch 2/60, Training Loss: 2.2723, Validation Loss: 1.7656\n",
      "[Trial 9] Epoch 13/60, Training Loss: 1.6245, Validation Loss: 1.3704\n",
      "[Trial 14] Epoch 41/60, Training Loss: 0.5722, Validation Loss: 0.4820\n",
      "[Trial 17] Epoch 11/60, Training Loss: 0.9785, Validation Loss: 0.8472\n",
      "[Trial 13] Epoch 55/60, Training Loss: 0.6225, Validation Loss: 0.5442\n",
      "[Trial 19] Epoch 5/60, Training Loss: 187.1373, Validation Loss: 171.5656\n",
      "[Trial 4] Epoch 21/60, Training Loss: 0.6754, Validation Loss: 0.5753\n",
      "[Trial 11] Epoch 37/60, Training Loss: 1.5122, Validation Loss: 1.0670\n",
      "[Trial 10] Epoch 52/60, Training Loss: 1.8502, Validation Loss: 1.7559\n",
      "[Trial 15] Epoch 55/60, Training Loss: 1.2944, Validation Loss: 0.9539\n",
      "[Trial 2] Epoch 36/60, Training Loss: 1.2017, Validation Loss: 0.9898\n",
      "[Trial 3] Epoch 42/60, Training Loss: 0.8050, Validation Loss: 0.6506\n",
      "[Trial 0] Epoch 27/60, Training Loss: 0.8627, Validation Loss: 0.6998\n",
      "[Trial 13] Epoch 56/60, Training Loss: 0.6190, Validation Loss: 0.5437\n",
      "[Trial 20] Epoch 3/60, Training Loss: 1.9675, Validation Loss: 1.4542\n",
      "[Trial 14] Epoch 42/60, Training Loss: 0.5791, Validation Loss: 0.5136\n",
      "[Trial 6] Epoch 22/60, Training Loss: 0.6841, Validation Loss: 0.7260\n",
      "[Trial 15] Epoch 56/60, Training Loss: 1.2971, Validation Loss: 0.9484\n",
      "[Trial 10] Epoch 53/60, Training Loss: 1.8415, Validation Loss: 1.7544\n",
      "[Trial 17] Epoch 12/60, Training Loss: 0.9599, Validation Loss: 0.8507\n",
      "[Trial 12] Epoch 23/60, Training Loss: 1.9885, Validation Loss: 1.6454\n",
      "[Trial 19] Epoch 6/60, Training Loss: 163.3489, Validation Loss: 147.9825\n",
      "[Trial 11] Epoch 38/60, Training Loss: 1.4935, Validation Loss: 1.0489\n",
      "[Trial 2] Epoch 37/60, Training Loss: 1.1756, Validation Loss: 0.9510\n",
      "[Trial 13] Epoch 57/60, Training Loss: 0.6190, Validation Loss: 0.5360\n",
      "[Trial 3] Epoch 43/60, Training Loss: 0.8065, Validation Loss: 0.6485\n",
      "[Trial 15] Epoch 57/60, Training Loss: 1.2998, Validation Loss: 0.9595\n",
      "[Trial 10] Epoch 54/60, Training Loss: 1.8181, Validation Loss: 1.7316\n",
      "[Trial 14] Epoch 43/60, Training Loss: 0.5739, Validation Loss: 0.4928\n",
      "[Trial 20] Epoch 4/60, Training Loss: 1.8203, Validation Loss: 1.3557\n",
      "[Trial 4] Epoch 22/60, Training Loss: 0.6735, Validation Loss: 0.7419\n",
      "[Trial 18] Epoch 3/60, Training Loss: 1.4848, Validation Loss: 1.0847\n",
      "[Trial 17] Epoch 13/60, Training Loss: 0.9488, Validation Loss: 1.0867\n",
      "[Trial 0] Epoch 28/60, Training Loss: 0.8612, Validation Loss: 0.6687\n",
      "[Trial 13] Epoch 58/60, Training Loss: 0.6133, Validation Loss: 0.5358\n",
      "[Trial 19] Epoch 7/60, Training Loss: 144.7059, Validation Loss: 134.7695\n",
      "[Trial 11] Epoch 39/60, Training Loss: 1.4787, Validation Loss: 1.0518\n",
      "[Trial 3] Epoch 44/60, Training Loss: 0.7986, Validation Loss: 0.6414\n",
      "[Trial 15] Epoch 58/60, Training Loss: 1.2977, Validation Loss: 0.9501\n",
      "[Trial 2] Epoch 38/60, Training Loss: 1.1745, Validation Loss: 0.9367\n",
      "[Trial 10] Epoch 55/60, Training Loss: 1.8242, Validation Loss: 1.7260\n",
      "[Trial 9] Epoch 14/60, Training Loss: 1.6041, Validation Loss: 1.1794\n",
      "[Trial 6] Epoch 23/60, Training Loss: 0.7020, Validation Loss: 0.6108\n",
      "[Trial 14] Epoch 44/60, Training Loss: 0.5693, Validation Loss: 0.5249\n",
      "[Trial 12] Epoch 24/60, Training Loss: 1.9787, Validation Loss: 1.5274\n",
      "[Trial 13] Epoch 59/60, Training Loss: 0.6166, Validation Loss: 0.5347\n",
      "[Trial 20] Epoch 5/60, Training Loss: 1.7297, Validation Loss: 1.2544\n",
      "[Trial 17] Epoch 14/60, Training Loss: 0.9491, Validation Loss: 0.7852\n",
      "[Trial 15] Epoch 59/60, Training Loss: 1.2910, Validation Loss: 0.9508\n",
      "[Trial 10] Epoch 56/60, Training Loss: 1.8034, Validation Loss: 1.7283\n",
      "[Trial 3] Epoch 45/60, Training Loss: 0.7961, Validation Loss: 0.6037\n",
      "[Trial 19] Epoch 8/60, Training Loss: 127.8062, Validation Loss: 119.1149\n",
      "[Trial 11] Epoch 40/60, Training Loss: 1.4751, Validation Loss: 1.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:48:29,983] Trial 13 finished with value: 0.5346927503744762 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.0023437609222335632, 'batch_size': 64, 'patience': 9}. Best is trial 13 with value: 0.5346927503744762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 13] Epoch 60/60, Training Loss: 0.6239, Validation Loss: 0.5494\n",
      "[Trial 2] Epoch 39/60, Training Loss: 1.1489, Validation Loss: 0.9098\n",
      "[Trial 0] Epoch 29/60, Training Loss: 0.8542, Validation Loss: 0.6852\n",
      "[Trial 14] Epoch 45/60, Training Loss: 0.5679, Validation Loss: 0.5001\n",
      "[Trial 4] Epoch 23/60, Training Loss: 0.6687, Validation Loss: 0.6053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:48:41,904] Trial 15 finished with value: 0.9483716249465942 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.00021613823492433375, 'batch_size': 64, 'patience': 5}. Best is trial 13 with value: 0.5346927503744762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 15] Epoch 60/60, Training Loss: 1.2840, Validation Loss: 0.9518\n",
      "[Trial 10] Epoch 57/60, Training Loss: 1.7907, Validation Loss: 1.7002\n",
      "[Trial 20] Epoch 6/60, Training Loss: 1.6660, Validation Loss: 1.2547\n",
      "[Trial 17] Epoch 15/60, Training Loss: 0.8587, Validation Loss: 0.7397\n",
      "[Trial 3] Epoch 46/60, Training Loss: 0.7857, Validation Loss: 0.6099\n",
      "[Trial 11] Epoch 41/60, Training Loss: 1.4664, Validation Loss: 1.0390\n",
      "[Trial 19] Epoch 9/60, Training Loss: 113.2971, Validation Loss: 105.1974\n",
      "[Trial 12] Epoch 25/60, Training Loss: 1.9515, Validation Loss: 1.5071\n",
      "[Trial 6] Epoch 24/60, Training Loss: 0.6933, Validation Loss: 0.7011\n",
      "[Trial 2] Epoch 40/60, Training Loss: 1.1130, Validation Loss: 0.8670\n",
      "[Trial 18] Epoch 4/60, Training Loss: 1.3039, Validation Loss: 0.8253\n",
      "[Trial 14] Epoch 46/60, Training Loss: 0.5600, Validation Loss: 0.4876\n",
      "[Trial 10] Epoch 58/60, Training Loss: 1.7923, Validation Loss: 1.6906\n",
      "[Trial 0] Epoch 30/60, Training Loss: 0.8441, Validation Loss: 0.6526\n",
      "[Trial 17] Epoch 16/60, Training Loss: 0.8752, Validation Loss: 0.7515\n",
      "[Trial 20] Epoch 7/60, Training Loss: 1.5892, Validation Loss: 1.3057\n",
      "[Trial 3] Epoch 47/60, Training Loss: 0.7911, Validation Loss: 0.6607\n",
      "[Trial 21] Epoch 1/60, Training Loss: 143.3771, Validation Loss: 4.3423\n",
      "[Trial 10] Epoch 59/60, Training Loss: 1.7800, Validation Loss: 1.6751\n",
      "[Trial 11] Epoch 42/60, Training Loss: 1.4557, Validation Loss: 1.0365\n",
      "[Trial 19] Epoch 10/60, Training Loss: 100.7796, Validation Loss: 92.7173\n",
      "[Trial 4] Epoch 24/60, Training Loss: 0.6340, Validation Loss: 0.5224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:49:52,550] Trial 14 finished with value: 0.4819520185391108 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.011221164275093365, 'batch_size': 32, 'patience': 6}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 14] Epoch 47/60, Training Loss: 0.5590, Validation Loss: 0.4956\n",
      "[Trial 14] Early stopping after 47 epochs.\n",
      "[Trial 2] Epoch 41/60, Training Loss: 1.1253, Validation Loss: 0.8803\n",
      "[Trial 9] Epoch 15/60, Training Loss: 1.6365, Validation Loss: 1.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:50:15,410] Trial 10 finished with value: 1.6498510122299195 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 3.590415000370903e-05, 'batch_size': 64, 'patience': 4}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 17] Epoch 17/60, Training Loss: 0.8276, Validation Loss: 0.7693\n",
      "[Trial 10] Epoch 60/60, Training Loss: 1.7817, Validation Loss: 1.6499\n",
      "[Trial 3] Epoch 48/60, Training Loss: 0.7709, Validation Loss: 0.6512\n",
      "[Trial 12] Epoch 26/60, Training Loss: 1.9268, Validation Loss: 1.4467\n",
      "[Trial 20] Epoch 8/60, Training Loss: 1.5186, Validation Loss: 1.0600\n",
      "[Trial 23] Epoch 1/60, Training Loss: 33.9369, Validation Loss: 13.0920\n",
      "[Trial 6] Epoch 25/60, Training Loss: 0.7065, Validation Loss: 0.6962\n",
      "[Trial 11] Epoch 43/60, Training Loss: 1.4561, Validation Loss: 1.0220\n",
      "[Trial 19] Epoch 11/60, Training Loss: 90.8087, Validation Loss: 86.5168\n",
      "[Trial 0] Epoch 31/60, Training Loss: 0.8312, Validation Loss: 0.6920\n",
      "[Trial 2] Epoch 42/60, Training Loss: 1.1192, Validation Loss: 0.8712\n",
      "[Trial 22] Epoch 1/60, Training Loss: 3.5906, Validation Loss: 1.9885\n",
      "[Trial 24] Epoch 1/60, Training Loss: 14.6807, Validation Loss: 4.3793\n",
      "[Trial 23] Epoch 2/60, Training Loss: 23.4786, Validation Loss: 11.3577\n",
      "[Trial 21] Epoch 2/60, Training Loss: 3.3188, Validation Loss: 2.8425\n",
      "[Trial 3] Epoch 49/60, Training Loss: 0.7792, Validation Loss: 0.6572\n",
      "[Trial 17] Epoch 18/60, Training Loss: 0.8593, Validation Loss: 0.9426\n",
      "[Trial 20] Epoch 9/60, Training Loss: 1.4763, Validation Loss: 1.0638\n",
      "[Trial 4] Epoch 25/60, Training Loss: 0.6336, Validation Loss: 0.5786\n",
      "[Trial 18] Epoch 5/60, Training Loss: 1.2959, Validation Loss: 1.1266\n",
      "[Trial 24] Epoch 2/60, Training Loss: 4.6265, Validation Loss: 2.7815\n",
      "[Trial 23] Epoch 3/60, Training Loss: 16.5436, Validation Loss: 9.2769\n",
      "[Trial 11] Epoch 44/60, Training Loss: 1.4301, Validation Loss: 1.0334\n",
      "[Trial 19] Epoch 12/60, Training Loss: 81.2737, Validation Loss: 77.4725\n",
      "[Trial 2] Epoch 43/60, Training Loss: 1.1174, Validation Loss: 0.8903\n",
      "[Trial 12] Epoch 27/60, Training Loss: 1.9056, Validation Loss: 1.4583\n",
      "[Trial 6] Epoch 26/60, Training Loss: 0.6978, Validation Loss: 0.7873\n",
      "[Trial 3] Epoch 50/60, Training Loss: 0.7441, Validation Loss: 0.5953\n",
      "[Trial 24] Epoch 3/60, Training Loss: 3.4760, Validation Loss: 2.3064\n",
      "[Trial 0] Epoch 32/60, Training Loss: 0.8417, Validation Loss: 0.7082\n",
      "[Trial 17] Epoch 19/60, Training Loss: 0.8622, Validation Loss: 0.6966\n",
      "[Trial 23] Epoch 4/60, Training Loss: 11.9863, Validation Loss: 7.6155\n",
      "[Trial 20] Epoch 10/60, Training Loss: 1.4471, Validation Loss: 1.0805\n",
      "[Trial 11] Epoch 45/60, Training Loss: 1.4052, Validation Loss: 0.9898\n",
      "[Trial 19] Epoch 13/60, Training Loss: 72.7144, Validation Loss: 65.9791\n",
      "[Trial 9] Epoch 16/60, Training Loss: 1.6820, Validation Loss: 1.4737\n",
      "[Trial 21] Epoch 3/60, Training Loss: 2.7039, Validation Loss: 2.5352\n",
      "[Trial 24] Epoch 4/60, Training Loss: 2.9511, Validation Loss: 2.0487\n",
      "[Trial 2] Epoch 44/60, Training Loss: 1.1039, Validation Loss: 0.8562\n",
      "[Trial 23] Epoch 5/60, Training Loss: 9.2726, Validation Loss: 6.2479\n",
      "[Trial 3] Epoch 51/60, Training Loss: 0.7418, Validation Loss: 0.6039\n",
      "[Trial 4] Epoch 26/60, Training Loss: 0.6282, Validation Loss: 0.5496\n",
      "[Trial 17] Epoch 20/60, Training Loss: 0.8397, Validation Loss: 0.7510\n",
      "[Trial 20] Epoch 11/60, Training Loss: 1.3894, Validation Loss: 0.9746\n",
      "[Trial 24] Epoch 5/60, Training Loss: 2.6432, Validation Loss: 1.9723\n",
      "[Trial 23] Epoch 6/60, Training Loss: 7.7179, Validation Loss: 5.4525\n",
      "[Trial 12] Epoch 28/60, Training Loss: 1.8777, Validation Loss: 1.4273\n",
      "[Trial 11] Epoch 46/60, Training Loss: 1.4208, Validation Loss: 0.9965\n",
      "[Trial 0] Epoch 33/60, Training Loss: 0.8561, Validation Loss: 0.6471\n",
      "[Trial 19] Epoch 14/60, Training Loss: 65.6924, Validation Loss: 63.8812\n",
      "[Trial 22] Epoch 2/60, Training Loss: 1.5227, Validation Loss: 1.5740\n",
      "[Trial 6] Epoch 27/60, Training Loss: 0.6500, Validation Loss: 0.5873\n",
      "[Trial 2] Epoch 45/60, Training Loss: 1.0841, Validation Loss: 0.8369\n",
      "[Trial 3] Epoch 52/60, Training Loss: 0.7381, Validation Loss: 0.6039\n",
      "[Trial 18] Epoch 6/60, Training Loss: 1.2437, Validation Loss: 1.0583\n",
      "[Trial 24] Epoch 6/60, Training Loss: 2.4188, Validation Loss: 1.9995\n",
      "[Trial 23] Epoch 7/60, Training Loss: 6.7413, Validation Loss: 4.7604\n",
      "[Trial 17] Epoch 21/60, Training Loss: 0.8079, Validation Loss: 0.6911\n",
      "[Trial 20] Epoch 12/60, Training Loss: 1.3822, Validation Loss: 0.9882\n",
      "[Trial 21] Epoch 4/60, Training Loss: 2.3834, Validation Loss: 2.0073\n",
      "[Trial 11] Epoch 47/60, Training Loss: 1.4060, Validation Loss: 0.9903\n",
      "[Trial 24] Epoch 7/60, Training Loss: 2.2510, Validation Loss: 1.9575\n",
      "[Trial 19] Epoch 15/60, Training Loss: 59.4704, Validation Loss: 58.7603\n",
      "[Trial 23] Epoch 8/60, Training Loss: 6.0636, Validation Loss: 4.2690\n",
      "[Trial 4] Epoch 27/60, Training Loss: 0.6330, Validation Loss: 0.5391\n",
      "[Trial 3] Epoch 53/60, Training Loss: 0.7347, Validation Loss: 0.6005\n",
      "[Trial 2] Epoch 46/60, Training Loss: 1.0939, Validation Loss: 0.8547\n",
      "[Trial 0] Epoch 34/60, Training Loss: 0.8173, Validation Loss: 0.6520\n",
      "[Trial 17] Epoch 22/60, Training Loss: 0.7873, Validation Loss: 0.7531\n",
      "[Trial 12] Epoch 29/60, Training Loss: 1.8616, Validation Loss: 1.4462\n",
      "[Trial 24] Epoch 8/60, Training Loss: 2.1424, Validation Loss: 1.7415\n",
      "[Trial 23] Epoch 9/60, Training Loss: 5.5591, Validation Loss: 3.9850\n",
      "[Trial 20] Epoch 13/60, Training Loss: 1.3512, Validation Loss: 0.9913\n",
      "[Trial 6] Epoch 28/60, Training Loss: 0.6401, Validation Loss: 0.6465\n",
      "[Trial 9] Epoch 17/60, Training Loss: 77752494403546726400.0000, Validation Loss: inf\n",
      "[Trial 11] Epoch 48/60, Training Loss: 1.3815, Validation Loss: 0.9736\n",
      "[Trial 19] Epoch 16/60, Training Loss: 54.4268, Validation Loss: 50.7489\n",
      "[Trial 3] Epoch 54/60, Training Loss: 0.7344, Validation Loss: 0.5898\n",
      "[Trial 2] Epoch 47/60, Training Loss: 1.0975, Validation Loss: 0.8518\n",
      "[Trial 24] Epoch 9/60, Training Loss: 2.0612, Validation Loss: 1.6785\n",
      "[Trial 23] Epoch 10/60, Training Loss: 5.1714, Validation Loss: 3.6706\n",
      "[Trial 21] Epoch 5/60, Training Loss: 2.1336, Validation Loss: 2.1544\n",
      "[Trial 17] Epoch 23/60, Training Loss: 0.7787, Validation Loss: 0.6940\n",
      "[Trial 20] Epoch 14/60, Training Loss: 1.3617, Validation Loss: 0.9616\n",
      "[Trial 4] Epoch 28/60, Training Loss: 0.6156, Validation Loss: 0.5206\n",
      "[Trial 18] Epoch 7/60, Training Loss: 1.2041, Validation Loss: 1.2031\n",
      "[Trial 24] Epoch 10/60, Training Loss: 1.9702, Validation Loss: 1.6384\n",
      "[Trial 11] Epoch 49/60, Training Loss: 1.3815, Validation Loss: 0.9603\n",
      "[Trial 23] Epoch 11/60, Training Loss: 4.8861, Validation Loss: 3.4598\n",
      "[Trial 0] Epoch 35/60, Training Loss: 0.8144, Validation Loss: 0.6210\n",
      "[Trial 22] Epoch 3/60, Training Loss: 1.2508, Validation Loss: 0.9377\n",
      "[Trial 3] Epoch 55/60, Training Loss: 0.7327, Validation Loss: 0.5961\n",
      "[Trial 19] Epoch 17/60, Training Loss: 49.5916, Validation Loss: 47.2269\n",
      "[Trial 12] Epoch 30/60, Training Loss: 1.8396, Validation Loss: 1.3370\n",
      "[Trial 2] Epoch 48/60, Training Loss: 1.0737, Validation Loss: 0.8738\n",
      "[Trial 17] Epoch 24/60, Training Loss: 0.7491, Validation Loss: 0.6248\n",
      "[Trial 6] Epoch 29/60, Training Loss: 0.6607, Validation Loss: 0.5344\n",
      "[Trial 24] Epoch 11/60, Training Loss: 1.9200, Validation Loss: 1.5442\n",
      "[Trial 23] Epoch 12/60, Training Loss: 4.6253, Validation Loss: 3.3607\n",
      "[Trial 20] Epoch 15/60, Training Loss: 1.3424, Validation Loss: 0.9583\n",
      "[Trial 3] Epoch 56/60, Training Loss: 0.7270, Validation Loss: 0.5897\n",
      "[Trial 11] Epoch 50/60, Training Loss: 1.3764, Validation Loss: 0.9846\n",
      "[Trial 21] Epoch 6/60, Training Loss: 2.0128, Validation Loss: 1.9454\n",
      "[Trial 19] Epoch 18/60, Training Loss: 45.6219, Validation Loss: 45.4570\n",
      "[Trial 24] Epoch 12/60, Training Loss: 1.8639, Validation Loss: 1.5380\n",
      "[Trial 23] Epoch 13/60, Training Loss: 4.4268, Validation Loss: 3.1548\n",
      "[Trial 2] Epoch 49/60, Training Loss: 1.0826, Validation Loss: 0.8860\n",
      "[Trial 17] Epoch 25/60, Training Loss: 0.7849, Validation Loss: 0.6550\n",
      "[Trial 0] Epoch 36/60, Training Loss: 0.7966, Validation Loss: 0.6323\n",
      "[Trial 4] Epoch 29/60, Training Loss: 0.6109, Validation Loss: 0.5324\n",
      "[Trial 20] Epoch 16/60, Training Loss: 1.3210, Validation Loss: 0.9464\n",
      "[Trial 9] Epoch 18/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 12] Epoch 31/60, Training Loss: 1.8456, Validation Loss: 1.3590\n",
      "[Trial 24] Epoch 13/60, Training Loss: 1.8170, Validation Loss: 1.4842\n",
      "[Trial 3] Epoch 57/60, Training Loss: 0.7341, Validation Loss: 0.5815\n",
      "[Trial 23] Epoch 14/60, Training Loss: 4.2587, Validation Loss: 3.0690\n",
      "[Trial 11] Epoch 51/60, Training Loss: 1.3614, Validation Loss: 0.9737\n",
      "[Trial 19] Epoch 19/60, Training Loss: 41.8602, Validation Loss: 41.6250\n",
      "[Trial 6] Epoch 30/60, Training Loss: 0.6273, Validation Loss: 0.6033\n",
      "[Trial 2] Epoch 50/60, Training Loss: 1.0404, Validation Loss: 0.8314\n",
      "[Trial 17] Epoch 26/60, Training Loss: 0.7451, Validation Loss: 0.6140\n",
      "[Trial 18] Epoch 8/60, Training Loss: 1.2099, Validation Loss: 1.1202\n",
      "[Trial 24] Epoch 14/60, Training Loss: 1.7617, Validation Loss: 1.4795\n",
      "[Trial 23] Epoch 15/60, Training Loss: 4.0950, Validation Loss: 2.9869\n",
      "[Trial 3] Epoch 58/60, Training Loss: 0.7272, Validation Loss: 0.5997\n",
      "[Trial 20] Epoch 17/60, Training Loss: 1.3113, Validation Loss: 0.9593\n",
      "[Trial 21] Epoch 7/60, Training Loss: 1.8494, Validation Loss: 1.6395\n",
      "[Trial 0] Epoch 37/60, Training Loss: 0.7959, Validation Loss: 0.6276\n",
      "[Trial 22] Epoch 4/60, Training Loss: 1.1023, Validation Loss: 0.9464\n",
      "[Trial 11] Epoch 52/60, Training Loss: 1.3536, Validation Loss: 0.9444\n",
      "[Trial 23] Epoch 16/60, Training Loss: 3.9457, Validation Loss: 2.8558\n",
      "[Trial 24] Epoch 15/60, Training Loss: 1.7291, Validation Loss: 1.4412\n",
      "[Trial 4] Epoch 30/60, Training Loss: 0.6119, Validation Loss: 0.5170\n",
      "[Trial 19] Epoch 20/60, Training Loss: 38.6026, Validation Loss: 36.7646\n",
      "[Trial 2] Epoch 51/60, Training Loss: 1.0347, Validation Loss: 0.8013\n",
      "[Trial 17] Epoch 27/60, Training Loss: 0.7872, Validation Loss: 0.7174\n",
      "[Trial 12] Epoch 32/60, Training Loss: 1.8189, Validation Loss: 1.3017\n",
      "[Trial 3] Epoch 59/60, Training Loss: 0.7337, Validation Loss: 0.6148\n",
      "[Trial 23] Epoch 17/60, Training Loss: 3.8235, Validation Loss: 2.7967\n",
      "[Trial 24] Epoch 16/60, Training Loss: 1.7132, Validation Loss: 1.3793\n",
      "[Trial 20] Epoch 18/60, Training Loss: 1.3000, Validation Loss: 0.9365\n",
      "[Trial 6] Epoch 31/60, Training Loss: 0.6287, Validation Loss: 0.5973\n",
      "[Trial 11] Epoch 53/60, Training Loss: 1.3378, Validation Loss: 0.9751\n",
      "[Trial 19] Epoch 21/60, Training Loss: 35.6998, Validation Loss: 35.6499\n",
      "[Trial 2] Epoch 52/60, Training Loss: 1.0265, Validation Loss: 0.7816\n",
      "[Trial 17] Epoch 28/60, Training Loss: 0.7795, Validation Loss: 0.7451\n",
      "[Trial 0] Epoch 38/60, Training Loss: 0.7850, Validation Loss: 0.6292\n",
      "[Trial 23] Epoch 18/60, Training Loss: 3.7000, Validation Loss: 2.7096\n",
      "[Trial 24] Epoch 17/60, Training Loss: 1.6716, Validation Loss: 1.3073\n",
      "[Trial 21] Epoch 8/60, Training Loss: 1.8512, Validation Loss: 2.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 01:58:14,227] Trial 3 finished with value: 0.5814549585183462 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006464597607491608, 'batch_size': 32, 'patience': 6}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 3] Epoch 60/60, Training Loss: 0.7231, Validation Loss: 0.5965\n",
      "[Trial 9] Epoch 19/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 20] Epoch 19/60, Training Loss: 1.2870, Validation Loss: 0.9222\n",
      "[Trial 11] Epoch 54/60, Training Loss: 1.3322, Validation Loss: 0.9292\n",
      "[Trial 4] Epoch 31/60, Training Loss: 0.6069, Validation Loss: 0.5299\n",
      "[Trial 23] Epoch 19/60, Training Loss: 3.6003, Validation Loss: 2.6396\n",
      "[Trial 24] Epoch 18/60, Training Loss: 1.6483, Validation Loss: 1.2632\n",
      "[Trial 18] Epoch 9/60, Training Loss: 0.9983, Validation Loss: 0.7068\n",
      "[Trial 12] Epoch 33/60, Training Loss: 1.7933, Validation Loss: 1.3177\n",
      "[Trial 19] Epoch 22/60, Training Loss: 33.0597, Validation Loss: 31.9736\n",
      "[Trial 2] Epoch 53/60, Training Loss: 1.0325, Validation Loss: 0.7998\n",
      "[Trial 17] Epoch 29/60, Training Loss: 0.7643, Validation Loss: 0.6824\n",
      "[Trial 6] Epoch 32/60, Training Loss: 0.6197, Validation Loss: 0.5373\n",
      "[Trial 23] Epoch 20/60, Training Loss: 3.4881, Validation Loss: 2.5895\n",
      "[Trial 24] Epoch 19/60, Training Loss: 1.6145, Validation Loss: 1.2690\n",
      "[Trial 22] Epoch 5/60, Training Loss: 0.9963, Validation Loss: 0.8006\n",
      "[Trial 0] Epoch 39/60, Training Loss: 0.7716, Validation Loss: 0.5845\n",
      "[Trial 20] Epoch 20/60, Training Loss: 1.2840, Validation Loss: 0.9279\n",
      "[Trial 11] Epoch 55/60, Training Loss: 1.3150, Validation Loss: 0.9286\n",
      "[Trial 25] Epoch 1/60, Training Loss: 3.2351, Validation Loss: 1.5084\n",
      "[Trial 21] Epoch 9/60, Training Loss: 1.6954, Validation Loss: 1.7066\n",
      "[Trial 23] Epoch 21/60, Training Loss: 3.4031, Validation Loss: 2.5034\n",
      "[Trial 17] Epoch 30/60, Training Loss: 0.7154, Validation Loss: 0.6117\n",
      "[Trial 24] Epoch 20/60, Training Loss: 1.6144, Validation Loss: 1.2209\n",
      "[Trial 19] Epoch 23/60, Training Loss: 30.5072, Validation Loss: 30.4607\n",
      "[Trial 2] Epoch 54/60, Training Loss: 1.0183, Validation Loss: 0.8300\n",
      "[Trial 4] Epoch 32/60, Training Loss: 0.6077, Validation Loss: 0.5309\n",
      "[Trial 12] Epoch 34/60, Training Loss: 1.7929, Validation Loss: 1.4339\n",
      "[Trial 20] Epoch 21/60, Training Loss: 1.2922, Validation Loss: 0.9222\n",
      "[Trial 23] Epoch 22/60, Training Loss: 3.3290, Validation Loss: 2.4698\n",
      "[Trial 11] Epoch 56/60, Training Loss: 1.3134, Validation Loss: 0.9212\n",
      "[Trial 24] Epoch 21/60, Training Loss: 1.5916, Validation Loss: 1.1809\n",
      "[Trial 17] Epoch 31/60, Training Loss: 0.7541, Validation Loss: 0.7368\n",
      "[Trial 0] Epoch 40/60, Training Loss: 0.7799, Validation Loss: 0.6438\n",
      "[Trial 6] Epoch 33/60, Training Loss: 0.6105, Validation Loss: 0.6058\n",
      "[Trial 19] Epoch 24/60, Training Loss: 28.6010, Validation Loss: 28.0306\n",
      "[Trial 2] Epoch 55/60, Training Loss: 1.0061, Validation Loss: 0.8148\n",
      "[Trial 23] Epoch 23/60, Training Loss: 3.2397, Validation Loss: 2.4099\n",
      "[Trial 9] Epoch 20/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 24] Epoch 22/60, Training Loss: 1.5619, Validation Loss: 1.1911\n",
      "[Trial 18] Epoch 10/60, Training Loss: 1.0031, Validation Loss: 0.7176\n",
      "[Trial 25] Epoch 2/60, Training Loss: 1.6814, Validation Loss: 1.2985\n",
      "[Trial 21] Epoch 10/60, Training Loss: 1.7160, Validation Loss: 1.5054\n",
      "[Trial 20] Epoch 22/60, Training Loss: 1.2663, Validation Loss: 0.9033\n",
      "[Trial 11] Epoch 57/60, Training Loss: 1.3113, Validation Loss: 0.9107\n",
      "[Trial 23] Epoch 24/60, Training Loss: 3.1420, Validation Loss: 2.3773\n",
      "[Trial 17] Epoch 32/60, Training Loss: 0.7523, Validation Loss: 0.6672\n",
      "[Trial 24] Epoch 23/60, Training Loss: 1.5572, Validation Loss: 1.1819\n",
      "[Trial 2] Epoch 56/60, Training Loss: 1.0010, Validation Loss: 0.7980\n",
      "[Trial 19] Epoch 25/60, Training Loss: 26.7823, Validation Loss: 26.0250\n",
      "[Trial 4] Epoch 33/60, Training Loss: 0.6036, Validation Loss: 0.5245\n",
      "[Trial 12] Epoch 35/60, Training Loss: 1.7734, Validation Loss: 1.2527\n",
      "[Trial 22] Epoch 6/60, Training Loss: 0.9701, Validation Loss: 0.8020\n",
      "[Trial 0] Epoch 41/60, Training Loss: 0.7709, Validation Loss: 0.6287\n",
      "[Trial 23] Epoch 25/60, Training Loss: 3.0916, Validation Loss: 2.3457\n",
      "[Trial 20] Epoch 23/60, Training Loss: 1.2578, Validation Loss: 0.9016\n",
      "[Trial 24] Epoch 24/60, Training Loss: 1.5447, Validation Loss: 1.1610\n",
      "[Trial 11] Epoch 58/60, Training Loss: 1.2888, Validation Loss: 0.8832\n",
      "[Trial 6] Epoch 34/60, Training Loss: 0.6082, Validation Loss: 0.5431\n",
      "[Trial 17] Epoch 33/60, Training Loss: 0.7277, Validation Loss: 0.5771\n",
      "[Trial 2] Epoch 57/60, Training Loss: 0.9977, Validation Loss: 0.7769\n",
      "[Trial 19] Epoch 26/60, Training Loss: 24.9163, Validation Loss: 24.5417\n",
      "[Trial 25] Epoch 3/60, Training Loss: 1.3536, Validation Loss: 1.3123\n",
      "[Trial 23] Epoch 26/60, Training Loss: 3.0137, Validation Loss: 2.2906\n",
      "[Trial 21] Epoch 11/60, Training Loss: 1.6406, Validation Loss: 2.0107\n",
      "[Trial 24] Epoch 25/60, Training Loss: 1.5096, Validation Loss: 1.1083\n",
      "[Trial 11] Epoch 59/60, Training Loss: 1.2805, Validation Loss: 0.8785\n",
      "[Trial 20] Epoch 24/60, Training Loss: 1.2507, Validation Loss: 0.9110\n",
      "[Trial 12] Epoch 36/60, Training Loss: 1.7504, Validation Loss: 1.4072\n",
      "[Trial 23] Epoch 27/60, Training Loss: 2.9648, Validation Loss: 2.2511\n",
      "[Trial 4] Epoch 34/60, Training Loss: 0.5894, Validation Loss: 0.5114\n",
      "[Trial 17] Epoch 34/60, Training Loss: 0.7239, Validation Loss: 0.6704\n",
      "[Trial 0] Epoch 42/60, Training Loss: 0.7695, Validation Loss: 0.6091\n",
      "[Trial 24] Epoch 26/60, Training Loss: 1.4915, Validation Loss: 1.1106\n",
      "[Trial 18] Epoch 11/60, Training Loss: 0.9559, Validation Loss: 0.7358\n",
      "[Trial 2] Epoch 58/60, Training Loss: 0.9925, Validation Loss: 0.7889\n",
      "[Trial 19] Epoch 27/60, Training Loss: 23.4629, Validation Loss: 23.1080\n",
      "[Trial 9] Epoch 21/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 6] Epoch 35/60, Training Loss: 0.5906, Validation Loss: 0.5534\n",
      "[Trial 23] Epoch 28/60, Training Loss: 2.9028, Validation Loss: 2.2397\n",
      "[Trial 24] Epoch 27/60, Training Loss: 1.4802, Validation Loss: 1.0688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:02:37,185] Trial 11 finished with value: 0.8784587939580282 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 7.135956824653065e-05, 'batch_size': 32, 'patience': 9}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 11] Epoch 60/60, Training Loss: 1.2718, Validation Loss: 0.8842\n",
      "[Trial 20] Epoch 25/60, Training Loss: 1.2478, Validation Loss: 0.9063\n",
      "[Trial 25] Epoch 4/60, Training Loss: 1.2012, Validation Loss: 0.9629\n",
      "[Trial 17] Epoch 35/60, Training Loss: 0.7244, Validation Loss: 0.6613\n",
      "[Trial 21] Epoch 12/60, Training Loss: 1.6976, Validation Loss: 1.8923\n",
      "[Trial 2] Epoch 59/60, Training Loss: 0.9863, Validation Loss: 0.7776\n",
      "[Trial 23] Epoch 29/60, Training Loss: 2.8451, Validation Loss: 2.1915\n",
      "[Trial 19] Epoch 28/60, Training Loss: 22.1354, Validation Loss: 21.3525\n",
      "[Trial 24] Epoch 28/60, Training Loss: 1.4796, Validation Loss: 1.0843\n",
      "[Trial 22] Epoch 7/60, Training Loss: 0.9353, Validation Loss: 0.9612\n",
      "[Trial 0] Epoch 43/60, Training Loss: 0.7641, Validation Loss: 0.6265\n",
      "[Trial 12] Epoch 37/60, Training Loss: 1.7420, Validation Loss: 1.2804\n",
      "[Trial 4] Epoch 35/60, Training Loss: 0.5949, Validation Loss: 0.5071\n",
      "[Trial 20] Epoch 26/60, Training Loss: 1.2463, Validation Loss: 0.8987\n",
      "[Trial 23] Epoch 30/60, Training Loss: 2.7846, Validation Loss: 2.1931\n",
      "[Trial 17] Epoch 36/60, Training Loss: 0.7436, Validation Loss: 0.6480\n",
      "[Trial 24] Epoch 29/60, Training Loss: 1.4494, Validation Loss: 1.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:03:35,618] Trial 2 finished with value: 0.7756042361259461 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.02957663036181066, 'batch_size': 32, 'patience': 7}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 2] Epoch 60/60, Training Loss: 0.9960, Validation Loss: 0.7756\n",
      "[Trial 19] Epoch 29/60, Training Loss: 20.8656, Validation Loss: 20.1092\n",
      "[Trial 6] Epoch 36/60, Training Loss: 0.5848, Validation Loss: 0.5207\n",
      "[Trial 26] Epoch 1/60, Training Loss: 3.2325, Validation Loss: 1.4919\n",
      "[Trial 25] Epoch 5/60, Training Loss: 1.0553, Validation Loss: 0.8505\n",
      "[Trial 23] Epoch 31/60, Training Loss: 2.7184, Validation Loss: 2.1444\n",
      "[Trial 24] Epoch 30/60, Training Loss: 1.4453, Validation Loss: 1.0532\n",
      "[Trial 18] Epoch 12/60, Training Loss: 0.9840, Validation Loss: 0.8121\n",
      "[Trial 21] Epoch 13/60, Training Loss: 1.5434, Validation Loss: 1.3563\n",
      "[Trial 20] Epoch 27/60, Training Loss: 1.2412, Validation Loss: 0.8918\n",
      "[Trial 17] Epoch 37/60, Training Loss: 0.7263, Validation Loss: 0.6074\n",
      "[Trial 0] Epoch 44/60, Training Loss: 0.7352, Validation Loss: 0.5773\n",
      "[Trial 23] Epoch 32/60, Training Loss: 2.6751, Validation Loss: 2.1142\n",
      "[Trial 9] Epoch 22/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 12] Epoch 38/60, Training Loss: 1.7275, Validation Loss: 1.4174\n",
      "[Trial 19] Epoch 30/60, Training Loss: 19.3907, Validation Loss: 19.2992\n",
      "[Trial 24] Epoch 31/60, Training Loss: 1.4341, Validation Loss: 1.0059\n",
      "[Trial 4] Epoch 36/60, Training Loss: 0.5935, Validation Loss: 0.5090\n",
      "[Trial 27] Epoch 1/60, Training Loss: 3.1681, Validation Loss: 1.8175\n",
      "[Trial 20] Epoch 28/60, Training Loss: 1.2359, Validation Loss: 0.8992\n",
      "[Trial 23] Epoch 33/60, Training Loss: 2.6212, Validation Loss: 2.0958\n",
      "[Trial 17] Epoch 38/60, Training Loss: 0.6960, Validation Loss: 0.6091\n",
      "[Trial 24] Epoch 32/60, Training Loss: 1.4069, Validation Loss: 1.0220\n",
      "[Trial 6] Epoch 37/60, Training Loss: 0.5862, Validation Loss: 0.5206\n",
      "[Trial 26] Epoch 2/60, Training Loss: 1.7104, Validation Loss: 1.1211\n",
      "[Trial 25] Epoch 6/60, Training Loss: 1.0206, Validation Loss: 1.1439\n",
      "[Trial 19] Epoch 31/60, Training Loss: 18.3790, Validation Loss: 17.7388\n",
      "[Trial 22] Epoch 8/60, Training Loss: 0.9190, Validation Loss: 0.8003\n",
      "[Trial 21] Epoch 14/60, Training Loss: 1.4752, Validation Loss: 2.3242\n",
      "[Trial 23] Epoch 34/60, Training Loss: 2.5777, Validation Loss: 2.0894\n",
      "[Trial 0] Epoch 45/60, Training Loss: 0.7313, Validation Loss: 0.5768\n",
      "[Trial 24] Epoch 33/60, Training Loss: 1.4208, Validation Loss: 1.0138\n",
      "[Trial 20] Epoch 29/60, Training Loss: 1.2344, Validation Loss: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:05:22,159] Trial 12 finished with value: 1.2526650110880533 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 2.7581918267234887e-05, 'batch_size': 16, 'patience': 4}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 12] Epoch 39/60, Training Loss: 1.7300, Validation Loss: 1.2942\n",
      "[Trial 12] Early stopping after 39 epochs.\n",
      "[Trial 17] Epoch 39/60, Training Loss: 0.6327, Validation Loss: 0.5730\n",
      "[Trial 23] Epoch 35/60, Training Loss: 2.5502, Validation Loss: 2.0455\n",
      "[Trial 4] Epoch 37/60, Training Loss: 0.5892, Validation Loss: 0.5099\n",
      "[Trial 24] Epoch 34/60, Training Loss: 1.3981, Validation Loss: 1.0267\n",
      "[Trial 19] Epoch 32/60, Training Loss: 17.4195, Validation Loss: 26.6849\n",
      "[Trial 18] Epoch 13/60, Training Loss: 0.9515, Validation Loss: 0.7657\n",
      "[Trial 27] Epoch 2/60, Training Loss: 1.6606, Validation Loss: 1.2555\n",
      "[Trial 26] Epoch 3/60, Training Loss: 1.3523, Validation Loss: 1.1128\n",
      "[Trial 6] Epoch 38/60, Training Loss: 0.5845, Validation Loss: 0.5377\n",
      "[Trial 25] Epoch 7/60, Training Loss: 1.0723, Validation Loss: 0.9982\n",
      "[Trial 23] Epoch 36/60, Training Loss: 2.4975, Validation Loss: 2.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:06:00,104] Trial 20 finished with value: 0.8917519450187683 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.0007307430511273894, 'batch_size': 32, 'patience': 3}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 20] Epoch 30/60, Training Loss: 1.2334, Validation Loss: 0.8951\n",
      "[Trial 20] Early stopping after 30 epochs.\n",
      "[Trial 24] Epoch 35/60, Training Loss: 1.3857, Validation Loss: 1.0155\n",
      "[Trial 17] Epoch 40/60, Training Loss: 0.6276, Validation Loss: 0.5379\n",
      "[Trial 0] Epoch 46/60, Training Loss: 0.7239, Validation Loss: 0.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:06:11,281] Trial 9 finished with value: 1.1794321104884147 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.06828982503828891, 'batch_size': 8, 'patience': 9}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 9] Epoch 23/60, Training Loss: nan, Validation Loss: nan\n",
      "[Trial 9] Early stopping after 23 epochs.\n",
      "[Trial 21] Epoch 15/60, Training Loss: 1.4884, Validation Loss: 1.4846\n",
      "[Trial 19] Epoch 33/60, Training Loss: 17.3827, Validation Loss: 17.6182\n",
      "[Trial 23] Epoch 37/60, Training Loss: 2.4709, Validation Loss: 2.0158\n",
      "[Trial 28] Epoch 1/60, Training Loss: 3.1646, Validation Loss: 1.5312\n",
      "[Trial 24] Epoch 36/60, Training Loss: 1.3701, Validation Loss: 0.9651\n",
      "[Trial 30] Epoch 1/60, Training Loss: 5.4910, Validation Loss: 2.4856\n",
      "[Trial 4] Epoch 38/60, Training Loss: 0.5891, Validation Loss: 0.5006\n",
      "[Trial 17] Epoch 41/60, Training Loss: 0.6163, Validation Loss: 0.5221\n",
      "[Trial 23] Epoch 38/60, Training Loss: 2.4404, Validation Loss: 2.0605\n",
      "[Trial 27] Epoch 3/60, Training Loss: 1.2999, Validation Loss: 1.0227\n",
      "[Trial 24] Epoch 37/60, Training Loss: 1.3688, Validation Loss: 0.9634\n",
      "[Trial 26] Epoch 4/60, Training Loss: 1.1460, Validation Loss: 0.8794\n",
      "[Trial 22] Epoch 9/60, Training Loss: 0.9097, Validation Loss: 0.7501\n",
      "[Trial 30] Epoch 2/60, Training Loss: 2.2328, Validation Loss: 1.4920\n",
      "[Trial 25] Epoch 8/60, Training Loss: 0.9262, Validation Loss: 0.7092\n",
      "[Trial 19] Epoch 34/60, Training Loss: 15.8549, Validation Loss: 19.2321\n",
      "[Trial 6] Epoch 39/60, Training Loss: 0.5863, Validation Loss: 0.5371\n",
      "[Trial 29] Epoch 1/60, Training Loss: 3.1267, Validation Loss: 1.8740\n",
      "[Trial 0] Epoch 47/60, Training Loss: 0.7188, Validation Loss: 0.5624\n",
      "[Trial 23] Epoch 39/60, Training Loss: 2.3895, Validation Loss: 1.9668\n",
      "[Trial 24] Epoch 38/60, Training Loss: 1.3499, Validation Loss: 0.9329\n",
      "[Trial 21] Epoch 16/60, Training Loss: 1.5018, Validation Loss: 1.3317\n",
      "[Trial 17] Epoch 42/60, Training Loss: 0.6124, Validation Loss: 0.5560\n",
      "[Trial 30] Epoch 3/60, Training Loss: 1.8303, Validation Loss: 1.3749\n",
      "[Trial 28] Epoch 2/60, Training Loss: 1.6725, Validation Loss: 1.0971\n",
      "[Trial 18] Epoch 14/60, Training Loss: 0.8547, Validation Loss: 0.6734\n",
      "[Trial 23] Epoch 40/60, Training Loss: 2.3623, Validation Loss: 1.9945\n",
      "[Trial 19] Epoch 35/60, Training Loss: 15.4914, Validation Loss: 17.6978\n",
      "[Trial 24] Epoch 39/60, Training Loss: 1.3338, Validation Loss: 0.9504\n",
      "[Trial 30] Epoch 4/60, Training Loss: 1.6483, Validation Loss: 1.2648\n",
      "[Trial 4] Epoch 39/60, Training Loss: 0.5903, Validation Loss: 0.5056\n",
      "[Trial 27] Epoch 4/60, Training Loss: 1.1432, Validation Loss: 0.9812\n",
      "[Trial 26] Epoch 5/60, Training Loss: 1.0400, Validation Loss: 0.7397\n",
      "[Trial 17] Epoch 43/60, Training Loss: 0.6232, Validation Loss: 0.5550\n",
      "[Trial 23] Epoch 41/60, Training Loss: 2.3443, Validation Loss: 1.9647\n",
      "[Trial 25] Epoch 9/60, Training Loss: 0.8787, Validation Loss: 0.7419\n",
      "[Trial 29] Epoch 2/60, Training Loss: 1.6684, Validation Loss: 1.2175\n",
      "[Trial 6] Epoch 40/60, Training Loss: 0.5785, Validation Loss: 0.5417\n",
      "[Trial 24] Epoch 40/60, Training Loss: 1.3123, Validation Loss: 0.9269\n",
      "[Trial 0] Epoch 48/60, Training Loss: 0.7142, Validation Loss: 0.5885\n",
      "[Trial 30] Epoch 5/60, Training Loss: 1.4917, Validation Loss: 1.0532\n",
      "[Trial 19] Epoch 36/60, Training Loss: 18.2046, Validation Loss: 18.2235\n",
      "[Trial 23] Epoch 42/60, Training Loss: 2.3124, Validation Loss: 1.9565\n",
      "[Trial 21] Epoch 17/60, Training Loss: 1.5626, Validation Loss: 1.2613\n",
      "[Trial 28] Epoch 3/60, Training Loss: 1.3179, Validation Loss: 1.0824\n",
      "[Trial 30] Epoch 6/60, Training Loss: 1.3602, Validation Loss: 0.9329\n",
      "[Trial 24] Epoch 41/60, Training Loss: 1.3148, Validation Loss: 0.9604\n",
      "[Trial 17] Epoch 44/60, Training Loss: 0.6269, Validation Loss: 0.5710\n",
      "[Trial 23] Epoch 43/60, Training Loss: 2.2764, Validation Loss: 1.9511\n",
      "[Trial 22] Epoch 10/60, Training Loss: 0.8593, Validation Loss: 0.7433\n",
      "[Trial 4] Epoch 40/60, Training Loss: 0.5817, Validation Loss: 0.4956\n",
      "[Trial 27] Epoch 5/60, Training Loss: 1.0175, Validation Loss: 0.9062\n",
      "[Trial 30] Epoch 7/60, Training Loss: 1.1644, Validation Loss: 1.0769\n",
      "[Trial 24] Epoch 42/60, Training Loss: 1.2945, Validation Loss: 0.9327\n",
      "[Trial 19] Epoch 37/60, Training Loss: 18.3314, Validation Loss: 18.4010\n",
      "[Trial 26] Epoch 6/60, Training Loss: 0.9783, Validation Loss: 0.7478\n",
      "[Trial 25] Epoch 10/60, Training Loss: 0.8478, Validation Loss: 0.8315\n",
      "[Trial 29] Epoch 3/60, Training Loss: 1.3178, Validation Loss: 0.9578\n",
      "[Trial 0] Epoch 49/60, Training Loss: 0.7182, Validation Loss: 0.5725\n",
      "[Trial 18] Epoch 15/60, Training Loss: 0.8606, Validation Loss: 0.6538\n",
      "[Trial 6] Epoch 41/60, Training Loss: 0.5821, Validation Loss: 0.5148\n",
      "[Trial 23] Epoch 44/60, Training Loss: 2.2506, Validation Loss: 1.8826\n",
      "[Trial 17] Epoch 45/60, Training Loss: 0.6256, Validation Loss: 0.6061\n",
      "[Trial 30] Epoch 8/60, Training Loss: 1.1264, Validation Loss: 0.8703\n",
      "[Trial 24] Epoch 43/60, Training Loss: 1.2867, Validation Loss: 0.9591\n",
      "[Trial 28] Epoch 4/60, Training Loss: 1.1327, Validation Loss: 0.9084\n",
      "[Trial 21] Epoch 18/60, Training Loss: 1.3392, Validation Loss: 1.9608\n",
      "[Trial 19] Epoch 38/60, Training Loss: 17.4063, Validation Loss: 18.4022\n",
      "[Trial 23] Epoch 45/60, Training Loss: 2.2277, Validation Loss: 1.8911\n",
      "[Trial 30] Epoch 9/60, Training Loss: 1.0457, Validation Loss: 0.7891\n",
      "[Trial 24] Epoch 44/60, Training Loss: 1.2788, Validation Loss: 0.9249\n",
      "[Trial 17] Epoch 46/60, Training Loss: 0.6246, Validation Loss: 0.5823\n",
      "[Trial 27] Epoch 6/60, Training Loss: 0.9816, Validation Loss: 0.7810\n",
      "[Trial 4] Epoch 41/60, Training Loss: 0.5925, Validation Loss: 0.5093\n",
      "[Trial 23] Epoch 46/60, Training Loss: 2.2030, Validation Loss: 1.9047\n",
      "[Trial 26] Epoch 7/60, Training Loss: 0.9536, Validation Loss: 0.8246\n",
      "[Trial 30] Epoch 10/60, Training Loss: 1.0122, Validation Loss: 0.8776\n",
      "[Trial 0] Epoch 50/60, Training Loss: 0.7188, Validation Loss: 0.5688\n",
      "[Trial 29] Epoch 4/60, Training Loss: 1.1367, Validation Loss: 1.1722\n",
      "[Trial 25] Epoch 11/60, Training Loss: 0.8508, Validation Loss: 0.8881\n",
      "[Trial 24] Epoch 45/60, Training Loss: 1.2590, Validation Loss: 0.9113\n",
      "[Trial 19] Epoch 39/60, Training Loss: 17.3387, Validation Loss: 17.2862\n",
      "[Trial 6] Epoch 42/60, Training Loss: 0.5704, Validation Loss: 0.5418\n",
      "[Trial 23] Epoch 47/60, Training Loss: 2.1892, Validation Loss: 1.8616\n",
      "[Trial 30] Epoch 11/60, Training Loss: 0.9912, Validation Loss: 0.7249\n",
      "[Trial 28] Epoch 5/60, Training Loss: 1.0474, Validation Loss: 0.9515\n",
      "[Trial 17] Epoch 47/60, Training Loss: 0.5843, Validation Loss: 0.4925\n",
      "[Trial 24] Epoch 46/60, Training Loss: 1.2381, Validation Loss: 0.9278\n",
      "[Trial 21] Epoch 19/60, Training Loss: 1.4480, Validation Loss: 1.1629\n",
      "[Trial 22] Epoch 11/60, Training Loss: 0.8747, Validation Loss: 0.7880\n",
      "[Trial 30] Epoch 12/60, Training Loss: 0.9242, Validation Loss: 0.8040\n",
      "[Trial 23] Epoch 48/60, Training Loss: 2.1522, Validation Loss: 1.8589\n",
      "[Trial 18] Epoch 16/60, Training Loss: 0.8510, Validation Loss: 0.6323\n",
      "[Trial 19] Epoch 40/60, Training Loss: 16.0308, Validation Loss: 15.9718\n",
      "[Trial 27] Epoch 7/60, Training Loss: 0.9219, Validation Loss: 0.7974\n",
      "[Trial 24] Epoch 47/60, Training Loss: 1.2246, Validation Loss: 0.9049\n",
      "[Trial 0] Epoch 51/60, Training Loss: 0.7078, Validation Loss: 0.5686\n",
      "[Trial 4] Epoch 42/60, Training Loss: 0.5840, Validation Loss: 0.4970\n",
      "[Trial 26] Epoch 8/60, Training Loss: 0.9130, Validation Loss: 0.8770\n",
      "[Trial 29] Epoch 5/60, Training Loss: 1.0589, Validation Loss: 0.7930\n",
      "[Trial 17] Epoch 48/60, Training Loss: 0.5723, Validation Loss: 0.5208\n",
      "[Trial 25] Epoch 12/60, Training Loss: 0.8321, Validation Loss: 0.7979\n",
      "[Trial 30] Epoch 13/60, Training Loss: 0.9308, Validation Loss: 0.7455\n",
      "[Trial 23] Epoch 49/60, Training Loss: 2.1464, Validation Loss: 1.8300\n",
      "[Trial 24] Epoch 48/60, Training Loss: 1.2130, Validation Loss: 0.8725\n",
      "[Trial 6] Epoch 43/60, Training Loss: 0.5719, Validation Loss: 0.5295\n",
      "[Trial 28] Epoch 6/60, Training Loss: 0.9922, Validation Loss: 0.7532\n",
      "[Trial 19] Epoch 41/60, Training Loss: 14.9104, Validation Loss: 17.5306\n",
      "[Trial 30] Epoch 14/60, Training Loss: 0.8928, Validation Loss: 0.6875\n",
      "[Trial 23] Epoch 50/60, Training Loss: 2.1264, Validation Loss: 1.8400\n",
      "[Trial 21] Epoch 20/60, Training Loss: 1.2842, Validation Loss: 1.6951\n",
      "[Trial 17] Epoch 49/60, Training Loss: 0.5694, Validation Loss: 0.5199\n",
      "[Trial 24] Epoch 49/60, Training Loss: 1.2029, Validation Loss: 0.8921\n",
      "[Trial 27] Epoch 8/60, Training Loss: 0.8597, Validation Loss: 0.7140\n",
      "[Trial 30] Epoch 15/60, Training Loss: 0.8798, Validation Loss: 0.8786\n",
      "[Trial 0] Epoch 52/60, Training Loss: 0.6914, Validation Loss: 0.5455\n",
      "[Trial 23] Epoch 51/60, Training Loss: 2.1023, Validation Loss: 1.8008\n",
      "[Trial 26] Epoch 9/60, Training Loss: 0.8948, Validation Loss: 0.7611\n",
      "[Trial 29] Epoch 6/60, Training Loss: 0.9595, Validation Loss: 0.9359\n",
      "[Trial 4] Epoch 43/60, Training Loss: 0.5852, Validation Loss: 0.5267\n",
      "[Trial 25] Epoch 13/60, Training Loss: 0.7520, Validation Loss: 0.6075\n",
      "[Trial 24] Epoch 50/60, Training Loss: 1.1780, Validation Loss: 0.8619\n",
      "[Trial 19] Epoch 42/60, Training Loss: 14.5319, Validation Loss: 14.4279\n",
      "[Trial 30] Epoch 16/60, Training Loss: 0.8975, Validation Loss: 0.6961\n",
      "[Trial 17] Epoch 50/60, Training Loss: 0.5777, Validation Loss: 0.5073\n",
      "[Trial 23] Epoch 52/60, Training Loss: 2.0798, Validation Loss: 1.7810\n",
      "[Trial 6] Epoch 44/60, Training Loss: 0.5752, Validation Loss: 0.5154\n",
      "[Trial 28] Epoch 7/60, Training Loss: 0.9258, Validation Loss: 0.7757\n",
      "[Trial 22] Epoch 12/60, Training Loss: 0.8389, Validation Loss: 0.9697\n",
      "[Trial 18] Epoch 17/60, Training Loss: 0.8336, Validation Loss: 0.6408\n",
      "[Trial 24] Epoch 51/60, Training Loss: 1.1839, Validation Loss: 0.8542\n",
      "[Trial 30] Epoch 17/60, Training Loss: 0.8314, Validation Loss: 0.6205\n",
      "[Trial 21] Epoch 21/60, Training Loss: 1.2721, Validation Loss: 2.0982\n",
      "[Trial 19] Epoch 43/60, Training Loss: 14.0385, Validation Loss: 14.0198\n",
      "[Trial 23] Epoch 53/60, Training Loss: 2.0672, Validation Loss: 1.7718\n",
      "[Trial 0] Epoch 53/60, Training Loss: 0.6885, Validation Loss: 0.5466\n",
      "[Trial 27] Epoch 9/60, Training Loss: 0.8559, Validation Loss: 1.1759\n",
      "[Trial 24] Epoch 52/60, Training Loss: 1.1644, Validation Loss: 0.8893\n",
      "[Trial 17] Epoch 51/60, Training Loss: 0.5722, Validation Loss: 0.5137\n",
      "[Trial 30] Epoch 18/60, Training Loss: 0.8151, Validation Loss: 0.6299\n",
      "[Trial 26] Epoch 10/60, Training Loss: 0.8605, Validation Loss: 0.6825\n",
      "[Trial 29] Epoch 7/60, Training Loss: 0.9447, Validation Loss: 0.7256\n",
      "[Trial 25] Epoch 14/60, Training Loss: 0.7172, Validation Loss: 0.5851\n",
      "[Trial 23] Epoch 54/60, Training Loss: 2.0534, Validation Loss: 1.7480\n",
      "[Trial 4] Epoch 44/60, Training Loss: 0.5784, Validation Loss: 0.4962\n",
      "[Trial 24] Epoch 53/60, Training Loss: 1.1503, Validation Loss: 0.8626\n",
      "[Trial 19] Epoch 44/60, Training Loss: 13.3410, Validation Loss: 12.8509\n",
      "[Trial 30] Epoch 19/60, Training Loss: 0.8067, Validation Loss: 0.6435\n",
      "[Trial 28] Epoch 8/60, Training Loss: 0.8828, Validation Loss: 0.7004\n",
      "[Trial 6] Epoch 45/60, Training Loss: 0.5771, Validation Loss: 0.5097\n",
      "[Trial 17] Epoch 52/60, Training Loss: 0.5736, Validation Loss: 0.5071\n",
      "[Trial 23] Epoch 55/60, Training Loss: 2.0552, Validation Loss: 1.7680\n",
      "[Trial 24] Epoch 54/60, Training Loss: 1.1318, Validation Loss: 0.8528\n",
      "[Trial 21] Epoch 22/60, Training Loss: 1.4394, Validation Loss: 1.1419\n",
      "[Trial 30] Epoch 20/60, Training Loss: 0.7820, Validation Loss: 0.6077\n",
      "[Trial 0] Epoch 54/60, Training Loss: 0.6958, Validation Loss: 0.5393\n",
      "[Trial 27] Epoch 10/60, Training Loss: 0.9065, Validation Loss: 0.7007\n",
      "[Trial 23] Epoch 56/60, Training Loss: 2.0183, Validation Loss: 1.7198\n",
      "[Trial 19] Epoch 45/60, Training Loss: 12.7272, Validation Loss: 12.9361\n",
      "[Trial 26] Epoch 11/60, Training Loss: 0.8240, Validation Loss: 0.6703\n",
      "[Trial 29] Epoch 8/60, Training Loss: 0.9017, Validation Loss: 0.7840\n",
      "[Trial 24] Epoch 55/60, Training Loss: 1.1086, Validation Loss: 0.8166\n",
      "[Trial 25] Epoch 15/60, Training Loss: 0.7121, Validation Loss: 0.5914\n",
      "[Trial 30] Epoch 21/60, Training Loss: 0.7884, Validation Loss: 0.7130\n",
      "[Trial 17] Epoch 53/60, Training Loss: 0.5552, Validation Loss: 0.5027\n",
      "[Trial 18] Epoch 18/60, Training Loss: 0.8362, Validation Loss: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:14:37,382] Trial 4 finished with value: 0.495582015812397 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.006636311474790783, 'batch_size': 16, 'patience': 5}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 4] Epoch 45/60, Training Loss: 0.5840, Validation Loss: 0.5025\n",
      "[Trial 4] Early stopping after 45 epochs.\n",
      "[Trial 22] Epoch 13/60, Training Loss: 0.8411, Validation Loss: 0.9966\n",
      "[Trial 23] Epoch 57/60, Training Loss: 1.9995, Validation Loss: 1.7064\n",
      "[Trial 28] Epoch 9/60, Training Loss: 0.8664, Validation Loss: 0.9531\n",
      "[Trial 6] Epoch 46/60, Training Loss: 0.5778, Validation Loss: 0.5655\n",
      "[Trial 24] Epoch 56/60, Training Loss: 1.1034, Validation Loss: 0.7986\n",
      "[Trial 30] Epoch 22/60, Training Loss: 0.8067, Validation Loss: 0.6745\n",
      "[Trial 19] Epoch 46/60, Training Loss: 12.1614, Validation Loss: 12.3154\n",
      "[Trial 23] Epoch 58/60, Training Loss: 1.9800, Validation Loss: 1.6791\n",
      "[Trial 0] Epoch 55/60, Training Loss: 0.6811, Validation Loss: 0.5363\n",
      "[Trial 17] Epoch 54/60, Training Loss: 0.5491, Validation Loss: 0.4811\n",
      "[Trial 21] Epoch 23/60, Training Loss: 1.2904, Validation Loss: 1.1327\n",
      "[Trial 24] Epoch 57/60, Training Loss: 1.0820, Validation Loss: 0.8189\n",
      "[Trial 30] Epoch 23/60, Training Loss: 0.7887, Validation Loss: 0.6374\n",
      "[Trial 27] Epoch 11/60, Training Loss: 0.8052, Validation Loss: 0.6657\n",
      "[Trial 29] Epoch 9/60, Training Loss: 0.8520, Validation Loss: 0.8661\n",
      "[Trial 26] Epoch 12/60, Training Loss: 0.7965, Validation Loss: 0.6712\n",
      "[Trial 23] Epoch 59/60, Training Loss: 1.9664, Validation Loss: 1.6910\n",
      "[Trial 25] Epoch 16/60, Training Loss: 0.7038, Validation Loss: 0.6243\n",
      "[Trial 30] Epoch 24/60, Training Loss: 0.7548, Validation Loss: 0.6435\n",
      "[Trial 19] Epoch 47/60, Training Loss: 11.6664, Validation Loss: 12.3145\n",
      "[Trial 24] Epoch 58/60, Training Loss: 1.0779, Validation Loss: 0.8272\n",
      "[Trial 31] Epoch 1/60, Training Loss: 5.3189, Validation Loss: 2.0258\n",
      "[Trial 28] Epoch 10/60, Training Loss: 0.8475, Validation Loss: 0.6841\n",
      "[Trial 17] Epoch 55/60, Training Loss: 0.5483, Validation Loss: 0.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:15:58,565] Trial 23 finished with value: 1.671994725863139 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 2.580404171793656e-05, 'batch_size': 64, 'patience': 5}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 23] Epoch 60/60, Training Loss: 1.9675, Validation Loss: 1.6720\n",
      "[Trial 6] Epoch 47/60, Training Loss: 0.5824, Validation Loss: 0.5972\n",
      "[Trial 30] Epoch 25/60, Training Loss: 0.7589, Validation Loss: 0.6062\n",
      "[Trial 24] Epoch 59/60, Training Loss: 1.0478, Validation Loss: 0.8095\n",
      "[Trial 0] Epoch 56/60, Training Loss: 0.6768, Validation Loss: 0.5423\n",
      "[Trial 21] Epoch 24/60, Training Loss: 1.2286, Validation Loss: 5.1475\n",
      "[Trial 18] Epoch 19/60, Training Loss: 0.8337, Validation Loss: 0.7718\n",
      "[Trial 19] Epoch 48/60, Training Loss: 11.2576, Validation Loss: 11.3383\n",
      "[Trial 27] Epoch 12/60, Training Loss: 0.7880, Validation Loss: 0.5962\n",
      "[Trial 17] Epoch 56/60, Training Loss: 0.5474, Validation Loss: 0.4803\n",
      "[Trial 30] Epoch 26/60, Training Loss: 0.7520, Validation Loss: 0.5908\n",
      "[Trial 29] Epoch 10/60, Training Loss: 0.8402, Validation Loss: 0.6343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:16:35,188] Trial 24 finished with value: 0.7960556983947754 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 0.0002229032950194669, 'batch_size': 64, 'patience': 8}. Best is trial 14 with value: 0.4819520185391108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 24] Epoch 60/60, Training Loss: 1.0537, Validation Loss: 0.7961\n",
      "[Trial 26] Epoch 13/60, Training Loss: 0.7817, Validation Loss: 0.7491\n",
      "[Trial 22] Epoch 14/60, Training Loss: 0.8453, Validation Loss: 0.7017\n",
      "[Trial 25] Epoch 17/60, Training Loss: 0.7072, Validation Loss: 0.6289\n",
      "[Trial 31] Epoch 2/60, Training Loss: 2.0023, Validation Loss: 1.9722\n",
      "[Trial 28] Epoch 11/60, Training Loss: 0.8105, Validation Loss: 0.8151\n",
      "[Trial 30] Epoch 27/60, Training Loss: 0.7414, Validation Loss: 0.5864\n",
      "[Trial 19] Epoch 49/60, Training Loss: 11.1726, Validation Loss: 11.6607\n",
      "[Trial 32] Epoch 1/60, Training Loss: 7.9873, Validation Loss: 2.8677\n",
      "[Trial 6] Epoch 48/60, Training Loss: 0.5704, Validation Loss: 0.5216\n",
      "[Trial 17] Epoch 57/60, Training Loss: 0.5455, Validation Loss: 0.4846\n",
      "[Trial 0] Epoch 57/60, Training Loss: 0.6716, Validation Loss: 0.5393\n",
      "[Trial 30] Epoch 28/60, Training Loss: 0.7432, Validation Loss: 0.5928\n",
      "[Trial 21] Epoch 25/60, Training Loss: 1.3684, Validation Loss: 7.2112\n",
      "[Trial 27] Epoch 13/60, Training Loss: 0.7600, Validation Loss: 0.6251\n",
      "[Trial 29] Epoch 11/60, Training Loss: 0.8153, Validation Loss: 0.7527\n",
      "[Trial 26] Epoch 14/60, Training Loss: 0.7757, Validation Loss: 0.6649\n",
      "[Trial 30] Epoch 29/60, Training Loss: 0.7123, Validation Loss: 0.6012\n",
      "[Trial 25] Epoch 18/60, Training Loss: 0.7022, Validation Loss: 0.6340\n",
      "[Trial 33] Epoch 1/60, Training Loss: 4.8357, Validation Loss: 2.5262\n",
      "[Trial 19] Epoch 50/60, Training Loss: 10.4986, Validation Loss: 10.2960\n",
      "[Trial 17] Epoch 58/60, Training Loss: 0.5482, Validation Loss: 0.4964\n",
      "[Trial 28] Epoch 12/60, Training Loss: 0.8098, Validation Loss: 0.5780\n",
      "[Trial 31] Epoch 3/60, Training Loss: 1.5952, Validation Loss: 1.2797\n",
      "[Trial 30] Epoch 30/60, Training Loss: 0.7219, Validation Loss: 0.5792\n",
      "[Trial 18] Epoch 20/60, Training Loss: 0.8282, Validation Loss: 0.6429\n",
      "[Trial 32] Epoch 2/60, Training Loss: 2.1779, Validation Loss: 1.5815\n",
      "[Trial 6] Epoch 49/60, Training Loss: 0.5773, Validation Loss: 0.5429\n",
      "[Trial 0] Epoch 58/60, Training Loss: 0.6729, Validation Loss: 0.5424\n",
      "[Trial 19] Epoch 51/60, Training Loss: 10.0905, Validation Loss: 10.0977\n",
      "[Trial 17] Epoch 59/60, Training Loss: 0.5522, Validation Loss: 0.4747\n",
      "[Trial 30] Epoch 31/60, Training Loss: 0.7119, Validation Loss: 0.5995\n",
      "[Trial 22] Epoch 15/60, Training Loss: 0.8304, Validation Loss: 0.7467\n",
      "[Trial 21] Epoch 26/60, Training Loss: 18.1035, Validation Loss: 3.2338\n",
      "[Trial 27] Epoch 14/60, Training Loss: 0.7657, Validation Loss: 0.6960\n",
      "[Trial 29] Epoch 12/60, Training Loss: 0.8336, Validation Loss: 0.7748\n",
      "[Trial 26] Epoch 15/60, Training Loss: 0.7601, Validation Loss: 0.6877\n",
      "[Trial 25] Epoch 19/60, Training Loss: 0.6559, Validation Loss: 0.5572\n",
      "[Trial 33] Epoch 2/60, Training Loss: 1.9143, Validation Loss: 1.5226\n",
      "[Trial 30] Epoch 32/60, Training Loss: 0.7211, Validation Loss: 0.6422\n",
      "[Trial 28] Epoch 13/60, Training Loss: 0.7686, Validation Loss: 0.6841\n",
      "[Trial 19] Epoch 52/60, Training Loss: 9.7389, Validation Loss: 10.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:19:03,036] Trial 17 finished with value: 0.4747499664624532 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.014168872519325975, 'batch_size': 32, 'patience': 8}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 17] Epoch 60/60, Training Loss: 0.5456, Validation Loss: 0.5083\n",
      "[Trial 31] Epoch 4/60, Training Loss: 1.2772, Validation Loss: 1.3410\n",
      "[Trial 0] Epoch 59/60, Training Loss: 0.6786, Validation Loss: 0.5349\n",
      "[Trial 32] Epoch 3/60, Training Loss: 1.7496, Validation Loss: 1.3199\n",
      "[Trial 30] Epoch 33/60, Training Loss: 0.7188, Validation Loss: 0.5874\n",
      "[Trial 6] Epoch 50/60, Training Loss: 0.5640, Validation Loss: 0.5139\n",
      "[Trial 27] Epoch 15/60, Training Loss: 0.7809, Validation Loss: 0.8377\n",
      "[Trial 21] Epoch 27/60, Training Loss: 2.9523, Validation Loss: 2.6875\n",
      "[Trial 30] Epoch 34/60, Training Loss: 0.7079, Validation Loss: 0.5852\n",
      "[Trial 29] Epoch 13/60, Training Loss: 0.7897, Validation Loss: 0.6158\n",
      "[Trial 19] Epoch 53/60, Training Loss: 9.3944, Validation Loss: 8.9542\n",
      "[Trial 34] Epoch 1/60, Training Loss: 10.8456, Validation Loss: 3.2071\n",
      "[Trial 26] Epoch 16/60, Training Loss: 0.7791, Validation Loss: 0.7730\n",
      "[Trial 25] Epoch 20/60, Training Loss: 0.6571, Validation Loss: 0.5778\n",
      "[Trial 18] Epoch 21/60, Training Loss: 0.7680, Validation Loss: 0.6125\n",
      "[Trial 33] Epoch 3/60, Training Loss: 1.4790, Validation Loss: 1.1146\n",
      "[Trial 28] Epoch 14/60, Training Loss: 0.7796, Validation Loss: 0.7738\n",
      "[Trial 30] Epoch 35/60, Training Loss: 0.6924, Validation Loss: 0.5618\n",
      "[Trial 31] Epoch 5/60, Training Loss: 1.1799, Validation Loss: 1.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:20:15,654] Trial 0 finished with value: 0.5348610038558642 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'learning_rate': 0.00045295916890157525, 'batch_size': 16, 'patience': 6}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 60/60, Training Loss: 0.6757, Validation Loss: 0.5367\n",
      "[Trial 19] Epoch 54/60, Training Loss: 9.0566, Validation Loss: 8.7696\n",
      "[Trial 32] Epoch 4/60, Training Loss: 1.5013, Validation Loss: 2.1541\n",
      "[Trial 34] Epoch 2/60, Training Loss: 2.3658, Validation Loss: 2.1696\n",
      "[Trial 6] Epoch 51/60, Training Loss: 0.5486, Validation Loss: 0.4992\n",
      "[Trial 22] Epoch 16/60, Training Loss: 0.8060, Validation Loss: 0.7407\n",
      "[Trial 30] Epoch 36/60, Training Loss: 0.7064, Validation Loss: 0.5958\n",
      "[Trial 27] Epoch 16/60, Training Loss: 0.7482, Validation Loss: 0.7019\n",
      "[Trial 29] Epoch 14/60, Training Loss: 0.7584, Validation Loss: 0.9267\n",
      "[Trial 21] Epoch 28/60, Training Loss: 2.4959, Validation Loss: 2.2862\n",
      "[Trial 26] Epoch 17/60, Training Loss: 0.8625, Validation Loss: 0.6650\n",
      "[Trial 30] Epoch 37/60, Training Loss: 0.7002, Validation Loss: 0.5825\n",
      "[Trial 25] Epoch 21/60, Training Loss: 0.6622, Validation Loss: 0.5636\n",
      "[Trial 35] Epoch 1/60, Training Loss: 14.5805, Validation Loss: 3.4986\n",
      "[Trial 19] Epoch 55/60, Training Loss: 8.8886, Validation Loss: 8.8871\n",
      "[Trial 34] Epoch 3/60, Training Loss: 1.9173, Validation Loss: 1.6914\n",
      "[Trial 28] Epoch 15/60, Training Loss: 0.7819, Validation Loss: 0.5891\n",
      "[Trial 33] Epoch 4/60, Training Loss: 1.3523, Validation Loss: 3.3710\n",
      "[Trial 30] Epoch 38/60, Training Loss: 0.7032, Validation Loss: 0.5640\n",
      "[Trial 31] Epoch 6/60, Training Loss: 1.0801, Validation Loss: 1.0429\n",
      "[Trial 32] Epoch 5/60, Training Loss: 1.3619, Validation Loss: 1.0037\n",
      "[Trial 6] Epoch 52/60, Training Loss: 0.5541, Validation Loss: 0.5034\n",
      "[Trial 35] Epoch 2/60, Training Loss: 2.7427, Validation Loss: 2.0840\n",
      "[Trial 30] Epoch 39/60, Training Loss: 0.6822, Validation Loss: 0.5770\n",
      "[Trial 19] Epoch 56/60, Training Loss: 8.6213, Validation Loss: 8.6604\n",
      "[Trial 34] Epoch 4/60, Training Loss: 1.6495, Validation Loss: 1.7022\n",
      "[Trial 18] Epoch 22/60, Training Loss: 0.7692, Validation Loss: 0.6209\n",
      "[Trial 27] Epoch 17/60, Training Loss: 0.7338, Validation Loss: 0.6117\n",
      "[Trial 29] Epoch 15/60, Training Loss: 0.7458, Validation Loss: 0.9822\n",
      "[Trial 21] Epoch 29/60, Training Loss: 2.3683, Validation Loss: 2.1035\n",
      "[Trial 26] Epoch 18/60, Training Loss: 0.7455, Validation Loss: 0.6106\n",
      "[Trial 25] Epoch 22/60, Training Loss: 0.6498, Validation Loss: 0.5554\n",
      "[Trial 30] Epoch 40/60, Training Loss: 0.6874, Validation Loss: 0.5748\n",
      "[Trial 28] Epoch 16/60, Training Loss: 0.7408, Validation Loss: 0.7543\n",
      "[Trial 33] Epoch 5/60, Training Loss: 1.3132, Validation Loss: 0.8773\n",
      "[Trial 35] Epoch 3/60, Training Loss: 2.0398, Validation Loss: 1.5205\n",
      "[Trial 22] Epoch 17/60, Training Loss: 0.8056, Validation Loss: 0.7052\n",
      "[Trial 19] Epoch 57/60, Training Loss: 8.3583, Validation Loss: 8.4072\n",
      "[Trial 34] Epoch 5/60, Training Loss: 1.4928, Validation Loss: 1.2539\n",
      "[Trial 31] Epoch 7/60, Training Loss: 1.0150, Validation Loss: 0.8382\n",
      "[Trial 30] Epoch 41/60, Training Loss: 0.6745, Validation Loss: 0.5946\n",
      "[Trial 32] Epoch 6/60, Training Loss: 1.1965, Validation Loss: 1.1522\n",
      "[Trial 6] Epoch 53/60, Training Loss: 0.5504, Validation Loss: 0.4909\n",
      "[Trial 27] Epoch 18/60, Training Loss: 0.7499, Validation Loss: 1.1323\n",
      "[Trial 30] Epoch 42/60, Training Loss: 0.6383, Validation Loss: 0.5222\n",
      "[Trial 29] Epoch 16/60, Training Loss: 0.7566, Validation Loss: 0.7126\n",
      "[Trial 35] Epoch 4/60, Training Loss: 1.7720, Validation Loss: 1.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:23:07,304] Trial 21 finished with value: 1.1327479789654413 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'learning_rate': 0.017130303125701636, 'batch_size': 16, 'patience': 7}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 21] Epoch 30/60, Training Loss: 2.2433, Validation Loss: 2.3312\n",
      "[Trial 21] Early stopping after 30 epochs.\n",
      "[Trial 26] Epoch 19/60, Training Loss: 0.7231, Validation Loss: 0.8013\n",
      "[Trial 19] Epoch 58/60, Training Loss: 8.2925, Validation Loss: 7.9665\n",
      "[Trial 34] Epoch 6/60, Training Loss: 1.3335, Validation Loss: 1.2794\n",
      "[Trial 25] Epoch 23/60, Training Loss: 0.6447, Validation Loss: 0.5345\n",
      "[Trial 28] Epoch 17/60, Training Loss: 0.7743, Validation Loss: 0.6008\n",
      "[Trial 30] Epoch 43/60, Training Loss: 0.6199, Validation Loss: 0.5292\n",
      "[Trial 33] Epoch 6/60, Training Loss: 1.0781, Validation Loss: 1.0439\n",
      "[Trial 18] Epoch 23/60, Training Loss: 0.7690, Validation Loss: 0.6296\n",
      "[Trial 31] Epoch 8/60, Training Loss: 0.9504, Validation Loss: 1.0025\n",
      "[Trial 35] Epoch 5/60, Training Loss: 1.5720, Validation Loss: 1.3229\n",
      "[Trial 30] Epoch 44/60, Training Loss: 0.6247, Validation Loss: 0.5229\n",
      "[Trial 34] Epoch 7/60, Training Loss: 1.2443, Validation Loss: 0.9522\n",
      "[Trial 19] Epoch 59/60, Training Loss: 8.1417, Validation Loss: 9.4846\n",
      "[Trial 32] Epoch 7/60, Training Loss: 1.1688, Validation Loss: 0.9416\n",
      "[Trial 6] Epoch 54/60, Training Loss: 0.5504, Validation Loss: 0.4856\n",
      "[Trial 27] Epoch 19/60, Training Loss: 0.7276, Validation Loss: 0.5554\n",
      "[Trial 29] Epoch 17/60, Training Loss: 0.7429, Validation Loss: 0.7375\n",
      "[Trial 30] Epoch 45/60, Training Loss: 0.6208, Validation Loss: 0.5122\n",
      "[Trial 26] Epoch 20/60, Training Loss: 0.7345, Validation Loss: 0.7246\n",
      "[Trial 36] Epoch 1/60, Training Loss: 4.9359, Validation Loss: 1.9140\n",
      "[Trial 25] Epoch 24/60, Training Loss: 0.6447, Validation Loss: 0.5928\n",
      "[Trial 28] Epoch 18/60, Training Loss: 0.7441, Validation Loss: 0.6781\n",
      "[Trial 22] Epoch 18/60, Training Loss: 0.8100, Validation Loss: 0.7998\n",
      "[Trial 35] Epoch 6/60, Training Loss: 1.4631, Validation Loss: 1.1149\n",
      "[Trial 34] Epoch 8/60, Training Loss: 1.1597, Validation Loss: 0.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:24:33,923] Trial 19 finished with value: 7.966457223892212 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.08138282516053706, 'batch_size': 32, 'patience': 6}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 19] Epoch 60/60, Training Loss: 7.9240, Validation Loss: 8.3660\n",
      "[Trial 30] Epoch 46/60, Training Loss: 0.6186, Validation Loss: 0.5173\n",
      "[Trial 33] Epoch 7/60, Training Loss: 1.0209, Validation Loss: 1.1076\n",
      "[Trial 31] Epoch 9/60, Training Loss: 0.9613, Validation Loss: 0.8465\n",
      "[Trial 30] Epoch 47/60, Training Loss: 0.6272, Validation Loss: 0.5381\n",
      "[Trial 32] Epoch 8/60, Training Loss: 1.0772, Validation Loss: 0.8370\n",
      "[Trial 6] Epoch 55/60, Training Loss: 0.5466, Validation Loss: 0.5012\n",
      "[Trial 27] Epoch 20/60, Training Loss: 0.6503, Validation Loss: 0.5425\n",
      "[Trial 29] Epoch 18/60, Training Loss: 0.7757, Validation Loss: 0.9272\n",
      "[Trial 35] Epoch 7/60, Training Loss: 1.2693, Validation Loss: 1.3108\n",
      "[Trial 34] Epoch 9/60, Training Loss: 1.1033, Validation Loss: 0.9765\n",
      "[Trial 26] Epoch 21/60, Training Loss: 0.7199, Validation Loss: 0.6051\n",
      "[Trial 36] Epoch 2/60, Training Loss: 2.0245, Validation Loss: 1.6391\n",
      "[Trial 30] Epoch 48/60, Training Loss: 0.6155, Validation Loss: 0.5224\n",
      "[Trial 25] Epoch 25/60, Training Loss: 0.6550, Validation Loss: 0.5306\n",
      "[Trial 28] Epoch 19/60, Training Loss: 0.6806, Validation Loss: 0.6246\n",
      "[Trial 18] Epoch 24/60, Training Loss: 0.7596, Validation Loss: 0.5753\n",
      "[Trial 37] Epoch 1/60, Training Loss: 4.8593, Validation Loss: 2.2979\n",
      "[Trial 30] Epoch 49/60, Training Loss: 0.6183, Validation Loss: 0.5072\n",
      "[Trial 33] Epoch 8/60, Training Loss: 1.0911, Validation Loss: 0.8789\n",
      "[Trial 35] Epoch 8/60, Training Loss: 1.2473, Validation Loss: 1.0675\n",
      "[Trial 34] Epoch 10/60, Training Loss: 1.0950, Validation Loss: 1.3250\n",
      "[Trial 31] Epoch 10/60, Training Loss: 0.9134, Validation Loss: 1.1177\n",
      "[Trial 32] Epoch 9/60, Training Loss: 1.0271, Validation Loss: 0.8694\n",
      "[Trial 30] Epoch 50/60, Training Loss: 0.6176, Validation Loss: 0.5104\n",
      "[Trial 27] Epoch 21/60, Training Loss: 0.6417, Validation Loss: 0.5448\n",
      "[Trial 6] Epoch 56/60, Training Loss: 0.5511, Validation Loss: 0.4916\n",
      "[Trial 29] Epoch 19/60, Training Loss: 0.7605, Validation Loss: 0.8017\n",
      "[Trial 22] Epoch 19/60, Training Loss: 0.8037, Validation Loss: 0.7499\n",
      "[Trial 26] Epoch 22/60, Training Loss: 0.7178, Validation Loss: 0.6406\n",
      "[Trial 36] Epoch 3/60, Training Loss: 1.5793, Validation Loss: 1.2221\n",
      "[Trial 25] Epoch 26/60, Training Loss: 0.6503, Validation Loss: 0.5806\n",
      "[Trial 28] Epoch 20/60, Training Loss: 0.6989, Validation Loss: 0.6012\n",
      "[Trial 35] Epoch 9/60, Training Loss: 1.1620, Validation Loss: 1.1359\n",
      "[Trial 34] Epoch 11/60, Training Loss: 1.0625, Validation Loss: 1.0449\n",
      "[Trial 30] Epoch 51/60, Training Loss: 0.6112, Validation Loss: 0.5332\n",
      "[Trial 37] Epoch 2/60, Training Loss: 1.9297, Validation Loss: 1.6178\n",
      "[Trial 33] Epoch 9/60, Training Loss: 0.9425, Validation Loss: 1.0429\n",
      "[Trial 30] Epoch 52/60, Training Loss: 0.6254, Validation Loss: 0.5196\n",
      "[Trial 31] Epoch 11/60, Training Loss: 0.8915, Validation Loss: 0.8496\n",
      "[Trial 35] Epoch 10/60, Training Loss: 1.0758, Validation Loss: 0.8575\n",
      "[Trial 32] Epoch 10/60, Training Loss: 1.0102, Validation Loss: 0.9772\n",
      "[Trial 34] Epoch 12/60, Training Loss: 1.0065, Validation Loss: 0.7687\n",
      "[Trial 18] Epoch 25/60, Training Loss: 0.7487, Validation Loss: 0.6143\n",
      "[Trial 29] Epoch 20/60, Training Loss: 0.7070, Validation Loss: 0.5532\n",
      "[Trial 27] Epoch 22/60, Training Loss: 0.6520, Validation Loss: 0.6566\n",
      "[Trial 6] Epoch 57/60, Training Loss: 0.5432, Validation Loss: 0.4824\n",
      "[Trial 30] Epoch 53/60, Training Loss: 0.6140, Validation Loss: 0.5254\n",
      "[Trial 26] Epoch 23/60, Training Loss: 0.6969, Validation Loss: 0.6647\n",
      "[Trial 28] Epoch 21/60, Training Loss: 0.6468, Validation Loss: 0.5423\n",
      "[Trial 36] Epoch 4/60, Training Loss: 1.3548, Validation Loss: 1.1270\n",
      "[Trial 25] Epoch 27/60, Training Loss: 0.6391, Validation Loss: 0.5717\n",
      "[Trial 30] Epoch 54/60, Training Loss: 0.6161, Validation Loss: 0.5217\n",
      "[Trial 37] Epoch 3/60, Training Loss: 1.5401, Validation Loss: 1.3215\n",
      "[Trial 35] Epoch 11/60, Training Loss: 1.0450, Validation Loss: 0.8992\n",
      "[Trial 34] Epoch 13/60, Training Loss: 0.9480, Validation Loss: 0.8104\n",
      "[Trial 33] Epoch 10/60, Training Loss: 0.8315, Validation Loss: 0.6642\n",
      "[Trial 31] Epoch 12/60, Training Loss: 0.7715, Validation Loss: 0.6671\n",
      "[Trial 30] Epoch 55/60, Training Loss: 0.6096, Validation Loss: 0.5245\n",
      "[Trial 22] Epoch 20/60, Training Loss: 0.6943, Validation Loss: 0.6368\n",
      "[Trial 32] Epoch 11/60, Training Loss: 0.9448, Validation Loss: 0.8483\n",
      "[Trial 29] Epoch 21/60, Training Loss: 0.6503, Validation Loss: 0.5326\n",
      "[Trial 27] Epoch 23/60, Training Loss: 0.6638, Validation Loss: 0.6507\n",
      "[Trial 6] Epoch 58/60, Training Loss: 0.5479, Validation Loss: 0.4877\n",
      "[Trial 35] Epoch 12/60, Training Loss: 1.0192, Validation Loss: 0.8819\n",
      "[Trial 34] Epoch 14/60, Training Loss: 0.8866, Validation Loss: 0.8264\n",
      "[Trial 28] Epoch 22/60, Training Loss: 0.6604, Validation Loss: 0.6268\n",
      "[Trial 30] Epoch 56/60, Training Loss: 0.5858, Validation Loss: 0.4958\n",
      "[Trial 26] Epoch 24/60, Training Loss: 0.6947, Validation Loss: 0.6832\n",
      "[Trial 36] Epoch 5/60, Training Loss: 1.2091, Validation Loss: 1.4882\n",
      "[Trial 25] Epoch 28/60, Training Loss: 0.6352, Validation Loss: 0.5462\n",
      "[Trial 37] Epoch 4/60, Training Loss: 1.3054, Validation Loss: 1.4790\n",
      "[Trial 30] Epoch 57/60, Training Loss: 0.5848, Validation Loss: 0.4974\n",
      "[Trial 18] Epoch 26/60, Training Loss: 0.7598, Validation Loss: 0.5855\n",
      "[Trial 34] Epoch 15/60, Training Loss: 0.8747, Validation Loss: 0.7551\n",
      "[Trial 33] Epoch 11/60, Training Loss: 0.8031, Validation Loss: 0.6958\n",
      "[Trial 35] Epoch 13/60, Training Loss: 1.0291, Validation Loss: 0.8475\n",
      "[Trial 31] Epoch 13/60, Training Loss: 0.7615, Validation Loss: 0.6263\n",
      "[Trial 30] Epoch 58/60, Training Loss: 0.5921, Validation Loss: 0.5021\n",
      "[Trial 29] Epoch 22/60, Training Loss: 0.6505, Validation Loss: 0.5908\n",
      "[Trial 32] Epoch 12/60, Training Loss: 0.9422, Validation Loss: 1.2869\n",
      "[Trial 27] Epoch 24/60, Training Loss: 0.6478, Validation Loss: 0.5552\n",
      "[Trial 6] Epoch 59/60, Training Loss: 0.5580, Validation Loss: 0.5034\n",
      "[Trial 28] Epoch 23/60, Training Loss: 0.6941, Validation Loss: 0.7279\n",
      "[Trial 26] Epoch 25/60, Training Loss: 0.6966, Validation Loss: 0.6959\n",
      "[Trial 36] Epoch 6/60, Training Loss: 1.1155, Validation Loss: 1.0219\n",
      "[Trial 25] Epoch 29/60, Training Loss: 0.6367, Validation Loss: 0.5312\n",
      "[Trial 30] Epoch 59/60, Training Loss: 0.5910, Validation Loss: 0.5005\n",
      "[Trial 34] Epoch 16/60, Training Loss: 0.8632, Validation Loss: 0.8505\n",
      "[Trial 35] Epoch 14/60, Training Loss: 0.9673, Validation Loss: 0.8508\n",
      "[Trial 37] Epoch 5/60, Training Loss: 1.1938, Validation Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:30:21,101] Trial 30 finished with value: 0.4958431581656138 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.004986326214774751, 'batch_size': 64, 'patience': 10}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 30] Epoch 60/60, Training Loss: 0.5834, Validation Loss: 0.5006\n",
      "[Trial 22] Epoch 21/60, Training Loss: 0.6871, Validation Loss: 0.5982\n",
      "[Trial 31] Epoch 14/60, Training Loss: 0.7482, Validation Loss: 0.6088\n",
      "[Trial 33] Epoch 12/60, Training Loss: 0.8022, Validation Loss: 0.6962\n",
      "[Trial 29] Epoch 23/60, Training Loss: 0.6626, Validation Loss: 0.6158\n",
      "[Trial 32] Epoch 13/60, Training Loss: 0.8354, Validation Loss: 0.8517\n",
      "[Trial 27] Epoch 25/60, Training Loss: 0.6291, Validation Loss: 0.5414\n",
      "[Trial 34] Epoch 17/60, Training Loss: 0.8637, Validation Loss: 0.7022\n",
      "[Trial 35] Epoch 15/60, Training Loss: 0.9112, Validation Loss: 0.7143\n",
      "[Trial 28] Epoch 24/60, Training Loss: 0.6501, Validation Loss: 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:30:51,471] Trial 6 finished with value: 0.4824086844921112 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.009255285207454856, 'batch_size': 16, 'patience': 9}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 6] Epoch 60/60, Training Loss: 0.5523, Validation Loss: 0.4885\n",
      "[Trial 26] Epoch 26/60, Training Loss: 0.7029, Validation Loss: 0.8223\n",
      "[Trial 36] Epoch 7/60, Training Loss: 1.0280, Validation Loss: 0.8164\n",
      "[Trial 25] Epoch 30/60, Training Loss: 0.6098, Validation Loss: 0.5242\n",
      "[Trial 18] Epoch 27/60, Training Loss: 0.7408, Validation Loss: 0.6090\n",
      "[Trial 37] Epoch 6/60, Training Loss: 1.0633, Validation Loss: 1.0310\n",
      "[Trial 34] Epoch 18/60, Training Loss: 0.8317, Validation Loss: 0.7888\n",
      "[Trial 38] Epoch 1/60, Training Loss: 4.7419, Validation Loss: 4.2929\n",
      "[Trial 35] Epoch 16/60, Training Loss: 0.9270, Validation Loss: 0.8162\n",
      "[Trial 39] Epoch 1/60, Training Loss: 5308.0068, Validation Loss: 4.7898\n",
      "[Trial 31] Epoch 15/60, Training Loss: 0.7369, Validation Loss: 0.7810\n",
      "[Trial 29] Epoch 24/60, Training Loss: 0.6878, Validation Loss: 0.6017\n",
      "[Trial 33] Epoch 13/60, Training Loss: 0.7774, Validation Loss: 0.8022\n",
      "[Trial 27] Epoch 26/60, Training Loss: 0.6291, Validation Loss: 0.5726\n",
      "[Trial 32] Epoch 14/60, Training Loss: 0.7828, Validation Loss: 0.6201\n",
      "[Trial 28] Epoch 25/60, Training Loss: 0.6353, Validation Loss: 0.5261\n",
      "[Trial 26] Epoch 27/60, Training Loss: 0.6956, Validation Loss: 0.6129\n",
      "[Trial 36] Epoch 8/60, Training Loss: 0.9573, Validation Loss: 0.9555\n",
      "[Trial 25] Epoch 31/60, Training Loss: 0.6059, Validation Loss: 0.5104\n",
      "[Trial 34] Epoch 19/60, Training Loss: 0.8992, Validation Loss: 0.7060\n",
      "[Trial 35] Epoch 17/60, Training Loss: 0.9201, Validation Loss: 0.9015\n",
      "[Trial 39] Epoch 2/60, Training Loss: 4.5137, Validation Loss: 3.8547\n",
      "[Trial 37] Epoch 7/60, Training Loss: 0.9836, Validation Loss: 1.1968\n",
      "[Trial 22] Epoch 22/60, Training Loss: 0.6761, Validation Loss: 0.6029\n",
      "[Trial 38] Epoch 2/60, Training Loss: 1.9668, Validation Loss: 2.7111\n",
      "[Trial 34] Epoch 20/60, Training Loss: 0.8370, Validation Loss: 0.7081\n",
      "[Trial 31] Epoch 16/60, Training Loss: 0.7353, Validation Loss: 0.6944\n",
      "[Trial 29] Epoch 25/60, Training Loss: 0.6712, Validation Loss: 0.6733\n",
      "[Trial 39] Epoch 3/60, Training Loss: 3.8127, Validation Loss: 3.1849\n",
      "[Trial 35] Epoch 18/60, Training Loss: 0.9161, Validation Loss: 0.7794\n",
      "[Trial 18] Epoch 28/60, Training Loss: 0.7528, Validation Loss: 0.6041\n",
      "[Trial 33] Epoch 14/60, Training Loss: 0.7629, Validation Loss: 0.5823\n",
      "[Trial 27] Epoch 27/60, Training Loss: 0.6428, Validation Loss: 0.5865\n",
      "[Trial 28] Epoch 26/60, Training Loss: 0.6442, Validation Loss: 0.6234\n",
      "[Trial 32] Epoch 15/60, Training Loss: 0.7842, Validation Loss: 0.7511\n",
      "[Trial 26] Epoch 28/60, Training Loss: 0.6369, Validation Loss: 0.5673\n",
      "[Trial 25] Epoch 32/60, Training Loss: 0.6048, Validation Loss: 0.5365\n",
      "[Trial 36] Epoch 9/60, Training Loss: 0.9506, Validation Loss: 0.8633\n",
      "[Trial 37] Epoch 8/60, Training Loss: 0.9730, Validation Loss: 0.8654\n",
      "[Trial 34] Epoch 21/60, Training Loss: 0.7980, Validation Loss: 0.6428\n",
      "[Trial 39] Epoch 4/60, Training Loss: 3.3143, Validation Loss: 2.9483\n",
      "[Trial 35] Epoch 19/60, Training Loss: 0.8826, Validation Loss: 0.7470\n",
      "[Trial 38] Epoch 3/60, Training Loss: 1.5742, Validation Loss: 1.7498\n",
      "[Trial 29] Epoch 26/60, Training Loss: 0.6557, Validation Loss: 0.5942\n",
      "[Trial 31] Epoch 17/60, Training Loss: 0.7257, Validation Loss: 0.6173\n",
      "[Trial 27] Epoch 28/60, Training Loss: 0.6620, Validation Loss: 0.6150\n",
      "[Trial 28] Epoch 27/60, Training Loss: 0.6437, Validation Loss: 0.5318\n",
      "[Trial 33] Epoch 15/60, Training Loss: 0.7755, Validation Loss: 0.8353\n",
      "[Trial 32] Epoch 16/60, Training Loss: 0.8019, Validation Loss: 0.7507\n",
      "[Trial 34] Epoch 22/60, Training Loss: 0.7770, Validation Loss: 0.7866\n",
      "[Trial 39] Epoch 5/60, Training Loss: 2.9549, Validation Loss: 2.7179\n",
      "[Trial 35] Epoch 20/60, Training Loss: 0.8419, Validation Loss: 0.6442\n",
      "[Trial 26] Epoch 29/60, Training Loss: 0.6407, Validation Loss: 0.5859\n",
      "[Trial 25] Epoch 33/60, Training Loss: 0.6036, Validation Loss: 0.5498\n",
      "[Trial 36] Epoch 10/60, Training Loss: 0.9095, Validation Loss: 0.7306\n",
      "[Trial 22] Epoch 23/60, Training Loss: 0.6794, Validation Loss: 0.6445\n",
      "[Trial 37] Epoch 9/60, Training Loss: 0.9590, Validation Loss: 0.8809\n",
      "[Trial 18] Epoch 29/60, Training Loss: 0.7351, Validation Loss: 0.5826\n",
      "[Trial 34] Epoch 23/60, Training Loss: 0.8434, Validation Loss: 0.6916\n",
      "[Trial 39] Epoch 6/60, Training Loss: 2.6786, Validation Loss: 2.5062\n",
      "[Trial 38] Epoch 4/60, Training Loss: 1.3375, Validation Loss: 1.4383\n",
      "[Trial 35] Epoch 21/60, Training Loss: 0.8441, Validation Loss: 0.8150\n",
      "[Trial 29] Epoch 27/60, Training Loss: 0.6375, Validation Loss: 0.5671\n",
      "[Trial 31] Epoch 18/60, Training Loss: 0.7117, Validation Loss: 0.6229\n",
      "[Trial 28] Epoch 28/60, Training Loss: 0.6458, Validation Loss: 0.5375\n",
      "[Trial 27] Epoch 29/60, Training Loss: 0.6537, Validation Loss: 0.5911\n",
      "[Trial 33] Epoch 16/60, Training Loss: 0.7755, Validation Loss: 0.7146\n",
      "[Trial 32] Epoch 17/60, Training Loss: 0.7802, Validation Loss: 0.7259\n",
      "[Trial 26] Epoch 30/60, Training Loss: 0.6583, Validation Loss: 0.5485\n",
      "[Trial 25] Epoch 34/60, Training Loss: 0.5995, Validation Loss: 0.5394\n",
      "[Trial 36] Epoch 11/60, Training Loss: 0.8660, Validation Loss: 0.7121\n",
      "[Trial 34] Epoch 24/60, Training Loss: 0.7677, Validation Loss: 0.6677\n",
      "[Trial 39] Epoch 7/60, Training Loss: 2.7402, Validation Loss: 2.0093\n",
      "[Trial 35] Epoch 22/60, Training Loss: 0.8531, Validation Loss: 0.7125\n",
      "[Trial 37] Epoch 10/60, Training Loss: 0.9042, Validation Loss: 0.8031\n",
      "[Trial 38] Epoch 5/60, Training Loss: 1.1685, Validation Loss: 2.3867\n",
      "[Trial 29] Epoch 28/60, Training Loss: 0.6021, Validation Loss: 0.5217\n",
      "[Trial 28] Epoch 29/60, Training Loss: 0.6342, Validation Loss: 0.6390\n",
      "[Trial 34] Epoch 25/60, Training Loss: 0.7742, Validation Loss: 0.6762\n",
      "[Trial 31] Epoch 19/60, Training Loss: 0.6638, Validation Loss: 0.5776\n",
      "[Trial 39] Epoch 8/60, Training Loss: 2.2578, Validation Loss: 1.7795\n",
      "[Trial 27] Epoch 30/60, Training Loss: 0.6348, Validation Loss: 0.5607\n",
      "[Trial 35] Epoch 23/60, Training Loss: 0.8078, Validation Loss: 0.7355\n",
      "[Trial 22] Epoch 24/60, Training Loss: 0.6730, Validation Loss: 0.5874\n",
      "[Trial 32] Epoch 18/60, Training Loss: 0.7814, Validation Loss: 0.8583\n",
      "[Trial 33] Epoch 17/60, Training Loss: 0.7599, Validation Loss: 0.6358\n",
      "[Trial 26] Epoch 31/60, Training Loss: 0.6195, Validation Loss: 0.5915\n",
      "[Trial 25] Epoch 35/60, Training Loss: 0.6047, Validation Loss: 0.5168\n",
      "[Trial 36] Epoch 12/60, Training Loss: 0.8566, Validation Loss: 0.8866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:36:42,124] Trial 18 finished with value: 0.57527495448788 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.039255556691918665, 'batch_size': 8, 'patience': 6}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 18] Epoch 30/60, Training Loss: 0.7243, Validation Loss: 0.5761\n",
      "[Trial 18] Early stopping after 30 epochs.\n",
      "[Trial 37] Epoch 11/60, Training Loss: 0.8455, Validation Loss: 0.8579\n",
      "[Trial 39] Epoch 9/60, Training Loss: 2.0745, Validation Loss: 1.7308\n",
      "[Trial 34] Epoch 26/60, Training Loss: 0.7594, Validation Loss: 0.7039\n",
      "[Trial 35] Epoch 24/60, Training Loss: 0.8060, Validation Loss: 0.7056\n",
      "[Trial 38] Epoch 6/60, Training Loss: 1.1444, Validation Loss: 1.0091\n",
      "[Trial 29] Epoch 29/60, Training Loss: 0.5941, Validation Loss: 0.5162\n",
      "[Trial 40] Epoch 1/60, Training Loss: 12.7336, Validation Loss: 2.6447\n",
      "[Trial 28] Epoch 30/60, Training Loss: 0.6504, Validation Loss: 0.5585\n",
      "[Trial 27] Epoch 31/60, Training Loss: 0.6310, Validation Loss: 0.6425\n",
      "[Trial 31] Epoch 20/60, Training Loss: 0.6633, Validation Loss: 0.5574\n",
      "[Trial 32] Epoch 19/60, Training Loss: 0.7386, Validation Loss: 0.6318\n",
      "[Trial 33] Epoch 18/60, Training Loss: 0.7511, Validation Loss: 0.6885\n",
      "[Trial 39] Epoch 10/60, Training Loss: 2.0242, Validation Loss: 2.8888\n",
      "[Trial 34] Epoch 27/60, Training Loss: 0.7446, Validation Loss: 0.7025\n",
      "[Trial 26] Epoch 32/60, Training Loss: 0.6054, Validation Loss: 0.5173\n",
      "[Trial 25] Epoch 36/60, Training Loss: 0.5889, Validation Loss: 0.5060\n",
      "[Trial 36] Epoch 13/60, Training Loss: 0.8640, Validation Loss: 1.1803\n",
      "[Trial 35] Epoch 25/60, Training Loss: 0.7971, Validation Loss: 0.7166\n",
      "[Trial 37] Epoch 12/60, Training Loss: 0.8946, Validation Loss: 0.8143\n",
      "[Trial 40] Epoch 2/60, Training Loss: 2.7303, Validation Loss: 2.0043\n",
      "[Trial 39] Epoch 11/60, Training Loss: 1.9749, Validation Loss: 2.8849\n",
      "[Trial 34] Epoch 28/60, Training Loss: 0.6687, Validation Loss: 0.5759\n",
      "[Trial 29] Epoch 30/60, Training Loss: 0.5856, Validation Loss: 0.5335\n",
      "[Trial 28] Epoch 31/60, Training Loss: 0.6621, Validation Loss: 0.5802\n",
      "[Trial 38] Epoch 7/60, Training Loss: 1.0008, Validation Loss: 0.7846\n",
      "[Trial 22] Epoch 25/60, Training Loss: 0.6759, Validation Loss: 0.6145\n",
      "[Trial 35] Epoch 26/60, Training Loss: 0.8048, Validation Loss: 0.8490\n",
      "[Trial 27] Epoch 32/60, Training Loss: 0.5995, Validation Loss: 0.4842\n",
      "[Trial 31] Epoch 21/60, Training Loss: 0.6757, Validation Loss: 0.5810\n",
      "[Trial 40] Epoch 3/60, Training Loss: 2.2852, Validation Loss: 2.0209\n",
      "[Trial 32] Epoch 20/60, Training Loss: 0.7069, Validation Loss: 0.5827\n",
      "[Trial 26] Epoch 33/60, Training Loss: 0.6122, Validation Loss: 0.5500\n",
      "[Trial 33] Epoch 19/60, Training Loss: 0.7042, Validation Loss: 0.6120\n",
      "[Trial 25] Epoch 37/60, Training Loss: 0.5861, Validation Loss: 0.4993\n",
      "[Trial 36] Epoch 14/60, Training Loss: 0.8777, Validation Loss: 0.8957\n",
      "[Trial 39] Epoch 12/60, Training Loss: 1.9017, Validation Loss: 1.4248\n",
      "[Trial 34] Epoch 29/60, Training Loss: 0.6424, Validation Loss: 0.5697\n",
      "[Trial 37] Epoch 13/60, Training Loss: 0.8764, Validation Loss: 0.7499\n",
      "[Trial 35] Epoch 27/60, Training Loss: 0.7126, Validation Loss: 0.5989\n",
      "[Trial 40] Epoch 4/60, Training Loss: 2.0953, Validation Loss: 1.5382\n",
      "[Trial 28] Epoch 32/60, Training Loss: 0.6051, Validation Loss: 0.4901\n",
      "[Trial 29] Epoch 31/60, Training Loss: 0.5943, Validation Loss: 0.5378\n",
      "[Trial 38] Epoch 8/60, Training Loss: 0.9688, Validation Loss: 1.3398\n",
      "[Trial 27] Epoch 33/60, Training Loss: 0.5845, Validation Loss: 0.4813\n",
      "[Trial 39] Epoch 13/60, Training Loss: 1.8560, Validation Loss: 1.4886\n",
      "[Trial 34] Epoch 30/60, Training Loss: 0.6451, Validation Loss: 0.5750\n",
      "[Trial 31] Epoch 22/60, Training Loss: 0.6699, Validation Loss: 0.5877\n",
      "[Trial 35] Epoch 28/60, Training Loss: 0.6841, Validation Loss: 0.5815\n",
      "[Trial 26] Epoch 34/60, Training Loss: 0.6269, Validation Loss: 0.6229\n",
      "[Trial 25] Epoch 38/60, Training Loss: 0.5901, Validation Loss: 0.5084\n",
      "[Trial 32] Epoch 21/60, Training Loss: 0.6944, Validation Loss: 0.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 02:40:13,824] Trial 33 finished with value: 0.5822793856263161 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.0049436782224346444, 'batch_size': 16, 'patience': 6}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 33] Epoch 20/60, Training Loss: 0.7062, Validation Loss: 0.5829\n",
      "[Trial 33] Early stopping after 20 epochs.\n",
      "[Trial 36] Epoch 15/60, Training Loss: 0.8071, Validation Loss: 0.7263\n",
      "[Trial 40] Epoch 5/60, Training Loss: 1.7783, Validation Loss: 1.6141\n",
      "[Trial 37] Epoch 14/60, Training Loss: 0.8108, Validation Loss: 0.7807\n",
      "[Trial 39] Epoch 14/60, Training Loss: 1.7237, Validation Loss: 4.7268\n",
      "[Trial 34] Epoch 31/60, Training Loss: 0.6465, Validation Loss: 0.5569\n",
      "[Trial 22] Epoch 26/60, Training Loss: 0.6715, Validation Loss: 0.6867\n",
      "[Trial 35] Epoch 29/60, Training Loss: 0.6826, Validation Loss: 0.6552\n",
      "[Trial 28] Epoch 33/60, Training Loss: 0.5960, Validation Loss: 0.5350\n",
      "[Trial 29] Epoch 32/60, Training Loss: 0.6027, Validation Loss: 0.5194\n",
      "[Trial 41] Epoch 1/60, Training Loss: 18.3758, Validation Loss: 3.8311\n",
      "[Trial 27] Epoch 34/60, Training Loss: 0.5785, Validation Loss: 0.4962\n",
      "[Trial 38] Epoch 9/60, Training Loss: 1.0152, Validation Loss: 1.0549\n",
      "[Trial 40] Epoch 6/60, Training Loss: 1.5844, Validation Loss: 1.2885\n",
      "[Trial 31] Epoch 23/60, Training Loss: 0.6543, Validation Loss: 0.5525\n",
      "[Trial 26] Epoch 35/60, Training Loss: 0.6354, Validation Loss: 0.5328\n",
      "[Trial 39] Epoch 15/60, Training Loss: 1.8399, Validation Loss: 1.3237\n",
      "[Trial 25] Epoch 39/60, Training Loss: 0.5837, Validation Loss: 0.4979\n",
      "[Trial 32] Epoch 22/60, Training Loss: 0.6905, Validation Loss: 0.5480\n",
      "[Trial 34] Epoch 32/60, Training Loss: 0.6498, Validation Loss: 0.6354\n",
      "[Trial 36] Epoch 16/60, Training Loss: 0.8029, Validation Loss: 0.8077\n",
      "[Trial 35] Epoch 30/60, Training Loss: 0.6851, Validation Loss: 0.6061\n",
      "[Trial 37] Epoch 15/60, Training Loss: 0.8227, Validation Loss: 1.1197\n",
      "[Trial 41] Epoch 2/60, Training Loss: 2.7670, Validation Loss: 2.4034\n",
      "[Trial 40] Epoch 7/60, Training Loss: 1.4375, Validation Loss: 1.2110\n",
      "[Trial 28] Epoch 34/60, Training Loss: 0.6138, Validation Loss: 0.4993\n",
      "[Trial 39] Epoch 16/60, Training Loss: 1.6100, Validation Loss: 1.3505\n",
      "[Trial 29] Epoch 33/60, Training Loss: 0.5993, Validation Loss: 0.6022\n",
      "[Trial 34] Epoch 33/60, Training Loss: 0.6410, Validation Loss: 0.5581\n",
      "[Trial 27] Epoch 35/60, Training Loss: 0.5844, Validation Loss: 0.5271\n",
      "[Trial 38] Epoch 10/60, Training Loss: 0.9182, Validation Loss: 1.0151\n",
      "[Trial 35] Epoch 31/60, Training Loss: 0.6812, Validation Loss: 0.6051\n",
      "[Trial 31] Epoch 24/60, Training Loss: 0.6460, Validation Loss: 0.5419\n",
      "[Trial 41] Epoch 3/60, Training Loss: 2.2806, Validation Loss: 1.7980\n",
      "[Trial 26] Epoch 36/60, Training Loss: 0.6208, Validation Loss: 0.5985\n",
      "[Trial 25] Epoch 40/60, Training Loss: 0.5838, Validation Loss: 0.5013\n",
      "[Trial 40] Epoch 8/60, Training Loss: 1.3391, Validation Loss: 1.1397\n",
      "[Trial 32] Epoch 23/60, Training Loss: 0.7042, Validation Loss: 0.6127\n",
      "[Trial 36] Epoch 17/60, Training Loss: 0.7779, Validation Loss: 0.8468\n",
      "[Trial 39] Epoch 17/60, Training Loss: 1.5684, Validation Loss: 1.4585\n",
      "[Trial 22] Epoch 27/60, Training Loss: 0.6724, Validation Loss: 0.5912\n",
      "[Trial 34] Epoch 34/60, Training Loss: 0.6423, Validation Loss: 0.5674\n",
      "[Trial 37] Epoch 16/60, Training Loss: 0.8423, Validation Loss: 0.8160\n",
      "[Trial 35] Epoch 32/60, Training Loss: 0.6804, Validation Loss: 0.5913\n",
      "[Trial 28] Epoch 35/60, Training Loss: 0.5962, Validation Loss: 0.4907\n",
      "[Trial 41] Epoch 4/60, Training Loss: 1.9358, Validation Loss: 2.0799\n",
      "[Trial 29] Epoch 34/60, Training Loss: 0.6060, Validation Loss: 0.5492\n",
      "[Trial 40] Epoch 9/60, Training Loss: 1.1812, Validation Loss: 1.0215\n",
      "[Trial 27] Epoch 36/60, Training Loss: 0.5841, Validation Loss: 0.4845\n",
      "[Trial 39] Epoch 18/60, Training Loss: 1.5129, Validation Loss: 1.1713\n",
      "[Trial 38] Epoch 11/60, Training Loss: 0.7997, Validation Loss: 0.6878\n",
      "[Trial 34] Epoch 35/60, Training Loss: 0.6502, Validation Loss: 0.5712\n",
      "[Trial 31] Epoch 25/60, Training Loss: 0.6484, Validation Loss: 0.5562\n",
      "[Trial 25] Epoch 41/60, Training Loss: 0.5861, Validation Loss: 0.5053\n",
      "[Trial 26] Epoch 37/60, Training Loss: 0.6111, Validation Loss: 0.5398\n",
      "[Trial 35] Epoch 33/60, Training Loss: 0.6918, Validation Loss: 0.5921\n",
      "[Trial 32] Epoch 24/60, Training Loss: 0.6994, Validation Loss: 0.5425\n",
      "[Trial 36] Epoch 18/60, Training Loss: 0.7146, Validation Loss: 0.6341\n",
      "[Trial 41] Epoch 5/60, Training Loss: 1.7251, Validation Loss: 1.2735\n",
      "[Trial 40] Epoch 10/60, Training Loss: 1.1423, Validation Loss: 1.2227\n",
      "[Trial 37] Epoch 17/60, Training Loss: 0.7197, Validation Loss: 0.6392\n",
      "[Trial 39] Epoch 19/60, Training Loss: 1.4420, Validation Loss: 1.2741\n",
      "[Trial 28] Epoch 36/60, Training Loss: 0.5985, Validation Loss: 0.4935\n",
      "[Trial 34] Epoch 36/60, Training Loss: 0.6469, Validation Loss: 0.5697\n",
      "[Trial 29] Epoch 35/60, Training Loss: 0.6059, Validation Loss: 0.5253\n",
      "[Trial 27] Epoch 37/60, Training Loss: 0.5823, Validation Loss: 0.4905\n",
      "[Trial 35] Epoch 34/60, Training Loss: 0.6833, Validation Loss: 0.5972\n",
      "[Trial 41] Epoch 6/60, Training Loss: 1.6250, Validation Loss: 1.5120\n",
      "[Trial 38] Epoch 12/60, Training Loss: 0.7647, Validation Loss: 0.6712\n",
      "[Trial 40] Epoch 11/60, Training Loss: 1.0877, Validation Loss: 0.9194\n",
      "[Trial 31] Epoch 26/60, Training Loss: 0.6451, Validation Loss: 0.6051\n",
      "[Trial 26] Epoch 38/60, Training Loss: 0.6091, Validation Loss: 0.5597\n",
      "[Trial 25] Epoch 42/60, Training Loss: 0.5817, Validation Loss: 0.4941\n",
      "[Trial 39] Epoch 20/60, Training Loss: 1.5550, Validation Loss: 1.3040\n",
      "[Trial 22] Epoch 28/60, Training Loss: 0.6710, Validation Loss: 0.6194\n",
      "[Trial 34] Epoch 37/60, Training Loss: 0.6499, Validation Loss: 0.5478\n",
      "[Trial 36] Epoch 19/60, Training Loss: 0.6749, Validation Loss: 0.5829\n",
      "[Trial 32] Epoch 25/60, Training Loss: 0.6819, Validation Loss: 0.6236\n",
      "[Trial 35] Epoch 35/60, Training Loss: 0.6441, Validation Loss: 0.5650\n",
      "[Trial 37] Epoch 18/60, Training Loss: 0.6910, Validation Loss: 0.6342\n",
      "[Trial 28] Epoch 37/60, Training Loss: 0.5916, Validation Loss: 0.4916\n",
      "[Trial 41] Epoch 7/60, Training Loss: 1.4573, Validation Loss: 1.2570\n",
      "[Trial 40] Epoch 12/60, Training Loss: 1.0534, Validation Loss: 0.7842\n",
      "[Trial 29] Epoch 36/60, Training Loss: 0.5715, Validation Loss: 0.4917\n",
      "[Trial 39] Epoch 21/60, Training Loss: 1.4471, Validation Loss: 1.4724\n",
      "[Trial 27] Epoch 38/60, Training Loss: 0.5826, Validation Loss: 0.5066\n",
      "[Trial 34] Epoch 38/60, Training Loss: 0.6407, Validation Loss: 0.5690\n",
      "[Trial 38] Epoch 13/60, Training Loss: 0.7613, Validation Loss: 0.6500\n",
      "[Trial 35] Epoch 36/60, Training Loss: 0.6236, Validation Loss: 0.5475\n",
      "[Trial 26] Epoch 39/60, Training Loss: 0.5776, Validation Loss: 0.5094\n",
      "[Trial 25] Epoch 43/60, Training Loss: 0.5796, Validation Loss: 0.5037\n",
      "[Trial 31] Epoch 27/60, Training Loss: 0.6595, Validation Loss: 0.5757\n",
      "[Trial 41] Epoch 8/60, Training Loss: 1.4411, Validation Loss: 1.9379\n",
      "[Trial 40] Epoch 13/60, Training Loss: 1.0138, Validation Loss: 0.9156\n",
      "[Trial 36] Epoch 20/60, Training Loss: 0.6670, Validation Loss: 0.5522\n",
      "[Trial 32] Epoch 26/60, Training Loss: 0.6934, Validation Loss: 0.7279\n",
      "[Trial 39] Epoch 22/60, Training Loss: 1.3783, Validation Loss: 1.1289\n",
      "[Trial 34] Epoch 39/60, Training Loss: 0.6313, Validation Loss: 0.5840\n",
      "[Trial 37] Epoch 19/60, Training Loss: 0.6963, Validation Loss: 0.5806\n",
      "[Trial 28] Epoch 38/60, Training Loss: 0.5909, Validation Loss: 0.5281\n",
      "[Trial 35] Epoch 37/60, Training Loss: 0.6296, Validation Loss: 0.5497\n",
      "[Trial 29] Epoch 37/60, Training Loss: 0.5727, Validation Loss: 0.4908\n",
      "[Trial 27] Epoch 39/60, Training Loss: 0.5825, Validation Loss: 0.5096\n",
      "[Trial 41] Epoch 9/60, Training Loss: 1.3502, Validation Loss: 0.9152\n",
      "[Trial 40] Epoch 14/60, Training Loss: 0.9489, Validation Loss: 0.8482\n",
      "[Trial 39] Epoch 23/60, Training Loss: 1.3578, Validation Loss: 1.1732\n",
      "[Trial 22] Epoch 29/60, Training Loss: 0.6639, Validation Loss: 0.6286\n",
      "[Trial 38] Epoch 14/60, Training Loss: 0.7629, Validation Loss: 0.6551\n",
      "[Trial 34] Epoch 40/60, Training Loss: 0.6476, Validation Loss: 0.5832\n",
      "[Trial 26] Epoch 40/60, Training Loss: 0.5734, Validation Loss: 0.5066\n",
      "[Trial 25] Epoch 44/60, Training Loss: 0.5777, Validation Loss: 0.5071\n",
      "[Trial 31] Epoch 28/60, Training Loss: 0.6457, Validation Loss: 0.5489\n",
      "[Trial 36] Epoch 21/60, Training Loss: 0.6819, Validation Loss: 0.6035\n",
      "[Trial 35] Epoch 38/60, Training Loss: 0.6285, Validation Loss: 0.5521\n",
      "[Trial 32] Epoch 27/60, Training Loss: 0.7190, Validation Loss: 0.6192\n",
      "[Trial 41] Epoch 10/60, Training Loss: 1.1819, Validation Loss: 1.0693\n",
      "[Trial 40] Epoch 15/60, Training Loss: 0.9402, Validation Loss: 0.7482\n",
      "[Trial 37] Epoch 20/60, Training Loss: 0.6789, Validation Loss: 0.6174\n",
      "[Trial 28] Epoch 39/60, Training Loss: 0.5693, Validation Loss: 0.4679\n",
      "[Trial 39] Epoch 24/60, Training Loss: 1.2918, Validation Loss: 1.4092\n",
      "[Trial 29] Epoch 38/60, Training Loss: 0.5620, Validation Loss: 0.4934\n",
      "[Trial 34] Epoch 41/60, Training Loss: 0.6260, Validation Loss: 0.5648\n",
      "[Trial 27] Epoch 40/60, Training Loss: 0.5614, Validation Loss: 0.4870\n",
      "[Trial 35] Epoch 39/60, Training Loss: 0.6344, Validation Loss: 0.5556\n",
      "[Trial 38] Epoch 15/60, Training Loss: 0.7348, Validation Loss: 0.6067\n",
      "[Trial 40] Epoch 16/60, Training Loss: 0.8823, Validation Loss: 0.8164\n",
      "[Trial 41] Epoch 11/60, Training Loss: 1.1038, Validation Loss: 0.9324\n",
      "[Trial 26] Epoch 41/60, Training Loss: 0.5871, Validation Loss: 0.5130\n",
      "[Trial 25] Epoch 45/60, Training Loss: 0.5944, Validation Loss: 0.5018\n",
      "[Trial 31] Epoch 29/60, Training Loss: 0.6086, Validation Loss: 0.5378\n",
      "[Trial 39] Epoch 25/60, Training Loss: 1.3873, Validation Loss: 1.1197\n",
      "[Trial 36] Epoch 22/60, Training Loss: 0.6850, Validation Loss: 0.5757\n",
      "[Trial 34] Epoch 42/60, Training Loss: 0.6307, Validation Loss: 0.5737\n",
      "[Trial 32] Epoch 28/60, Training Loss: 0.6777, Validation Loss: 0.5757\n",
      "[Trial 28] Epoch 40/60, Training Loss: 0.5600, Validation Loss: 0.4650\n",
      "[Trial 37] Epoch 21/60, Training Loss: 0.6836, Validation Loss: 0.6108\n",
      "[Trial 35] Epoch 40/60, Training Loss: 0.6304, Validation Loss: 0.5754\n",
      "[Trial 29] Epoch 39/60, Training Loss: 0.5704, Validation Loss: 0.4917\n",
      "[Trial 40] Epoch 17/60, Training Loss: 0.8653, Validation Loss: 0.7564\n",
      "[Trial 41] Epoch 12/60, Training Loss: 1.1235, Validation Loss: 0.8419\n",
      "[Trial 27] Epoch 41/60, Training Loss: 0.5582, Validation Loss: 0.4684\n",
      "[Trial 22] Epoch 30/60, Training Loss: 0.6197, Validation Loss: 0.5921\n",
      "[Trial 39] Epoch 26/60, Training Loss: 1.2751, Validation Loss: 1.0873\n",
      "[Trial 34] Epoch 43/60, Training Loss: 0.6439, Validation Loss: 0.5775\n",
      "[Trial 26] Epoch 42/60, Training Loss: 0.5808, Validation Loss: 0.4913\n",
      "[Trial 38] Epoch 16/60, Training Loss: 0.7368, Validation Loss: 0.6704\n",
      "[Trial 25] Epoch 46/60, Training Loss: 0.5844, Validation Loss: 0.4948\n",
      "[Trial 35] Epoch 41/60, Training Loss: 0.6331, Validation Loss: 0.5489\n",
      "[Trial 31] Epoch 30/60, Training Loss: 0.5981, Validation Loss: 0.5272\n",
      "[Trial 36] Epoch 23/60, Training Loss: 0.6686, Validation Loss: 0.6033\n",
      "[Trial 40] Epoch 18/60, Training Loss: 0.8587, Validation Loss: 0.7465\n",
      "[Trial 41] Epoch 13/60, Training Loss: 1.1114, Validation Loss: 1.0059\n",
      "[Trial 32] Epoch 29/60, Training Loss: 0.6303, Validation Loss: 0.5558\n",
      "[Trial 39] Epoch 27/60, Training Loss: 1.4257, Validation Loss: 1.0937\n",
      "[Trial 28] Epoch 41/60, Training Loss: 0.5613, Validation Loss: 0.4623\n",
      "[Trial 34] Epoch 44/60, Training Loss: 0.5841, Validation Loss: 0.5199\n",
      "[Trial 37] Epoch 22/60, Training Loss: 0.6922, Validation Loss: 0.5896\n",
      "[Trial 29] Epoch 40/60, Training Loss: 0.5613, Validation Loss: 0.4881\n",
      "[Trial 27] Epoch 42/60, Training Loss: 0.5666, Validation Loss: 0.4952\n",
      "[Trial 35] Epoch 42/60, Training Loss: 0.6387, Validation Loss: 0.5564\n",
      "[Trial 40] Epoch 19/60, Training Loss: 0.8309, Validation Loss: 0.7195\n",
      "[Trial 41] Epoch 14/60, Training Loss: 0.9936, Validation Loss: 0.9590\n",
      "[Trial 39] Epoch 28/60, Training Loss: 1.2359, Validation Loss: 0.9834\n",
      "[Trial 26] Epoch 43/60, Training Loss: 0.6031, Validation Loss: 0.5598\n",
      "[Trial 25] Epoch 47/60, Training Loss: 0.5762, Validation Loss: 0.4941\n",
      "[Trial 38] Epoch 17/60, Training Loss: 0.7566, Validation Loss: 0.7290\n",
      "[Trial 34] Epoch 45/60, Training Loss: 0.5772, Validation Loss: 0.5288\n",
      "[Trial 31] Epoch 31/60, Training Loss: 0.6106, Validation Loss: 0.5529\n",
      "[Trial 36] Epoch 24/60, Training Loss: 0.6635, Validation Loss: 0.8414\n",
      "[Trial 35] Epoch 43/60, Training Loss: 0.6068, Validation Loss: 0.5312\n",
      "[Trial 28] Epoch 42/60, Training Loss: 0.5604, Validation Loss: 0.4779\n",
      "[Trial 32] Epoch 30/60, Training Loss: 0.6393, Validation Loss: 0.5405\n",
      "[Trial 40] Epoch 20/60, Training Loss: 0.8276, Validation Loss: 0.6812\n",
      "[Trial 37] Epoch 23/60, Training Loss: 0.6416, Validation Loss: 0.5726\n",
      "[Trial 41] Epoch 15/60, Training Loss: 0.9644, Validation Loss: 0.8633\n",
      "[Trial 29] Epoch 41/60, Training Loss: 0.5738, Validation Loss: 0.4884\n",
      "[Trial 22] Epoch 31/60, Training Loss: 0.6218, Validation Loss: 0.5596\n",
      "[Trial 39] Epoch 29/60, Training Loss: 1.2340, Validation Loss: 1.1938\n",
      "[Trial 27] Epoch 43/60, Training Loss: 0.5521, Validation Loss: 0.4752\n",
      "[Trial 34] Epoch 46/60, Training Loss: 0.5776, Validation Loss: 0.5163\n",
      "[Trial 35] Epoch 44/60, Training Loss: 0.5914, Validation Loss: 0.5076\n",
      "[Trial 26] Epoch 44/60, Training Loss: 0.6061, Validation Loss: 0.5547\n",
      "[Trial 25] Epoch 48/60, Training Loss: 0.5737, Validation Loss: 0.4979\n",
      "[Trial 40] Epoch 21/60, Training Loss: 0.8198, Validation Loss: 0.7739\n",
      "[Trial 38] Epoch 18/60, Training Loss: 0.7602, Validation Loss: 0.6760\n",
      "[Trial 41] Epoch 16/60, Training Loss: 0.9436, Validation Loss: 0.7408\n",
      "[Trial 39] Epoch 30/60, Training Loss: 1.2545, Validation Loss: 1.2046\n",
      "[Trial 31] Epoch 32/60, Training Loss: 0.6198, Validation Loss: 0.5157\n",
      "[Trial 36] Epoch 25/60, Training Loss: 0.7131, Validation Loss: 0.6164\n",
      "[Trial 34] Epoch 47/60, Training Loss: 0.5808, Validation Loss: 0.5368\n",
      "[Trial 28] Epoch 43/60, Training Loss: 0.5560, Validation Loss: 0.4579\n",
      "[Trial 32] Epoch 31/60, Training Loss: 0.6343, Validation Loss: 0.5760\n",
      "[Trial 37] Epoch 24/60, Training Loss: 0.6423, Validation Loss: 0.5955\n",
      "[Trial 29] Epoch 42/60, Training Loss: 0.5654, Validation Loss: 0.4945\n",
      "[Trial 35] Epoch 45/60, Training Loss: 0.5957, Validation Loss: 0.5201\n",
      "[Trial 27] Epoch 44/60, Training Loss: 0.5647, Validation Loss: 0.4783\n",
      "[Trial 40] Epoch 22/60, Training Loss: 0.8210, Validation Loss: 0.6518\n",
      "[Trial 39] Epoch 31/60, Training Loss: 1.1962, Validation Loss: 0.9873\n",
      "[Trial 41] Epoch 17/60, Training Loss: 0.9366, Validation Loss: 0.7763\n",
      "[Trial 34] Epoch 48/60, Training Loss: 0.5756, Validation Loss: 0.5118\n",
      "[Trial 26] Epoch 45/60, Training Loss: 0.5730, Validation Loss: 0.5181\n",
      "[Trial 25] Epoch 49/60, Training Loss: 0.5707, Validation Loss: 0.4959\n",
      "[Trial 38] Epoch 19/60, Training Loss: 0.6641, Validation Loss: 0.5432\n",
      "[Trial 35] Epoch 46/60, Training Loss: 0.5954, Validation Loss: 0.5186\n",
      "[Trial 31] Epoch 33/60, Training Loss: 0.5959, Validation Loss: 0.5136\n",
      "[Trial 36] Epoch 26/60, Training Loss: 0.6704, Validation Loss: 0.5811\n",
      "[Trial 28] Epoch 44/60, Training Loss: 0.5631, Validation Loss: 0.4750\n",
      "[Trial 40] Epoch 23/60, Training Loss: 0.7616, Validation Loss: 0.6435\n",
      "[Trial 22] Epoch 32/60, Training Loss: 0.6153, Validation Loss: 0.5476\n",
      "[Trial 39] Epoch 32/60, Training Loss: 1.1903, Validation Loss: 1.5011\n",
      "[Trial 41] Epoch 18/60, Training Loss: 0.9085, Validation Loss: 0.7904\n",
      "[Trial 32] Epoch 32/60, Training Loss: 0.6313, Validation Loss: 0.6044\n",
      "[Trial 29] Epoch 43/60, Training Loss: 0.5641, Validation Loss: 0.4850\n",
      "[Trial 37] Epoch 25/60, Training Loss: 0.6352, Validation Loss: 0.7194\n",
      "[Trial 34] Epoch 49/60, Training Loss: 0.5796, Validation Loss: 0.5413\n",
      "[Trial 27] Epoch 45/60, Training Loss: 0.5536, Validation Loss: 0.4719\n",
      "[Trial 35] Epoch 47/60, Training Loss: 0.5983, Validation Loss: 0.5231\n",
      "[Trial 40] Epoch 24/60, Training Loss: 0.7720, Validation Loss: 0.7500\n",
      "[Trial 39] Epoch 33/60, Training Loss: 1.3117, Validation Loss: 0.9509\n",
      "[Trial 26] Epoch 46/60, Training Loss: 0.5628, Validation Loss: 0.4794\n",
      "[Trial 25] Epoch 50/60, Training Loss: 0.5698, Validation Loss: 0.4915\n",
      "[Trial 41] Epoch 19/60, Training Loss: 0.9253, Validation Loss: 0.7730\n",
      "[Trial 34] Epoch 50/60, Training Loss: 0.5857, Validation Loss: 0.5218\n",
      "[Trial 38] Epoch 20/60, Training Loss: 0.6659, Validation Loss: 0.5854\n",
      "[Trial 28] Epoch 45/60, Training Loss: 0.5596, Validation Loss: 0.4766\n",
      "[Trial 31] Epoch 34/60, Training Loss: 0.6057, Validation Loss: 0.5374\n",
      "[Trial 36] Epoch 27/60, Training Loss: 0.6223, Validation Loss: 0.5294\n",
      "[Trial 35] Epoch 48/60, Training Loss: 0.5909, Validation Loss: 0.5315\n",
      "[Trial 32] Epoch 33/60, Training Loss: 0.6284, Validation Loss: 0.5442\n",
      "[Trial 29] Epoch 44/60, Training Loss: 0.5584, Validation Loss: 0.5072\n",
      "[Trial 37] Epoch 26/60, Training Loss: 0.6476, Validation Loss: 0.5617\n",
      "[Trial 40] Epoch 25/60, Training Loss: 0.7631, Validation Loss: 0.6380\n",
      "[Trial 39] Epoch 34/60, Training Loss: 1.1792, Validation Loss: 0.9546\n",
      "[Trial 27] Epoch 46/60, Training Loss: 0.5585, Validation Loss: 0.4909\n",
      "[Trial 41] Epoch 20/60, Training Loss: 0.8742, Validation Loss: 0.6613\n",
      "[Trial 34] Epoch 51/60, Training Loss: 0.5761, Validation Loss: 0.5455\n",
      "[Trial 26] Epoch 47/60, Training Loss: 0.5670, Validation Loss: 0.4926\n",
      "[Trial 35] Epoch 49/60, Training Loss: 0.5860, Validation Loss: 0.5319\n",
      "[Trial 25] Epoch 51/60, Training Loss: 0.5721, Validation Loss: 0.4985\n",
      "[Trial 22] Epoch 33/60, Training Loss: 0.6089, Validation Loss: 0.5800\n",
      "[Trial 38] Epoch 21/60, Training Loss: 0.6796, Validation Loss: 0.5644\n",
      "[Trial 39] Epoch 35/60, Training Loss: 1.1252, Validation Loss: 0.9842\n",
      "[Trial 28] Epoch 46/60, Training Loss: 0.5573, Validation Loss: 0.4670\n",
      "[Trial 40] Epoch 26/60, Training Loss: 0.7666, Validation Loss: 0.7003\n",
      "[Trial 36] Epoch 28/60, Training Loss: 0.6175, Validation Loss: 0.5638\n",
      "[Trial 31] Epoch 35/60, Training Loss: 0.6002, Validation Loss: 0.5017\n",
      "[Trial 41] Epoch 21/60, Training Loss: 0.8748, Validation Loss: 0.7570\n",
      "[Trial 34] Epoch 52/60, Training Loss: 0.5744, Validation Loss: 0.5232\n",
      "[Trial 29] Epoch 45/60, Training Loss: 0.5595, Validation Loss: 0.4935\n",
      "[Trial 32] Epoch 34/60, Training Loss: 0.6343, Validation Loss: 0.5163\n",
      "[Trial 37] Epoch 27/60, Training Loss: 0.6351, Validation Loss: 0.5348\n",
      "[Trial 35] Epoch 50/60, Training Loss: 0.5929, Validation Loss: 0.5348\n",
      "[Trial 27] Epoch 47/60, Training Loss: 0.5554, Validation Loss: 0.4672\n",
      "[Trial 39] Epoch 36/60, Training Loss: 1.1993, Validation Loss: 0.9153\n",
      "[Trial 40] Epoch 27/60, Training Loss: 0.7659, Validation Loss: 0.5926\n",
      "[Trial 41] Epoch 22/60, Training Loss: 0.8265, Validation Loss: 0.8410\n",
      "[Trial 34] Epoch 53/60, Training Loss: 0.5809, Validation Loss: 0.5429\n",
      "[Trial 26] Epoch 48/60, Training Loss: 0.5764, Validation Loss: 0.5408\n",
      "[Trial 25] Epoch 52/60, Training Loss: 0.5733, Validation Loss: 0.4945\n",
      "[Trial 28] Epoch 47/60, Training Loss: 0.5533, Validation Loss: 0.4672\n",
      "[Trial 38] Epoch 22/60, Training Loss: 0.6815, Validation Loss: 0.5865\n",
      "[Trial 35] Epoch 51/60, Training Loss: 0.5804, Validation Loss: 0.5078\n",
      "[Trial 36] Epoch 29/60, Training Loss: 0.6116, Validation Loss: 0.5297\n",
      "[Trial 31] Epoch 36/60, Training Loss: 0.5934, Validation Loss: 0.5567\n",
      "[Trial 39] Epoch 37/60, Training Loss: 1.1144, Validation Loss: 1.2604\n",
      "[Trial 40] Epoch 28/60, Training Loss: 0.7502, Validation Loss: 0.6517\n",
      "[Trial 29] Epoch 46/60, Training Loss: 0.5654, Validation Loss: 0.5152\n",
      "[Trial 37] Epoch 28/60, Training Loss: 0.6307, Validation Loss: 0.5400\n",
      "[Trial 32] Epoch 35/60, Training Loss: 0.6505, Validation Loss: 0.5335\n",
      "[Trial 41] Epoch 23/60, Training Loss: 0.8818, Validation Loss: 0.6637\n",
      "[Trial 34] Epoch 54/60, Training Loss: 0.5837, Validation Loss: 0.5204\n",
      "[Trial 27] Epoch 48/60, Training Loss: 0.5615, Validation Loss: 0.4801\n",
      "[Trial 35] Epoch 52/60, Training Loss: 0.5756, Validation Loss: 0.5152\n",
      "[Trial 22] Epoch 34/60, Training Loss: 0.6107, Validation Loss: 0.5756\n",
      "[Trial 39] Epoch 38/60, Training Loss: 1.6313, Validation Loss: 0.8996\n",
      "[Trial 26] Epoch 49/60, Training Loss: 0.5725, Validation Loss: 0.4971\n",
      "[Trial 25] Epoch 53/60, Training Loss: 0.5690, Validation Loss: 0.4926\n",
      "[Trial 40] Epoch 29/60, Training Loss: 0.7327, Validation Loss: 0.6467\n",
      "[Trial 28] Epoch 48/60, Training Loss: 0.5580, Validation Loss: 0.4642\n",
      "[Trial 34] Epoch 55/60, Training Loss: 0.5525, Validation Loss: 0.5032\n",
      "[Trial 41] Epoch 24/60, Training Loss: 0.8113, Validation Loss: 0.7008\n",
      "[Trial 38] Epoch 23/60, Training Loss: 0.6307, Validation Loss: 0.5228\n",
      "[Trial 36] Epoch 30/60, Training Loss: 0.6071, Validation Loss: 0.5114\n",
      "[Trial 31] Epoch 37/60, Training Loss: 0.5901, Validation Loss: 0.5220\n",
      "[Trial 29] Epoch 47/60, Training Loss: 0.5600, Validation Loss: 0.4804\n",
      "[Trial 35] Epoch 53/60, Training Loss: 0.5761, Validation Loss: 0.4972\n",
      "[Trial 37] Epoch 29/60, Training Loss: 0.6211, Validation Loss: 0.5448\n",
      "[Trial 32] Epoch 36/60, Training Loss: 0.6413, Validation Loss: 0.5842\n",
      "[Trial 39] Epoch 39/60, Training Loss: 1.1430, Validation Loss: 0.9551\n",
      "[Trial 27] Epoch 49/60, Training Loss: 0.5606, Validation Loss: 0.5052\n",
      "[Trial 40] Epoch 30/60, Training Loss: 0.7178, Validation Loss: 0.6244\n",
      "[Trial 34] Epoch 56/60, Training Loss: 0.5476, Validation Loss: 0.4974\n",
      "[Trial 41] Epoch 25/60, Training Loss: 0.8069, Validation Loss: 1.0309\n",
      "[Trial 26] Epoch 50/60, Training Loss: 0.5651, Validation Loss: 0.5080\n",
      "[Trial 25] Epoch 54/60, Training Loss: 0.5685, Validation Loss: 0.5002\n",
      "[Trial 28] Epoch 49/60, Training Loss: 0.5642, Validation Loss: 0.4891\n",
      "[Trial 35] Epoch 54/60, Training Loss: 0.5729, Validation Loss: 0.5094\n",
      "[Trial 39] Epoch 40/60, Training Loss: 1.2933, Validation Loss: 0.9297\n",
      "[Trial 40] Epoch 31/60, Training Loss: 0.7142, Validation Loss: 0.5996\n",
      "[Trial 38] Epoch 24/60, Training Loss: 0.6257, Validation Loss: 0.5424\n",
      "[Trial 36] Epoch 31/60, Training Loss: 0.6108, Validation Loss: 0.5700\n",
      "[Trial 31] Epoch 38/60, Training Loss: 0.5924, Validation Loss: 0.5154\n",
      "[Trial 29] Epoch 48/60, Training Loss: 0.5557, Validation Loss: 0.4883\n",
      "[Trial 34] Epoch 57/60, Training Loss: 0.5504, Validation Loss: 0.5006\n",
      "[Trial 41] Epoch 26/60, Training Loss: 0.8154, Validation Loss: 0.6377\n",
      "[Trial 37] Epoch 30/60, Training Loss: 0.6170, Validation Loss: 0.5495\n",
      "[Trial 32] Epoch 37/60, Training Loss: 0.6298, Validation Loss: 0.5448\n",
      "[Trial 27] Epoch 50/60, Training Loss: 0.5555, Validation Loss: 0.4677\n",
      "[Trial 22] Epoch 35/60, Training Loss: 0.6192, Validation Loss: 0.5601\n",
      "[Trial 35] Epoch 55/60, Training Loss: 0.5747, Validation Loss: 0.4990\n",
      "[Trial 39] Epoch 41/60, Training Loss: 1.0856, Validation Loss: 0.9301\n",
      "[Trial 40] Epoch 32/60, Training Loss: 0.7106, Validation Loss: 0.6440\n",
      "[Trial 26] Epoch 51/60, Training Loss: 0.5679, Validation Loss: 0.5147\n",
      "[Trial 25] Epoch 55/60, Training Loss: 0.5625, Validation Loss: 0.4891\n",
      "[Trial 34] Epoch 58/60, Training Loss: 0.5466, Validation Loss: 0.4919\n",
      "[Trial 28] Epoch 50/60, Training Loss: 0.5479, Validation Loss: 0.4491\n",
      "[Trial 41] Epoch 27/60, Training Loss: 0.7747, Validation Loss: 0.6193\n",
      "[Trial 38] Epoch 25/60, Training Loss: 0.6187, Validation Loss: 0.5385\n",
      "[Trial 36] Epoch 32/60, Training Loss: 0.6058, Validation Loss: 0.5506\n",
      "[Trial 35] Epoch 56/60, Training Loss: 0.5723, Validation Loss: 0.5197\n",
      "[Trial 29] Epoch 49/60, Training Loss: 0.5627, Validation Loss: 0.5230\n",
      "[Trial 39] Epoch 42/60, Training Loss: 1.5215, Validation Loss: 3.5471\n",
      "[Trial 31] Epoch 39/60, Training Loss: 0.5959, Validation Loss: 0.5231\n",
      "[Trial 40] Epoch 33/60, Training Loss: 0.6874, Validation Loss: 0.6305\n",
      "[Trial 37] Epoch 31/60, Training Loss: 0.6004, Validation Loss: 0.5217\n",
      "[Trial 27] Epoch 51/60, Training Loss: 0.5463, Validation Loss: 0.4776\n",
      "[Trial 32] Epoch 38/60, Training Loss: 0.6211, Validation Loss: 0.5685\n",
      "[Trial 34] Epoch 59/60, Training Loss: 0.5482, Validation Loss: 0.5146\n",
      "[Trial 41] Epoch 28/60, Training Loss: 0.7662, Validation Loss: 0.6303\n",
      "[Trial 35] Epoch 57/60, Training Loss: 0.5709, Validation Loss: 0.5108\n",
      "[Trial 26] Epoch 52/60, Training Loss: 0.5776, Validation Loss: 0.5040\n",
      "[Trial 25] Epoch 56/60, Training Loss: 0.5637, Validation Loss: 0.4917\n",
      "[Trial 28] Epoch 51/60, Training Loss: 0.5494, Validation Loss: 0.4624\n",
      "[Trial 39] Epoch 43/60, Training Loss: 3.6139, Validation Loss: 1.0144\n",
      "[Trial 40] Epoch 34/60, Training Loss: 0.6388, Validation Loss: 0.6146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:02:11,212] Trial 34 finished with value: 0.49192925294240314 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.009346989377859766, 'batch_size': 32, 'patience': 10}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 34] Epoch 60/60, Training Loss: 0.5456, Validation Loss: 0.4936\n",
      "[Trial 41] Epoch 29/60, Training Loss: 0.8170, Validation Loss: 0.7882\n",
      "[Trial 36] Epoch 33/60, Training Loss: 0.5998, Validation Loss: 0.5253\n",
      "[Trial 38] Epoch 26/60, Training Loss: 0.6245, Validation Loss: 0.5322\n",
      "[Trial 29] Epoch 50/60, Training Loss: 0.5779, Validation Loss: 0.5096\n",
      "[Trial 31] Epoch 40/60, Training Loss: 0.5704, Validation Loss: 0.4873\n",
      "[Trial 22] Epoch 36/60, Training Loss: 0.6056, Validation Loss: 0.5701\n",
      "[Trial 37] Epoch 32/60, Training Loss: 0.5928, Validation Loss: 0.5139\n",
      "[Trial 35] Epoch 58/60, Training Loss: 0.5714, Validation Loss: 0.5191\n",
      "[Trial 27] Epoch 52/60, Training Loss: 0.5496, Validation Loss: 0.4843\n",
      "[Trial 39] Epoch 44/60, Training Loss: 1.0855, Validation Loss: 0.9025\n",
      "[Trial 32] Epoch 39/60, Training Loss: 0.6045, Validation Loss: 0.4898\n",
      "[Trial 40] Epoch 35/60, Training Loss: 0.6360, Validation Loss: 0.5645\n",
      "[Trial 42] Epoch 1/60, Training Loss: 6.1075, Validation Loss: 2.9337\n",
      "[Trial 41] Epoch 30/60, Training Loss: 0.7989, Validation Loss: 0.6698\n",
      "[Trial 28] Epoch 52/60, Training Loss: 0.5474, Validation Loss: 0.4628\n",
      "[Trial 26] Epoch 53/60, Training Loss: 0.5489, Validation Loss: 0.4792\n",
      "[Trial 25] Epoch 57/60, Training Loss: 0.5789, Validation Loss: 0.4951\n",
      "[Trial 35] Epoch 59/60, Training Loss: 0.5651, Validation Loss: 0.4997\n",
      "[Trial 39] Epoch 45/60, Training Loss: 0.9962, Validation Loss: 0.7752\n",
      "[Trial 36] Epoch 34/60, Training Loss: 0.6083, Validation Loss: 0.5391\n",
      "[Trial 29] Epoch 51/60, Training Loss: 0.5550, Validation Loss: 0.5090\n",
      "[Trial 40] Epoch 36/60, Training Loss: 0.6165, Validation Loss: 0.5440\n",
      "[Trial 38] Epoch 27/60, Training Loss: 0.6056, Validation Loss: 0.4927\n",
      "[Trial 31] Epoch 41/60, Training Loss: 0.5689, Validation Loss: 0.5012\n",
      "[Trial 42] Epoch 2/60, Training Loss: 2.3746, Validation Loss: 1.9458\n",
      "[Trial 37] Epoch 33/60, Training Loss: 0.6286, Validation Loss: 0.6006\n",
      "[Trial 41] Epoch 31/60, Training Loss: 0.7795, Validation Loss: 0.6300\n",
      "[Trial 27] Epoch 53/60, Training Loss: 0.5494, Validation Loss: 0.4696\n",
      "[Trial 32] Epoch 40/60, Training Loss: 0.5933, Validation Loss: 0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:04:08,502] Trial 35 finished with value: 0.4972381482521693 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.006733466123141883, 'batch_size': 32, 'patience': 10}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 39] Epoch 46/60, Training Loss: 0.9504, Validation Loss: 0.8045\n",
      "[Trial 35] Epoch 60/60, Training Loss: 0.5645, Validation Loss: 0.5031\n",
      "[Trial 28] Epoch 53/60, Training Loss: 0.5430, Validation Loss: 0.4531\n",
      "[Trial 40] Epoch 37/60, Training Loss: 0.6251, Validation Loss: 0.5707\n",
      "[Trial 26] Epoch 54/60, Training Loss: 0.5488, Validation Loss: 0.4807\n",
      "[Trial 25] Epoch 58/60, Training Loss: 0.5723, Validation Loss: 0.5040\n",
      "[Trial 42] Epoch 3/60, Training Loss: 1.8976, Validation Loss: 1.4867\n",
      "[Trial 41] Epoch 32/60, Training Loss: 0.7692, Validation Loss: 0.7157\n",
      "[Trial 22] Epoch 37/60, Training Loss: 0.6045, Validation Loss: 0.5901\n",
      "[Trial 29] Epoch 52/60, Training Loss: 0.5573, Validation Loss: 0.5135\n",
      "[Trial 36] Epoch 35/60, Training Loss: 0.6077, Validation Loss: 0.5560\n",
      "[Trial 38] Epoch 28/60, Training Loss: 0.5949, Validation Loss: 0.5128\n",
      "[Trial 39] Epoch 47/60, Training Loss: 0.9328, Validation Loss: 0.7746\n",
      "[Trial 31] Epoch 42/60, Training Loss: 0.5745, Validation Loss: 0.4941\n",
      "[Trial 37] Epoch 34/60, Training Loss: 0.6125, Validation Loss: 0.5081\n",
      "[Trial 27] Epoch 54/60, Training Loss: 0.5349, Validation Loss: 0.4588\n",
      "[Trial 40] Epoch 38/60, Training Loss: 0.6346, Validation Loss: 0.5503\n",
      "[Trial 32] Epoch 41/60, Training Loss: 0.5954, Validation Loss: 0.5248\n",
      "[Trial 42] Epoch 4/60, Training Loss: 1.6750, Validation Loss: 1.3088\n",
      "[Trial 43] Epoch 1/60, Training Loss: 3.5527, Validation Loss: 2.0647\n",
      "[Trial 41] Epoch 33/60, Training Loss: 0.7748, Validation Loss: 0.6968\n",
      "[Trial 28] Epoch 54/60, Training Loss: 0.5430, Validation Loss: 0.4553\n",
      "[Trial 26] Epoch 55/60, Training Loss: 0.5425, Validation Loss: 0.4799\n",
      "[Trial 25] Epoch 59/60, Training Loss: 0.5683, Validation Loss: 0.4895\n",
      "[Trial 39] Epoch 48/60, Training Loss: 0.9219, Validation Loss: 0.7656\n",
      "[Trial 40] Epoch 39/60, Training Loss: 0.6242, Validation Loss: 0.5409\n",
      "[Trial 29] Epoch 53/60, Training Loss: 0.5591, Validation Loss: 0.5019\n",
      "[Trial 36] Epoch 36/60, Training Loss: 0.6039, Validation Loss: 0.6119\n",
      "[Trial 42] Epoch 5/60, Training Loss: 1.5508, Validation Loss: 1.3693\n",
      "[Trial 38] Epoch 29/60, Training Loss: 0.5980, Validation Loss: 0.4997\n",
      "[Trial 41] Epoch 34/60, Training Loss: 0.6906, Validation Loss: 0.5609\n",
      "[Trial 31] Epoch 43/60, Training Loss: 0.5628, Validation Loss: 0.4921\n",
      "[Trial 37] Epoch 35/60, Training Loss: 0.5894, Validation Loss: 0.5064\n",
      "[Trial 27] Epoch 55/60, Training Loss: 0.5349, Validation Loss: 0.4640\n",
      "[Trial 39] Epoch 49/60, Training Loss: 0.9297, Validation Loss: 0.7504\n",
      "[Trial 32] Epoch 42/60, Training Loss: 0.6017, Validation Loss: 0.5312\n",
      "[Trial 43] Epoch 2/60, Training Loss: 1.9440, Validation Loss: 1.3257\n",
      "[Trial 40] Epoch 40/60, Training Loss: 0.6224, Validation Loss: 0.5611\n",
      "[Trial 28] Epoch 55/60, Training Loss: 0.5439, Validation Loss: 0.4444\n",
      "[Trial 26] Epoch 56/60, Training Loss: 0.5438, Validation Loss: 0.4830\n",
      "[Trial 42] Epoch 6/60, Training Loss: 1.3941, Validation Loss: 1.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:06:41,700] Trial 25 finished with value: 0.4890572423736254 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0030466834220488296, 'batch_size': 16, 'patience': 6}. Best is trial 17 with value: 0.4747499664624532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 25] Epoch 60/60, Training Loss: 0.5654, Validation Loss: 0.5039\n",
      "[Trial 22] Epoch 38/60, Training Loss: 0.5777, Validation Loss: 0.5385\n",
      "[Trial 41] Epoch 35/60, Training Loss: 0.6547, Validation Loss: 0.5576\n",
      "[Trial 39] Epoch 50/60, Training Loss: 0.8962, Validation Loss: 0.7270\n",
      "[Trial 29] Epoch 54/60, Training Loss: 0.5466, Validation Loss: 0.4805\n",
      "[Trial 36] Epoch 37/60, Training Loss: 0.5823, Validation Loss: 0.5018\n",
      "[Trial 38] Epoch 30/60, Training Loss: 0.5994, Validation Loss: 0.5202\n",
      "[Trial 40] Epoch 41/60, Training Loss: 0.6172, Validation Loss: 0.5763\n",
      "[Trial 31] Epoch 44/60, Training Loss: 0.5618, Validation Loss: 0.4829\n",
      "[Trial 27] Epoch 56/60, Training Loss: 0.5403, Validation Loss: 0.4690\n",
      "[Trial 37] Epoch 36/60, Training Loss: 0.5865, Validation Loss: 0.5080\n",
      "[Trial 42] Epoch 7/60, Training Loss: 1.2802, Validation Loss: 1.0299\n",
      "[Trial 32] Epoch 43/60, Training Loss: 0.5947, Validation Loss: 0.5237\n",
      "[Trial 41] Epoch 36/60, Training Loss: 0.6616, Validation Loss: 0.5283\n",
      "[Trial 43] Epoch 3/60, Training Loss: 1.7229, Validation Loss: 1.2455\n",
      "[Trial 28] Epoch 56/60, Training Loss: 0.5414, Validation Loss: 0.4571\n",
      "[Trial 39] Epoch 51/60, Training Loss: 0.8868, Validation Loss: 0.7221\n",
      "[Trial 26] Epoch 57/60, Training Loss: 0.5430, Validation Loss: 0.4779\n",
      "[Trial 44] Epoch 1/60, Training Loss: 3.8007, Validation Loss: 1.9562\n",
      "[Trial 40] Epoch 42/60, Training Loss: 0.6294, Validation Loss: 0.5651\n",
      "[Trial 42] Epoch 8/60, Training Loss: 1.1808, Validation Loss: 0.9675\n",
      "[Trial 29] Epoch 55/60, Training Loss: 0.5529, Validation Loss: 0.4823\n",
      "[Trial 41] Epoch 37/60, Training Loss: 0.6528, Validation Loss: 0.5871\n",
      "[Trial 36] Epoch 38/60, Training Loss: 0.5716, Validation Loss: 0.5009\n",
      "[Trial 38] Epoch 31/60, Training Loss: 0.5866, Validation Loss: 0.4952\n",
      "[Trial 39] Epoch 52/60, Training Loss: 0.8930, Validation Loss: 0.8304\n",
      "[Trial 27] Epoch 57/60, Training Loss: 0.5407, Validation Loss: 0.4914\n",
      "[Trial 31] Epoch 45/60, Training Loss: 0.5787, Validation Loss: 0.4890\n",
      "[Trial 37] Epoch 37/60, Training Loss: 0.5976, Validation Loss: 0.5396\n",
      "[Trial 40] Epoch 43/60, Training Loss: 0.6198, Validation Loss: 0.5572\n",
      "[Trial 43] Epoch 4/60, Training Loss: 1.5096, Validation Loss: 1.0620\n",
      "[Trial 32] Epoch 44/60, Training Loss: 0.5795, Validation Loss: 0.4890\n",
      "[Trial 28] Epoch 57/60, Training Loss: 0.5436, Validation Loss: 0.4492\n",
      "[Trial 42] Epoch 9/60, Training Loss: 1.1081, Validation Loss: 0.8898\n",
      "[Trial 22] Epoch 39/60, Training Loss: 0.5818, Validation Loss: 0.5596\n",
      "[Trial 26] Epoch 58/60, Training Loss: 0.5540, Validation Loss: 0.4915\n",
      "[Trial 41] Epoch 38/60, Training Loss: 0.6572, Validation Loss: 0.5654\n",
      "[Trial 39] Epoch 53/60, Training Loss: 0.9179, Validation Loss: 0.7443\n",
      "[Trial 44] Epoch 2/60, Training Loss: 1.9434, Validation Loss: 1.7581\n",
      "[Trial 29] Epoch 56/60, Training Loss: 0.5451, Validation Loss: 0.4822\n",
      "[Trial 40] Epoch 44/60, Training Loss: 0.6314, Validation Loss: 0.5396\n",
      "[Trial 36] Epoch 39/60, Training Loss: 0.5790, Validation Loss: 0.5412\n",
      "[Trial 38] Epoch 32/60, Training Loss: 0.5884, Validation Loss: 0.4841\n",
      "[Trial 42] Epoch 10/60, Training Loss: 1.0676, Validation Loss: 0.9714\n",
      "[Trial 27] Epoch 58/60, Training Loss: 0.5535, Validation Loss: 0.4806\n",
      "[Trial 37] Epoch 38/60, Training Loss: 0.5920, Validation Loss: 0.5211\n",
      "[Trial 31] Epoch 46/60, Training Loss: 0.5689, Validation Loss: 0.4838\n",
      "[Trial 41] Epoch 39/60, Training Loss: 0.6557, Validation Loss: 0.6053\n",
      "[Trial 39] Epoch 54/60, Training Loss: 0.8655, Validation Loss: 0.6947\n",
      "[Trial 43] Epoch 5/60, Training Loss: 1.3416, Validation Loss: 0.9908\n",
      "[Trial 28] Epoch 58/60, Training Loss: 0.5342, Validation Loss: 0.4529\n",
      "[Trial 32] Epoch 45/60, Training Loss: 0.5825, Validation Loss: 0.5019\n",
      "[Trial 40] Epoch 45/60, Training Loss: 0.6150, Validation Loss: 0.5454\n",
      "[Trial 26] Epoch 59/60, Training Loss: 0.5495, Validation Loss: 0.4683\n",
      "[Trial 42] Epoch 11/60, Training Loss: 1.0413, Validation Loss: 0.8608\n",
      "[Trial 44] Epoch 3/60, Training Loss: 1.6413, Validation Loss: 1.3074\n",
      "[Trial 29] Epoch 57/60, Training Loss: 0.5498, Validation Loss: 0.4796\n",
      "[Trial 41] Epoch 40/60, Training Loss: 0.6501, Validation Loss: 0.6040\n",
      "[Trial 39] Epoch 55/60, Training Loss: 0.8903, Validation Loss: 0.7517\n",
      "[Trial 36] Epoch 40/60, Training Loss: 0.5716, Validation Loss: 0.4934\n",
      "[Trial 38] Epoch 33/60, Training Loss: 0.5940, Validation Loss: 0.4945\n",
      "[Trial 40] Epoch 46/60, Training Loss: 0.6223, Validation Loss: 0.5613\n",
      "[Trial 27] Epoch 59/60, Training Loss: 0.5489, Validation Loss: 0.4730\n",
      "[Trial 37] Epoch 39/60, Training Loss: 0.5726, Validation Loss: 0.5117\n",
      "[Trial 31] Epoch 47/60, Training Loss: 0.5646, Validation Loss: 0.4899\n",
      "[Trial 22] Epoch 40/60, Training Loss: 0.5816, Validation Loss: 0.5511\n",
      "[Trial 43] Epoch 6/60, Training Loss: 1.1830, Validation Loss: 0.8580\n",
      "[Trial 28] Epoch 59/60, Training Loss: 0.5377, Validation Loss: 0.4471\n",
      "[Trial 42] Epoch 12/60, Training Loss: 0.9812, Validation Loss: 0.9592\n",
      "[Trial 32] Epoch 46/60, Training Loss: 0.5773, Validation Loss: 0.4857\n",
      "[Trial 39] Epoch 56/60, Training Loss: 0.8980, Validation Loss: 0.6839\n",
      "[Trial 41] Epoch 41/60, Training Loss: 0.6568, Validation Loss: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:11:24,331] Trial 26 finished with value: 0.46828088561693826 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0038689274775345318, 'batch_size': 16, 'patience': 10}. Best is trial 26 with value: 0.46828088561693826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 26] Epoch 60/60, Training Loss: 0.5425, Validation Loss: 0.4729\n",
      "[Trial 40] Epoch 47/60, Training Loss: 0.6254, Validation Loss: 0.5681\n",
      "[Trial 44] Epoch 4/60, Training Loss: 1.4262, Validation Loss: 1.1529\n",
      "[Trial 29] Epoch 58/60, Training Loss: 0.5499, Validation Loss: 0.4843\n",
      "[Trial 42] Epoch 13/60, Training Loss: 0.9331, Validation Loss: 0.8054\n",
      "[Trial 36] Epoch 41/60, Training Loss: 0.5687, Validation Loss: 0.5197\n",
      "[Trial 39] Epoch 57/60, Training Loss: 0.8691, Validation Loss: 0.7126\n",
      "[Trial 41] Epoch 42/60, Training Loss: 0.6628, Validation Loss: 0.5874\n",
      "[Trial 45] Epoch 1/60, Training Loss: 4.6918, Validation Loss: 1.8418\n",
      "[Trial 38] Epoch 34/60, Training Loss: 0.5824, Validation Loss: 0.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:12:09,583] Trial 27 finished with value: 0.4588208923737208 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.004167279529266887, 'batch_size': 16, 'patience': 10}. Best is trial 27 with value: 0.4588208923737208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 27] Epoch 60/60, Training Loss: 0.5383, Validation Loss: 0.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:12:12,634] Trial 37 finished with value: 0.5064229533076287 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.005792675013612571, 'batch_size': 16, 'patience': 5}. Best is trial 27 with value: 0.4588208923737208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 37] Epoch 40/60, Training Loss: 0.5708, Validation Loss: 0.5094\n",
      "[Trial 37] Early stopping after 40 epochs.\n",
      "[Trial 43] Epoch 7/60, Training Loss: 1.0737, Validation Loss: 0.8332\n",
      "[Trial 31] Epoch 48/60, Training Loss: 0.5591, Validation Loss: 0.4891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:12:18,306] Trial 28 finished with value: 0.4444171443581581 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0043018261552823945, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 28] Epoch 60/60, Training Loss: 0.5384, Validation Loss: 0.4526\n",
      "[Trial 40] Epoch 48/60, Training Loss: 0.6238, Validation Loss: 0.5488\n",
      "[Trial 32] Epoch 47/60, Training Loss: 0.5763, Validation Loss: 0.4972\n",
      "[Trial 42] Epoch 14/60, Training Loss: 0.9651, Validation Loss: 0.7518\n",
      "[Trial 39] Epoch 58/60, Training Loss: 0.8805, Validation Loss: 0.7318\n",
      "[Trial 45] Epoch 2/60, Training Loss: 2.0448, Validation Loss: 1.5237\n",
      "[Trial 41] Epoch 43/60, Training Loss: 0.6214, Validation Loss: 0.5122\n",
      "[Trial 29] Epoch 59/60, Training Loss: 0.5468, Validation Loss: 0.4787\n",
      "[Trial 44] Epoch 5/60, Training Loss: 1.3040, Validation Loss: 0.9729\n",
      "[Trial 40] Epoch 49/60, Training Loss: 0.6175, Validation Loss: 0.5266\n",
      "[Trial 36] Epoch 42/60, Training Loss: 0.5723, Validation Loss: 0.5161\n",
      "[Trial 22] Epoch 41/60, Training Loss: 0.5856, Validation Loss: 0.5593\n",
      "[Trial 38] Epoch 35/60, Training Loss: 0.5847, Validation Loss: 0.4845\n",
      "[Trial 47] Epoch 1/60, Training Loss: 4.8081, Validation Loss: 2.0923\n",
      "[Trial 46] Epoch 1/60, Training Loss: 3.5112, Validation Loss: 1.6704\n",
      "[Trial 48] Epoch 1/60, Training Loss: 3.6772, Validation Loss: 1.6466\n",
      "[Trial 42] Epoch 15/60, Training Loss: 0.9035, Validation Loss: 0.7304\n",
      "[Trial 43] Epoch 8/60, Training Loss: 1.0015, Validation Loss: 0.8551\n",
      "[Trial 39] Epoch 59/60, Training Loss: 0.8777, Validation Loss: 0.7739\n",
      "[Trial 31] Epoch 49/60, Training Loss: 0.5500, Validation Loss: 0.4744\n",
      "[Trial 45] Epoch 3/60, Training Loss: 1.7864, Validation Loss: 1.4623\n",
      "[Trial 41] Epoch 44/60, Training Loss: 0.5968, Validation Loss: 0.5180\n",
      "[Trial 32] Epoch 48/60, Training Loss: 0.5784, Validation Loss: 0.4936\n",
      "[Trial 40] Epoch 50/60, Training Loss: 0.6174, Validation Loss: 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:14:02,898] Trial 29 finished with value: 0.4787170852224032 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.004106232605432456, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 29] Epoch 60/60, Training Loss: 0.5410, Validation Loss: 0.4895\n",
      "[Trial 42] Epoch 16/60, Training Loss: 0.8865, Validation Loss: 0.7134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:14:12,683] Trial 39 finished with value: 0.6838546613852183 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.008571686941244201, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 44] Epoch 6/60, Training Loss: 1.1782, Validation Loss: 0.9925\n",
      "[Trial 39] Epoch 60/60, Training Loss: 0.9343, Validation Loss: 0.7110\n",
      "[Trial 45] Epoch 4/60, Training Loss: 1.6350, Validation Loss: 1.2328\n",
      "[Trial 36] Epoch 43/60, Training Loss: 0.5661, Validation Loss: 0.5317\n",
      "[Trial 41] Epoch 45/60, Training Loss: 0.6031, Validation Loss: 0.5217\n",
      "[Trial 48] Epoch 2/60, Training Loss: 1.9188, Validation Loss: 1.3415\n",
      "[Trial 47] Epoch 2/60, Training Loss: 2.0340, Validation Loss: 1.2110\n",
      "[Trial 46] Epoch 2/60, Training Loss: 1.9739, Validation Loss: 1.4021\n",
      "[Trial 38] Epoch 36/60, Training Loss: 0.5803, Validation Loss: 0.4853\n",
      "[Trial 43] Epoch 9/60, Training Loss: 0.9816, Validation Loss: 0.7243\n",
      "[Trial 40] Epoch 51/60, Training Loss: 0.6257, Validation Loss: 0.5428\n",
      "[Trial 31] Epoch 50/60, Training Loss: 0.5499, Validation Loss: 0.4718\n",
      "[Trial 42] Epoch 17/60, Training Loss: 0.8553, Validation Loss: 0.8952\n",
      "[Trial 32] Epoch 49/60, Training Loss: 0.5770, Validation Loss: 0.4878\n",
      "[Trial 45] Epoch 5/60, Training Loss: 1.4219, Validation Loss: 1.0804\n",
      "[Trial 41] Epoch 46/60, Training Loss: 0.5963, Validation Loss: 0.5147\n",
      "[Trial 49] Epoch 1/60, Training Loss: 3.6552, Validation Loss: 1.5578\n",
      "[Trial 50] Epoch 1/60, Training Loss: 3.7419, Validation Loss: 1.6173\n",
      "[Trial 22] Epoch 42/60, Training Loss: 0.5827, Validation Loss: 0.5471\n",
      "[Trial 40] Epoch 52/60, Training Loss: 0.6127, Validation Loss: 0.5432\n",
      "[Trial 44] Epoch 7/60, Training Loss: 1.0809, Validation Loss: 0.9220\n",
      "[Trial 36] Epoch 44/60, Training Loss: 0.5620, Validation Loss: 0.4849\n",
      "[Trial 48] Epoch 3/60, Training Loss: 1.6446, Validation Loss: 1.1765\n",
      "[Trial 47] Epoch 3/60, Training Loss: 1.4363, Validation Loss: 0.8723\n",
      "[Trial 42] Epoch 18/60, Training Loss: 0.8459, Validation Loss: 0.7424\n",
      "[Trial 45] Epoch 6/60, Training Loss: 1.3121, Validation Loss: 1.0101\n",
      "[Trial 46] Epoch 3/60, Training Loss: 1.7356, Validation Loss: 1.1294\n",
      "[Trial 43] Epoch 10/60, Training Loss: 0.9252, Validation Loss: 0.8170\n",
      "[Trial 38] Epoch 37/60, Training Loss: 0.5845, Validation Loss: 0.5068\n",
      "[Trial 41] Epoch 47/60, Training Loss: 0.6038, Validation Loss: 0.5036\n",
      "[Trial 31] Epoch 51/60, Training Loss: 0.5574, Validation Loss: 0.4872\n",
      "[Trial 40] Epoch 53/60, Training Loss: 0.6021, Validation Loss: 0.5172\n",
      "[Trial 32] Epoch 50/60, Training Loss: 0.5719, Validation Loss: 0.4863\n",
      "[Trial 49] Epoch 2/60, Training Loss: 1.9532, Validation Loss: 1.3564\n",
      "[Trial 45] Epoch 7/60, Training Loss: 1.2278, Validation Loss: 1.0961\n",
      "[Trial 42] Epoch 19/60, Training Loss: 0.8175, Validation Loss: 0.6824\n",
      "[Trial 50] Epoch 2/60, Training Loss: 1.9738, Validation Loss: 1.3619\n",
      "[Trial 41] Epoch 48/60, Training Loss: 0.5995, Validation Loss: 0.5136\n",
      "[Trial 48] Epoch 4/60, Training Loss: 1.4094, Validation Loss: 1.1292\n",
      "[Trial 44] Epoch 8/60, Training Loss: 1.0338, Validation Loss: 1.0586\n",
      "[Trial 36] Epoch 45/60, Training Loss: 0.5573, Validation Loss: 0.4850\n",
      "[Trial 47] Epoch 4/60, Training Loss: 1.1639, Validation Loss: 1.1963\n",
      "[Trial 40] Epoch 54/60, Training Loss: 0.6105, Validation Loss: 0.5364\n",
      "[Trial 43] Epoch 11/60, Training Loss: 0.9210, Validation Loss: 0.7409\n",
      "[Trial 46] Epoch 4/60, Training Loss: 1.4935, Validation Loss: 1.0637\n",
      "[Trial 38] Epoch 38/60, Training Loss: 0.5759, Validation Loss: 0.4879\n",
      "[Trial 45] Epoch 8/60, Training Loss: 1.1485, Validation Loss: 0.8550\n",
      "[Trial 42] Epoch 20/60, Training Loss: 0.8209, Validation Loss: 0.8243\n",
      "[Trial 31] Epoch 52/60, Training Loss: 0.5481, Validation Loss: 0.4860\n",
      "[Trial 32] Epoch 51/60, Training Loss: 0.5676, Validation Loss: 0.4789\n",
      "[Trial 22] Epoch 43/60, Training Loss: 0.5858, Validation Loss: 0.5778\n",
      "[Trial 49] Epoch 3/60, Training Loss: 1.6824, Validation Loss: 1.0814\n",
      "[Trial 41] Epoch 49/60, Training Loss: 0.5958, Validation Loss: 0.4925\n",
      "[Trial 50] Epoch 3/60, Training Loss: 1.7085, Validation Loss: 1.2968\n",
      "[Trial 40] Epoch 55/60, Training Loss: 0.6035, Validation Loss: 0.5486\n",
      "[Trial 45] Epoch 9/60, Training Loss: 1.0932, Validation Loss: 0.7974\n",
      "[Trial 48] Epoch 5/60, Training Loss: 1.2724, Validation Loss: 0.8987\n",
      "[Trial 42] Epoch 21/60, Training Loss: 0.8093, Validation Loss: 0.6921\n",
      "[Trial 47] Epoch 5/60, Training Loss: 1.0524, Validation Loss: 1.5963\n",
      "[Trial 36] Epoch 46/60, Training Loss: 0.5573, Validation Loss: 0.4996\n",
      "[Trial 44] Epoch 9/60, Training Loss: 1.0169, Validation Loss: 0.7840\n",
      "[Trial 43] Epoch 12/60, Training Loss: 0.8560, Validation Loss: 0.6936\n",
      "[Trial 46] Epoch 5/60, Training Loss: 1.2959, Validation Loss: 0.9756\n",
      "[Trial 41] Epoch 50/60, Training Loss: 0.5934, Validation Loss: 0.5211\n",
      "[Trial 38] Epoch 39/60, Training Loss: 0.5724, Validation Loss: 0.4824\n",
      "[Trial 40] Epoch 56/60, Training Loss: 0.6083, Validation Loss: 0.5297\n",
      "[Trial 31] Epoch 53/60, Training Loss: 0.5533, Validation Loss: 0.4864\n",
      "[Trial 45] Epoch 10/60, Training Loss: 1.0010, Validation Loss: 0.8013\n",
      "[Trial 32] Epoch 52/60, Training Loss: 0.5688, Validation Loss: 0.4893\n",
      "[Trial 49] Epoch 4/60, Training Loss: 1.4508, Validation Loss: 1.3400\n",
      "[Trial 50] Epoch 4/60, Training Loss: 1.4942, Validation Loss: 1.1192\n",
      "[Trial 42] Epoch 22/60, Training Loss: 0.7978, Validation Loss: 0.7352\n",
      "[Trial 48] Epoch 6/60, Training Loss: 1.1410, Validation Loss: 0.8921\n",
      "[Trial 41] Epoch 51/60, Training Loss: 0.6008, Validation Loss: 0.5233\n",
      "[Trial 40] Epoch 57/60, Training Loss: 0.5675, Validation Loss: 0.4933\n",
      "[Trial 47] Epoch 6/60, Training Loss: 0.9831, Validation Loss: 0.9185\n",
      "[Trial 36] Epoch 47/60, Training Loss: 0.5651, Validation Loss: 0.4883\n",
      "[Trial 45] Epoch 11/60, Training Loss: 0.9856, Validation Loss: 0.7967\n",
      "[Trial 44] Epoch 10/60, Training Loss: 0.9241, Validation Loss: 0.7759\n",
      "[Trial 43] Epoch 13/60, Training Loss: 0.8487, Validation Loss: 0.7187\n",
      "[Trial 46] Epoch 6/60, Training Loss: 1.1748, Validation Loss: 0.8528\n",
      "[Trial 42] Epoch 23/60, Training Loss: 0.8225, Validation Loss: 0.7291\n",
      "[Trial 38] Epoch 40/60, Training Loss: 0.5678, Validation Loss: 0.4862\n",
      "[Trial 22] Epoch 44/60, Training Loss: 0.5696, Validation Loss: 0.5270\n",
      "[Trial 31] Epoch 54/60, Training Loss: 0.5554, Validation Loss: 0.4957\n",
      "[Trial 49] Epoch 5/60, Training Loss: 1.2717, Validation Loss: 0.8603\n",
      "[Trial 50] Epoch 5/60, Training Loss: 1.2385, Validation Loss: 0.8978\n",
      "[Trial 41] Epoch 52/60, Training Loss: 0.5963, Validation Loss: 0.5259\n",
      "[Trial 32] Epoch 53/60, Training Loss: 0.5725, Validation Loss: 0.4925\n",
      "[Trial 40] Epoch 58/60, Training Loss: 0.5600, Validation Loss: 0.5000\n",
      "[Trial 45] Epoch 12/60, Training Loss: 0.9519, Validation Loss: 0.7240\n",
      "[Trial 48] Epoch 7/60, Training Loss: 1.0749, Validation Loss: 0.8292\n",
      "[Trial 42] Epoch 24/60, Training Loss: 0.6939, Validation Loss: 0.5644\n",
      "[Trial 47] Epoch 7/60, Training Loss: 1.0145, Validation Loss: 0.9822\n",
      "[Trial 36] Epoch 48/60, Training Loss: 0.5585, Validation Loss: 0.5131\n",
      "[Trial 43] Epoch 14/60, Training Loss: 0.8293, Validation Loss: 0.8047\n",
      "[Trial 40] Epoch 59/60, Training Loss: 0.5598, Validation Loss: 0.5094\n",
      "[Trial 41] Epoch 53/60, Training Loss: 0.6008, Validation Loss: 0.5115\n",
      "[Trial 44] Epoch 11/60, Training Loss: 0.9031, Validation Loss: 0.7469\n",
      "[Trial 46] Epoch 7/60, Training Loss: 1.0869, Validation Loss: 0.8895\n",
      "[Trial 45] Epoch 13/60, Training Loss: 0.9135, Validation Loss: 0.7203\n",
      "[Trial 38] Epoch 41/60, Training Loss: 0.5724, Validation Loss: 0.4850\n",
      "[Trial 49] Epoch 6/60, Training Loss: 1.1236, Validation Loss: 0.8687\n",
      "[Trial 50] Epoch 6/60, Training Loss: 1.1263, Validation Loss: 0.8326\n",
      "[Trial 31] Epoch 55/60, Training Loss: 0.5428, Validation Loss: 0.4760\n",
      "[Trial 42] Epoch 25/60, Training Loss: 0.6783, Validation Loss: 0.5849\n",
      "[Trial 32] Epoch 54/60, Training Loss: 0.5698, Validation Loss: 0.4957\n",
      "[Trial 48] Epoch 8/60, Training Loss: 1.0203, Validation Loss: 0.7859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:20:51,545] Trial 40 finished with value: 0.4815680573383967 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'learning_rate': 0.010017463726537095, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 40] Epoch 60/60, Training Loss: 0.5695, Validation Loss: 0.4816\n",
      "[Trial 41] Epoch 54/60, Training Loss: 0.5986, Validation Loss: 0.4974\n",
      "[Trial 45] Epoch 14/60, Training Loss: 0.9019, Validation Loss: 0.7325\n",
      "[Trial 47] Epoch 8/60, Training Loss: 0.9087, Validation Loss: 1.0974\n",
      "[Trial 36] Epoch 49/60, Training Loss: 0.5645, Validation Loss: 0.4998\n",
      "[Trial 43] Epoch 15/60, Training Loss: 0.8071, Validation Loss: 0.6346\n",
      "[Trial 22] Epoch 45/60, Training Loss: 0.5649, Validation Loss: 0.5475\n",
      "[Trial 42] Epoch 26/60, Training Loss: 0.6835, Validation Loss: 0.5684\n",
      "[Trial 44] Epoch 12/60, Training Loss: 0.8604, Validation Loss: 0.7190\n",
      "[Trial 46] Epoch 8/60, Training Loss: 1.0578, Validation Loss: 0.8935\n",
      "[Trial 50] Epoch 7/60, Training Loss: 1.0467, Validation Loss: 0.7943\n",
      "[Trial 49] Epoch 7/60, Training Loss: 1.0473, Validation Loss: 0.8028\n",
      "[Trial 38] Epoch 42/60, Training Loss: 0.5697, Validation Loss: 0.4866\n",
      "[Trial 45] Epoch 15/60, Training Loss: 0.8830, Validation Loss: 0.7359\n",
      "[Trial 41] Epoch 55/60, Training Loss: 0.5993, Validation Loss: 0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:21:37,206] Trial 31 finished with value: 0.47176629602909087 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.005913610195372778, 'batch_size': 16, 'patience': 6}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 31] Epoch 56/60, Training Loss: 0.5470, Validation Loss: 0.4737\n",
      "[Trial 31] Early stopping after 56 epochs.\n",
      "[Trial 32] Epoch 55/60, Training Loss: 0.5758, Validation Loss: 0.4883\n",
      "[Trial 48] Epoch 9/60, Training Loss: 0.9755, Validation Loss: 0.8350\n",
      "[Trial 51] Epoch 1/60, Training Loss: 3.4535, Validation Loss: 1.8561\n",
      "[Trial 42] Epoch 27/60, Training Loss: 0.6779, Validation Loss: 0.5706\n",
      "[Trial 47] Epoch 9/60, Training Loss: 0.9246, Validation Loss: 0.8734\n",
      "[Trial 36] Epoch 50/60, Training Loss: 0.5548, Validation Loss: 0.4871\n",
      "[Trial 45] Epoch 16/60, Training Loss: 0.8515, Validation Loss: 0.6959\n",
      "[Trial 43] Epoch 16/60, Training Loss: 0.7946, Validation Loss: 0.6536\n",
      "[Trial 41] Epoch 56/60, Training Loss: 0.5763, Validation Loss: 0.5113\n",
      "[Trial 46] Epoch 9/60, Training Loss: 1.0235, Validation Loss: 0.7815\n",
      "[Trial 50] Epoch 8/60, Training Loss: 1.0036, Validation Loss: 0.8038\n",
      "[Trial 49] Epoch 8/60, Training Loss: 1.0165, Validation Loss: 0.7286\n",
      "[Trial 44] Epoch 13/60, Training Loss: 0.8491, Validation Loss: 0.7096\n",
      "[Trial 38] Epoch 43/60, Training Loss: 0.5704, Validation Loss: 0.4812\n",
      "[Trial 52] Epoch 1/60, Training Loss: 3.6205, Validation Loss: 1.7614\n",
      "[Trial 42] Epoch 28/60, Training Loss: 0.6626, Validation Loss: 0.5667\n",
      "[Trial 48] Epoch 10/60, Training Loss: 0.9366, Validation Loss: 0.7681\n",
      "[Trial 32] Epoch 56/60, Training Loss: 0.5630, Validation Loss: 0.4871\n",
      "[Trial 45] Epoch 17/60, Training Loss: 0.8554, Validation Loss: 0.7636\n",
      "[Trial 51] Epoch 2/60, Training Loss: 1.8977, Validation Loss: 1.1994\n",
      "[Trial 41] Epoch 57/60, Training Loss: 0.5695, Validation Loss: 0.4934\n",
      "[Trial 47] Epoch 10/60, Training Loss: 0.7703, Validation Loss: 0.6586\n",
      "[Trial 22] Epoch 46/60, Training Loss: 0.5697, Validation Loss: 0.5425\n",
      "[Trial 36] Epoch 51/60, Training Loss: 0.5417, Validation Loss: 0.4887\n",
      "[Trial 42] Epoch 29/60, Training Loss: 0.6376, Validation Loss: 0.5633\n",
      "[Trial 43] Epoch 17/60, Training Loss: 0.7732, Validation Loss: 0.6679\n",
      "[Trial 50] Epoch 9/60, Training Loss: 0.9263, Validation Loss: 0.8106\n",
      "[Trial 45] Epoch 18/60, Training Loss: 0.8459, Validation Loss: 0.7047\n",
      "[Trial 49] Epoch 9/60, Training Loss: 0.9274, Validation Loss: 0.7416\n",
      "[Trial 46] Epoch 10/60, Training Loss: 0.9558, Validation Loss: 0.7413\n",
      "[Trial 52] Epoch 2/60, Training Loss: 1.9616, Validation Loss: 1.5270\n",
      "[Trial 44] Epoch 14/60, Training Loss: 0.8356, Validation Loss: 1.0941\n",
      "[Trial 41] Epoch 58/60, Training Loss: 0.5609, Validation Loss: 0.4899\n",
      "[Trial 38] Epoch 44/60, Training Loss: 0.5735, Validation Loss: 0.4723\n",
      "[Trial 48] Epoch 11/60, Training Loss: 0.9188, Validation Loss: 0.7149\n",
      "[Trial 32] Epoch 57/60, Training Loss: 0.5624, Validation Loss: 0.4783\n",
      "[Trial 51] Epoch 3/60, Training Loss: 1.5786, Validation Loss: 1.1092\n",
      "[Trial 42] Epoch 30/60, Training Loss: 0.6365, Validation Loss: 0.5636\n",
      "[Trial 47] Epoch 11/60, Training Loss: 0.7454, Validation Loss: 0.5799\n",
      "[Trial 45] Epoch 19/60, Training Loss: 0.8255, Validation Loss: 0.7104\n",
      "[Trial 36] Epoch 52/60, Training Loss: 0.5486, Validation Loss: 0.5170\n",
      "[Trial 41] Epoch 59/60, Training Loss: 0.5619, Validation Loss: 0.5045\n",
      "[Trial 43] Epoch 18/60, Training Loss: 0.7846, Validation Loss: 0.6787\n",
      "[Trial 50] Epoch 10/60, Training Loss: 0.9350, Validation Loss: 0.8363\n",
      "[Trial 49] Epoch 10/60, Training Loss: 0.9200, Validation Loss: 0.7710\n",
      "[Trial 46] Epoch 11/60, Training Loss: 0.9437, Validation Loss: 0.8456\n",
      "[Trial 52] Epoch 3/60, Training Loss: 1.7042, Validation Loss: 1.1741\n",
      "[Trial 42] Epoch 31/60, Training Loss: 0.6353, Validation Loss: 0.5481\n",
      "[Trial 48] Epoch 12/60, Training Loss: 0.8850, Validation Loss: 0.6821\n",
      "[Trial 44] Epoch 15/60, Training Loss: 0.8802, Validation Loss: 0.6928\n",
      "[Trial 45] Epoch 20/60, Training Loss: 0.8314, Validation Loss: 0.6674\n",
      "[Trial 38] Epoch 45/60, Training Loss: 0.5683, Validation Loss: 0.4886\n",
      "[Trial 51] Epoch 4/60, Training Loss: 1.3275, Validation Loss: 0.9624\n",
      "[Trial 32] Epoch 58/60, Training Loss: 0.5607, Validation Loss: 0.4879\n",
      "[Trial 22] Epoch 47/60, Training Loss: 0.5641, Validation Loss: 0.5329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:25:01,549] Trial 41 finished with value: 0.4774972250064214 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 0.011058950992185491, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 41] Epoch 60/60, Training Loss: 0.5603, Validation Loss: 0.4775\n",
      "[Trial 47] Epoch 12/60, Training Loss: 0.7435, Validation Loss: 0.6313\n",
      "[Trial 42] Epoch 32/60, Training Loss: 0.6349, Validation Loss: 0.5577\n",
      "[Trial 36] Epoch 53/60, Training Loss: 0.5473, Validation Loss: 0.4674\n",
      "[Trial 45] Epoch 21/60, Training Loss: 0.8117, Validation Loss: 0.6907\n",
      "[Trial 43] Epoch 19/60, Training Loss: 0.7576, Validation Loss: 0.6915\n",
      "[Trial 50] Epoch 11/60, Training Loss: 0.9027, Validation Loss: 0.6929\n",
      "[Trial 49] Epoch 11/60, Training Loss: 0.8962, Validation Loss: 1.0193\n",
      "[Trial 52] Epoch 4/60, Training Loss: 1.4593, Validation Loss: 1.0944\n",
      "[Trial 46] Epoch 12/60, Training Loss: 0.9310, Validation Loss: 0.7842\n",
      "[Trial 48] Epoch 13/60, Training Loss: 0.8687, Validation Loss: 0.7382\n",
      "[Trial 38] Epoch 46/60, Training Loss: 0.5659, Validation Loss: 0.4839\n",
      "[Trial 44] Epoch 16/60, Training Loss: 0.8242, Validation Loss: 0.6976\n",
      "[Trial 51] Epoch 5/60, Training Loss: 1.1941, Validation Loss: 0.9381\n",
      "[Trial 42] Epoch 33/60, Training Loss: 0.6292, Validation Loss: 0.5452\n",
      "[Trial 32] Epoch 59/60, Training Loss: 0.5694, Validation Loss: 0.4789\n",
      "[Trial 45] Epoch 22/60, Training Loss: 0.7924, Validation Loss: 0.6479\n",
      "[Trial 53] Epoch 1/60, Training Loss: 3.8424, Validation Loss: 1.6629\n",
      "[Trial 47] Epoch 13/60, Training Loss: 0.7349, Validation Loss: 0.7163\n",
      "[Trial 50] Epoch 12/60, Training Loss: 0.8656, Validation Loss: 0.7060\n",
      "[Trial 36] Epoch 54/60, Training Loss: 0.5403, Validation Loss: 0.4779\n",
      "[Trial 43] Epoch 20/60, Training Loss: 0.7016, Validation Loss: 0.5600\n",
      "[Trial 49] Epoch 12/60, Training Loss: 0.9089, Validation Loss: 0.7317\n",
      "[Trial 52] Epoch 5/60, Training Loss: 1.2711, Validation Loss: 1.0128\n",
      "[Trial 42] Epoch 34/60, Training Loss: 0.6255, Validation Loss: 0.5298\n",
      "[Trial 45] Epoch 23/60, Training Loss: 0.7847, Validation Loss: 0.6582\n",
      "[Trial 48] Epoch 14/60, Training Loss: 0.8352, Validation Loss: 0.7376\n",
      "[Trial 46] Epoch 13/60, Training Loss: 0.8891, Validation Loss: 0.8885\n",
      "[Trial 22] Epoch 48/60, Training Loss: 0.5628, Validation Loss: 0.5257\n",
      "[Trial 51] Epoch 6/60, Training Loss: 1.0946, Validation Loss: 0.8109\n",
      "[Trial 38] Epoch 47/60, Training Loss: 0.5644, Validation Loss: 0.4772\n",
      "[Trial 44] Epoch 17/60, Training Loss: 0.8047, Validation Loss: 0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:27:04,879] Trial 32 finished with value: 0.4783337170879046 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.006083498607532219, 'batch_size': 16, 'patience': 6}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 32] Epoch 60/60, Training Loss: 0.5636, Validation Loss: 0.4928\n",
      "[Trial 47] Epoch 14/60, Training Loss: 0.7586, Validation Loss: 0.6259\n",
      "[Trial 53] Epoch 2/60, Training Loss: 2.0289, Validation Loss: 1.6625\n",
      "[Trial 45] Epoch 24/60, Training Loss: 0.7892, Validation Loss: 0.6524\n",
      "[Trial 42] Epoch 35/60, Training Loss: 0.6294, Validation Loss: 0.5820\n",
      "[Trial 50] Epoch 13/60, Training Loss: 0.8660, Validation Loss: 0.7968\n",
      "[Trial 36] Epoch 55/60, Training Loss: 0.5364, Validation Loss: 0.4754\n",
      "[Trial 43] Epoch 21/60, Training Loss: 0.7016, Validation Loss: 0.5556\n",
      "[Trial 49] Epoch 13/60, Training Loss: 0.8735, Validation Loss: 0.7266\n",
      "[Trial 52] Epoch 6/60, Training Loss: 1.1862, Validation Loss: 0.9397\n",
      "[Trial 48] Epoch 15/60, Training Loss: 0.8480, Validation Loss: 0.7103\n",
      "[Trial 46] Epoch 14/60, Training Loss: 0.9546, Validation Loss: 0.7751\n",
      "[Trial 51] Epoch 7/60, Training Loss: 1.0059, Validation Loss: 0.7309\n",
      "[Trial 45] Epoch 25/60, Training Loss: 0.7620, Validation Loss: 0.6376\n",
      "[Trial 42] Epoch 36/60, Training Loss: 0.6466, Validation Loss: 0.6315\n",
      "[Trial 38] Epoch 48/60, Training Loss: 0.5652, Validation Loss: 0.4851\n",
      "[Trial 54] Epoch 1/60, Training Loss: 3.4498, Validation Loss: 1.9059\n",
      "[Trial 44] Epoch 18/60, Training Loss: 0.7689, Validation Loss: 0.6568\n",
      "[Trial 47] Epoch 15/60, Training Loss: 0.7744, Validation Loss: 1.0839\n",
      "[Trial 53] Epoch 3/60, Training Loss: 1.8089, Validation Loss: 1.3086\n",
      "[Trial 50] Epoch 14/60, Training Loss: 0.8725, Validation Loss: 0.8495\n",
      "[Trial 36] Epoch 56/60, Training Loss: 0.5366, Validation Loss: 0.4883\n",
      "[Trial 45] Epoch 26/60, Training Loss: 0.7715, Validation Loss: 0.6120\n",
      "[Trial 49] Epoch 14/60, Training Loss: 0.8604, Validation Loss: 0.6345\n",
      "[Trial 43] Epoch 22/60, Training Loss: 0.6807, Validation Loss: 0.5711\n",
      "[Trial 52] Epoch 7/60, Training Loss: 1.0576, Validation Loss: 0.8425\n",
      "[Trial 42] Epoch 37/60, Training Loss: 0.6322, Validation Loss: 0.5515\n",
      "[Trial 48] Epoch 16/60, Training Loss: 0.8526, Validation Loss: 0.7491\n",
      "[Trial 22] Epoch 49/60, Training Loss: 0.5640, Validation Loss: 0.5445\n",
      "[Trial 46] Epoch 15/60, Training Loss: 0.8647, Validation Loss: 0.7106\n",
      "[Trial 51] Epoch 8/60, Training Loss: 0.9588, Validation Loss: 0.9026\n",
      "[Trial 54] Epoch 2/60, Training Loss: 1.9488, Validation Loss: 1.2252\n",
      "[Trial 47] Epoch 16/60, Training Loss: 0.7615, Validation Loss: 0.6023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:29:04,194] Trial 38 finished with value: 0.472335521876812 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.005686161189203003, 'batch_size': 16, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 38] Epoch 49/60, Training Loss: 0.5684, Validation Loss: 0.4763\n",
      "[Trial 38] Early stopping after 49 epochs.\n",
      "[Trial 45] Epoch 27/60, Training Loss: 0.7451, Validation Loss: 0.5792\n",
      "[Trial 53] Epoch 4/60, Training Loss: 1.5382, Validation Loss: 1.0222\n",
      "[Trial 44] Epoch 19/60, Training Loss: 0.7632, Validation Loss: 0.6671\n",
      "[Trial 42] Epoch 38/60, Training Loss: 0.6346, Validation Loss: 0.5660\n",
      "[Trial 50] Epoch 15/60, Training Loss: 0.8400, Validation Loss: 0.6700\n",
      "[Trial 49] Epoch 15/60, Training Loss: 0.8094, Validation Loss: 0.6567\n",
      "[Trial 36] Epoch 57/60, Training Loss: 0.5552, Validation Loss: 0.4974\n",
      "[Trial 52] Epoch 8/60, Training Loss: 1.0019, Validation Loss: 0.8321\n",
      "[Trial 43] Epoch 23/60, Training Loss: 0.6966, Validation Loss: 0.6990\n",
      "[Trial 48] Epoch 17/60, Training Loss: 0.8452, Validation Loss: 0.8755\n",
      "[Trial 45] Epoch 28/60, Training Loss: 0.7496, Validation Loss: 0.5928\n",
      "[Trial 51] Epoch 9/60, Training Loss: 0.9263, Validation Loss: 0.8360\n",
      "[Trial 46] Epoch 16/60, Training Loss: 0.8444, Validation Loss: 0.7085\n",
      "[Trial 42] Epoch 39/60, Training Loss: 0.5992, Validation Loss: 0.5212\n",
      "[Trial 54] Epoch 3/60, Training Loss: 1.5950, Validation Loss: 1.1590\n",
      "[Trial 47] Epoch 17/60, Training Loss: 0.7011, Validation Loss: 0.5951\n",
      "[Trial 55] Epoch 1/60, Training Loss: 4.2264, Validation Loss: 1.8645\n",
      "[Trial 53] Epoch 5/60, Training Loss: 1.3596, Validation Loss: 0.9259\n",
      "[Trial 44] Epoch 20/60, Training Loss: 0.7763, Validation Loss: 0.6834\n",
      "[Trial 50] Epoch 16/60, Training Loss: 0.7992, Validation Loss: 0.6755\n",
      "[Trial 45] Epoch 29/60, Training Loss: 0.7353, Validation Loss: 0.6206\n",
      "[Trial 22] Epoch 50/60, Training Loss: 0.5627, Validation Loss: 0.5267\n",
      "[Trial 52] Epoch 9/60, Training Loss: 0.9643, Validation Loss: 0.8009\n",
      "[Trial 49] Epoch 16/60, Training Loss: 0.8098, Validation Loss: 0.6848\n",
      "[Trial 36] Epoch 58/60, Training Loss: 0.5445, Validation Loss: 0.4906\n",
      "[Trial 42] Epoch 40/60, Training Loss: 0.5981, Validation Loss: 0.5172\n",
      "[Trial 48] Epoch 18/60, Training Loss: 0.8061, Validation Loss: 0.7211\n",
      "[Trial 43] Epoch 24/60, Training Loss: 0.7125, Validation Loss: 0.6110\n",
      "[Trial 51] Epoch 10/60, Training Loss: 0.9576, Validation Loss: 0.7888\n",
      "[Trial 46] Epoch 17/60, Training Loss: 0.8403, Validation Loss: 0.6924\n",
      "[Trial 54] Epoch 4/60, Training Loss: 1.3813, Validation Loss: 0.9205\n",
      "[Trial 45] Epoch 30/60, Training Loss: 0.7241, Validation Loss: 0.6108\n",
      "[Trial 47] Epoch 18/60, Training Loss: 0.6534, Validation Loss: 0.5533\n",
      "[Trial 55] Epoch 2/60, Training Loss: 2.0738, Validation Loss: 1.2709\n",
      "[Trial 53] Epoch 6/60, Training Loss: 1.2081, Validation Loss: 0.9548\n",
      "[Trial 50] Epoch 17/60, Training Loss: 0.7900, Validation Loss: 0.7362\n",
      "[Trial 42] Epoch 41/60, Training Loss: 0.6001, Validation Loss: 0.5163\n",
      "[Trial 44] Epoch 21/60, Training Loss: 0.7665, Validation Loss: 0.8089\n",
      "[Trial 52] Epoch 10/60, Training Loss: 0.9273, Validation Loss: 0.7364\n",
      "[Trial 49] Epoch 17/60, Training Loss: 0.7929, Validation Loss: 0.6141\n",
      "[Trial 45] Epoch 31/60, Training Loss: 0.7287, Validation Loss: 0.6111\n",
      "[Trial 48] Epoch 19/60, Training Loss: 0.7339, Validation Loss: 0.5717\n",
      "[Trial 36] Epoch 59/60, Training Loss: 0.5345, Validation Loss: 0.4867\n",
      "[Trial 43] Epoch 25/60, Training Loss: 0.7046, Validation Loss: 0.5984\n",
      "[Trial 51] Epoch 11/60, Training Loss: 0.8994, Validation Loss: 0.9066\n",
      "[Trial 54] Epoch 5/60, Training Loss: 1.1791, Validation Loss: 0.9603\n",
      "[Trial 42] Epoch 42/60, Training Loss: 0.5952, Validation Loss: 0.5298\n",
      "[Trial 46] Epoch 18/60, Training Loss: 0.8352, Validation Loss: 0.6385\n",
      "[Trial 47] Epoch 19/60, Training Loss: 0.6698, Validation Loss: 0.5641\n",
      "[Trial 55] Epoch 3/60, Training Loss: 1.8544, Validation Loss: 1.2112\n",
      "[Trial 45] Epoch 32/60, Training Loss: 0.6801, Validation Loss: 0.5555\n",
      "[Trial 53] Epoch 7/60, Training Loss: 1.1144, Validation Loss: 0.8990\n",
      "[Trial 50] Epoch 18/60, Training Loss: 0.8005, Validation Loss: 0.6591\n",
      "[Trial 22] Epoch 51/60, Training Loss: 0.5591, Validation Loss: 0.5191\n",
      "[Trial 44] Epoch 22/60, Training Loss: 0.7266, Validation Loss: 0.5694\n",
      "[Trial 52] Epoch 11/60, Training Loss: 0.9019, Validation Loss: 0.7513\n",
      "[Trial 49] Epoch 18/60, Training Loss: 0.7871, Validation Loss: 0.6281\n",
      "[Trial 48] Epoch 20/60, Training Loss: 0.7352, Validation Loss: 0.5994\n",
      "[Trial 42] Epoch 43/60, Training Loss: 0.5973, Validation Loss: 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:32:24,719] Trial 36 finished with value: 0.46737755884726845 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.005509073065932226, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 36] Epoch 60/60, Training Loss: 0.5328, Validation Loss: 0.4724\n",
      "[Trial 43] Epoch 26/60, Training Loss: 0.6531, Validation Loss: 0.5581\n",
      "[Trial 51] Epoch 12/60, Training Loss: 0.9258, Validation Loss: 0.7813\n",
      "[Trial 45] Epoch 33/60, Training Loss: 0.6653, Validation Loss: 0.5620\n",
      "[Trial 54] Epoch 6/60, Training Loss: 1.0761, Validation Loss: 0.7957\n",
      "[Trial 46] Epoch 19/60, Training Loss: 0.8094, Validation Loss: 0.6995\n",
      "[Trial 47] Epoch 20/60, Training Loss: 0.6605, Validation Loss: 0.5232\n",
      "[Trial 55] Epoch 4/60, Training Loss: 1.7101, Validation Loss: 1.1738\n",
      "[Trial 50] Epoch 19/60, Training Loss: 0.7793, Validation Loss: 0.6299\n",
      "[Trial 53] Epoch 8/60, Training Loss: 1.0585, Validation Loss: 0.7555\n",
      "[Trial 42] Epoch 44/60, Training Loss: 0.5935, Validation Loss: 0.5149\n",
      "[Trial 45] Epoch 34/60, Training Loss: 0.6697, Validation Loss: 0.5521\n",
      "[Trial 44] Epoch 23/60, Training Loss: 0.6751, Validation Loss: 0.5601\n",
      "[Trial 52] Epoch 12/60, Training Loss: 0.9004, Validation Loss: 0.8516\n",
      "[Trial 48] Epoch 21/60, Training Loss: 0.7315, Validation Loss: 0.5891\n",
      "[Trial 49] Epoch 19/60, Training Loss: 0.7950, Validation Loss: 0.6102\n",
      "[Trial 56] Epoch 1/60, Training Loss: 3.4516, Validation Loss: 1.5789\n",
      "[Trial 43] Epoch 27/60, Training Loss: 0.6442, Validation Loss: 0.5191\n",
      "[Trial 51] Epoch 13/60, Training Loss: 0.7888, Validation Loss: 0.6329\n",
      "[Trial 54] Epoch 7/60, Training Loss: 0.9998, Validation Loss: 0.8047\n",
      "[Trial 42] Epoch 45/60, Training Loss: 0.5855, Validation Loss: 0.5112\n",
      "[Trial 47] Epoch 21/60, Training Loss: 0.6554, Validation Loss: 0.6539\n",
      "[Trial 45] Epoch 35/60, Training Loss: 0.6721, Validation Loss: 0.5395\n",
      "[Trial 46] Epoch 20/60, Training Loss: 0.8296, Validation Loss: 0.6388\n",
      "[Trial 55] Epoch 5/60, Training Loss: 1.5261, Validation Loss: 0.9989\n",
      "[Trial 50] Epoch 20/60, Training Loss: 0.7563, Validation Loss: 0.6487\n",
      "[Trial 22] Epoch 52/60, Training Loss: 0.5623, Validation Loss: 0.5265\n",
      "[Trial 53] Epoch 9/60, Training Loss: 1.0022, Validation Loss: 0.9300\n",
      "[Trial 52] Epoch 13/60, Training Loss: 0.8673, Validation Loss: 0.7527\n",
      "[Trial 48] Epoch 22/60, Training Loss: 0.7483, Validation Loss: 0.6767\n",
      "[Trial 42] Epoch 46/60, Training Loss: 0.5958, Validation Loss: 0.5147\n",
      "[Trial 49] Epoch 20/60, Training Loss: 0.7761, Validation Loss: 0.6186\n",
      "[Trial 44] Epoch 24/60, Training Loss: 0.6672, Validation Loss: 0.5505\n",
      "[Trial 56] Epoch 2/60, Training Loss: 1.9404, Validation Loss: 1.3315\n",
      "[Trial 45] Epoch 36/60, Training Loss: 0.6661, Validation Loss: 0.5469\n",
      "[Trial 43] Epoch 28/60, Training Loss: 0.6451, Validation Loss: 0.5813\n",
      "[Trial 51] Epoch 14/60, Training Loss: 0.7691, Validation Loss: 0.6032\n",
      "[Trial 54] Epoch 8/60, Training Loss: 0.9549, Validation Loss: 0.8119\n",
      "[Trial 47] Epoch 22/60, Training Loss: 0.6586, Validation Loss: 0.5830\n",
      "[Trial 46] Epoch 21/60, Training Loss: 0.7775, Validation Loss: 0.5979\n",
      "[Trial 50] Epoch 21/60, Training Loss: 0.7474, Validation Loss: 0.6628\n",
      "[Trial 55] Epoch 6/60, Training Loss: 1.3728, Validation Loss: 0.9371\n",
      "[Trial 42] Epoch 47/60, Training Loss: 0.5894, Validation Loss: 0.5102\n",
      "[Trial 53] Epoch 10/60, Training Loss: 0.9847, Validation Loss: 0.8281\n",
      "[Trial 45] Epoch 37/60, Training Loss: 0.6600, Validation Loss: 0.5158\n",
      "[Trial 52] Epoch 14/60, Training Loss: 0.8525, Validation Loss: 0.7410\n",
      "[Trial 48] Epoch 23/60, Training Loss: 0.7292, Validation Loss: 0.6007\n",
      "[Trial 49] Epoch 21/60, Training Loss: 0.7795, Validation Loss: 0.6402\n",
      "[Trial 56] Epoch 3/60, Training Loss: 1.6804, Validation Loss: 1.1256\n",
      "[Trial 44] Epoch 25/60, Training Loss: 0.6633, Validation Loss: 0.5489\n",
      "[Trial 51] Epoch 15/60, Training Loss: 0.7572, Validation Loss: 0.6197\n",
      "[Trial 43] Epoch 29/60, Training Loss: 0.6428, Validation Loss: 0.5344\n",
      "[Trial 54] Epoch 9/60, Training Loss: 0.9147, Validation Loss: 0.7288\n",
      "[Trial 42] Epoch 48/60, Training Loss: 0.5824, Validation Loss: 0.5091\n",
      "[Trial 45] Epoch 38/60, Training Loss: 0.6605, Validation Loss: 0.5428\n",
      "[Trial 22] Epoch 53/60, Training Loss: 0.5622, Validation Loss: 0.5247\n",
      "[Trial 47] Epoch 23/60, Training Loss: 0.6468, Validation Loss: 0.5990\n",
      "[Trial 50] Epoch 22/60, Training Loss: 0.7449, Validation Loss: 0.6492\n",
      "[Trial 46] Epoch 22/60, Training Loss: 0.7739, Validation Loss: 0.6066\n",
      "[Trial 55] Epoch 7/60, Training Loss: 1.2426, Validation Loss: 0.9909\n",
      "[Trial 53] Epoch 11/60, Training Loss: 0.9547, Validation Loss: 0.7589\n",
      "[Trial 52] Epoch 15/60, Training Loss: 0.8268, Validation Loss: 0.7615\n",
      "[Trial 48] Epoch 24/60, Training Loss: 0.7197, Validation Loss: 0.5767\n",
      "[Trial 42] Epoch 49/60, Training Loss: 0.5928, Validation Loss: 0.5119\n",
      "[Trial 45] Epoch 39/60, Training Loss: 0.6483, Validation Loss: 0.5595\n",
      "[Trial 49] Epoch 22/60, Training Loss: 0.7780, Validation Loss: 0.6705\n",
      "[Trial 56] Epoch 4/60, Training Loss: 1.4242, Validation Loss: 1.2323\n",
      "[Trial 51] Epoch 16/60, Training Loss: 0.7582, Validation Loss: 0.6264\n",
      "[Trial 44] Epoch 26/60, Training Loss: 0.6665, Validation Loss: 0.5726\n",
      "[Trial 54] Epoch 10/60, Training Loss: 0.8893, Validation Loss: 0.7274\n",
      "[Trial 43] Epoch 30/60, Training Loss: 0.6342, Validation Loss: 0.5358\n",
      "[Trial 47] Epoch 24/60, Training Loss: 0.6470, Validation Loss: 0.5797\n",
      "[Trial 50] Epoch 23/60, Training Loss: 0.7454, Validation Loss: 0.7049\n",
      "[Trial 45] Epoch 40/60, Training Loss: 0.6609, Validation Loss: 0.5317\n",
      "[Trial 55] Epoch 8/60, Training Loss: 1.1339, Validation Loss: 0.8245\n",
      "[Trial 42] Epoch 50/60, Training Loss: 0.5889, Validation Loss: 0.5143\n",
      "[Trial 46] Epoch 23/60, Training Loss: 0.7714, Validation Loss: 0.5983\n",
      "[Trial 53] Epoch 12/60, Training Loss: 0.9073, Validation Loss: 0.7245\n",
      "[Trial 52] Epoch 16/60, Training Loss: 0.7749, Validation Loss: 0.6383\n",
      "[Trial 48] Epoch 25/60, Training Loss: 0.7117, Validation Loss: 0.5802\n",
      "[Trial 49] Epoch 23/60, Training Loss: 0.7876, Validation Loss: 0.5940\n",
      "[Trial 56] Epoch 5/60, Training Loss: 1.2368, Validation Loss: 0.9084\n",
      "[Trial 51] Epoch 17/60, Training Loss: 0.7424, Validation Loss: 0.6113\n",
      "[Trial 45] Epoch 41/60, Training Loss: 0.6561, Validation Loss: 0.5711\n",
      "[Trial 54] Epoch 11/60, Training Loss: 0.8894, Validation Loss: 0.8800\n",
      "[Trial 43] Epoch 31/60, Training Loss: 0.6409, Validation Loss: 0.5439\n",
      "[Trial 42] Epoch 51/60, Training Loss: 0.5828, Validation Loss: 0.5165\n",
      "[Trial 22] Epoch 54/60, Training Loss: 0.5616, Validation Loss: 0.5252\n",
      "[Trial 44] Epoch 27/60, Training Loss: 0.6643, Validation Loss: 0.5548\n",
      "[Trial 47] Epoch 25/60, Training Loss: 0.6389, Validation Loss: 0.6460\n",
      "[Trial 50] Epoch 24/60, Training Loss: 0.7356, Validation Loss: 0.6273\n",
      "[Trial 55] Epoch 9/60, Training Loss: 1.0692, Validation Loss: 0.7643\n",
      "[Trial 46] Epoch 24/60, Training Loss: 0.7607, Validation Loss: 0.7829\n",
      "[Trial 53] Epoch 13/60, Training Loss: 0.8656, Validation Loss: 0.6857\n",
      "[Trial 45] Epoch 42/60, Training Loss: 0.6341, Validation Loss: 0.5196\n",
      "[Trial 52] Epoch 17/60, Training Loss: 0.7488, Validation Loss: 0.6444\n",
      "[Trial 48] Epoch 26/60, Training Loss: 0.6809, Validation Loss: 0.5625\n",
      "[Trial 42] Epoch 52/60, Training Loss: 0.5909, Validation Loss: 0.5130\n",
      "[Trial 56] Epoch 6/60, Training Loss: 1.0719, Validation Loss: 0.8015\n",
      "[Trial 49] Epoch 24/60, Training Loss: 0.7345, Validation Loss: 0.6165\n",
      "[Trial 51] Epoch 18/60, Training Loss: 0.7398, Validation Loss: 0.6336\n",
      "[Trial 54] Epoch 12/60, Training Loss: 0.8639, Validation Loss: 0.6886\n",
      "[Trial 43] Epoch 32/60, Training Loss: 0.6214, Validation Loss: 0.5322\n",
      "[Trial 44] Epoch 28/60, Training Loss: 0.6697, Validation Loss: 0.5642\n",
      "[Trial 45] Epoch 43/60, Training Loss: 0.6299, Validation Loss: 0.5241\n",
      "[Trial 47] Epoch 26/60, Training Loss: 0.6399, Validation Loss: 0.7089\n",
      "[Trial 50] Epoch 25/60, Training Loss: 0.7316, Validation Loss: 0.6217\n",
      "[Trial 42] Epoch 53/60, Training Loss: 0.5719, Validation Loss: 0.4960\n",
      "[Trial 55] Epoch 10/60, Training Loss: 1.0306, Validation Loss: 0.7164\n",
      "[Trial 46] Epoch 25/60, Training Loss: 0.7567, Validation Loss: 0.7706\n",
      "[Trial 53] Epoch 14/60, Training Loss: 0.8737, Validation Loss: 0.7337\n",
      "[Trial 52] Epoch 18/60, Training Loss: 0.7490, Validation Loss: 0.6559\n",
      "[Trial 48] Epoch 27/60, Training Loss: 0.6825, Validation Loss: 0.5490\n",
      "[Trial 56] Epoch 7/60, Training Loss: 1.0155, Validation Loss: 0.7807\n",
      "[Trial 49] Epoch 25/60, Training Loss: 0.7437, Validation Loss: 0.6608\n",
      "[Trial 45] Epoch 44/60, Training Loss: 0.6255, Validation Loss: 0.5092\n",
      "[Trial 22] Epoch 55/60, Training Loss: 0.5571, Validation Loss: 0.5213\n",
      "[Trial 51] Epoch 19/60, Training Loss: 0.7403, Validation Loss: 0.6461\n",
      "[Trial 54] Epoch 13/60, Training Loss: 0.8091, Validation Loss: 0.6486\n",
      "[Trial 42] Epoch 54/60, Training Loss: 0.5718, Validation Loss: 0.4983\n",
      "[Trial 43] Epoch 33/60, Training Loss: 0.6248, Validation Loss: 0.5157\n",
      "[Trial 47] Epoch 27/60, Training Loss: 0.6302, Validation Loss: 0.5651\n",
      "[Trial 50] Epoch 26/60, Training Loss: 0.7230, Validation Loss: 0.6144\n",
      "[Trial 44] Epoch 29/60, Training Loss: 0.6652, Validation Loss: 0.5843\n",
      "[Trial 55] Epoch 11/60, Training Loss: 0.9694, Validation Loss: 0.7490\n",
      "[Trial 45] Epoch 45/60, Training Loss: 0.6289, Validation Loss: 0.5044\n",
      "[Trial 46] Epoch 26/60, Training Loss: 0.7647, Validation Loss: 0.6066\n",
      "[Trial 53] Epoch 15/60, Training Loss: 0.8592, Validation Loss: 0.7512\n",
      "[Trial 52] Epoch 19/60, Training Loss: 0.7414, Validation Loss: 0.6320\n",
      "[Trial 48] Epoch 28/60, Training Loss: 0.6641, Validation Loss: 0.5395\n",
      "[Trial 42] Epoch 55/60, Training Loss: 0.5751, Validation Loss: 0.4965\n",
      "[Trial 56] Epoch 8/60, Training Loss: 0.9619, Validation Loss: 0.8917\n",
      "[Trial 49] Epoch 26/60, Training Loss: 0.7511, Validation Loss: 0.6337\n",
      "[Trial 51] Epoch 20/60, Training Loss: 0.6993, Validation Loss: 0.5692\n",
      "[Trial 54] Epoch 14/60, Training Loss: 0.7961, Validation Loss: 0.6351\n",
      "[Trial 45] Epoch 46/60, Training Loss: 0.6197, Validation Loss: 0.5055\n",
      "[Trial 43] Epoch 34/60, Training Loss: 0.6154, Validation Loss: 0.5122\n",
      "[Trial 50] Epoch 27/60, Training Loss: 0.7270, Validation Loss: 0.7061\n",
      "[Trial 47] Epoch 28/60, Training Loss: 0.6200, Validation Loss: 0.5174\n",
      "[Trial 42] Epoch 56/60, Training Loss: 0.5693, Validation Loss: 0.4990\n",
      "[Trial 44] Epoch 30/60, Training Loss: 0.6288, Validation Loss: 0.5379\n",
      "[Trial 55] Epoch 12/60, Training Loss: 0.9220, Validation Loss: 0.7261\n",
      "[Trial 52] Epoch 20/60, Training Loss: 0.7378, Validation Loss: 0.6027\n",
      "[Trial 46] Epoch 27/60, Training Loss: 0.7551, Validation Loss: 0.7477\n",
      "[Trial 48] Epoch 29/60, Training Loss: 0.6637, Validation Loss: 0.5461\n",
      "[Trial 53] Epoch 16/60, Training Loss: 0.8694, Validation Loss: 0.7220\n",
      "[Trial 45] Epoch 47/60, Training Loss: 0.6235, Validation Loss: 0.5171\n",
      "[Trial 56] Epoch 9/60, Training Loss: 0.9528, Validation Loss: 0.6643\n",
      "[Trial 22] Epoch 56/60, Training Loss: 0.5611, Validation Loss: 0.5349\n",
      "[Trial 49] Epoch 27/60, Training Loss: 0.7264, Validation Loss: 0.5936\n",
      "[Trial 51] Epoch 21/60, Training Loss: 0.6934, Validation Loss: 0.5726\n",
      "[Trial 54] Epoch 15/60, Training Loss: 0.7974, Validation Loss: 0.6298\n",
      "[Trial 42] Epoch 57/60, Training Loss: 0.5691, Validation Loss: 0.4979\n",
      "[Trial 43] Epoch 35/60, Training Loss: 0.6152, Validation Loss: 0.5203\n",
      "[Trial 50] Epoch 28/60, Training Loss: 0.7245, Validation Loss: 0.6377\n",
      "[Trial 47] Epoch 29/60, Training Loss: 0.6034, Validation Loss: 0.5147\n",
      "[Trial 45] Epoch 48/60, Training Loss: 0.6164, Validation Loss: 0.5059\n",
      "[Trial 44] Epoch 31/60, Training Loss: 0.6176, Validation Loss: 0.5358\n",
      "[Trial 55] Epoch 13/60, Training Loss: 0.9254, Validation Loss: 0.8842\n",
      "[Trial 48] Epoch 30/60, Training Loss: 0.6602, Validation Loss: 0.5416\n",
      "[Trial 52] Epoch 21/60, Training Loss: 0.7218, Validation Loss: 0.6106\n",
      "[Trial 42] Epoch 58/60, Training Loss: 0.5645, Validation Loss: 0.4901\n",
      "[Trial 53] Epoch 17/60, Training Loss: 0.8392, Validation Loss: 0.7148\n",
      "[Trial 46] Epoch 28/60, Training Loss: 0.7077, Validation Loss: 0.5613\n",
      "[Trial 56] Epoch 10/60, Training Loss: 0.8906, Validation Loss: 0.6764\n",
      "[Trial 49] Epoch 28/60, Training Loss: 0.7290, Validation Loss: 0.6653\n",
      "[Trial 51] Epoch 22/60, Training Loss: 0.6840, Validation Loss: 0.5697\n",
      "[Trial 54] Epoch 16/60, Training Loss: 0.7798, Validation Loss: 0.7244\n",
      "[Trial 45] Epoch 49/60, Training Loss: 0.6159, Validation Loss: 0.5128\n",
      "[Trial 50] Epoch 29/60, Training Loss: 0.7194, Validation Loss: 0.6142\n",
      "[Trial 43] Epoch 36/60, Training Loss: 0.6136, Validation Loss: 0.5204\n",
      "[Trial 47] Epoch 30/60, Training Loss: 0.5968, Validation Loss: 0.5045\n",
      "[Trial 42] Epoch 59/60, Training Loss: 0.5639, Validation Loss: 0.4853\n",
      "[Trial 55] Epoch 14/60, Training Loss: 0.9081, Validation Loss: 0.6858\n",
      "[Trial 44] Epoch 32/60, Training Loss: 0.6233, Validation Loss: 0.5573\n",
      "[Trial 45] Epoch 50/60, Training Loss: 0.6076, Validation Loss: 0.4988\n",
      "[Trial 48] Epoch 31/60, Training Loss: 0.6657, Validation Loss: 0.5525\n",
      "[Trial 22] Epoch 57/60, Training Loss: 0.5547, Validation Loss: 0.5120\n",
      "[Trial 52] Epoch 22/60, Training Loss: 0.7220, Validation Loss: 0.6212\n",
      "[Trial 56] Epoch 11/60, Training Loss: 0.8672, Validation Loss: 0.8161\n",
      "[Trial 53] Epoch 18/60, Training Loss: 0.8195, Validation Loss: 0.7428\n",
      "[Trial 46] Epoch 29/60, Training Loss: 0.6846, Validation Loss: 0.5767\n",
      "[Trial 49] Epoch 29/60, Training Loss: 0.7365, Validation Loss: 0.6230\n",
      "[Trial 54] Epoch 17/60, Training Loss: 0.7986, Validation Loss: 0.7003\n",
      "[Trial 51] Epoch 23/60, Training Loss: 0.6889, Validation Loss: 0.5661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:42:38,799] Trial 42 finished with value: 0.4852802962064743 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 0.0025702858880844244, 'batch_size': 32, 'patience': 7}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 42] Epoch 60/60, Training Loss: 0.5607, Validation Loss: 0.4885\n",
      "[Trial 50] Epoch 30/60, Training Loss: 0.7046, Validation Loss: 0.6216\n",
      "[Trial 45] Epoch 51/60, Training Loss: 0.5996, Validation Loss: 0.4994\n",
      "[Trial 47] Epoch 31/60, Training Loss: 0.5963, Validation Loss: 0.5053\n",
      "[Trial 43] Epoch 37/60, Training Loss: 0.6131, Validation Loss: 0.5156\n",
      "[Trial 55] Epoch 15/60, Training Loss: 0.8681, Validation Loss: 0.7467\n",
      "[Trial 48] Epoch 32/60, Training Loss: 0.6669, Validation Loss: 0.5409\n",
      "[Trial 52] Epoch 23/60, Training Loss: 0.7484, Validation Loss: 0.6596\n",
      "[Trial 44] Epoch 33/60, Training Loss: 0.6258, Validation Loss: 0.5159\n",
      "[Trial 56] Epoch 12/60, Training Loss: 0.8596, Validation Loss: 0.7925\n",
      "[Trial 53] Epoch 19/60, Training Loss: 0.7601, Validation Loss: 0.6025\n",
      "[Trial 46] Epoch 30/60, Training Loss: 0.6839, Validation Loss: 0.6126\n",
      "[Trial 45] Epoch 52/60, Training Loss: 0.6031, Validation Loss: 0.5041\n",
      "[Trial 49] Epoch 30/60, Training Loss: 0.7096, Validation Loss: 0.5919\n",
      "[Trial 54] Epoch 18/60, Training Loss: 0.7807, Validation Loss: 0.7496\n",
      "[Trial 51] Epoch 24/60, Training Loss: 0.6882, Validation Loss: 0.6081\n",
      "[Trial 57] Epoch 1/60, Training Loss: 3.3763, Validation Loss: 1.4694\n",
      "[Trial 50] Epoch 31/60, Training Loss: 0.7193, Validation Loss: 0.9410\n",
      "[Trial 47] Epoch 32/60, Training Loss: 0.5933, Validation Loss: 0.5068\n",
      "[Trial 43] Epoch 38/60, Training Loss: 0.6146, Validation Loss: 0.5119\n",
      "[Trial 45] Epoch 53/60, Training Loss: 0.6034, Validation Loss: 0.5009\n",
      "[Trial 22] Epoch 58/60, Training Loss: 0.5500, Validation Loss: 0.5188\n",
      "[Trial 55] Epoch 16/60, Training Loss: 0.8812, Validation Loss: 0.6968\n",
      "[Trial 48] Epoch 33/60, Training Loss: 0.6574, Validation Loss: 0.5395\n",
      "[Trial 52] Epoch 24/60, Training Loss: 0.7178, Validation Loss: 0.6044\n",
      "[Trial 56] Epoch 13/60, Training Loss: 0.8399, Validation Loss: 0.7688\n",
      "[Trial 44] Epoch 34/60, Training Loss: 0.6218, Validation Loss: 0.5198\n",
      "[Trial 53] Epoch 20/60, Training Loss: 0.7519, Validation Loss: 0.6164\n",
      "[Trial 54] Epoch 19/60, Training Loss: 0.7613, Validation Loss: 0.6426\n",
      "[Trial 49] Epoch 31/60, Training Loss: 0.7122, Validation Loss: 0.6028\n",
      "[Trial 51] Epoch 25/60, Training Loss: 0.6750, Validation Loss: 0.5808\n",
      "[Trial 46] Epoch 31/60, Training Loss: 0.6892, Validation Loss: 0.5697\n",
      "[Trial 57] Epoch 2/60, Training Loss: 1.9073, Validation Loss: 1.4984\n",
      "[Trial 45] Epoch 54/60, Training Loss: 0.6026, Validation Loss: 0.4993\n",
      "[Trial 50] Epoch 32/60, Training Loss: 0.7456, Validation Loss: 0.6670\n",
      "[Trial 47] Epoch 33/60, Training Loss: 0.6039, Validation Loss: 0.5122\n",
      "[Trial 43] Epoch 39/60, Training Loss: 0.6075, Validation Loss: 0.5119\n",
      "[Trial 48] Epoch 34/60, Training Loss: 0.6625, Validation Loss: 0.5478\n",
      "[Trial 55] Epoch 17/60, Training Loss: 0.8349, Validation Loss: 0.6944\n",
      "[Trial 52] Epoch 25/60, Training Loss: 0.7049, Validation Loss: 0.6253\n",
      "[Trial 56] Epoch 14/60, Training Loss: 0.8256, Validation Loss: 0.6995\n",
      "[Trial 45] Epoch 55/60, Training Loss: 0.5988, Validation Loss: 0.4987\n",
      "[Trial 53] Epoch 21/60, Training Loss: 0.7424, Validation Loss: 0.6008\n",
      "[Trial 54] Epoch 20/60, Training Loss: 0.7043, Validation Loss: 0.5655\n",
      "[Trial 51] Epoch 26/60, Training Loss: 0.6754, Validation Loss: 0.5651\n",
      "[Trial 44] Epoch 35/60, Training Loss: 0.6149, Validation Loss: 0.5099\n",
      "[Trial 49] Epoch 32/60, Training Loss: 0.7353, Validation Loss: 0.5610\n",
      "[Trial 46] Epoch 32/60, Training Loss: 0.6854, Validation Loss: 0.5816\n",
      "[Trial 57] Epoch 3/60, Training Loss: 1.6045, Validation Loss: 1.1708\n",
      "[Trial 50] Epoch 33/60, Training Loss: 0.7039, Validation Loss: 0.6183\n",
      "[Trial 47] Epoch 34/60, Training Loss: 0.5995, Validation Loss: 0.5151\n",
      "[Trial 22] Epoch 59/60, Training Loss: 0.5547, Validation Loss: 0.5180\n",
      "[Trial 45] Epoch 56/60, Training Loss: 0.5933, Validation Loss: 0.4990\n",
      "[Trial 43] Epoch 40/60, Training Loss: 0.6092, Validation Loss: 0.5134\n",
      "[Trial 48] Epoch 35/60, Training Loss: 0.6451, Validation Loss: 0.5261\n",
      "[Trial 55] Epoch 18/60, Training Loss: 0.8352, Validation Loss: 0.6150\n",
      "[Trial 52] Epoch 26/60, Training Loss: 0.6981, Validation Loss: 0.5811\n",
      "[Trial 56] Epoch 15/60, Training Loss: 0.7550, Validation Loss: 0.6442\n",
      "[Trial 54] Epoch 21/60, Training Loss: 0.6914, Validation Loss: 0.5541\n",
      "[Trial 51] Epoch 27/60, Training Loss: 0.6708, Validation Loss: 0.5664\n",
      "[Trial 49] Epoch 33/60, Training Loss: 0.7112, Validation Loss: 0.7868\n",
      "[Trial 53] Epoch 22/60, Training Loss: 0.7402, Validation Loss: 0.5750\n",
      "[Trial 45] Epoch 57/60, Training Loss: 0.5951, Validation Loss: 0.4953\n",
      "[Trial 44] Epoch 36/60, Training Loss: 0.6091, Validation Loss: 0.5495\n",
      "[Trial 46] Epoch 33/60, Training Loss: 0.6801, Validation Loss: 0.5632\n",
      "[Trial 57] Epoch 4/60, Training Loss: 1.3350, Validation Loss: 0.9677\n",
      "[Trial 50] Epoch 34/60, Training Loss: 0.6971, Validation Loss: 0.6069\n",
      "[Trial 47] Epoch 35/60, Training Loss: 0.5905, Validation Loss: 0.5396\n",
      "[Trial 43] Epoch 41/60, Training Loss: 0.6152, Validation Loss: 0.5150\n",
      "[Trial 45] Epoch 58/60, Training Loss: 0.5906, Validation Loss: 0.4930\n",
      "[Trial 48] Epoch 36/60, Training Loss: 0.6400, Validation Loss: 0.5254\n",
      "[Trial 52] Epoch 27/60, Training Loss: 0.6800, Validation Loss: 0.5618\n",
      "[Trial 55] Epoch 19/60, Training Loss: 0.8157, Validation Loss: 0.6810\n",
      "[Trial 56] Epoch 16/60, Training Loss: 0.7574, Validation Loss: 0.6186\n",
      "[Trial 54] Epoch 22/60, Training Loss: 0.6866, Validation Loss: 0.6002\n",
      "[Trial 51] Epoch 28/60, Training Loss: 0.6753, Validation Loss: 0.5716\n",
      "[Trial 49] Epoch 34/60, Training Loss: 0.7615, Validation Loss: 0.6029\n",
      "[Trial 53] Epoch 23/60, Training Loss: 0.7313, Validation Loss: 0.5743\n",
      "[Trial 44] Epoch 37/60, Training Loss: 0.6178, Validation Loss: 0.5109\n",
      "[Trial 57] Epoch 5/60, Training Loss: 1.1824, Validation Loss: 1.2071\n",
      "[Trial 46] Epoch 34/60, Training Loss: 0.6746, Validation Loss: 0.5699\n",
      "[Trial 50] Epoch 35/60, Training Loss: 0.6970, Validation Loss: 0.6058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:47:10,206] Trial 22 finished with value: 0.5119647870461146 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.010094796379723959, 'batch_size': 8, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 22] Epoch 60/60, Training Loss: 0.5535, Validation Loss: 0.5291\n",
      "[Trial 45] Epoch 59/60, Training Loss: 0.5923, Validation Loss: 0.4887\n",
      "[Trial 47] Epoch 36/60, Training Loss: 0.5881, Validation Loss: 0.5135\n",
      "[Trial 43] Epoch 42/60, Training Loss: 0.6063, Validation Loss: 0.4967\n",
      "[Trial 48] Epoch 37/60, Training Loss: 0.6420, Validation Loss: 0.5060\n",
      "[Trial 52] Epoch 28/60, Training Loss: 0.6691, Validation Loss: 0.5590\n",
      "[Trial 55] Epoch 20/60, Training Loss: 0.8190, Validation Loss: 0.6314\n",
      "[Trial 56] Epoch 17/60, Training Loss: 0.7437, Validation Loss: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:47:44,317] Trial 45 finished with value: 0.48874779641628263 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.0017027532682520302, 'batch_size': 32, 'patience': 7}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 45] Epoch 60/60, Training Loss: 0.5938, Validation Loss: 0.4966\n",
      "[Trial 54] Epoch 23/60, Training Loss: 0.6895, Validation Loss: 0.5989\n",
      "[Trial 51] Epoch 29/60, Training Loss: 0.7000, Validation Loss: 0.6119\n",
      "[Trial 49] Epoch 35/60, Training Loss: 0.6874, Validation Loss: 0.5728\n",
      "[Trial 53] Epoch 24/60, Training Loss: 0.7317, Validation Loss: 0.5932\n",
      "[Trial 57] Epoch 6/60, Training Loss: 1.0732, Validation Loss: 0.7903\n",
      "[Trial 50] Epoch 36/60, Training Loss: 0.6901, Validation Loss: 0.6301\n",
      "[Trial 46] Epoch 35/60, Training Loss: 0.6584, Validation Loss: 0.5454\n",
      "[Trial 58] Epoch 1/60, Training Loss: 3.9807, Validation Loss: 1.7175\n",
      "[Trial 44] Epoch 38/60, Training Loss: 0.6223, Validation Loss: 0.5120\n",
      "[Trial 47] Epoch 37/60, Training Loss: 0.5613, Validation Loss: 0.4590\n",
      "[Trial 43] Epoch 43/60, Training Loss: 0.6033, Validation Loss: 0.5214\n",
      "[Trial 48] Epoch 38/60, Training Loss: 0.6348, Validation Loss: 0.5259\n",
      "[Trial 52] Epoch 29/60, Training Loss: 0.6689, Validation Loss: 0.5741\n",
      "[Trial 56] Epoch 18/60, Training Loss: 0.7420, Validation Loss: 0.5902\n",
      "[Trial 55] Epoch 21/60, Training Loss: 0.7877, Validation Loss: 0.7132\n",
      "[Trial 54] Epoch 24/60, Training Loss: 0.6902, Validation Loss: 0.5550\n",
      "[Trial 59] Epoch 1/60, Training Loss: 3.7953, Validation Loss: 1.9461\n",
      "[Trial 51] Epoch 30/60, Training Loss: 0.6972, Validation Loss: 0.5625\n",
      "[Trial 49] Epoch 36/60, Training Loss: 0.6931, Validation Loss: 0.6448\n",
      "[Trial 53] Epoch 25/60, Training Loss: 0.7380, Validation Loss: 0.6658\n",
      "[Trial 50] Epoch 37/60, Training Loss: 0.6935, Validation Loss: 0.6321\n",
      "[Trial 57] Epoch 7/60, Training Loss: 0.9996, Validation Loss: 0.8425\n",
      "[Trial 58] Epoch 2/60, Training Loss: 1.9735, Validation Loss: 1.3445\n",
      "[Trial 46] Epoch 36/60, Training Loss: 0.6447, Validation Loss: 0.5336\n",
      "[Trial 44] Epoch 39/60, Training Loss: 0.6163, Validation Loss: 0.5470\n",
      "[Trial 47] Epoch 38/60, Training Loss: 0.5597, Validation Loss: 0.4582\n",
      "[Trial 43] Epoch 44/60, Training Loss: 0.6019, Validation Loss: 0.5028\n",
      "[Trial 48] Epoch 39/60, Training Loss: 0.6386, Validation Loss: 0.5276\n",
      "[Trial 52] Epoch 30/60, Training Loss: 0.6688, Validation Loss: 0.5631\n",
      "[Trial 56] Epoch 19/60, Training Loss: 0.7181, Validation Loss: 0.5958\n",
      "[Trial 55] Epoch 22/60, Training Loss: 0.7816, Validation Loss: 0.6117\n",
      "[Trial 54] Epoch 25/60, Training Loss: 0.6680, Validation Loss: 0.5797\n",
      "[Trial 51] Epoch 31/60, Training Loss: 0.6647, Validation Loss: 0.5969\n",
      "[Trial 59] Epoch 2/60, Training Loss: 2.0289, Validation Loss: 1.3749\n",
      "[Trial 49] Epoch 37/60, Training Loss: 0.6979, Validation Loss: 0.6127\n",
      "[Trial 53] Epoch 26/60, Training Loss: 0.7379, Validation Loss: 0.6293\n",
      "[Trial 50] Epoch 38/60, Training Loss: 0.6829, Validation Loss: 0.6270\n",
      "[Trial 57] Epoch 8/60, Training Loss: 0.9727, Validation Loss: 0.8181\n",
      "[Trial 58] Epoch 3/60, Training Loss: 1.7612, Validation Loss: 1.3322\n",
      "[Trial 46] Epoch 37/60, Training Loss: 0.6484, Validation Loss: 0.5364\n",
      "[Trial 47] Epoch 39/60, Training Loss: 0.5673, Validation Loss: 0.4717\n",
      "[Trial 44] Epoch 40/60, Training Loss: 0.5939, Validation Loss: 0.4936\n",
      "[Trial 48] Epoch 40/60, Training Loss: 0.6373, Validation Loss: 0.5198\n",
      "[Trial 43] Epoch 45/60, Training Loss: 0.6014, Validation Loss: 0.5179\n",
      "[Trial 52] Epoch 31/60, Training Loss: 0.6622, Validation Loss: 0.5555\n",
      "[Trial 56] Epoch 20/60, Training Loss: 0.7181, Validation Loss: 0.6574\n",
      "[Trial 55] Epoch 23/60, Training Loss: 0.7721, Validation Loss: 0.6233\n",
      "[Trial 54] Epoch 26/60, Training Loss: 0.6488, Validation Loss: 0.5324\n",
      "[Trial 51] Epoch 32/60, Training Loss: 0.6567, Validation Loss: 0.5568\n",
      "[Trial 59] Epoch 3/60, Training Loss: 1.7540, Validation Loss: 1.1594\n",
      "[Trial 49] Epoch 38/60, Training Loss: 0.6702, Validation Loss: 0.5442\n",
      "[Trial 50] Epoch 39/60, Training Loss: 0.6822, Validation Loss: 0.6324\n",
      "[Trial 53] Epoch 27/60, Training Loss: 0.7332, Validation Loss: 0.5834\n",
      "[Trial 58] Epoch 4/60, Training Loss: 1.5514, Validation Loss: 1.2692\n",
      "[Trial 57] Epoch 9/60, Training Loss: 0.9425, Validation Loss: 0.7375\n",
      "[Trial 46] Epoch 38/60, Training Loss: 0.6508, Validation Loss: 0.5387\n",
      "[Trial 47] Epoch 40/60, Training Loss: 0.5688, Validation Loss: 0.4850\n",
      "[Trial 44] Epoch 41/60, Training Loss: 0.5913, Validation Loss: 0.4986\n",
      "[Trial 48] Epoch 41/60, Training Loss: 0.6292, Validation Loss: 0.5222\n",
      "[Trial 52] Epoch 32/60, Training Loss: 0.6785, Validation Loss: 0.6058\n",
      "[Trial 43] Epoch 46/60, Training Loss: 0.6033, Validation Loss: 0.5107\n",
      "[Trial 56] Epoch 21/60, Training Loss: 0.7272, Validation Loss: 0.6114\n",
      "[Trial 55] Epoch 24/60, Training Loss: 0.7635, Validation Loss: 0.6058\n",
      "[Trial 54] Epoch 27/60, Training Loss: 0.6461, Validation Loss: 0.5485\n",
      "[Trial 51] Epoch 33/60, Training Loss: 0.6563, Validation Loss: 0.5587\n",
      "[Trial 49] Epoch 39/60, Training Loss: 0.6542, Validation Loss: 0.5827\n",
      "[Trial 59] Epoch 4/60, Training Loss: 1.5503, Validation Loss: 1.1154\n",
      "[Trial 50] Epoch 40/60, Training Loss: 0.7028, Validation Loss: 0.6105\n",
      "[Trial 58] Epoch 5/60, Training Loss: 1.3651, Validation Loss: 0.9166\n",
      "[Trial 53] Epoch 28/60, Training Loss: 0.7264, Validation Loss: 0.5890\n",
      "[Trial 57] Epoch 10/60, Training Loss: 0.9077, Validation Loss: 0.7547\n",
      "[Trial 47] Epoch 41/60, Training Loss: 0.5567, Validation Loss: 0.4786\n",
      "[Trial 46] Epoch 39/60, Training Loss: 0.6518, Validation Loss: 0.5338\n",
      "[Trial 48] Epoch 42/60, Training Loss: 0.6399, Validation Loss: 0.5285\n",
      "[Trial 44] Epoch 42/60, Training Loss: 0.5897, Validation Loss: 0.5063\n",
      "[Trial 52] Epoch 33/60, Training Loss: 0.6794, Validation Loss: 0.5584\n",
      "[Trial 56] Epoch 22/60, Training Loss: 0.7111, Validation Loss: 0.6119\n",
      "[Trial 43] Epoch 47/60, Training Loss: 0.5983, Validation Loss: 0.4972\n",
      "[Trial 54] Epoch 28/60, Training Loss: 0.6518, Validation Loss: 0.5436\n",
      "[Trial 55] Epoch 25/60, Training Loss: 0.7667, Validation Loss: 0.6460\n",
      "[Trial 51] Epoch 34/60, Training Loss: 0.6530, Validation Loss: 0.5509\n",
      "[Trial 49] Epoch 40/60, Training Loss: 0.6595, Validation Loss: 0.5535\n",
      "[Trial 59] Epoch 5/60, Training Loss: 1.3666, Validation Loss: 0.9280\n",
      "[Trial 50] Epoch 41/60, Training Loss: 0.6422, Validation Loss: 0.5495\n",
      "[Trial 58] Epoch 6/60, Training Loss: 1.1857, Validation Loss: 0.9125\n",
      "[Trial 53] Epoch 29/60, Training Loss: 0.6881, Validation Loss: 0.5370\n",
      "[Trial 57] Epoch 11/60, Training Loss: 0.8546, Validation Loss: 0.7575\n",
      "[Trial 47] Epoch 42/60, Training Loss: 0.5514, Validation Loss: 0.4715\n",
      "[Trial 46] Epoch 40/60, Training Loss: 0.6337, Validation Loss: 0.5242\n",
      "[Trial 48] Epoch 43/60, Training Loss: 0.6399, Validation Loss: 0.5305\n",
      "[Trial 52] Epoch 34/60, Training Loss: 0.6500, Validation Loss: 0.5502\n",
      "[Trial 56] Epoch 23/60, Training Loss: 0.7164, Validation Loss: 0.6117\n",
      "[Trial 44] Epoch 43/60, Training Loss: 0.5847, Validation Loss: 0.4895\n",
      "[Trial 43] Epoch 48/60, Training Loss: 0.5934, Validation Loss: 0.5005\n",
      "[Trial 54] Epoch 29/60, Training Loss: 0.6429, Validation Loss: 0.5474\n",
      "[Trial 55] Epoch 26/60, Training Loss: 0.7631, Validation Loss: 0.5719\n",
      "[Trial 51] Epoch 35/60, Training Loss: 0.6634, Validation Loss: 0.5562\n",
      "[Trial 49] Epoch 41/60, Training Loss: 0.6509, Validation Loss: 0.5216\n",
      "[Trial 50] Epoch 42/60, Training Loss: 0.6338, Validation Loss: 0.5265\n",
      "[Trial 59] Epoch 6/60, Training Loss: 1.2221, Validation Loss: 0.9083\n",
      "[Trial 58] Epoch 7/60, Training Loss: 1.0711, Validation Loss: 0.8533\n",
      "[Trial 57] Epoch 12/60, Training Loss: 0.8586, Validation Loss: 0.8553\n",
      "[Trial 53] Epoch 30/60, Training Loss: 0.6928, Validation Loss: 0.5608\n",
      "[Trial 47] Epoch 43/60, Training Loss: 0.5540, Validation Loss: 0.4759\n",
      "[Trial 46] Epoch 41/60, Training Loss: 0.6338, Validation Loss: 0.5275\n",
      "[Trial 48] Epoch 44/60, Training Loss: 0.6261, Validation Loss: 0.5149\n",
      "[Trial 52] Epoch 35/60, Training Loss: 0.6586, Validation Loss: 0.5559\n",
      "[Trial 56] Epoch 24/60, Training Loss: 0.6673, Validation Loss: 0.5489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:53:45,614] Trial 43 finished with value: 0.49673078457514447 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.0016940549150168617, 'batch_size': 16, 'patience': 7}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 43] Epoch 49/60, Training Loss: 0.5994, Validation Loss: 0.5066\n",
      "[Trial 43] Early stopping after 49 epochs.\n",
      "[Trial 54] Epoch 30/60, Training Loss: 0.6354, Validation Loss: 0.5380\n",
      "[Trial 44] Epoch 44/60, Training Loss: 0.5789, Validation Loss: 0.5109\n",
      "[Trial 55] Epoch 27/60, Training Loss: 0.7460, Validation Loss: 0.5945\n",
      "[Trial 51] Epoch 36/60, Training Loss: 0.6496, Validation Loss: 0.5346\n",
      "[Trial 49] Epoch 42/60, Training Loss: 0.6421, Validation Loss: 0.5452\n",
      "[Trial 50] Epoch 43/60, Training Loss: 0.6356, Validation Loss: 0.5479\n",
      "[Trial 59] Epoch 7/60, Training Loss: 1.1147, Validation Loss: 0.8512\n",
      "[Trial 58] Epoch 8/60, Training Loss: 1.0223, Validation Loss: 0.8043\n",
      "[Trial 57] Epoch 13/60, Training Loss: 0.8496, Validation Loss: 0.6684\n",
      "[Trial 53] Epoch 31/60, Training Loss: 0.6794, Validation Loss: 0.5610\n",
      "[Trial 47] Epoch 44/60, Training Loss: 0.5603, Validation Loss: 0.4929\n",
      "[Trial 48] Epoch 45/60, Training Loss: 0.6204, Validation Loss: 0.5155\n",
      "[Trial 46] Epoch 42/60, Training Loss: 0.6329, Validation Loss: 0.5284\n",
      "[Trial 56] Epoch 25/60, Training Loss: 0.6666, Validation Loss: 0.5494\n",
      "[Trial 52] Epoch 36/60, Training Loss: 0.6618, Validation Loss: 0.5697\n",
      "[Trial 54] Epoch 31/60, Training Loss: 0.6243, Validation Loss: 0.5216\n",
      "[Trial 60] Epoch 1/60, Training Loss: 4.0260, Validation Loss: 1.6475\n",
      "[Trial 55] Epoch 28/60, Training Loss: 0.7307, Validation Loss: 0.6177\n",
      "[Trial 51] Epoch 37/60, Training Loss: 0.6481, Validation Loss: 0.5487\n",
      "[Trial 44] Epoch 45/60, Training Loss: 0.5877, Validation Loss: 0.5198\n",
      "[Trial 49] Epoch 43/60, Training Loss: 0.6406, Validation Loss: 0.5361\n",
      "[Trial 50] Epoch 44/60, Training Loss: 0.6335, Validation Loss: 0.5520\n",
      "[Trial 58] Epoch 9/60, Training Loss: 0.9567, Validation Loss: 0.7726\n",
      "[Trial 59] Epoch 8/60, Training Loss: 1.0235, Validation Loss: 0.7747\n",
      "[Trial 57] Epoch 14/60, Training Loss: 0.8054, Validation Loss: 0.6330\n",
      "[Trial 53] Epoch 32/60, Training Loss: 0.6769, Validation Loss: 0.5411\n",
      "[Trial 47] Epoch 45/60, Training Loss: 0.5550, Validation Loss: 0.4635\n",
      "[Trial 48] Epoch 46/60, Training Loss: 0.6235, Validation Loss: 0.5136\n",
      "[Trial 56] Epoch 26/60, Training Loss: 0.6710, Validation Loss: 0.5906\n",
      "[Trial 52] Epoch 37/60, Training Loss: 0.6798, Validation Loss: 0.6025\n",
      "[Trial 46] Epoch 43/60, Training Loss: 0.6445, Validation Loss: 0.5827\n",
      "[Trial 54] Epoch 32/60, Training Loss: 0.6186, Validation Loss: 0.5187\n",
      "[Trial 60] Epoch 2/60, Training Loss: 1.9760, Validation Loss: 1.2808\n",
      "[Trial 55] Epoch 29/60, Training Loss: 0.7271, Validation Loss: 0.5882\n",
      "[Trial 51] Epoch 38/60, Training Loss: 0.6542, Validation Loss: 0.5569\n",
      "[Trial 44] Epoch 46/60, Training Loss: 0.5860, Validation Loss: 0.4910\n",
      "[Trial 49] Epoch 44/60, Training Loss: 0.6560, Validation Loss: 0.5567\n",
      "[Trial 50] Epoch 45/60, Training Loss: 0.6312, Validation Loss: 0.5551\n",
      "[Trial 58] Epoch 10/60, Training Loss: 0.9268, Validation Loss: 0.7603\n",
      "[Trial 59] Epoch 9/60, Training Loss: 0.9732, Validation Loss: 0.7661\n",
      "[Trial 57] Epoch 15/60, Training Loss: 0.7975, Validation Loss: 0.6808\n",
      "[Trial 53] Epoch 33/60, Training Loss: 0.6701, Validation Loss: 0.5505\n",
      "[Trial 47] Epoch 46/60, Training Loss: 0.5456, Validation Loss: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:56:10,674] Trial 48 finished with value: 0.505975762506326 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.001677356971872195, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 48] Epoch 47/60, Training Loss: 0.6322, Validation Loss: 0.5171\n",
      "[Trial 48] Early stopping after 47 epochs.\n",
      "[Trial 56] Epoch 27/60, Training Loss: 0.6831, Validation Loss: 0.6199\n",
      "[Trial 52] Epoch 38/60, Training Loss: 0.6515, Validation Loss: 0.5489\n",
      "[Trial 46] Epoch 44/60, Training Loss: 0.6531, Validation Loss: 0.5735\n",
      "[Trial 54] Epoch 33/60, Training Loss: 0.6251, Validation Loss: 0.5200\n",
      "[Trial 60] Epoch 3/60, Training Loss: 1.6959, Validation Loss: 1.1698\n",
      "[Trial 51] Epoch 39/60, Training Loss: 0.6417, Validation Loss: 0.5311\n",
      "[Trial 55] Epoch 30/60, Training Loss: 0.7300, Validation Loss: 0.6984\n",
      "[Trial 50] Epoch 46/60, Training Loss: 0.6350, Validation Loss: 0.5707\n",
      "[Trial 49] Epoch 45/60, Training Loss: 0.6509, Validation Loss: 0.5082\n",
      "[Trial 44] Epoch 47/60, Training Loss: 0.5901, Validation Loss: 0.4874\n",
      "[Trial 58] Epoch 11/60, Training Loss: 0.9191, Validation Loss: 0.7733\n",
      "[Trial 59] Epoch 10/60, Training Loss: 0.9484, Validation Loss: 0.8036\n",
      "[Trial 57] Epoch 16/60, Training Loss: 0.7934, Validation Loss: 0.6154\n",
      "[Trial 53] Epoch 34/60, Training Loss: 0.6697, Validation Loss: 0.5394\n",
      "[Trial 47] Epoch 47/60, Training Loss: 0.5433, Validation Loss: 0.4628\n",
      "[Trial 61] Epoch 1/60, Training Loss: 4.6920, Validation Loss: 1.6529\n",
      "[Trial 56] Epoch 28/60, Training Loss: 0.6900, Validation Loss: 0.6165\n",
      "[Trial 52] Epoch 39/60, Training Loss: 0.6460, Validation Loss: 0.5390\n",
      "[Trial 54] Epoch 34/60, Training Loss: 0.6237, Validation Loss: 0.5222\n",
      "[Trial 46] Epoch 45/60, Training Loss: 0.6443, Validation Loss: 0.5319\n",
      "[Trial 60] Epoch 4/60, Training Loss: 1.5261, Validation Loss: 1.1239\n",
      "[Trial 51] Epoch 40/60, Training Loss: 0.6381, Validation Loss: 0.5284\n",
      "[Trial 55] Epoch 31/60, Training Loss: 0.6969, Validation Loss: 0.5660\n",
      "[Trial 50] Epoch 47/60, Training Loss: 0.6329, Validation Loss: 0.5385\n",
      "[Trial 49] Epoch 46/60, Training Loss: 0.6410, Validation Loss: 0.5436\n",
      "[Trial 58] Epoch 12/60, Training Loss: 0.8940, Validation Loss: 0.7195\n",
      "[Trial 44] Epoch 48/60, Training Loss: 0.5864, Validation Loss: 0.4904\n",
      "[Trial 57] Epoch 17/60, Training Loss: 0.7747, Validation Loss: 0.7290\n",
      "[Trial 59] Epoch 11/60, Training Loss: 0.9384, Validation Loss: 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 03:57:49,587] Trial 47 finished with value: 0.45815725525220236 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.015322534368208315, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 47] Epoch 48/60, Training Loss: 0.5462, Validation Loss: 0.4638\n",
      "[Trial 47] Early stopping after 48 epochs.\n",
      "[Trial 53] Epoch 35/60, Training Loss: 0.6644, Validation Loss: 0.5280\n",
      "[Trial 61] Epoch 2/60, Training Loss: 1.7588, Validation Loss: 1.2388\n",
      "[Trial 56] Epoch 29/60, Training Loss: 0.6640, Validation Loss: 0.5533\n",
      "[Trial 52] Epoch 40/60, Training Loss: 0.6446, Validation Loss: 0.5665\n",
      "[Trial 54] Epoch 35/60, Training Loss: 0.6329, Validation Loss: 0.5237\n",
      "[Trial 60] Epoch 5/60, Training Loss: 1.3720, Validation Loss: 1.0100\n",
      "[Trial 46] Epoch 46/60, Training Loss: 0.6273, Validation Loss: 0.5051\n",
      "[Trial 51] Epoch 41/60, Training Loss: 0.6487, Validation Loss: 0.5923\n",
      "[Trial 55] Epoch 32/60, Training Loss: 0.6864, Validation Loss: 0.5585\n",
      "[Trial 50] Epoch 48/60, Training Loss: 0.6118, Validation Loss: 0.5339\n",
      "[Trial 49] Epoch 47/60, Training Loss: 0.6333, Validation Loss: 0.4983\n",
      "[Trial 58] Epoch 13/60, Training Loss: 0.8695, Validation Loss: 0.7049\n",
      "[Trial 44] Epoch 49/60, Training Loss: 0.5879, Validation Loss: 0.5151\n",
      "[Trial 57] Epoch 18/60, Training Loss: 0.7804, Validation Loss: 0.6122\n",
      "[Trial 59] Epoch 12/60, Training Loss: 0.8856, Validation Loss: 0.7638\n",
      "[Trial 62] Epoch 1/60, Training Loss: 4.6602, Validation Loss: 3.2863\n",
      "[Trial 53] Epoch 36/60, Training Loss: 0.6588, Validation Loss: 0.5449\n",
      "[Trial 61] Epoch 3/60, Training Loss: 1.3710, Validation Loss: 1.4530\n",
      "[Trial 56] Epoch 30/60, Training Loss: 0.6539, Validation Loss: 0.5572\n",
      "[Trial 52] Epoch 41/60, Training Loss: 0.6522, Validation Loss: 0.5467\n",
      "[Trial 54] Epoch 36/60, Training Loss: 0.6182, Validation Loss: 0.5181\n",
      "[Trial 60] Epoch 6/60, Training Loss: 1.2536, Validation Loss: 1.0096\n",
      "[Trial 51] Epoch 42/60, Training Loss: 0.6516, Validation Loss: 0.5447\n",
      "[Trial 46] Epoch 47/60, Training Loss: 0.6288, Validation Loss: 0.5218\n",
      "[Trial 55] Epoch 33/60, Training Loss: 0.6821, Validation Loss: 0.5571\n",
      "[Trial 50] Epoch 49/60, Training Loss: 0.6053, Validation Loss: 0.5275\n",
      "[Trial 58] Epoch 14/60, Training Loss: 0.8320, Validation Loss: 0.7257\n",
      "[Trial 49] Epoch 48/60, Training Loss: 0.6409, Validation Loss: 0.5512\n",
      "[Trial 57] Epoch 19/60, Training Loss: 0.7648, Validation Loss: 0.6515\n",
      "[Trial 44] Epoch 50/60, Training Loss: 0.5905, Validation Loss: 0.4977\n",
      "[Trial 59] Epoch 13/60, Training Loss: 0.8664, Validation Loss: 0.6907\n",
      "[Trial 62] Epoch 2/60, Training Loss: 1.8815, Validation Loss: 1.1529\n",
      "[Trial 61] Epoch 4/60, Training Loss: 1.2070, Validation Loss: 0.8458\n",
      "[Trial 53] Epoch 37/60, Training Loss: 0.6558, Validation Loss: 0.5385\n",
      "[Trial 56] Epoch 31/60, Training Loss: 0.6422, Validation Loss: 0.5278\n",
      "[Trial 52] Epoch 42/60, Training Loss: 0.6381, Validation Loss: 0.5461\n",
      "[Trial 54] Epoch 37/60, Training Loss: 0.6096, Validation Loss: 0.5184\n",
      "[Trial 51] Epoch 43/60, Training Loss: 0.6422, Validation Loss: 0.5403\n",
      "[Trial 60] Epoch 7/60, Training Loss: 1.1579, Validation Loss: 1.0064\n",
      "[Trial 55] Epoch 34/60, Training Loss: 0.6764, Validation Loss: 0.5556\n",
      "[Trial 46] Epoch 48/60, Training Loss: 0.6322, Validation Loss: 0.5200\n",
      "[Trial 50] Epoch 50/60, Training Loss: 0.6060, Validation Loss: 0.5263\n",
      "[Trial 58] Epoch 15/60, Training Loss: 0.8262, Validation Loss: 0.6954\n",
      "[Trial 49] Epoch 49/60, Training Loss: 0.6400, Validation Loss: 0.5524\n",
      "[Trial 57] Epoch 20/60, Training Loss: 0.7504, Validation Loss: 0.6020\n",
      "[Trial 62] Epoch 3/60, Training Loss: 1.4021, Validation Loss: 1.3041\n",
      "[Trial 59] Epoch 14/60, Training Loss: 0.8368, Validation Loss: 0.6838\n",
      "[Trial 44] Epoch 51/60, Training Loss: 0.5830, Validation Loss: 0.5040\n",
      "[Trial 61] Epoch 5/60, Training Loss: 1.0256, Validation Loss: 1.0954\n",
      "[Trial 56] Epoch 32/60, Training Loss: 0.6350, Validation Loss: 0.5300\n",
      "[Trial 53] Epoch 38/60, Training Loss: 0.6560, Validation Loss: 0.5305\n",
      "[Trial 52] Epoch 43/60, Training Loss: 0.6536, Validation Loss: 0.6117\n",
      "[Trial 54] Epoch 38/60, Training Loss: 0.6208, Validation Loss: 0.5253\n",
      "[Trial 51] Epoch 44/60, Training Loss: 0.6424, Validation Loss: 0.5358\n",
      "[Trial 60] Epoch 8/60, Training Loss: 1.0588, Validation Loss: 0.8523\n",
      "[Trial 55] Epoch 35/60, Training Loss: 0.6863, Validation Loss: 0.5722\n",
      "[Trial 50] Epoch 51/60, Training Loss: 0.6025, Validation Loss: 0.5220\n",
      "[Trial 46] Epoch 49/60, Training Loss: 0.6345, Validation Loss: 0.5344\n",
      "[Trial 58] Epoch 16/60, Training Loss: 0.8081, Validation Loss: 0.6936\n",
      "[Trial 49] Epoch 50/60, Training Loss: 0.6446, Validation Loss: 0.5188\n",
      "[Trial 57] Epoch 21/60, Training Loss: 0.7535, Validation Loss: 0.6631\n",
      "[Trial 62] Epoch 4/60, Training Loss: 1.2207, Validation Loss: 1.2599\n",
      "[Trial 61] Epoch 6/60, Training Loss: 1.0293, Validation Loss: 0.8030\n",
      "[Trial 59] Epoch 15/60, Training Loss: 0.8289, Validation Loss: 0.7495\n",
      "[Trial 56] Epoch 33/60, Training Loss: 0.6394, Validation Loss: 0.5197\n",
      "[Trial 44] Epoch 52/60, Training Loss: 0.5725, Validation Loss: 0.4808\n",
      "[Trial 53] Epoch 39/60, Training Loss: 0.6621, Validation Loss: 0.5312\n",
      "[Trial 52] Epoch 44/60, Training Loss: 0.6549, Validation Loss: 0.5488\n",
      "[Trial 54] Epoch 39/60, Training Loss: 0.6231, Validation Loss: 0.5329\n",
      "[Trial 51] Epoch 45/60, Training Loss: 0.6393, Validation Loss: 0.5301\n",
      "[Trial 60] Epoch 9/60, Training Loss: 1.0125, Validation Loss: 0.8021\n",
      "[Trial 55] Epoch 36/60, Training Loss: 0.6928, Validation Loss: 0.5624\n",
      "[Trial 50] Epoch 52/60, Training Loss: 0.6049, Validation Loss: 0.5346\n",
      "[Trial 58] Epoch 17/60, Training Loss: 0.8018, Validation Loss: 0.7108\n",
      "[Trial 46] Epoch 50/60, Training Loss: 0.6287, Validation Loss: 0.5565\n",
      "[Trial 49] Epoch 51/60, Training Loss: 0.6323, Validation Loss: 0.5159\n",
      "[Trial 57] Epoch 22/60, Training Loss: 0.7454, Validation Loss: 0.5880\n",
      "[Trial 62] Epoch 5/60, Training Loss: 1.1014, Validation Loss: 1.5399\n",
      "[Trial 61] Epoch 7/60, Training Loss: 1.0210, Validation Loss: 1.1700\n",
      "[Trial 59] Epoch 16/60, Training Loss: 0.8075, Validation Loss: 0.6119\n",
      "[Trial 56] Epoch 34/60, Training Loss: 0.6443, Validation Loss: 0.5505\n",
      "[Trial 52] Epoch 45/60, Training Loss: 0.6265, Validation Loss: 0.5200\n",
      "[Trial 54] Epoch 40/60, Training Loss: 0.6137, Validation Loss: 0.5261\n",
      "[Trial 53] Epoch 40/60, Training Loss: 0.6511, Validation Loss: 0.5340\n",
      "[Trial 44] Epoch 53/60, Training Loss: 0.5683, Validation Loss: 0.4818\n",
      "[Trial 51] Epoch 46/60, Training Loss: 0.6287, Validation Loss: 0.5248\n",
      "[Trial 60] Epoch 10/60, Training Loss: 0.9863, Validation Loss: 0.9494\n",
      "[Trial 55] Epoch 37/60, Training Loss: 0.6723, Validation Loss: 0.5511\n",
      "[Trial 50] Epoch 53/60, Training Loss: 0.6066, Validation Loss: 0.5134\n",
      "[Trial 58] Epoch 18/60, Training Loss: 0.7917, Validation Loss: 0.6340\n",
      "[Trial 46] Epoch 51/60, Training Loss: 0.6285, Validation Loss: 0.5345\n",
      "[Trial 49] Epoch 52/60, Training Loss: 0.6281, Validation Loss: 0.4956\n",
      "[Trial 57] Epoch 23/60, Training Loss: 0.7360, Validation Loss: 0.6007\n",
      "[Trial 62] Epoch 6/60, Training Loss: 1.1663, Validation Loss: 0.8585\n",
      "[Trial 61] Epoch 8/60, Training Loss: 0.9690, Validation Loss: 0.9917\n",
      "[Trial 56] Epoch 35/60, Training Loss: 0.6306, Validation Loss: 0.5201\n",
      "[Trial 59] Epoch 17/60, Training Loss: 0.7995, Validation Loss: 0.6797\n",
      "[Trial 52] Epoch 46/60, Training Loss: 0.6227, Validation Loss: 0.5318\n",
      "[Trial 54] Epoch 41/60, Training Loss: 0.6095, Validation Loss: 0.5203\n",
      "[Trial 53] Epoch 41/60, Training Loss: 0.6455, Validation Loss: 0.5336\n",
      "[Trial 44] Epoch 54/60, Training Loss: 0.5632, Validation Loss: 0.4810\n",
      "[Trial 51] Epoch 47/60, Training Loss: 0.6217, Validation Loss: 0.5327\n",
      "[Trial 60] Epoch 11/60, Training Loss: 1.0174, Validation Loss: 0.6935\n",
      "[Trial 50] Epoch 54/60, Training Loss: 0.5926, Validation Loss: 0.5128\n",
      "[Trial 55] Epoch 38/60, Training Loss: 0.6622, Validation Loss: 0.5455\n",
      "[Trial 58] Epoch 19/60, Training Loss: 0.7792, Validation Loss: 0.6725\n",
      "[Trial 49] Epoch 53/60, Training Loss: 0.6184, Validation Loss: 0.5267\n",
      "[Trial 46] Epoch 52/60, Training Loss: 0.6248, Validation Loss: 0.5359\n",
      "[Trial 62] Epoch 7/60, Training Loss: 0.9588, Validation Loss: 1.6204\n",
      "[Trial 57] Epoch 24/60, Training Loss: 0.7404, Validation Loss: 0.6060\n",
      "[Trial 61] Epoch 9/60, Training Loss: 0.9113, Validation Loss: 0.7658\n",
      "[Trial 56] Epoch 36/60, Training Loss: 0.6284, Validation Loss: 0.5221\n",
      "[Trial 52] Epoch 47/60, Training Loss: 0.6219, Validation Loss: 0.5374\n",
      "[Trial 54] Epoch 42/60, Training Loss: 0.5989, Validation Loss: 0.5027\n",
      "[Trial 59] Epoch 18/60, Training Loss: 0.7923, Validation Loss: 0.8383\n",
      "[Trial 53] Epoch 42/60, Training Loss: 0.6426, Validation Loss: 0.5263\n",
      "[Trial 51] Epoch 48/60, Training Loss: 0.6138, Validation Loss: 0.5308\n",
      "[Trial 44] Epoch 55/60, Training Loss: 0.5647, Validation Loss: 0.4813\n",
      "[Trial 60] Epoch 12/60, Training Loss: 0.9042, Validation Loss: 0.7448\n",
      "[Trial 50] Epoch 55/60, Training Loss: 0.5966, Validation Loss: 0.5158\n",
      "[Trial 55] Epoch 39/60, Training Loss: 0.6579, Validation Loss: 0.5431\n",
      "[Trial 58] Epoch 20/60, Training Loss: 0.7698, Validation Loss: 0.6429\n",
      "[Trial 49] Epoch 54/60, Training Loss: 0.6224, Validation Loss: 0.5198\n",
      "[Trial 46] Epoch 53/60, Training Loss: 0.6138, Validation Loss: 0.5087\n",
      "[Trial 62] Epoch 8/60, Training Loss: 0.9569, Validation Loss: 1.2415\n",
      "[Trial 61] Epoch 10/60, Training Loss: 0.9118, Validation Loss: 0.7771\n",
      "[Trial 57] Epoch 25/60, Training Loss: 0.7327, Validation Loss: 0.6947\n",
      "[Trial 56] Epoch 37/60, Training Loss: 0.6238, Validation Loss: 0.5199\n",
      "[Trial 54] Epoch 43/60, Training Loss: 0.6012, Validation Loss: 0.5205\n",
      "[Trial 52] Epoch 48/60, Training Loss: 0.6213, Validation Loss: 0.5341\n",
      "[Trial 59] Epoch 19/60, Training Loss: 0.7846, Validation Loss: 0.6664\n",
      "[Trial 53] Epoch 43/60, Training Loss: 0.6483, Validation Loss: 0.5296\n",
      "[Trial 51] Epoch 49/60, Training Loss: 0.6118, Validation Loss: 0.5218\n",
      "[Trial 60] Epoch 13/60, Training Loss: 0.8841, Validation Loss: 0.6950\n",
      "[Trial 44] Epoch 56/60, Training Loss: 0.5616, Validation Loss: 0.4838\n",
      "[Trial 50] Epoch 56/60, Training Loss: 0.6006, Validation Loss: 0.5187\n",
      "[Trial 55] Epoch 40/60, Training Loss: 0.6820, Validation Loss: 0.7091\n",
      "[Trial 58] Epoch 21/60, Training Loss: 0.7752, Validation Loss: 0.6062\n",
      "[Trial 49] Epoch 55/60, Training Loss: 0.6198, Validation Loss: 0.5129\n",
      "[Trial 46] Epoch 54/60, Training Loss: 0.6092, Validation Loss: 0.5084\n",
      "[Trial 62] Epoch 9/60, Training Loss: 0.9603, Validation Loss: 1.1025\n",
      "[Trial 61] Epoch 11/60, Training Loss: 0.8699, Validation Loss: 1.0473\n",
      "[Trial 57] Epoch 26/60, Training Loss: 0.7361, Validation Loss: 0.6255\n",
      "[Trial 56] Epoch 38/60, Training Loss: 0.6234, Validation Loss: 0.5274\n",
      "[Trial 54] Epoch 44/60, Training Loss: 0.5991, Validation Loss: 0.5078\n",
      "[Trial 52] Epoch 49/60, Training Loss: 0.6152, Validation Loss: 0.5181\n",
      "[Trial 59] Epoch 20/60, Training Loss: 0.7680, Validation Loss: 0.6489\n",
      "[Trial 51] Epoch 50/60, Training Loss: 0.6115, Validation Loss: 0.5181\n",
      "[Trial 53] Epoch 44/60, Training Loss: 0.6381, Validation Loss: 0.5184\n",
      "[Trial 60] Epoch 14/60, Training Loss: 0.8545, Validation Loss: 0.6835\n",
      "[Trial 50] Epoch 57/60, Training Loss: 0.5968, Validation Loss: 0.5173\n",
      "[Trial 58] Epoch 22/60, Training Loss: 0.7489, Validation Loss: 0.6417\n",
      "[Trial 55] Epoch 41/60, Training Loss: 0.6684, Validation Loss: 0.5578\n",
      "[Trial 44] Epoch 57/60, Training Loss: 0.5609, Validation Loss: 0.4833\n",
      "[Trial 49] Epoch 56/60, Training Loss: 0.6273, Validation Loss: 0.5102\n",
      "[Trial 62] Epoch 10/60, Training Loss: 0.9464, Validation Loss: 0.9569\n",
      "[Trial 46] Epoch 55/60, Training Loss: 0.6018, Validation Loss: 0.4973\n",
      "[Trial 61] Epoch 12/60, Training Loss: 0.8798, Validation Loss: 1.4666\n",
      "[Trial 57] Epoch 27/60, Training Loss: 0.7268, Validation Loss: 0.6733\n",
      "[Trial 56] Epoch 39/60, Training Loss: 0.6295, Validation Loss: 0.5288\n",
      "[Trial 54] Epoch 45/60, Training Loss: 0.6079, Validation Loss: 0.5108\n",
      "[Trial 52] Epoch 50/60, Training Loss: 0.6144, Validation Loss: 0.5326\n",
      "[Trial 59] Epoch 21/60, Training Loss: 0.7575, Validation Loss: 0.6565\n",
      "[Trial 51] Epoch 51/60, Training Loss: 0.6097, Validation Loss: 0.5141\n",
      "[Trial 53] Epoch 45/60, Training Loss: 0.6347, Validation Loss: 0.5179\n",
      "[Trial 60] Epoch 15/60, Training Loss: 0.8429, Validation Loss: 0.6876\n",
      "[Trial 50] Epoch 58/60, Training Loss: 0.6032, Validation Loss: 0.5225\n",
      "[Trial 58] Epoch 23/60, Training Loss: 0.7426, Validation Loss: 0.6889\n",
      "[Trial 55] Epoch 42/60, Training Loss: 0.6693, Validation Loss: 0.5660\n",
      "[Trial 44] Epoch 58/60, Training Loss: 0.5605, Validation Loss: 0.4763\n",
      "[Trial 49] Epoch 57/60, Training Loss: 0.6298, Validation Loss: 0.5769\n",
      "[Trial 62] Epoch 11/60, Training Loss: 0.8872, Validation Loss: 0.7483\n",
      "[Trial 61] Epoch 13/60, Training Loss: 0.9257, Validation Loss: 0.7347\n",
      "[Trial 46] Epoch 56/60, Training Loss: 0.6061, Validation Loss: 0.4934\n",
      "[Trial 57] Epoch 28/60, Training Loss: 0.6967, Validation Loss: 0.5570\n",
      "[Trial 56] Epoch 40/60, Training Loss: 0.6216, Validation Loss: 0.5125\n",
      "[Trial 54] Epoch 46/60, Training Loss: 0.5952, Validation Loss: 0.5075\n",
      "[Trial 52] Epoch 51/60, Training Loss: 0.6166, Validation Loss: 0.5217\n",
      "[Trial 51] Epoch 52/60, Training Loss: 0.6033, Validation Loss: 0.5065\n",
      "[Trial 59] Epoch 22/60, Training Loss: 0.7124, Validation Loss: 0.5833\n",
      "[Trial 53] Epoch 46/60, Training Loss: 0.6429, Validation Loss: 0.5172\n",
      "[Trial 60] Epoch 16/60, Training Loss: 0.8300, Validation Loss: 0.6815\n",
      "[Trial 50] Epoch 59/60, Training Loss: 0.6028, Validation Loss: 0.5288\n",
      "[Trial 58] Epoch 24/60, Training Loss: 0.7439, Validation Loss: 0.6163\n",
      "[Trial 55] Epoch 43/60, Training Loss: 0.6633, Validation Loss: 0.5793\n",
      "[Trial 49] Epoch 58/60, Training Loss: 0.6094, Validation Loss: 0.5087\n",
      "[Trial 44] Epoch 59/60, Training Loss: 0.5623, Validation Loss: 0.4731\n",
      "[Trial 62] Epoch 12/60, Training Loss: 0.8771, Validation Loss: 1.2525\n",
      "[Trial 61] Epoch 14/60, Training Loss: 0.8742, Validation Loss: 0.7135\n",
      "[Trial 57] Epoch 29/60, Training Loss: 0.6961, Validation Loss: 0.5924\n",
      "[Trial 56] Epoch 41/60, Training Loss: 0.6242, Validation Loss: 0.5239\n",
      "[Trial 46] Epoch 57/60, Training Loss: 0.6273, Validation Loss: 0.5255\n",
      "[Trial 54] Epoch 47/60, Training Loss: 0.5886, Validation Loss: 0.5012\n",
      "[Trial 52] Epoch 52/60, Training Loss: 0.6150, Validation Loss: 0.5151\n",
      "[Trial 51] Epoch 53/60, Training Loss: 0.6061, Validation Loss: 0.5194\n",
      "[Trial 59] Epoch 23/60, Training Loss: 0.7001, Validation Loss: 0.5773\n",
      "[Trial 60] Epoch 17/60, Training Loss: 0.8074, Validation Loss: 0.7038\n",
      "[Trial 53] Epoch 47/60, Training Loss: 0.6371, Validation Loss: 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:08:35,307] Trial 50 finished with value: 0.5127605110406875 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.001674460559183928, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 50] Epoch 60/60, Training Loss: 0.5918, Validation Loss: 0.5162\n",
      "[Trial 58] Epoch 25/60, Training Loss: 0.7412, Validation Loss: 0.6334\n",
      "[Trial 55] Epoch 44/60, Training Loss: 0.6474, Validation Loss: 0.5330\n",
      "[Trial 49] Epoch 59/60, Training Loss: 0.6003, Validation Loss: 0.4921\n",
      "[Trial 62] Epoch 13/60, Training Loss: 0.9873, Validation Loss: 0.9158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:08:57,145] Trial 44 finished with value: 0.47313284277915957 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.001676435253167674, 'batch_size': 16, 'patience': 7}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 61] Epoch 15/60, Training Loss: 0.8608, Validation Loss: 0.7058\n",
      "[Trial 44] Epoch 60/60, Training Loss: 0.5608, Validation Loss: 0.4812\n",
      "[Trial 57] Epoch 30/60, Training Loss: 0.6622, Validation Loss: 0.5733\n",
      "[Trial 56] Epoch 42/60, Training Loss: 0.6243, Validation Loss: 0.5248\n",
      "[Trial 54] Epoch 48/60, Training Loss: 0.5951, Validation Loss: 0.5097\n",
      "[Trial 46] Epoch 58/60, Training Loss: 0.6164, Validation Loss: 0.5116\n",
      "[Trial 52] Epoch 53/60, Training Loss: 0.6186, Validation Loss: 0.5213\n",
      "[Trial 51] Epoch 54/60, Training Loss: 0.6053, Validation Loss: 0.5096\n",
      "[Trial 59] Epoch 24/60, Training Loss: 0.6976, Validation Loss: 0.5799\n",
      "[Trial 63] Epoch 1/60, Training Loss: 4.6248, Validation Loss: 2.1074\n",
      "[Trial 60] Epoch 18/60, Training Loss: 0.7979, Validation Loss: 0.6967\n",
      "[Trial 53] Epoch 48/60, Training Loss: 0.6440, Validation Loss: 0.5175\n",
      "[Trial 58] Epoch 26/60, Training Loss: 0.7370, Validation Loss: 0.7305\n",
      "[Trial 55] Epoch 45/60, Training Loss: 0.6285, Validation Loss: 0.5114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:09:40,642] Trial 49 finished with value: 0.4921125277876854 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0017525435610436775, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 49] Epoch 60/60, Training Loss: 0.5938, Validation Loss: 0.4945\n",
      "[Trial 62] Epoch 14/60, Training Loss: 0.9077, Validation Loss: 0.7951\n",
      "[Trial 61] Epoch 16/60, Training Loss: 0.8281, Validation Loss: 0.8493\n",
      "[Trial 64] Epoch 1/60, Training Loss: 3.1461, Validation Loss: 1.4581\n",
      "[Trial 57] Epoch 31/60, Training Loss: 0.6613, Validation Loss: 0.5486\n",
      "[Trial 56] Epoch 43/60, Training Loss: 0.6523, Validation Loss: 0.5294\n",
      "[Trial 54] Epoch 49/60, Training Loss: 0.5912, Validation Loss: 0.4987\n",
      "[Trial 52] Epoch 54/60, Training Loss: 0.6143, Validation Loss: 0.5254\n",
      "[Trial 46] Epoch 59/60, Training Loss: 0.6098, Validation Loss: 0.5055\n",
      "[Trial 51] Epoch 55/60, Training Loss: 0.6041, Validation Loss: 0.5046\n",
      "[Trial 63] Epoch 2/60, Training Loss: 1.7574, Validation Loss: 1.1849\n",
      "[Trial 59] Epoch 25/60, Training Loss: 0.6895, Validation Loss: 0.5829\n",
      "[Trial 60] Epoch 19/60, Training Loss: 0.8088, Validation Loss: 0.6654\n",
      "[Trial 58] Epoch 27/60, Training Loss: 0.6967, Validation Loss: 0.5628\n",
      "[Trial 53] Epoch 49/60, Training Loss: 0.6355, Validation Loss: 0.5192\n",
      "[Trial 55] Epoch 46/60, Training Loss: 0.6270, Validation Loss: 0.5233\n",
      "[Trial 65] Epoch 1/60, Training Loss: 3.0945, Validation Loss: 2.1628\n",
      "[Trial 62] Epoch 15/60, Training Loss: 0.8783, Validation Loss: 0.7416\n",
      "[Trial 61] Epoch 17/60, Training Loss: 0.8529, Validation Loss: 0.8105\n",
      "[Trial 64] Epoch 2/60, Training Loss: 1.4888, Validation Loss: 0.9984\n",
      "[Trial 56] Epoch 44/60, Training Loss: 0.6200, Validation Loss: 0.5147\n",
      "[Trial 57] Epoch 32/60, Training Loss: 0.6554, Validation Loss: 0.5359\n",
      "[Trial 54] Epoch 50/60, Training Loss: 0.5914, Validation Loss: 0.5043\n",
      "[Trial 52] Epoch 55/60, Training Loss: 0.6057, Validation Loss: 0.5175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:10:55,669] Trial 46 finished with value: 0.4934413154919942 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.0017137771392593188, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 46] Epoch 60/60, Training Loss: 0.6037, Validation Loss: 0.5148\n",
      "[Trial 51] Epoch 56/60, Training Loss: 0.6100, Validation Loss: 0.5097\n",
      "[Trial 63] Epoch 3/60, Training Loss: 1.2772, Validation Loss: 1.2444\n",
      "[Trial 60] Epoch 20/60, Training Loss: 0.8075, Validation Loss: 0.6426\n",
      "[Trial 59] Epoch 26/60, Training Loss: 0.6938, Validation Loss: 0.5879\n",
      "[Trial 58] Epoch 28/60, Training Loss: 0.6875, Validation Loss: 0.5723\n",
      "[Trial 53] Epoch 50/60, Training Loss: 0.6416, Validation Loss: 0.5152\n",
      "[Trial 55] Epoch 47/60, Training Loss: 0.6335, Validation Loss: 0.5177\n",
      "[Trial 65] Epoch 2/60, Training Loss: 1.5105, Validation Loss: 1.2195\n",
      "[Trial 62] Epoch 16/60, Training Loss: 0.8500, Validation Loss: 0.8328\n",
      "[Trial 61] Epoch 18/60, Training Loss: 0.8543, Validation Loss: 0.7513\n",
      "[Trial 64] Epoch 3/60, Training Loss: 1.1905, Validation Loss: 1.1917\n",
      "[Trial 56] Epoch 45/60, Training Loss: 0.6134, Validation Loss: 0.5124\n",
      "[Trial 57] Epoch 33/60, Training Loss: 0.6524, Validation Loss: 0.5091\n",
      "[Trial 54] Epoch 51/60, Training Loss: 0.5967, Validation Loss: 0.5036\n",
      "[Trial 52] Epoch 56/60, Training Loss: 0.6141, Validation Loss: 0.5345\n",
      "[Trial 66] Epoch 1/60, Training Loss: 3.7457, Validation Loss: 1.7127\n",
      "[Trial 51] Epoch 57/60, Training Loss: 0.6143, Validation Loss: 0.5319\n",
      "[Trial 63] Epoch 4/60, Training Loss: 1.1424, Validation Loss: 1.1062\n",
      "[Trial 60] Epoch 21/60, Training Loss: 0.7598, Validation Loss: 0.6628\n",
      "[Trial 58] Epoch 29/60, Training Loss: 0.6786, Validation Loss: 0.5855\n",
      "[Trial 59] Epoch 27/60, Training Loss: 0.6917, Validation Loss: 0.6126\n",
      "[Trial 53] Epoch 51/60, Training Loss: 0.6312, Validation Loss: 0.5155\n",
      "[Trial 55] Epoch 48/60, Training Loss: 0.6280, Validation Loss: 0.5168\n",
      "[Trial 65] Epoch 3/60, Training Loss: 1.2318, Validation Loss: 0.9000\n",
      "[Trial 62] Epoch 17/60, Training Loss: 0.8423, Validation Loss: 0.9878\n",
      "[Trial 61] Epoch 19/60, Training Loss: 0.7993, Validation Loss: 0.7876\n",
      "[Trial 64] Epoch 4/60, Training Loss: 1.0845, Validation Loss: 1.0618\n",
      "[Trial 56] Epoch 46/60, Training Loss: 0.6263, Validation Loss: 0.5212\n",
      "[Trial 54] Epoch 52/60, Training Loss: 0.6031, Validation Loss: 0.5002\n",
      "[Trial 57] Epoch 34/60, Training Loss: 0.6523, Validation Loss: 0.5852\n",
      "[Trial 52] Epoch 57/60, Training Loss: 0.6132, Validation Loss: 0.5313\n",
      "[Trial 51] Epoch 58/60, Training Loss: 0.6127, Validation Loss: 0.5025\n",
      "[Trial 66] Epoch 2/60, Training Loss: 1.6322, Validation Loss: 1.1710\n",
      "[Trial 63] Epoch 5/60, Training Loss: 1.0940, Validation Loss: 2.7122\n",
      "[Trial 60] Epoch 22/60, Training Loss: 0.7626, Validation Loss: 0.6855\n",
      "[Trial 58] Epoch 30/60, Training Loss: 0.6728, Validation Loss: 0.5858\n",
      "[Trial 59] Epoch 28/60, Training Loss: 0.6872, Validation Loss: 0.5999\n",
      "[Trial 53] Epoch 52/60, Training Loss: 0.6326, Validation Loss: 0.5272\n",
      "[Trial 55] Epoch 49/60, Training Loss: 0.6311, Validation Loss: 0.5442\n",
      "[Trial 65] Epoch 4/60, Training Loss: 1.0964, Validation Loss: 1.0411\n",
      "[Trial 62] Epoch 18/60, Training Loss: 0.8582, Validation Loss: 0.8299\n",
      "[Trial 61] Epoch 20/60, Training Loss: 0.8595, Validation Loss: 0.9779\n",
      "[Trial 56] Epoch 47/60, Training Loss: 0.6162, Validation Loss: 0.5168\n",
      "[Trial 64] Epoch 5/60, Training Loss: 1.0345, Validation Loss: 1.2702\n",
      "[Trial 54] Epoch 53/60, Training Loss: 0.5945, Validation Loss: 0.4994\n",
      "[Trial 57] Epoch 35/60, Training Loss: 0.6519, Validation Loss: 0.5241\n",
      "[Trial 52] Epoch 58/60, Training Loss: 0.5981, Validation Loss: 0.5080\n",
      "[Trial 51] Epoch 59/60, Training Loss: 0.5991, Validation Loss: 0.5086\n",
      "[Trial 66] Epoch 3/60, Training Loss: 1.1955, Validation Loss: 1.0182\n",
      "[Trial 63] Epoch 6/60, Training Loss: 1.0099, Validation Loss: 0.8448\n",
      "[Trial 58] Epoch 31/60, Training Loss: 0.6769, Validation Loss: 0.5642\n",
      "[Trial 60] Epoch 23/60, Training Loss: 0.7752, Validation Loss: 0.6615\n",
      "[Trial 59] Epoch 29/60, Training Loss: 0.6613, Validation Loss: 0.5692\n",
      "[Trial 53] Epoch 53/60, Training Loss: 0.6342, Validation Loss: 0.5214\n",
      "[Trial 65] Epoch 5/60, Training Loss: 1.0344, Validation Loss: 0.9687\n",
      "[Trial 55] Epoch 50/60, Training Loss: 0.6181, Validation Loss: 0.5121\n",
      "[Trial 62] Epoch 19/60, Training Loss: 0.8959, Validation Loss: 0.9080\n",
      "[Trial 61] Epoch 21/60, Training Loss: 0.7487, Validation Loss: 0.6713\n",
      "[Trial 56] Epoch 48/60, Training Loss: 0.6178, Validation Loss: 0.5256\n",
      "[Trial 54] Epoch 54/60, Training Loss: 0.5958, Validation Loss: 0.4941\n",
      "[Trial 64] Epoch 6/60, Training Loss: 1.0374, Validation Loss: 0.8183\n",
      "[Trial 57] Epoch 36/60, Training Loss: 0.6474, Validation Loss: 0.5618\n",
      "[Trial 52] Epoch 59/60, Training Loss: 0.6099, Validation Loss: 0.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:14:19,722] Trial 51 finished with value: 0.5025122056404749 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0024250729306687846, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 51] Epoch 60/60, Training Loss: 0.6077, Validation Loss: 0.5121\n",
      "[Trial 66] Epoch 4/60, Training Loss: 1.0647, Validation Loss: 1.7381\n",
      "[Trial 63] Epoch 7/60, Training Loss: 0.9406, Validation Loss: 1.0574\n",
      "[Trial 58] Epoch 32/60, Training Loss: 0.6643, Validation Loss: 0.5433\n",
      "[Trial 60] Epoch 24/60, Training Loss: 0.7562, Validation Loss: 0.6009\n",
      "[Trial 59] Epoch 30/60, Training Loss: 0.6511, Validation Loss: 0.5420\n",
      "[Trial 65] Epoch 6/60, Training Loss: 1.0060, Validation Loss: 0.8854\n",
      "[Trial 53] Epoch 54/60, Training Loss: 0.6328, Validation Loss: 0.5168\n",
      "[Trial 55] Epoch 51/60, Training Loss: 0.6250, Validation Loss: 0.5250\n",
      "[Trial 62] Epoch 20/60, Training Loss: 0.8527, Validation Loss: 0.7498\n",
      "[Trial 61] Epoch 22/60, Training Loss: 0.7281, Validation Loss: 0.6726\n",
      "[Trial 56] Epoch 49/60, Training Loss: 0.6080, Validation Loss: 0.5060\n",
      "[Trial 54] Epoch 55/60, Training Loss: 0.5952, Validation Loss: 0.4927\n",
      "[Trial 64] Epoch 7/60, Training Loss: 0.9229, Validation Loss: 1.0636\n",
      "[Trial 57] Epoch 37/60, Training Loss: 0.6506, Validation Loss: 0.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:15:03,951] Trial 52 finished with value: 0.5080287411808968 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.001814468857061117, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 52] Epoch 60/60, Training Loss: 0.6080, Validation Loss: 0.5102\n",
      "[Trial 67] Epoch 1/60, Training Loss: 11.4680, Validation Loss: 2.7324\n",
      "[Trial 66] Epoch 5/60, Training Loss: 1.0665, Validation Loss: 1.2390\n",
      "[Trial 63] Epoch 8/60, Training Loss: 0.9582, Validation Loss: 1.2525\n",
      "[Trial 58] Epoch 33/60, Training Loss: 0.6677, Validation Loss: 0.5772\n",
      "[Trial 60] Epoch 25/60, Training Loss: 0.7449, Validation Loss: 0.6247\n",
      "[Trial 65] Epoch 7/60, Training Loss: 0.9529, Validation Loss: 0.8144\n",
      "[Trial 59] Epoch 31/60, Training Loss: 0.6513, Validation Loss: 0.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:15:37,412] Trial 55 finished with value: 0.5113878587881724 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0011054765060882982, 'batch_size': 16, 'patience': 7}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 55] Epoch 52/60, Training Loss: 0.6254, Validation Loss: 0.5182\n",
      "[Trial 55] Early stopping after 52 epochs.\n",
      "[Trial 53] Epoch 55/60, Training Loss: 0.6259, Validation Loss: 0.5136\n",
      "[Trial 61] Epoch 23/60, Training Loss: 0.7205, Validation Loss: 0.6513\n",
      "[Trial 62] Epoch 21/60, Training Loss: 0.7486, Validation Loss: 0.7353\n",
      "[Trial 56] Epoch 50/60, Training Loss: 0.6193, Validation Loss: 0.5204\n",
      "[Trial 54] Epoch 56/60, Training Loss: 0.5913, Validation Loss: 0.5009\n",
      "[Trial 64] Epoch 8/60, Training Loss: 1.0045, Validation Loss: 1.1162\n",
      "[Trial 68] Epoch 1/60, Training Loss: 3.0085, Validation Loss: 1.4768\n",
      "[Trial 57] Epoch 38/60, Training Loss: 0.6453, Validation Loss: 0.5791\n",
      "[Trial 67] Epoch 2/60, Training Loss: 2.2704, Validation Loss: 1.5885\n",
      "[Trial 63] Epoch 9/60, Training Loss: 0.9565, Validation Loss: 0.9180\n",
      "[Trial 66] Epoch 6/60, Training Loss: 0.9454, Validation Loss: 1.0114\n",
      "[Trial 58] Epoch 34/60, Training Loss: 0.6700, Validation Loss: 0.5629\n",
      "[Trial 60] Epoch 26/60, Training Loss: 0.7417, Validation Loss: 0.6541\n",
      "[Trial 65] Epoch 8/60, Training Loss: 0.9567, Validation Loss: 0.7468\n",
      "[Trial 59] Epoch 32/60, Training Loss: 0.6485, Validation Loss: 0.5551\n",
      "[Trial 53] Epoch 56/60, Training Loss: 0.6307, Validation Loss: 0.5116\n",
      "[Trial 61] Epoch 24/60, Training Loss: 0.7207, Validation Loss: 0.6585\n",
      "[Trial 69] Epoch 1/60, Training Loss: 245.9000, Validation Loss: 3.0983\n",
      "[Trial 62] Epoch 22/60, Training Loss: 0.7497, Validation Loss: 0.6837\n",
      "[Trial 56] Epoch 51/60, Training Loss: 0.6126, Validation Loss: 0.5137\n",
      "[Trial 54] Epoch 57/60, Training Loss: 0.5977, Validation Loss: 0.4981\n",
      "[Trial 68] Epoch 2/60, Training Loss: 1.4739, Validation Loss: 1.0429\n",
      "[Trial 64] Epoch 9/60, Training Loss: 0.9846, Validation Loss: 0.7380\n",
      "[Trial 57] Epoch 39/60, Training Loss: 0.6261, Validation Loss: 0.4950\n",
      "[Trial 67] Epoch 3/60, Training Loss: 1.7718, Validation Loss: 1.2807\n",
      "[Trial 63] Epoch 10/60, Training Loss: 0.9335, Validation Loss: 1.1139\n",
      "[Trial 66] Epoch 7/60, Training Loss: 0.9485, Validation Loss: 0.7422\n",
      "[Trial 58] Epoch 35/60, Training Loss: 0.6612, Validation Loss: 0.5643\n",
      "[Trial 60] Epoch 27/60, Training Loss: 0.7223, Validation Loss: 0.5837\n",
      "[Trial 65] Epoch 9/60, Training Loss: 0.9294, Validation Loss: 1.3033\n",
      "[Trial 59] Epoch 33/60, Training Loss: 0.6504, Validation Loss: 0.5734\n",
      "[Trial 61] Epoch 25/60, Training Loss: 0.6972, Validation Loss: 0.6160\n",
      "[Trial 62] Epoch 23/60, Training Loss: 0.7289, Validation Loss: 0.5720\n",
      "[Trial 53] Epoch 57/60, Training Loss: 0.6283, Validation Loss: 0.5182\n",
      "[Trial 69] Epoch 2/60, Training Loss: 3.1860, Validation Loss: 2.6784\n",
      "[Trial 56] Epoch 52/60, Training Loss: 0.6090, Validation Loss: 0.5164\n",
      "[Trial 54] Epoch 58/60, Training Loss: 0.5891, Validation Loss: 0.4980\n",
      "[Trial 68] Epoch 3/60, Training Loss: 1.1945, Validation Loss: 1.0296\n",
      "[Trial 64] Epoch 10/60, Training Loss: 0.8907, Validation Loss: 0.7217\n",
      "[Trial 57] Epoch 40/60, Training Loss: 0.6189, Validation Loss: 0.5447\n",
      "[Trial 67] Epoch 4/60, Training Loss: 1.4238, Validation Loss: 1.3906\n",
      "[Trial 63] Epoch 11/60, Training Loss: 0.8861, Validation Loss: 0.8247\n",
      "[Trial 58] Epoch 36/60, Training Loss: 0.6569, Validation Loss: 0.5751\n",
      "[Trial 66] Epoch 8/60, Training Loss: 0.8750, Validation Loss: 0.7233\n",
      "[Trial 60] Epoch 28/60, Training Loss: 0.7169, Validation Loss: 0.6926\n",
      "[Trial 65] Epoch 10/60, Training Loss: 1.0162, Validation Loss: 0.8747\n",
      "[Trial 61] Epoch 26/60, Training Loss: 0.7028, Validation Loss: 0.6870\n",
      "[Trial 62] Epoch 24/60, Training Loss: 0.7334, Validation Loss: 0.7375\n",
      "[Trial 59] Epoch 34/60, Training Loss: 0.6565, Validation Loss: 0.5534\n",
      "[Trial 53] Epoch 58/60, Training Loss: 0.6394, Validation Loss: 0.5113\n",
      "[Trial 69] Epoch 3/60, Training Loss: 2.6058, Validation Loss: 1.7300\n",
      "[Trial 56] Epoch 53/60, Training Loss: 0.6076, Validation Loss: 0.5147\n",
      "[Trial 54] Epoch 59/60, Training Loss: 0.5986, Validation Loss: 0.4943\n",
      "[Trial 68] Epoch 4/60, Training Loss: 1.0499, Validation Loss: 1.0249\n",
      "[Trial 57] Epoch 41/60, Training Loss: 0.6226, Validation Loss: 0.4984\n",
      "[Trial 64] Epoch 11/60, Training Loss: 0.8985, Validation Loss: 0.9389\n",
      "[Trial 67] Epoch 5/60, Training Loss: 1.2863, Validation Loss: 1.1757\n",
      "[Trial 63] Epoch 12/60, Training Loss: 0.8534, Validation Loss: 1.4601\n",
      "[Trial 58] Epoch 37/60, Training Loss: 0.6650, Validation Loss: 0.5924\n",
      "[Trial 66] Epoch 9/60, Training Loss: 0.8762, Validation Loss: 0.7997\n",
      "[Trial 60] Epoch 29/60, Training Loss: 0.7131, Validation Loss: 0.6069\n",
      "[Trial 65] Epoch 11/60, Training Loss: 0.9001, Validation Loss: 0.8896\n",
      "[Trial 61] Epoch 27/60, Training Loss: 0.6999, Validation Loss: 0.5649\n",
      "[Trial 62] Epoch 25/60, Training Loss: 0.7866, Validation Loss: 0.7153\n",
      "[Trial 59] Epoch 35/60, Training Loss: 0.6476, Validation Loss: 0.5712\n",
      "[Trial 53] Epoch 59/60, Training Loss: 0.6309, Validation Loss: 0.5161\n",
      "[Trial 56] Epoch 54/60, Training Loss: 0.6096, Validation Loss: 0.5120\n",
      "[Trial 69] Epoch 4/60, Training Loss: 2.1088, Validation Loss: 2.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:19:15,404] Trial 54 finished with value: 0.49272140165170036 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0022025185597430346, 'batch_size': 16, 'patience': 7}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 54] Epoch 60/60, Training Loss: 0.5869, Validation Loss: 0.5023\n",
      "[Trial 68] Epoch 5/60, Training Loss: 0.9899, Validation Loss: 1.2413\n",
      "[Trial 57] Epoch 42/60, Training Loss: 0.6137, Validation Loss: 0.5125\n",
      "[Trial 64] Epoch 12/60, Training Loss: 0.8934, Validation Loss: 0.6935\n",
      "[Trial 63] Epoch 13/60, Training Loss: 0.8865, Validation Loss: 1.1146\n",
      "[Trial 67] Epoch 6/60, Training Loss: 1.1818, Validation Loss: 1.1544\n",
      "[Trial 58] Epoch 38/60, Training Loss: 0.6398, Validation Loss: 0.5272\n",
      "[Trial 66] Epoch 10/60, Training Loss: 0.8634, Validation Loss: 0.9047\n",
      "[Trial 60] Epoch 30/60, Training Loss: 0.7173, Validation Loss: 0.7616\n",
      "[Trial 65] Epoch 12/60, Training Loss: 0.8874, Validation Loss: 0.8932\n",
      "[Trial 61] Epoch 28/60, Training Loss: 0.7387, Validation Loss: 0.7976\n",
      "[Trial 62] Epoch 26/60, Training Loss: 0.7304, Validation Loss: 0.6337\n",
      "[Trial 59] Epoch 36/60, Training Loss: 0.6356, Validation Loss: 0.5449\n",
      "[Trial 56] Epoch 55/60, Training Loss: 0.6076, Validation Loss: 0.5127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:20:05,118] Trial 53 finished with value: 0.5113115385174751 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0014350826227726096, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 53] Epoch 60/60, Training Loss: 0.6373, Validation Loss: 0.5173\n",
      "[Trial 70] Epoch 1/60, Training Loss: 3.0796, Validation Loss: 1.5406\n",
      "[Trial 68] Epoch 6/60, Training Loss: 0.9971, Validation Loss: 0.8917\n",
      "[Trial 69] Epoch 5/60, Training Loss: 1.7999, Validation Loss: 1.9152\n",
      "[Trial 57] Epoch 43/60, Training Loss: 0.6067, Validation Loss: 0.4968\n",
      "[Trial 64] Epoch 13/60, Training Loss: 0.8910, Validation Loss: 1.2279\n",
      "[Trial 63] Epoch 14/60, Training Loss: 0.9237, Validation Loss: 0.6817\n",
      "[Trial 67] Epoch 7/60, Training Loss: 1.2357, Validation Loss: 1.1040\n",
      "[Trial 58] Epoch 39/60, Training Loss: 0.6295, Validation Loss: 0.5239\n",
      "[Trial 60] Epoch 31/60, Training Loss: 0.7292, Validation Loss: 0.6387\n",
      "[Trial 66] Epoch 11/60, Training Loss: 0.8586, Validation Loss: 0.8546\n",
      "[Trial 65] Epoch 13/60, Training Loss: 0.9311, Validation Loss: 1.1759\n",
      "[Trial 61] Epoch 29/60, Training Loss: 0.7360, Validation Loss: 0.6161\n",
      "[Trial 62] Epoch 27/60, Training Loss: 0.7132, Validation Loss: 0.7419\n",
      "[Trial 56] Epoch 56/60, Training Loss: 0.6056, Validation Loss: 0.5125\n",
      "[Trial 59] Epoch 37/60, Training Loss: 0.6255, Validation Loss: 0.5286\n",
      "[Trial 70] Epoch 2/60, Training Loss: 1.5229, Validation Loss: 1.2808\n",
      "[Trial 68] Epoch 7/60, Training Loss: 0.9798, Validation Loss: 0.7953\n",
      "[Trial 71] Epoch 1/60, Training Loss: 3.4894, Validation Loss: 1.6066\n",
      "[Trial 69] Epoch 6/60, Training Loss: 1.7269, Validation Loss: 1.5870\n",
      "[Trial 57] Epoch 44/60, Training Loss: 0.6163, Validation Loss: 0.5202\n",
      "[Trial 64] Epoch 14/60, Training Loss: 0.9345, Validation Loss: 1.0952\n",
      "[Trial 63] Epoch 15/60, Training Loss: 0.8121, Validation Loss: 0.8154\n",
      "[Trial 67] Epoch 8/60, Training Loss: 1.0381, Validation Loss: 0.9173\n",
      "[Trial 58] Epoch 40/60, Training Loss: 0.6307, Validation Loss: 0.5254\n",
      "[Trial 60] Epoch 32/60, Training Loss: 0.7051, Validation Loss: 0.5572\n",
      "[Trial 66] Epoch 12/60, Training Loss: 0.8398, Validation Loss: 0.7166\n",
      "[Trial 65] Epoch 14/60, Training Loss: 0.8256, Validation Loss: 0.6648\n",
      "[Trial 61] Epoch 30/60, Training Loss: 0.6883, Validation Loss: 0.8052\n",
      "[Trial 62] Epoch 28/60, Training Loss: 0.7162, Validation Loss: 0.7142\n",
      "[Trial 70] Epoch 3/60, Training Loss: 1.2082, Validation Loss: 0.8849\n",
      "[Trial 56] Epoch 57/60, Training Loss: 0.6036, Validation Loss: 0.5062\n",
      "[Trial 68] Epoch 8/60, Training Loss: 0.9287, Validation Loss: 1.0553\n",
      "[Trial 59] Epoch 38/60, Training Loss: 0.6371, Validation Loss: 0.5278\n",
      "[Trial 71] Epoch 2/60, Training Loss: 1.7255, Validation Loss: 1.1986\n",
      "[Trial 69] Epoch 7/60, Training Loss: 1.6390, Validation Loss: 3.4534\n",
      "[Trial 57] Epoch 45/60, Training Loss: 0.5996, Validation Loss: 0.5047\n",
      "[Trial 64] Epoch 15/60, Training Loss: 0.9152, Validation Loss: 0.8086\n",
      "[Trial 63] Epoch 16/60, Training Loss: 0.8239, Validation Loss: 0.6529\n",
      "[Trial 67] Epoch 9/60, Training Loss: 1.0931, Validation Loss: 0.7579\n",
      "[Trial 58] Epoch 41/60, Training Loss: 0.6291, Validation Loss: 0.5355\n",
      "[Trial 60] Epoch 33/60, Training Loss: 0.7049, Validation Loss: 0.6684\n",
      "[Trial 65] Epoch 15/60, Training Loss: 0.7610, Validation Loss: 0.5873\n",
      "[Trial 66] Epoch 13/60, Training Loss: 0.8081, Validation Loss: 0.8961\n",
      "[Trial 61] Epoch 31/60, Training Loss: 0.7100, Validation Loss: 0.6605\n",
      "[Trial 62] Epoch 29/60, Training Loss: 0.6683, Validation Loss: 0.5656\n",
      "[Trial 70] Epoch 4/60, Training Loss: 1.0735, Validation Loss: 1.1986\n",
      "[Trial 56] Epoch 58/60, Training Loss: 0.6080, Validation Loss: 0.5007\n",
      "[Trial 68] Epoch 9/60, Training Loss: 0.9772, Validation Loss: 0.8339\n",
      "[Trial 59] Epoch 39/60, Training Loss: 0.6261, Validation Loss: 0.5319\n",
      "[Trial 69] Epoch 8/60, Training Loss: 1.7675, Validation Loss: 1.8173\n",
      "[Trial 71] Epoch 3/60, Training Loss: 1.4053, Validation Loss: 1.0048\n",
      "[Trial 57] Epoch 46/60, Training Loss: 0.5957, Validation Loss: 0.5009\n",
      "[Trial 64] Epoch 16/60, Training Loss: 0.8571, Validation Loss: 0.8939\n",
      "[Trial 63] Epoch 17/60, Training Loss: 0.7956, Validation Loss: 1.2501\n",
      "[Trial 58] Epoch 42/60, Training Loss: 0.6283, Validation Loss: 0.5224\n",
      "[Trial 67] Epoch 10/60, Training Loss: 0.9948, Validation Loss: 1.1029\n",
      "[Trial 60] Epoch 34/60, Training Loss: 0.6939, Validation Loss: 0.5868\n",
      "[Trial 65] Epoch 16/60, Training Loss: 0.7614, Validation Loss: 0.6857\n",
      "[Trial 66] Epoch 14/60, Training Loss: 0.8296, Validation Loss: 0.8068\n",
      "[Trial 61] Epoch 32/60, Training Loss: 0.7259, Validation Loss: 0.7182\n",
      "[Trial 62] Epoch 30/60, Training Loss: 0.6493, Validation Loss: 0.5728\n",
      "[Trial 70] Epoch 5/60, Training Loss: 1.0287, Validation Loss: 0.7858\n",
      "[Trial 56] Epoch 59/60, Training Loss: 0.6053, Validation Loss: 0.5114\n",
      "[Trial 68] Epoch 10/60, Training Loss: 0.8913, Validation Loss: 0.9875\n",
      "[Trial 59] Epoch 40/60, Training Loss: 0.6204, Validation Loss: 0.5360\n",
      "[Trial 69] Epoch 9/60, Training Loss: 1.5581, Validation Loss: 2.7063\n",
      "[Trial 57] Epoch 47/60, Training Loss: 0.5933, Validation Loss: 0.4824\n",
      "[Trial 71] Epoch 4/60, Training Loss: 1.2587, Validation Loss: 1.0046\n",
      "[Trial 64] Epoch 17/60, Training Loss: 0.8649, Validation Loss: 0.8519\n",
      "[Trial 63] Epoch 18/60, Training Loss: 0.8601, Validation Loss: 0.7549\n",
      "[Trial 58] Epoch 43/60, Training Loss: 0.6371, Validation Loss: 0.5454\n",
      "[Trial 67] Epoch 11/60, Training Loss: 0.9799, Validation Loss: 1.0988\n",
      "[Trial 65] Epoch 17/60, Training Loss: 0.7753, Validation Loss: 0.5994\n",
      "[Trial 60] Epoch 35/60, Training Loss: 0.6914, Validation Loss: 0.5825\n",
      "[Trial 61] Epoch 33/60, Training Loss: 0.6518, Validation Loss: 0.5845\n",
      "[Trial 66] Epoch 15/60, Training Loss: 0.8059, Validation Loss: 0.6344\n",
      "[Trial 62] Epoch 31/60, Training Loss: 0.6553, Validation Loss: 0.5933\n",
      "[Trial 70] Epoch 6/60, Training Loss: 0.9680, Validation Loss: 0.8576\n",
      "[Trial 68] Epoch 11/60, Training Loss: 0.9133, Validation Loss: 0.8167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:24:20,424] Trial 56 finished with value: 0.5006808216373125 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.002350049066546124, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 56] Epoch 60/60, Training Loss: 0.6135, Validation Loss: 0.5136\n",
      "[Trial 59] Epoch 41/60, Training Loss: 0.6223, Validation Loss: 0.5239\n",
      "[Trial 57] Epoch 48/60, Training Loss: 0.5899, Validation Loss: 0.4843\n",
      "[Trial 69] Epoch 10/60, Training Loss: 1.4981, Validation Loss: 2.1577\n",
      "[Trial 64] Epoch 18/60, Training Loss: 0.7543, Validation Loss: 0.5752\n",
      "[Trial 71] Epoch 5/60, Training Loss: 1.1143, Validation Loss: 0.9089\n",
      "[Trial 63] Epoch 19/60, Training Loss: 0.8133, Validation Loss: 1.1315\n",
      "[Trial 58] Epoch 44/60, Training Loss: 0.6395, Validation Loss: 0.5301\n",
      "[Trial 67] Epoch 12/60, Training Loss: 0.9286, Validation Loss: 0.9372\n",
      "[Trial 65] Epoch 18/60, Training Loss: 0.7486, Validation Loss: 0.6041\n",
      "[Trial 60] Epoch 36/60, Training Loss: 0.6984, Validation Loss: 0.6133\n",
      "[Trial 61] Epoch 34/60, Training Loss: 0.6326, Validation Loss: 0.5805\n",
      "[Trial 62] Epoch 32/60, Training Loss: 0.6530, Validation Loss: 0.6294\n",
      "[Trial 66] Epoch 16/60, Training Loss: 0.7868, Validation Loss: 0.7924\n",
      "[Trial 70] Epoch 7/60, Training Loss: 0.9252, Validation Loss: 0.8496\n",
      "[Trial 68] Epoch 12/60, Training Loss: 0.8916, Validation Loss: 0.7627\n",
      "[Trial 59] Epoch 42/60, Training Loss: 0.6205, Validation Loss: 0.5225\n",
      "[Trial 57] Epoch 49/60, Training Loss: 0.5910, Validation Loss: 0.4933\n",
      "[Trial 69] Epoch 11/60, Training Loss: 1.5023, Validation Loss: 1.9444\n",
      "[Trial 63] Epoch 20/60, Training Loss: 0.8649, Validation Loss: 0.7671\n",
      "[Trial 64] Epoch 19/60, Training Loss: 0.7496, Validation Loss: 0.6082\n",
      "[Trial 71] Epoch 6/60, Training Loss: 0.9981, Validation Loss: 0.9179\n",
      "[Trial 58] Epoch 45/60, Training Loss: 0.6241, Validation Loss: 0.5426\n",
      "[Trial 67] Epoch 13/60, Training Loss: 0.9706, Validation Loss: 1.8846\n",
      "[Trial 65] Epoch 19/60, Training Loss: 0.7518, Validation Loss: 1.0031\n",
      "[Trial 60] Epoch 37/60, Training Loss: 0.6967, Validation Loss: 0.5911\n",
      "[Trial 61] Epoch 35/60, Training Loss: 0.6425, Validation Loss: 0.5691\n",
      "[Trial 62] Epoch 33/60, Training Loss: 0.6532, Validation Loss: 0.5458\n",
      "[Trial 72] Epoch 1/60, Training Loss: 21.4555, Validation Loss: 2.5104\n",
      "[Trial 70] Epoch 8/60, Training Loss: 0.9064, Validation Loss: 0.8995\n",
      "[Trial 66] Epoch 17/60, Training Loss: 0.7870, Validation Loss: 0.6718\n",
      "[Trial 68] Epoch 13/60, Training Loss: 0.8704, Validation Loss: 0.9043\n",
      "[Trial 59] Epoch 43/60, Training Loss: 0.6171, Validation Loss: 0.5260\n",
      "[Trial 57] Epoch 50/60, Training Loss: 0.5958, Validation Loss: 0.4941\n",
      "[Trial 63] Epoch 21/60, Training Loss: 0.7819, Validation Loss: 1.1806\n",
      "[Trial 64] Epoch 20/60, Training Loss: 0.7409, Validation Loss: 0.6803\n",
      "[Trial 69] Epoch 12/60, Training Loss: 1.3742, Validation Loss: 2.3869\n",
      "[Trial 58] Epoch 46/60, Training Loss: 0.6260, Validation Loss: 0.5588\n",
      "[Trial 71] Epoch 7/60, Training Loss: 0.9600, Validation Loss: 0.7979\n",
      "[Trial 67] Epoch 14/60, Training Loss: 1.0407, Validation Loss: 1.1032\n",
      "[Trial 65] Epoch 20/60, Training Loss: 0.7605, Validation Loss: 0.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:26:44,332] Trial 61 finished with value: 0.5649403676390647 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.02144614517554532, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 61] Epoch 36/60, Training Loss: 0.6432, Validation Loss: 0.5729\n",
      "[Trial 61] Early stopping after 36 epochs.\n",
      "[Trial 60] Epoch 38/60, Training Loss: 0.6539, Validation Loss: 0.5610\n",
      "[Trial 62] Epoch 34/60, Training Loss: 0.6622, Validation Loss: 0.6531\n",
      "[Trial 70] Epoch 9/60, Training Loss: 0.9213, Validation Loss: 0.9274\n",
      "[Trial 68] Epoch 14/60, Training Loss: 0.9095, Validation Loss: 0.8075\n",
      "[Trial 66] Epoch 18/60, Training Loss: 0.7925, Validation Loss: 1.3389\n",
      "[Trial 59] Epoch 44/60, Training Loss: 0.6231, Validation Loss: 0.5308\n",
      "[Trial 57] Epoch 51/60, Training Loss: 0.5983, Validation Loss: 0.4964\n",
      "[Trial 63] Epoch 22/60, Training Loss: 0.7579, Validation Loss: 0.6141\n",
      "[Trial 64] Epoch 21/60, Training Loss: 0.7431, Validation Loss: 0.7444\n",
      "[Trial 69] Epoch 13/60, Training Loss: 1.1808, Validation Loss: 0.9224\n",
      "[Trial 58] Epoch 47/60, Training Loss: 0.6329, Validation Loss: 0.5456\n",
      "[Trial 71] Epoch 8/60, Training Loss: 0.9516, Validation Loss: 0.8850\n",
      "[Trial 67] Epoch 15/60, Training Loss: 0.8341, Validation Loss: 0.8568\n",
      "[Trial 65] Epoch 21/60, Training Loss: 0.7012, Validation Loss: 0.5671\n",
      "[Trial 72] Epoch 2/60, Training Loss: 2.4589, Validation Loss: 1.8795\n",
      "[Trial 60] Epoch 39/60, Training Loss: 0.6527, Validation Loss: 0.5457\n",
      "[Trial 70] Epoch 10/60, Training Loss: 0.8733, Validation Loss: 0.8896\n",
      "[Trial 62] Epoch 35/60, Training Loss: 0.6849, Validation Loss: 0.5955\n",
      "[Trial 68] Epoch 15/60, Training Loss: 0.8624, Validation Loss: 0.9896\n",
      "[Trial 66] Epoch 19/60, Training Loss: 0.8554, Validation Loss: 0.9305\n",
      "[Trial 59] Epoch 45/60, Training Loss: 0.6163, Validation Loss: 0.5302\n",
      "[Trial 63] Epoch 23/60, Training Loss: 0.7004, Validation Loss: 0.7018\n",
      "[Trial 57] Epoch 52/60, Training Loss: 0.5943, Validation Loss: 0.4910\n",
      "[Trial 64] Epoch 22/60, Training Loss: 0.7664, Validation Loss: 0.5983\n",
      "[Trial 58] Epoch 48/60, Training Loss: 0.6135, Validation Loss: 0.5053\n",
      "[Trial 69] Epoch 14/60, Training Loss: 1.0989, Validation Loss: 1.0108\n",
      "[Trial 73] Epoch 1/60, Training Loss: 2.8557, Validation Loss: 1.4105\n",
      "[Trial 71] Epoch 9/60, Training Loss: 0.8794, Validation Loss: 0.7026\n",
      "[Trial 67] Epoch 16/60, Training Loss: 0.8491, Validation Loss: 1.3358\n",
      "[Trial 65] Epoch 22/60, Training Loss: 0.6872, Validation Loss: 0.6041\n",
      "[Trial 70] Epoch 11/60, Training Loss: 0.7802, Validation Loss: 0.5852\n",
      "[Trial 60] Epoch 40/60, Training Loss: 0.6419, Validation Loss: 0.5456\n",
      "[Trial 62] Epoch 36/60, Training Loss: 0.6471, Validation Loss: 0.5437\n",
      "[Trial 68] Epoch 16/60, Training Loss: 0.8841, Validation Loss: 1.0519\n",
      "[Trial 66] Epoch 20/60, Training Loss: 0.8022, Validation Loss: 0.7686\n",
      "[Trial 63] Epoch 24/60, Training Loss: 0.7154, Validation Loss: 0.7147\n",
      "[Trial 59] Epoch 46/60, Training Loss: 0.6195, Validation Loss: 0.5318\n",
      "[Trial 57] Epoch 53/60, Training Loss: 0.5841, Validation Loss: 0.4809\n",
      "[Trial 64] Epoch 23/60, Training Loss: 0.7280, Validation Loss: 0.7080\n",
      "[Trial 58] Epoch 49/60, Training Loss: 0.6067, Validation Loss: 0.5200\n",
      "[Trial 72] Epoch 3/60, Training Loss: 2.0257, Validation Loss: 1.5955\n",
      "[Trial 69] Epoch 15/60, Training Loss: 1.1442, Validation Loss: 0.9756\n",
      "[Trial 65] Epoch 23/60, Training Loss: 0.6865, Validation Loss: 0.6214\n",
      "[Trial 67] Epoch 17/60, Training Loss: 0.8831, Validation Loss: 0.7315\n",
      "[Trial 71] Epoch 10/60, Training Loss: 0.8539, Validation Loss: 0.7004\n",
      "[Trial 70] Epoch 12/60, Training Loss: 0.7445, Validation Loss: 0.6262\n",
      "[Trial 60] Epoch 41/60, Training Loss: 0.6454, Validation Loss: 0.5284\n",
      "[Trial 62] Epoch 37/60, Training Loss: 0.6432, Validation Loss: 0.6794\n",
      "[Trial 68] Epoch 17/60, Training Loss: 0.8713, Validation Loss: 0.9223\n",
      "[Trial 66] Epoch 21/60, Training Loss: 0.6830, Validation Loss: 0.6199\n",
      "[Trial 73] Epoch 2/60, Training Loss: 1.5578, Validation Loss: 0.9874\n",
      "[Trial 63] Epoch 25/60, Training Loss: 0.7105, Validation Loss: 0.6012\n",
      "[Trial 57] Epoch 54/60, Training Loss: 0.5779, Validation Loss: 0.4923\n",
      "[Trial 59] Epoch 47/60, Training Loss: 0.6192, Validation Loss: 0.5182\n",
      "[Trial 58] Epoch 50/60, Training Loss: 0.6040, Validation Loss: 0.5130\n",
      "[Trial 64] Epoch 24/60, Training Loss: 0.6993, Validation Loss: 0.5620\n",
      "[Trial 69] Epoch 16/60, Training Loss: 1.0620, Validation Loss: 0.8406\n",
      "[Trial 65] Epoch 24/60, Training Loss: 0.6982, Validation Loss: 0.5885\n",
      "[Trial 70] Epoch 13/60, Training Loss: 0.7435, Validation Loss: 0.9263\n",
      "[Trial 67] Epoch 18/60, Training Loss: 0.8095, Validation Loss: 0.8068\n",
      "[Trial 60] Epoch 42/60, Training Loss: 0.6324, Validation Loss: 0.5272\n",
      "[Trial 71] Epoch 11/60, Training Loss: 0.8179, Validation Loss: 0.7047\n",
      "[Trial 62] Epoch 38/60, Training Loss: 0.6642, Validation Loss: 0.5939\n",
      "[Trial 68] Epoch 18/60, Training Loss: 0.7830, Validation Loss: 0.7049\n",
      "[Trial 66] Epoch 22/60, Training Loss: 0.6819, Validation Loss: 0.5589\n",
      "[Trial 63] Epoch 26/60, Training Loss: 0.6820, Validation Loss: 0.5873\n",
      "[Trial 72] Epoch 4/60, Training Loss: 1.7906, Validation Loss: 1.6433\n",
      "[Trial 57] Epoch 55/60, Training Loss: 0.5824, Validation Loss: 0.4763\n",
      "[Trial 59] Epoch 48/60, Training Loss: 0.6250, Validation Loss: 0.5251\n",
      "[Trial 58] Epoch 51/60, Training Loss: 0.6072, Validation Loss: 0.5129\n",
      "[Trial 64] Epoch 25/60, Training Loss: 0.7042, Validation Loss: 0.6202\n",
      "[Trial 65] Epoch 25/60, Training Loss: 0.6808, Validation Loss: 0.5683\n",
      "[Trial 69] Epoch 17/60, Training Loss: 1.0871, Validation Loss: 0.9758\n",
      "[Trial 70] Epoch 14/60, Training Loss: 0.7852, Validation Loss: 0.7149\n",
      "[Trial 67] Epoch 19/60, Training Loss: 0.7764, Validation Loss: 0.8197\n",
      "[Trial 62] Epoch 39/60, Training Loss: 0.6320, Validation Loss: 0.5869\n",
      "[Trial 68] Epoch 19/60, Training Loss: 0.7704, Validation Loss: 0.7888\n",
      "[Trial 60] Epoch 43/60, Training Loss: 0.6455, Validation Loss: 0.5252\n",
      "[Trial 71] Epoch 12/60, Training Loss: 0.8270, Validation Loss: 0.8180\n",
      "[Trial 66] Epoch 23/60, Training Loss: 0.6861, Validation Loss: 0.9123\n",
      "[Trial 73] Epoch 3/60, Training Loss: 1.2480, Validation Loss: 1.0180\n",
      "[Trial 63] Epoch 27/60, Training Loss: 0.6807, Validation Loss: 0.7260\n",
      "[Trial 57] Epoch 56/60, Training Loss: 0.5773, Validation Loss: 0.4772\n",
      "[Trial 58] Epoch 52/60, Training Loss: 0.6134, Validation Loss: 0.5093\n",
      "[Trial 59] Epoch 49/60, Training Loss: 0.6289, Validation Loss: 0.5378\n",
      "[Trial 64] Epoch 26/60, Training Loss: 0.7086, Validation Loss: 0.5778\n",
      "[Trial 65] Epoch 26/60, Training Loss: 0.6718, Validation Loss: 0.5760\n",
      "[Trial 70] Epoch 15/60, Training Loss: 0.7699, Validation Loss: 0.6534\n",
      "[Trial 69] Epoch 18/60, Training Loss: 1.0871, Validation Loss: 1.5036\n",
      "[Trial 67] Epoch 20/60, Training Loss: 0.7949, Validation Loss: 0.6735\n",
      "[Trial 68] Epoch 20/60, Training Loss: 0.7956, Validation Loss: 0.7855\n",
      "[Trial 62] Epoch 40/60, Training Loss: 0.6303, Validation Loss: 0.5506\n",
      "[Trial 60] Epoch 44/60, Training Loss: 0.6391, Validation Loss: 0.5470\n",
      "[Trial 71] Epoch 13/60, Training Loss: 0.8261, Validation Loss: 0.7246\n",
      "[Trial 66] Epoch 24/60, Training Loss: 0.7275, Validation Loss: 0.6737\n",
      "[Trial 72] Epoch 5/60, Training Loss: 1.6786, Validation Loss: 1.6696\n",
      "[Trial 63] Epoch 28/60, Training Loss: 0.6872, Validation Loss: 0.6455\n",
      "[Trial 57] Epoch 57/60, Training Loss: 0.5789, Validation Loss: 0.4880\n",
      "[Trial 58] Epoch 53/60, Training Loss: 0.6081, Validation Loss: 0.5120\n",
      "[Trial 59] Epoch 50/60, Training Loss: 0.6205, Validation Loss: 0.5335\n",
      "[Trial 64] Epoch 27/60, Training Loss: 0.6842, Validation Loss: 0.5427\n",
      "[Trial 70] Epoch 16/60, Training Loss: 0.7641, Validation Loss: 0.7560\n",
      "[Trial 65] Epoch 27/60, Training Loss: 0.6532, Validation Loss: 0.5399\n",
      "[Trial 68] Epoch 21/60, Training Loss: 0.7569, Validation Loss: 0.7262\n",
      "[Trial 69] Epoch 19/60, Training Loss: 1.0734, Validation Loss: 1.2977\n",
      "[Trial 62] Epoch 41/60, Training Loss: 0.6213, Validation Loss: 0.5415\n",
      "[Trial 67] Epoch 21/60, Training Loss: 0.7825, Validation Loss: 0.6053\n",
      "[Trial 60] Epoch 45/60, Training Loss: 0.6356, Validation Loss: 0.5301\n",
      "[Trial 73] Epoch 4/60, Training Loss: 1.0944, Validation Loss: 0.7955\n",
      "[Trial 71] Epoch 14/60, Training Loss: 0.8049, Validation Loss: 0.6505\n",
      "[Trial 66] Epoch 25/60, Training Loss: 0.6973, Validation Loss: 0.6229\n",
      "[Trial 63] Epoch 29/60, Training Loss: 0.6985, Validation Loss: 0.6042\n",
      "[Trial 57] Epoch 58/60, Training Loss: 0.5781, Validation Loss: 0.4756\n",
      "[Trial 58] Epoch 54/60, Training Loss: 0.5978, Validation Loss: 0.5060\n",
      "[Trial 59] Epoch 51/60, Training Loss: 0.6174, Validation Loss: 0.5243\n",
      "[Trial 70] Epoch 17/60, Training Loss: 0.6947, Validation Loss: 0.5804\n",
      "[Trial 64] Epoch 28/60, Training Loss: 0.6777, Validation Loss: 0.5481\n",
      "[Trial 65] Epoch 28/60, Training Loss: 0.6447, Validation Loss: 0.5364\n",
      "[Trial 68] Epoch 22/60, Training Loss: 0.7387, Validation Loss: 0.6718\n",
      "[Trial 62] Epoch 42/60, Training Loss: 0.6293, Validation Loss: 0.6110\n",
      "[Trial 67] Epoch 22/60, Training Loss: 0.7444, Validation Loss: 0.6111\n",
      "[Trial 69] Epoch 20/60, Training Loss: 1.0678, Validation Loss: 2.7280\n",
      "[Trial 60] Epoch 46/60, Training Loss: 0.6434, Validation Loss: 0.5807\n",
      "[Trial 71] Epoch 15/60, Training Loss: 0.7801, Validation Loss: 1.0126\n",
      "[Trial 72] Epoch 6/60, Training Loss: 1.5647, Validation Loss: 1.6415\n",
      "[Trial 66] Epoch 26/60, Training Loss: 0.6780, Validation Loss: 0.5743\n",
      "[Trial 63] Epoch 30/60, Training Loss: 0.6954, Validation Loss: 1.0261\n",
      "[Trial 58] Epoch 55/60, Training Loss: 0.5958, Validation Loss: 0.5066\n",
      "[Trial 57] Epoch 59/60, Training Loss: 0.5801, Validation Loss: 0.4767\n",
      "[Trial 70] Epoch 18/60, Training Loss: 0.6807, Validation Loss: 0.5513\n",
      "[Trial 65] Epoch 29/60, Training Loss: 0.6512, Validation Loss: 0.5419\n",
      "[Trial 64] Epoch 29/60, Training Loss: 0.6749, Validation Loss: 0.5515\n",
      "[Trial 59] Epoch 52/60, Training Loss: 0.6149, Validation Loss: 0.5340\n",
      "[Trial 73] Epoch 5/60, Training Loss: 1.0199, Validation Loss: 0.8079\n",
      "[Trial 68] Epoch 23/60, Training Loss: 0.7374, Validation Loss: 0.6362\n",
      "[Trial 62] Epoch 43/60, Training Loss: 0.6267, Validation Loss: 0.5098\n",
      "[Trial 67] Epoch 23/60, Training Loss: 0.7560, Validation Loss: 1.0497\n",
      "[Trial 60] Epoch 47/60, Training Loss: 0.6452, Validation Loss: 0.5341\n",
      "[Trial 69] Epoch 21/60, Training Loss: 1.1012, Validation Loss: 0.7794\n",
      "[Trial 71] Epoch 16/60, Training Loss: 0.8155, Validation Loss: 0.6449\n",
      "[Trial 66] Epoch 27/60, Training Loss: 0.6599, Validation Loss: 0.6721\n",
      "[Trial 63] Epoch 31/60, Training Loss: 0.7358, Validation Loss: 0.6833\n",
      "[Trial 58] Epoch 56/60, Training Loss: 0.5940, Validation Loss: 0.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:35:07,679] Trial 57 finished with value: 0.4756350432833036 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.002369454037691211, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 57] Epoch 60/60, Training Loss: 0.5804, Validation Loss: 0.4798\n",
      "[Trial 70] Epoch 19/60, Training Loss: 0.6732, Validation Loss: 0.5682\n",
      "[Trial 65] Epoch 30/60, Training Loss: 0.6421, Validation Loss: 0.5369\n",
      "[Trial 64] Epoch 30/60, Training Loss: 0.6598, Validation Loss: 0.5727\n",
      "[Trial 59] Epoch 53/60, Training Loss: 0.6093, Validation Loss: 0.5199\n",
      "[Trial 68] Epoch 24/60, Training Loss: 0.7452, Validation Loss: 0.8617\n",
      "[Trial 62] Epoch 44/60, Training Loss: 0.6303, Validation Loss: 0.7325\n",
      "[Trial 60] Epoch 48/60, Training Loss: 0.6367, Validation Loss: 0.5467\n",
      "[Trial 67] Epoch 24/60, Training Loss: 0.7889, Validation Loss: 0.7930\n",
      "[Trial 69] Epoch 22/60, Training Loss: 1.0346, Validation Loss: 0.9179\n",
      "[Trial 72] Epoch 7/60, Training Loss: 1.4627, Validation Loss: 1.3440\n",
      "[Trial 71] Epoch 17/60, Training Loss: 0.7623, Validation Loss: 0.7053\n",
      "[Trial 63] Epoch 32/60, Training Loss: 0.6381, Validation Loss: 0.5910\n",
      "[Trial 66] Epoch 28/60, Training Loss: 0.6267, Validation Loss: 0.5886\n",
      "[Trial 58] Epoch 57/60, Training Loss: 0.6031, Validation Loss: 0.5068\n",
      "[Trial 73] Epoch 6/60, Training Loss: 0.9861, Validation Loss: 0.9773\n",
      "[Trial 70] Epoch 20/60, Training Loss: 0.6795, Validation Loss: 0.5914\n",
      "[Trial 65] Epoch 31/60, Training Loss: 0.6460, Validation Loss: 0.5176\n",
      "[Trial 64] Epoch 31/60, Training Loss: 0.6601, Validation Loss: 0.5330\n",
      "[Trial 68] Epoch 25/60, Training Loss: 0.7659, Validation Loss: 0.8137\n",
      "[Trial 59] Epoch 54/60, Training Loss: 0.6152, Validation Loss: 0.5236\n",
      "[Trial 62] Epoch 45/60, Training Loss: 0.6446, Validation Loss: 0.5583\n",
      "[Trial 60] Epoch 49/60, Training Loss: 0.6142, Validation Loss: 0.5023\n",
      "[Trial 67] Epoch 25/60, Training Loss: 0.7735, Validation Loss: 0.8275\n",
      "[Trial 69] Epoch 23/60, Training Loss: 1.0482, Validation Loss: 0.9842\n",
      "[Trial 63] Epoch 33/60, Training Loss: 0.6446, Validation Loss: 0.6355\n",
      "[Trial 71] Epoch 18/60, Training Loss: 0.7573, Validation Loss: 0.6536\n",
      "[Trial 66] Epoch 29/60, Training Loss: 0.6290, Validation Loss: 0.5485\n",
      "[Trial 74] Epoch 1/60, Training Loss: 2.9396, Validation Loss: 1.2999\n",
      "[Trial 58] Epoch 58/60, Training Loss: 0.5964, Validation Loss: 0.5067\n",
      "[Trial 70] Epoch 21/60, Training Loss: 0.6804, Validation Loss: 0.5567\n",
      "[Trial 65] Epoch 32/60, Training Loss: 0.6455, Validation Loss: 0.5340\n",
      "[Trial 68] Epoch 26/60, Training Loss: 0.7577, Validation Loss: 0.6865\n",
      "[Trial 64] Epoch 32/60, Training Loss: 0.6729, Validation Loss: 0.6073\n",
      "[Trial 62] Epoch 46/60, Training Loss: 0.6240, Validation Loss: 0.5950\n",
      "[Trial 59] Epoch 55/60, Training Loss: 0.6068, Validation Loss: 0.5216\n",
      "[Trial 72] Epoch 8/60, Training Loss: 1.4532, Validation Loss: 1.1469\n",
      "[Trial 60] Epoch 50/60, Training Loss: 0.6129, Validation Loss: 0.5234\n",
      "[Trial 67] Epoch 26/60, Training Loss: 0.7620, Validation Loss: 0.6846\n",
      "[Trial 69] Epoch 24/60, Training Loss: 1.0462, Validation Loss: 1.4689\n",
      "[Trial 63] Epoch 34/60, Training Loss: 0.6352, Validation Loss: 0.5439\n",
      "[Trial 73] Epoch 7/60, Training Loss: 1.0139, Validation Loss: 0.7347\n",
      "[Trial 71] Epoch 19/60, Training Loss: 0.7611, Validation Loss: 0.7664\n",
      "[Trial 66] Epoch 30/60, Training Loss: 0.6237, Validation Loss: 0.5682\n",
      "[Trial 58] Epoch 59/60, Training Loss: 0.6020, Validation Loss: 0.5029\n",
      "[Trial 70] Epoch 22/60, Training Loss: 0.6675, Validation Loss: 0.6079\n",
      "[Trial 65] Epoch 33/60, Training Loss: 0.6516, Validation Loss: 0.5406\n",
      "[Trial 68] Epoch 27/60, Training Loss: 0.7259, Validation Loss: 0.7050\n",
      "[Trial 62] Epoch 47/60, Training Loss: 0.6244, Validation Loss: 0.6257\n",
      "[Trial 64] Epoch 33/60, Training Loss: 0.6854, Validation Loss: 0.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:37:58,540] Trial 59 finished with value: 0.5181980162858963 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0015533658250038158, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 59] Epoch 56/60, Training Loss: 0.6247, Validation Loss: 0.5441\n",
      "[Trial 59] Early stopping after 56 epochs.\n",
      "[Trial 60] Epoch 51/60, Training Loss: 0.6122, Validation Loss: 0.5246\n",
      "[Trial 67] Epoch 27/60, Training Loss: 0.7031, Validation Loss: 0.6649\n",
      "[Trial 69] Epoch 25/60, Training Loss: 1.0363, Validation Loss: 5.1286\n",
      "[Trial 74] Epoch 2/60, Training Loss: 1.5606, Validation Loss: 1.0509\n",
      "[Trial 63] Epoch 35/60, Training Loss: 0.6224, Validation Loss: 0.6354\n",
      "[Trial 66] Epoch 31/60, Training Loss: 0.6177, Validation Loss: 0.5361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:38:30,009] Trial 58 finished with value: 0.5028666938344638 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.0013804500888643428, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 58] Epoch 60/60, Training Loss: 0.5994, Validation Loss: 0.5119\n",
      "[Trial 71] Epoch 20/60, Training Loss: 0.7481, Validation Loss: 0.6355\n",
      "[Trial 70] Epoch 23/60, Training Loss: 0.6735, Validation Loss: 0.5834\n",
      "[Trial 65] Epoch 34/60, Training Loss: 0.6484, Validation Loss: 0.5365\n",
      "[Trial 68] Epoch 28/60, Training Loss: 0.7473, Validation Loss: 0.7456\n",
      "[Trial 72] Epoch 9/60, Training Loss: 1.3323, Validation Loss: 1.0316\n",
      "[Trial 62] Epoch 48/60, Training Loss: 0.6406, Validation Loss: 0.5932\n",
      "[Trial 64] Epoch 34/60, Training Loss: 0.6817, Validation Loss: 0.5959\n",
      "[Trial 60] Epoch 52/60, Training Loss: 0.6527, Validation Loss: 0.5214\n",
      "[Trial 67] Epoch 28/60, Training Loss: 0.6961, Validation Loss: 0.5637\n",
      "[Trial 73] Epoch 8/60, Training Loss: 0.9282, Validation Loss: 0.7430\n",
      "[Trial 69] Epoch 26/60, Training Loss: 1.3429, Validation Loss: 0.8087\n",
      "[Trial 63] Epoch 36/60, Training Loss: 0.6457, Validation Loss: 0.5645\n",
      "[Trial 70] Epoch 24/60, Training Loss: 0.6323, Validation Loss: 0.5247\n",
      "[Trial 66] Epoch 32/60, Training Loss: 0.6243, Validation Loss: 0.6718\n",
      "[Trial 71] Epoch 21/60, Training Loss: 0.7385, Validation Loss: 0.6720\n",
      "[Trial 65] Epoch 35/60, Training Loss: 0.6328, Validation Loss: 0.5225\n",
      "[Trial 68] Epoch 29/60, Training Loss: 0.6973, Validation Loss: 0.5960\n",
      "[Trial 62] Epoch 49/60, Training Loss: 0.6100, Validation Loss: 0.5069\n",
      "[Trial 75] Epoch 1/60, Training Loss: 2.9377, Validation Loss: 1.9352\n",
      "[Trial 64] Epoch 35/60, Training Loss: 0.6738, Validation Loss: 0.5451\n",
      "[Trial 60] Epoch 53/60, Training Loss: 0.6200, Validation Loss: 0.5130\n",
      "[Trial 67] Epoch 29/60, Training Loss: 0.7021, Validation Loss: 0.7259\n",
      "[Trial 74] Epoch 3/60, Training Loss: 1.2467, Validation Loss: 0.8757\n",
      "[Trial 69] Epoch 27/60, Training Loss: 0.9753, Validation Loss: 3.0594\n",
      "[Trial 63] Epoch 37/60, Training Loss: 0.6215, Validation Loss: 0.5531\n",
      "[Trial 76] Epoch 1/60, Training Loss: 3.0428, Validation Loss: 1.5965\n",
      "[Trial 70] Epoch 25/60, Training Loss: 0.6336, Validation Loss: 0.5332\n",
      "[Trial 66] Epoch 33/60, Training Loss: 0.6366, Validation Loss: 0.5669\n",
      "[Trial 72] Epoch 10/60, Training Loss: 1.3379, Validation Loss: 1.2127\n",
      "[Trial 71] Epoch 22/60, Training Loss: 0.7468, Validation Loss: 0.6927\n",
      "[Trial 68] Epoch 30/60, Training Loss: 0.6830, Validation Loss: 0.6084\n",
      "[Trial 65] Epoch 36/60, Training Loss: 0.6337, Validation Loss: 0.5540\n",
      "[Trial 62] Epoch 50/60, Training Loss: 0.5929, Validation Loss: 0.5181\n",
      "[Trial 64] Epoch 36/60, Training Loss: 0.6677, Validation Loss: 0.5456\n",
      "[Trial 73] Epoch 9/60, Training Loss: 0.8908, Validation Loss: 0.7961\n",
      "[Trial 60] Epoch 54/60, Training Loss: 0.6055, Validation Loss: 0.5125\n",
      "[Trial 67] Epoch 30/60, Training Loss: 0.7065, Validation Loss: 0.5966\n",
      "[Trial 69] Epoch 28/60, Training Loss: 1.0245, Validation Loss: 0.6872\n",
      "[Trial 63] Epoch 38/60, Training Loss: 0.6146, Validation Loss: 0.5382\n",
      "[Trial 70] Epoch 26/60, Training Loss: 0.6393, Validation Loss: 0.5531\n",
      "[Trial 66] Epoch 34/60, Training Loss: 0.6273, Validation Loss: 0.5299\n",
      "[Trial 68] Epoch 31/60, Training Loss: 0.6897, Validation Loss: 0.5994\n",
      "[Trial 65] Epoch 37/60, Training Loss: 0.6189, Validation Loss: 0.5132\n",
      "[Trial 71] Epoch 23/60, Training Loss: 0.7316, Validation Loss: 0.6062\n",
      "[Trial 62] Epoch 51/60, Training Loss: 0.5939, Validation Loss: 0.5001\n",
      "[Trial 75] Epoch 2/60, Training Loss: 1.5449, Validation Loss: 1.1185\n",
      "[Trial 74] Epoch 4/60, Training Loss: 1.1330, Validation Loss: 0.9180\n",
      "[Trial 64] Epoch 37/60, Training Loss: 0.6476, Validation Loss: 0.5418\n",
      "[Trial 60] Epoch 55/60, Training Loss: 0.5984, Validation Loss: 0.5060\n",
      "[Trial 67] Epoch 31/60, Training Loss: 0.6686, Validation Loss: 0.6099\n",
      "[Trial 76] Epoch 2/60, Training Loss: 1.6012, Validation Loss: 1.5892\n",
      "[Trial 63] Epoch 39/60, Training Loss: 0.6235, Validation Loss: 0.9774\n",
      "[Trial 69] Epoch 29/60, Training Loss: 0.8470, Validation Loss: 0.6645\n",
      "[Trial 70] Epoch 27/60, Training Loss: 0.6394, Validation Loss: 0.5212\n",
      "[Trial 72] Epoch 11/60, Training Loss: 1.2397, Validation Loss: 0.9345\n",
      "[Trial 68] Epoch 32/60, Training Loss: 0.6640, Validation Loss: 0.5876\n",
      "[Trial 66] Epoch 35/60, Training Loss: 0.6146, Validation Loss: 0.5461\n",
      "[Trial 65] Epoch 38/60, Training Loss: 0.6198, Validation Loss: 0.5105\n",
      "[Trial 73] Epoch 10/60, Training Loss: 0.8904, Validation Loss: 0.6829\n",
      "[Trial 71] Epoch 24/60, Training Loss: 0.7132, Validation Loss: 0.6638\n",
      "[Trial 62] Epoch 52/60, Training Loss: 0.5841, Validation Loss: 0.5258\n",
      "[Trial 64] Epoch 38/60, Training Loss: 0.6423, Validation Loss: 0.5416\n",
      "[Trial 60] Epoch 56/60, Training Loss: 0.6033, Validation Loss: 0.5056\n",
      "[Trial 67] Epoch 32/60, Training Loss: 0.6804, Validation Loss: 0.5376\n",
      "[Trial 63] Epoch 40/60, Training Loss: 0.6374, Validation Loss: 0.6195\n",
      "[Trial 70] Epoch 28/60, Training Loss: 0.6345, Validation Loss: 0.5766\n",
      "[Trial 69] Epoch 30/60, Training Loss: 0.8550, Validation Loss: 0.7253\n",
      "[Trial 68] Epoch 33/60, Training Loss: 0.6695, Validation Loss: 0.5945\n",
      "[Trial 65] Epoch 39/60, Training Loss: 0.6143, Validation Loss: 0.5161\n",
      "[Trial 66] Epoch 36/60, Training Loss: 0.6170, Validation Loss: 0.5201\n",
      "[Trial 74] Epoch 5/60, Training Loss: 1.0252, Validation Loss: 0.9218\n",
      "[Trial 75] Epoch 3/60, Training Loss: 1.2421, Validation Loss: 0.9792\n",
      "[Trial 62] Epoch 53/60, Training Loss: 0.5862, Validation Loss: 0.5094\n",
      "[Trial 71] Epoch 25/60, Training Loss: 0.7115, Validation Loss: 0.5816\n",
      "[Trial 64] Epoch 39/60, Training Loss: 0.6351, Validation Loss: 0.5155\n",
      "[Trial 60] Epoch 57/60, Training Loss: 0.6014, Validation Loss: 0.5148\n",
      "[Trial 76] Epoch 3/60, Training Loss: 1.2770, Validation Loss: 0.9154\n",
      "[Trial 67] Epoch 33/60, Training Loss: 0.6650, Validation Loss: 0.6031\n",
      "[Trial 63] Epoch 41/60, Training Loss: 0.6145, Validation Loss: 0.5686\n",
      "[Trial 72] Epoch 12/60, Training Loss: 1.2236, Validation Loss: 2.1916\n",
      "[Trial 70] Epoch 29/60, Training Loss: 0.6387, Validation Loss: 0.5035\n",
      "[Trial 69] Epoch 31/60, Training Loss: 0.8432, Validation Loss: 1.0168\n",
      "[Trial 73] Epoch 11/60, Training Loss: 0.8606, Validation Loss: 0.6764\n",
      "[Trial 68] Epoch 34/60, Training Loss: 0.6701, Validation Loss: 0.5837\n",
      "[Trial 65] Epoch 40/60, Training Loss: 0.6229, Validation Loss: 0.5156\n",
      "[Trial 66] Epoch 37/60, Training Loss: 0.6128, Validation Loss: 0.5982\n",
      "[Trial 62] Epoch 54/60, Training Loss: 0.5903, Validation Loss: 0.5421\n",
      "[Trial 71] Epoch 26/60, Training Loss: 0.7016, Validation Loss: 0.7025\n",
      "[Trial 64] Epoch 40/60, Training Loss: 0.6292, Validation Loss: 0.5408\n",
      "[Trial 60] Epoch 58/60, Training Loss: 0.5928, Validation Loss: 0.5015\n",
      "[Trial 67] Epoch 34/60, Training Loss: 0.6789, Validation Loss: 0.6337\n",
      "[Trial 63] Epoch 42/60, Training Loss: 0.6086, Validation Loss: 0.5376\n",
      "[Trial 70] Epoch 30/60, Training Loss: 0.6166, Validation Loss: 0.5122\n",
      "[Trial 69] Epoch 32/60, Training Loss: 0.9596, Validation Loss: 0.7472\n",
      "[Trial 74] Epoch 6/60, Training Loss: 0.9727, Validation Loss: 0.7545\n",
      "[Trial 68] Epoch 35/60, Training Loss: 0.6709, Validation Loss: 0.5648\n",
      "[Trial 65] Epoch 41/60, Training Loss: 0.6291, Validation Loss: 0.5381\n",
      "[Trial 75] Epoch 4/60, Training Loss: 1.0895, Validation Loss: 0.9240\n",
      "[Trial 66] Epoch 38/60, Training Loss: 0.6091, Validation Loss: 0.5801\n",
      "[Trial 62] Epoch 55/60, Training Loss: 0.5898, Validation Loss: 0.4989\n",
      "[Trial 76] Epoch 4/60, Training Loss: 1.0922, Validation Loss: 0.7996\n",
      "[Trial 71] Epoch 27/60, Training Loss: 0.7171, Validation Loss: 0.6862\n",
      "[Trial 64] Epoch 41/60, Training Loss: 0.6356, Validation Loss: 0.5268\n",
      "[Trial 60] Epoch 59/60, Training Loss: 0.5887, Validation Loss: 0.4936\n",
      "[Trial 67] Epoch 35/60, Training Loss: 0.6690, Validation Loss: 0.5911\n",
      "[Trial 72] Epoch 13/60, Training Loss: 1.2031, Validation Loss: 1.1572\n",
      "[Trial 63] Epoch 43/60, Training Loss: 0.6046, Validation Loss: 0.5190\n",
      "[Trial 73] Epoch 12/60, Training Loss: 0.8624, Validation Loss: 0.6589\n",
      "[Trial 70] Epoch 31/60, Training Loss: 0.6259, Validation Loss: 0.5355\n",
      "[Trial 68] Epoch 36/60, Training Loss: 0.6610, Validation Loss: 0.6499\n",
      "[Trial 69] Epoch 33/60, Training Loss: 0.8238, Validation Loss: 0.7497\n",
      "[Trial 65] Epoch 42/60, Training Loss: 0.6169, Validation Loss: 0.5071\n",
      "[Trial 66] Epoch 39/60, Training Loss: 0.6257, Validation Loss: 0.5521\n",
      "[Trial 62] Epoch 56/60, Training Loss: 0.5952, Validation Loss: 0.5038\n",
      "[Trial 64] Epoch 42/60, Training Loss: 0.6265, Validation Loss: 0.5304\n",
      "[Trial 71] Epoch 28/60, Training Loss: 0.7209, Validation Loss: 0.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:45:53,811] Trial 60 finished with value: 0.4935940409700076 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0011018065136383056, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 60] Epoch 60/60, Training Loss: 0.6002, Validation Loss: 0.5106\n",
      "[Trial 67] Epoch 36/60, Training Loss: 0.6741, Validation Loss: 0.5526\n",
      "[Trial 63] Epoch 44/60, Training Loss: 0.6037, Validation Loss: 0.5512\n",
      "[Trial 70] Epoch 32/60, Training Loss: 0.6360, Validation Loss: 0.5171\n",
      "[Trial 74] Epoch 7/60, Training Loss: 0.9518, Validation Loss: 0.8874\n",
      "[Trial 68] Epoch 37/60, Training Loss: 0.6799, Validation Loss: 0.6103\n",
      "[Trial 69] Epoch 34/60, Training Loss: 0.8551, Validation Loss: 1.1015\n",
      "[Trial 65] Epoch 43/60, Training Loss: 0.6096, Validation Loss: 0.5290\n",
      "[Trial 75] Epoch 5/60, Training Loss: 1.0017, Validation Loss: 0.8652\n",
      "[Trial 62] Epoch 57/60, Training Loss: 0.5885, Validation Loss: 0.4989\n",
      "[Trial 66] Epoch 40/60, Training Loss: 0.6168, Validation Loss: 0.5274\n",
      "[Trial 76] Epoch 5/60, Training Loss: 1.0264, Validation Loss: 0.8221\n",
      "[Trial 64] Epoch 43/60, Training Loss: 0.6322, Validation Loss: 0.5424\n",
      "[Trial 72] Epoch 14/60, Training Loss: 1.1398, Validation Loss: 1.1474\n",
      "[Trial 73] Epoch 13/60, Training Loss: 0.8308, Validation Loss: 0.6567\n",
      "[Trial 71] Epoch 29/60, Training Loss: 0.7048, Validation Loss: 0.9558\n",
      "[Trial 67] Epoch 37/60, Training Loss: 0.6651, Validation Loss: 0.6575\n",
      "[Trial 63] Epoch 45/60, Training Loss: 0.5988, Validation Loss: 0.5443\n",
      "[Trial 70] Epoch 33/60, Training Loss: 0.6198, Validation Loss: 0.5183\n",
      "[Trial 68] Epoch 38/60, Training Loss: 0.6723, Validation Loss: 0.5661\n",
      "[Trial 65] Epoch 44/60, Training Loss: 0.6092, Validation Loss: 0.5134\n",
      "[Trial 69] Epoch 35/60, Training Loss: 0.8796, Validation Loss: 0.9201\n",
      "[Trial 62] Epoch 58/60, Training Loss: 0.5793, Validation Loss: 0.5073\n",
      "[Trial 66] Epoch 41/60, Training Loss: 0.5965, Validation Loss: 0.5045\n",
      "[Trial 77] Epoch 1/60, Training Loss: 19.7887, Validation Loss: 7.1714\n",
      "[Trial 64] Epoch 44/60, Training Loss: 0.6259, Validation Loss: 0.5154\n",
      "[Trial 71] Epoch 30/60, Training Loss: 0.7394, Validation Loss: 0.7772\n",
      "[Trial 74] Epoch 8/60, Training Loss: 0.9288, Validation Loss: 0.7434\n",
      "[Trial 70] Epoch 34/60, Training Loss: 0.6120, Validation Loss: 0.5033\n",
      "[Trial 63] Epoch 46/60, Training Loss: 0.5909, Validation Loss: 0.5755\n",
      "[Trial 67] Epoch 38/60, Training Loss: 0.6265, Validation Loss: 0.5327\n",
      "[Trial 68] Epoch 39/60, Training Loss: 0.6622, Validation Loss: 0.6355\n",
      "[Trial 75] Epoch 6/60, Training Loss: 0.9257, Validation Loss: 0.7413\n",
      "[Trial 65] Epoch 45/60, Training Loss: 0.6262, Validation Loss: 0.5255\n",
      "[Trial 76] Epoch 6/60, Training Loss: 0.9879, Validation Loss: 0.8071\n",
      "[Trial 69] Epoch 36/60, Training Loss: 0.7854, Validation Loss: 0.6480\n",
      "[Trial 62] Epoch 59/60, Training Loss: 0.5863, Validation Loss: 0.5456\n",
      "[Trial 73] Epoch 14/60, Training Loss: 0.8231, Validation Loss: 0.7489\n",
      "[Trial 66] Epoch 42/60, Training Loss: 0.5922, Validation Loss: 0.5337\n",
      "[Trial 72] Epoch 15/60, Training Loss: 1.1176, Validation Loss: 1.3161\n",
      "[Trial 64] Epoch 45/60, Training Loss: 0.6267, Validation Loss: 0.5685\n",
      "[Trial 70] Epoch 35/60, Training Loss: 0.6076, Validation Loss: 0.5037\n",
      "[Trial 63] Epoch 47/60, Training Loss: 0.6044, Validation Loss: 0.5706\n",
      "[Trial 67] Epoch 39/60, Training Loss: 0.6166, Validation Loss: 0.5198\n",
      "[Trial 71] Epoch 31/60, Training Loss: 0.7238, Validation Loss: 0.6916\n",
      "[Trial 68] Epoch 40/60, Training Loss: 0.6723, Validation Loss: 0.6291\n",
      "[Trial 65] Epoch 46/60, Training Loss: 0.6166, Validation Loss: 0.5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:49:03,766] Trial 62 finished with value: 0.49885817418495815 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.023904462672786467, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 69] Epoch 37/60, Training Loss: 0.7726, Validation Loss: 0.6935\n",
      "[Trial 62] Epoch 60/60, Training Loss: 0.5811, Validation Loss: 0.5030\n",
      "[Trial 77] Epoch 2/60, Training Loss: 7.4506, Validation Loss: 4.3817\n",
      "[Trial 66] Epoch 43/60, Training Loss: 0.6038, Validation Loss: 0.5476\n",
      "[Trial 74] Epoch 9/60, Training Loss: 0.8846, Validation Loss: 0.7330\n",
      "[Trial 64] Epoch 46/60, Training Loss: 0.6257, Validation Loss: 0.5395\n",
      "[Trial 70] Epoch 36/60, Training Loss: 0.6084, Validation Loss: 0.5047\n",
      "[Trial 63] Epoch 48/60, Training Loss: 0.6070, Validation Loss: 0.5314\n",
      "[Trial 67] Epoch 40/60, Training Loss: 0.6211, Validation Loss: 0.5202\n",
      "[Trial 71] Epoch 32/60, Training Loss: 0.6538, Validation Loss: 0.5320\n",
      "[Trial 68] Epoch 41/60, Training Loss: 0.6416, Validation Loss: 0.5824\n",
      "[Trial 76] Epoch 7/60, Training Loss: 0.9507, Validation Loss: 0.7144\n",
      "[Trial 75] Epoch 7/60, Training Loss: 0.9005, Validation Loss: 0.7819\n",
      "[Trial 65] Epoch 47/60, Training Loss: 0.6116, Validation Loss: 0.5028\n",
      "[Trial 73] Epoch 15/60, Training Loss: 0.8250, Validation Loss: 0.6830\n",
      "[Trial 72] Epoch 16/60, Training Loss: 1.1684, Validation Loss: 1.7762\n",
      "[Trial 69] Epoch 38/60, Training Loss: 0.7779, Validation Loss: 0.6828\n",
      "[Trial 66] Epoch 44/60, Training Loss: 0.6038, Validation Loss: 0.5424\n",
      "[Trial 70] Epoch 37/60, Training Loss: 0.6035, Validation Loss: 0.5229\n",
      "[Trial 64] Epoch 47/60, Training Loss: 0.6340, Validation Loss: 0.5181\n",
      "[Trial 63] Epoch 49/60, Training Loss: 0.5786, Validation Loss: 0.5528\n",
      "[Trial 67] Epoch 41/60, Training Loss: 0.6324, Validation Loss: 0.5407\n",
      "[Trial 71] Epoch 33/60, Training Loss: 0.6490, Validation Loss: 0.7538\n",
      "[Trial 68] Epoch 42/60, Training Loss: 0.6243, Validation Loss: 0.5472\n",
      "[Trial 65] Epoch 48/60, Training Loss: 0.6177, Validation Loss: 0.5243\n",
      "[Trial 78] Epoch 1/60, Training Loss: 3.2061, Validation Loss: 1.6455\n",
      "[Trial 77] Epoch 3/60, Training Loss: 5.2888, Validation Loss: 3.6270\n",
      "[Trial 69] Epoch 39/60, Training Loss: 0.7750, Validation Loss: 0.6885\n",
      "[Trial 74] Epoch 10/60, Training Loss: 0.8668, Validation Loss: 0.8600\n",
      "[Trial 66] Epoch 45/60, Training Loss: 0.6097, Validation Loss: 0.6966\n",
      "[Trial 70] Epoch 38/60, Training Loss: 0.6025, Validation Loss: 0.5304\n",
      "[Trial 64] Epoch 48/60, Training Loss: 0.6191, Validation Loss: 0.5093\n",
      "[Trial 63] Epoch 50/60, Training Loss: 0.5751, Validation Loss: 0.5335\n",
      "[Trial 67] Epoch 42/60, Training Loss: 0.6247, Validation Loss: 0.5510\n",
      "[Trial 76] Epoch 8/60, Training Loss: 0.9052, Validation Loss: 0.7906\n",
      "[Trial 68] Epoch 43/60, Training Loss: 0.6389, Validation Loss: 0.5752\n",
      "[Trial 73] Epoch 16/60, Training Loss: 0.8026, Validation Loss: 0.6362\n",
      "[Trial 71] Epoch 34/60, Training Loss: 0.6819, Validation Loss: 0.5349\n",
      "[Trial 75] Epoch 8/60, Training Loss: 0.8935, Validation Loss: 0.8204\n",
      "[Trial 65] Epoch 49/60, Training Loss: 0.6138, Validation Loss: 0.5250\n",
      "[Trial 72] Epoch 17/60, Training Loss: 1.1216, Validation Loss: 0.9202\n",
      "[Trial 69] Epoch 40/60, Training Loss: 0.7617, Validation Loss: 0.6378\n",
      "[Trial 66] Epoch 46/60, Training Loss: 0.6053, Validation Loss: 0.5683\n",
      "[Trial 70] Epoch 39/60, Training Loss: 0.6025, Validation Loss: 0.5196\n",
      "[Trial 63] Epoch 51/60, Training Loss: 0.5721, Validation Loss: 0.5254\n",
      "[Trial 64] Epoch 49/60, Training Loss: 0.6226, Validation Loss: 0.5135\n",
      "[Trial 67] Epoch 43/60, Training Loss: 0.6182, Validation Loss: 0.5313\n",
      "[Trial 68] Epoch 44/60, Training Loss: 0.6239, Validation Loss: 0.5239\n",
      "[Trial 78] Epoch 2/60, Training Loss: 1.6263, Validation Loss: 1.0916\n",
      "[Trial 71] Epoch 35/60, Training Loss: 0.6240, Validation Loss: 0.5231\n",
      "[Trial 65] Epoch 50/60, Training Loss: 0.6039, Validation Loss: 0.5063\n",
      "[Trial 77] Epoch 4/60, Training Loss: 4.5597, Validation Loss: 3.1351\n",
      "[Trial 74] Epoch 11/60, Training Loss: 0.8589, Validation Loss: 0.7122\n",
      "[Trial 69] Epoch 41/60, Training Loss: 0.7670, Validation Loss: 0.6556\n",
      "[Trial 70] Epoch 40/60, Training Loss: 0.5932, Validation Loss: 0.4913\n",
      "[Trial 66] Epoch 47/60, Training Loss: 0.5763, Validation Loss: 0.4930\n",
      "[Trial 63] Epoch 52/60, Training Loss: 0.5843, Validation Loss: 0.5134\n",
      "[Trial 73] Epoch 17/60, Training Loss: 0.7934, Validation Loss: 0.6032\n",
      "[Trial 64] Epoch 50/60, Training Loss: 0.6331, Validation Loss: 0.5711\n",
      "[Trial 76] Epoch 9/60, Training Loss: 0.8847, Validation Loss: 0.7168\n",
      "[Trial 68] Epoch 45/60, Training Loss: 0.6244, Validation Loss: 0.5569\n",
      "[Trial 67] Epoch 44/60, Training Loss: 0.6203, Validation Loss: 0.5357\n",
      "[Trial 75] Epoch 9/60, Training Loss: 0.8684, Validation Loss: 0.7366\n",
      "[Trial 72] Epoch 18/60, Training Loss: 1.0525, Validation Loss: 0.9025\n",
      "[Trial 65] Epoch 51/60, Training Loss: 0.6157, Validation Loss: 0.5162\n",
      "[Trial 71] Epoch 36/60, Training Loss: 0.6230, Validation Loss: 0.5102\n",
      "[Trial 69] Epoch 42/60, Training Loss: 0.7592, Validation Loss: 0.6669\n",
      "[Trial 70] Epoch 41/60, Training Loss: 0.5909, Validation Loss: 0.5001\n",
      "[Trial 66] Epoch 48/60, Training Loss: 0.5652, Validation Loss: 0.4903\n",
      "[Trial 63] Epoch 53/60, Training Loss: 0.5638, Validation Loss: 0.5217\n",
      "[Trial 64] Epoch 51/60, Training Loss: 0.6431, Validation Loss: 0.5399\n",
      "[Trial 68] Epoch 46/60, Training Loss: 0.6395, Validation Loss: 0.5713\n",
      "[Trial 78] Epoch 3/60, Training Loss: 1.2736, Validation Loss: 0.9675\n",
      "[Trial 67] Epoch 45/60, Training Loss: 0.5912, Validation Loss: 0.5012\n",
      "[Trial 74] Epoch 12/60, Training Loss: 0.8405, Validation Loss: 0.6708\n",
      "[Trial 65] Epoch 52/60, Training Loss: 0.6157, Validation Loss: 0.5082\n",
      "[Trial 77] Epoch 5/60, Training Loss: 4.0377, Validation Loss: 2.7756\n",
      "[Trial 71] Epoch 37/60, Training Loss: 0.6334, Validation Loss: 0.5433\n",
      "[Trial 70] Epoch 42/60, Training Loss: 0.5872, Validation Loss: 0.5010\n",
      "[Trial 73] Epoch 18/60, Training Loss: 0.7914, Validation Loss: 0.6486\n",
      "[Trial 69] Epoch 43/60, Training Loss: 0.7652, Validation Loss: 0.7288\n",
      "[Trial 76] Epoch 10/60, Training Loss: 0.8394, Validation Loss: 0.6686\n",
      "[Trial 66] Epoch 49/60, Training Loss: 0.5750, Validation Loss: 0.5083\n",
      "[Trial 63] Epoch 54/60, Training Loss: 0.5654, Validation Loss: 0.5105\n",
      "[Trial 64] Epoch 52/60, Training Loss: 0.6235, Validation Loss: 0.5398\n",
      "[Trial 68] Epoch 47/60, Training Loss: 0.6406, Validation Loss: 0.5718\n",
      "[Trial 72] Epoch 19/60, Training Loss: 1.0862, Validation Loss: 0.9363\n",
      "[Trial 75] Epoch 10/60, Training Loss: 0.8327, Validation Loss: 0.7853\n",
      "[Trial 67] Epoch 46/60, Training Loss: 0.5924, Validation Loss: 0.5104\n",
      "[Trial 65] Epoch 53/60, Training Loss: 0.5996, Validation Loss: 0.5019\n",
      "[Trial 71] Epoch 38/60, Training Loss: 0.6265, Validation Loss: 0.5412\n",
      "[Trial 70] Epoch 43/60, Training Loss: 0.5871, Validation Loss: 0.4943\n",
      "[Trial 69] Epoch 44/60, Training Loss: 0.7557, Validation Loss: 0.6256\n",
      "[Trial 63] Epoch 55/60, Training Loss: 0.5671, Validation Loss: 0.5273\n",
      "[Trial 66] Epoch 50/60, Training Loss: 0.5658, Validation Loss: 0.4765\n",
      "[Trial 78] Epoch 4/60, Training Loss: 1.1356, Validation Loss: 0.8336\n",
      "[Trial 68] Epoch 48/60, Training Loss: 0.6277, Validation Loss: 0.5612\n",
      "[Trial 64] Epoch 53/60, Training Loss: 0.6153, Validation Loss: 0.5290\n",
      "[Trial 74] Epoch 13/60, Training Loss: 0.8238, Validation Loss: 0.6990\n",
      "[Trial 67] Epoch 47/60, Training Loss: 0.5907, Validation Loss: 0.5295\n",
      "[Trial 77] Epoch 6/60, Training Loss: 3.6411, Validation Loss: 2.6162\n",
      "[Trial 65] Epoch 54/60, Training Loss: 0.6092, Validation Loss: 0.5109\n",
      "[Trial 73] Epoch 19/60, Training Loss: 0.7716, Validation Loss: 0.6629\n",
      "[Trial 71] Epoch 39/60, Training Loss: 0.6198, Validation Loss: 0.5134\n",
      "[Trial 76] Epoch 11/60, Training Loss: 0.8443, Validation Loss: 0.7942\n",
      "[Trial 70] Epoch 44/60, Training Loss: 0.5861, Validation Loss: 0.4924\n",
      "[Trial 69] Epoch 45/60, Training Loss: 0.7642, Validation Loss: 0.7289\n",
      "[Trial 63] Epoch 56/60, Training Loss: 0.5617, Validation Loss: 0.4938\n",
      "[Trial 72] Epoch 20/60, Training Loss: 1.0567, Validation Loss: 1.1395\n",
      "[Trial 66] Epoch 51/60, Training Loss: 0.5607, Validation Loss: 0.4895\n",
      "[Trial 68] Epoch 49/60, Training Loss: 0.6317, Validation Loss: 0.5882\n",
      "[Trial 64] Epoch 54/60, Training Loss: 0.6042, Validation Loss: 0.5039\n",
      "[Trial 75] Epoch 11/60, Training Loss: 0.8250, Validation Loss: 0.6479\n",
      "[Trial 67] Epoch 48/60, Training Loss: 0.5940, Validation Loss: 0.5262\n",
      "[Trial 65] Epoch 55/60, Training Loss: 0.5980, Validation Loss: 0.5041\n",
      "[Trial 71] Epoch 40/60, Training Loss: 0.6120, Validation Loss: 0.5156\n",
      "[Trial 70] Epoch 45/60, Training Loss: 0.5932, Validation Loss: 0.4861\n",
      "[Trial 63] Epoch 57/60, Training Loss: 0.5686, Validation Loss: 0.5635\n",
      "[Trial 78] Epoch 5/60, Training Loss: 1.0271, Validation Loss: 0.7444\n",
      "[Trial 69] Epoch 46/60, Training Loss: 0.7661, Validation Loss: 0.6002\n",
      "[Trial 74] Epoch 14/60, Training Loss: 0.8164, Validation Loss: 0.6368\n",
      "[Trial 66] Epoch 52/60, Training Loss: 0.5658, Validation Loss: 0.5165\n",
      "[Trial 68] Epoch 50/60, Training Loss: 0.6152, Validation Loss: 0.5442\n",
      "[Trial 64] Epoch 55/60, Training Loss: 0.5987, Validation Loss: 0.5022\n",
      "[Trial 77] Epoch 7/60, Training Loss: 3.3744, Validation Loss: 2.3705\n",
      "[Trial 67] Epoch 49/60, Training Loss: 0.5968, Validation Loss: 0.5361\n",
      "[Trial 65] Epoch 56/60, Training Loss: 0.6119, Validation Loss: 0.5019\n",
      "[Trial 73] Epoch 20/60, Training Loss: 0.7852, Validation Loss: 0.6905\n",
      "[Trial 76] Epoch 12/60, Training Loss: 0.8539, Validation Loss: 0.8471\n",
      "[Trial 70] Epoch 46/60, Training Loss: 0.5789, Validation Loss: 0.4911\n",
      "[Trial 71] Epoch 41/60, Training Loss: 0.6147, Validation Loss: 0.5504\n",
      "[Trial 72] Epoch 21/60, Training Loss: 1.0586, Validation Loss: 1.1469\n",
      "[Trial 63] Epoch 58/60, Training Loss: 0.5761, Validation Loss: 0.5298\n",
      "[Trial 69] Epoch 47/60, Training Loss: 0.7615, Validation Loss: 0.6368\n",
      "[Trial 68] Epoch 51/60, Training Loss: 0.6097, Validation Loss: 0.5467\n",
      "[Trial 66] Epoch 53/60, Training Loss: 0.5713, Validation Loss: 0.5353\n",
      "[Trial 75] Epoch 12/60, Training Loss: 0.8247, Validation Loss: 0.6494\n",
      "[Trial 64] Epoch 56/60, Training Loss: 0.6001, Validation Loss: 0.4970\n",
      "[Trial 67] Epoch 50/60, Training Loss: 0.6245, Validation Loss: 0.5927\n",
      "[Trial 65] Epoch 57/60, Training Loss: 0.5991, Validation Loss: 0.4978\n",
      "[Trial 70] Epoch 47/60, Training Loss: 0.5786, Validation Loss: 0.4776\n",
      "[Trial 78] Epoch 6/60, Training Loss: 0.9744, Validation Loss: 0.7443\n",
      "[Trial 74] Epoch 15/60, Training Loss: 0.8138, Validation Loss: 0.7370\n",
      "[Trial 71] Epoch 42/60, Training Loss: 0.6374, Validation Loss: 0.6054\n",
      "[Trial 63] Epoch 59/60, Training Loss: 0.5838, Validation Loss: 0.5256\n",
      "[Trial 68] Epoch 52/60, Training Loss: 0.6146, Validation Loss: 0.5420\n",
      "[Trial 69] Epoch 48/60, Training Loss: 0.7638, Validation Loss: 0.6849\n",
      "[Trial 77] Epoch 8/60, Training Loss: 3.1326, Validation Loss: 2.2277\n",
      "[Trial 66] Epoch 54/60, Training Loss: 0.5835, Validation Loss: 0.4960\n",
      "[Trial 73] Epoch 21/60, Training Loss: 0.7724, Validation Loss: 0.5949\n",
      "[Trial 64] Epoch 57/60, Training Loss: 0.5957, Validation Loss: 0.5173\n",
      "[Trial 65] Epoch 58/60, Training Loss: 0.5989, Validation Loss: 0.5148\n",
      "[Trial 67] Epoch 51/60, Training Loss: 0.5833, Validation Loss: 0.4998\n",
      "[Trial 76] Epoch 13/60, Training Loss: 0.8233, Validation Loss: 0.7170\n",
      "[Trial 70] Epoch 48/60, Training Loss: 0.5824, Validation Loss: 0.4872\n",
      "[Trial 72] Epoch 22/60, Training Loss: 1.1163, Validation Loss: 0.8426\n",
      "[Trial 71] Epoch 43/60, Training Loss: 0.6137, Validation Loss: 0.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:59:46,589] Trial 63 finished with value: 0.49380797147750854 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0237694627827148, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 63] Epoch 60/60, Training Loss: 0.5787, Validation Loss: 0.5071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 04:59:51,828] Trial 68 finished with value: 0.5238582462072372 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.020941130005150882, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 68] Epoch 53/60, Training Loss: 0.6099, Validation Loss: 0.5312\n",
      "[Trial 68] Early stopping after 53 epochs.\n",
      "[Trial 75] Epoch 13/60, Training Loss: 0.7949, Validation Loss: 0.6760\n",
      "[Trial 69] Epoch 49/60, Training Loss: 0.7428, Validation Loss: 0.6069\n",
      "[Trial 66] Epoch 55/60, Training Loss: 0.5716, Validation Loss: 0.5553\n",
      "[Trial 64] Epoch 58/60, Training Loss: 0.6078, Validation Loss: 0.5148\n",
      "[Trial 65] Epoch 59/60, Training Loss: 0.5948, Validation Loss: 0.5025\n",
      "[Trial 67] Epoch 52/60, Training Loss: 0.5721, Validation Loss: 0.5033\n",
      "[Trial 70] Epoch 49/60, Training Loss: 0.5806, Validation Loss: 0.4866\n",
      "[Trial 74] Epoch 16/60, Training Loss: 0.8151, Validation Loss: 0.6584\n",
      "[Trial 78] Epoch 7/60, Training Loss: 0.9518, Validation Loss: 0.7487\n",
      "[Trial 79] Epoch 1/60, Training Loss: 3.5852, Validation Loss: 1.8128\n",
      "[Trial 71] Epoch 44/60, Training Loss: 0.5920, Validation Loss: 0.4887\n",
      "[Trial 73] Epoch 22/60, Training Loss: 0.7731, Validation Loss: 0.5932\n",
      "[Trial 77] Epoch 9/60, Training Loss: 2.9257, Validation Loss: 1.9768\n",
      "[Trial 69] Epoch 50/60, Training Loss: 0.7374, Validation Loss: 0.5856\n",
      "[Trial 66] Epoch 56/60, Training Loss: 0.5598, Validation Loss: 0.4793\n",
      "[Trial 64] Epoch 59/60, Training Loss: 0.6014, Validation Loss: 0.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:01:00,664] Trial 65 finished with value: 0.4977641845742861 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.01973224005278925, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 65] Epoch 60/60, Training Loss: 0.5978, Validation Loss: 0.5029\n",
      "[Trial 76] Epoch 14/60, Training Loss: 0.7265, Validation Loss: 0.5814\n",
      "[Trial 67] Epoch 53/60, Training Loss: 0.5746, Validation Loss: 0.4895\n",
      "[Trial 72] Epoch 23/60, Training Loss: 1.0136, Validation Loss: 0.9408\n",
      "[Trial 70] Epoch 50/60, Training Loss: 0.5931, Validation Loss: 0.4994\n",
      "[Trial 80] Epoch 1/60, Training Loss: 3.1004, Validation Loss: 1.5387\n",
      "[Trial 79] Epoch 2/60, Training Loss: 1.7827, Validation Loss: 1.7709\n",
      "[Trial 71] Epoch 45/60, Training Loss: 0.5818, Validation Loss: 0.4886\n",
      "[Trial 75] Epoch 14/60, Training Loss: 0.7952, Validation Loss: 0.6627\n",
      "[Trial 69] Epoch 51/60, Training Loss: 0.7603, Validation Loss: 0.6518\n",
      "[Trial 66] Epoch 57/60, Training Loss: 0.5511, Validation Loss: 0.4802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:01:52,507] Trial 64 finished with value: 0.4969811553756396 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.023715623937006963, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 64] Epoch 60/60, Training Loss: 0.6090, Validation Loss: 0.4977\n",
      "[Trial 67] Epoch 54/60, Training Loss: 0.5720, Validation Loss: 0.5015\n",
      "[Trial 74] Epoch 17/60, Training Loss: 0.7830, Validation Loss: 0.6844\n",
      "[Trial 70] Epoch 51/60, Training Loss: 0.5844, Validation Loss: 0.4995\n",
      "[Trial 78] Epoch 8/60, Training Loss: 0.9064, Validation Loss: 0.7555\n",
      "[Trial 73] Epoch 23/60, Training Loss: 0.7480, Validation Loss: 0.5912\n",
      "[Trial 77] Epoch 10/60, Training Loss: 2.7749, Validation Loss: 1.9289\n",
      "[Trial 79] Epoch 3/60, Training Loss: 1.4278, Validation Loss: 1.0490\n",
      "[Trial 71] Epoch 46/60, Training Loss: 0.5945, Validation Loss: 0.5260\n",
      "[Trial 76] Epoch 15/60, Training Loss: 0.7124, Validation Loss: 0.6119\n",
      "[Trial 81] Epoch 1/60, Training Loss: 5.9011, Validation Loss: 1.9816\n",
      "[Trial 66] Epoch 58/60, Training Loss: 0.5600, Validation Loss: 0.4768\n",
      "[Trial 69] Epoch 52/60, Training Loss: 0.7539, Validation Loss: 0.5901\n",
      "[Trial 72] Epoch 24/60, Training Loss: 0.9949, Validation Loss: 0.9604\n",
      "[Trial 67] Epoch 55/60, Training Loss: 0.5698, Validation Loss: 0.4848\n",
      "[Trial 70] Epoch 52/60, Training Loss: 0.5862, Validation Loss: 0.4920\n",
      "[Trial 80] Epoch 2/60, Training Loss: 1.6705, Validation Loss: 1.6610\n",
      "[Trial 75] Epoch 15/60, Training Loss: 0.7696, Validation Loss: 0.6702\n",
      "[Trial 79] Epoch 4/60, Training Loss: 1.1864, Validation Loss: 0.9934\n",
      "[Trial 71] Epoch 47/60, Training Loss: 0.6032, Validation Loss: 0.5025\n",
      "[Trial 82] Epoch 1/60, Training Loss: 2.9960, Validation Loss: 1.6572\n",
      "[Trial 74] Epoch 18/60, Training Loss: 0.7942, Validation Loss: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:03:41,604] Trial 66 finished with value: 0.4765076021353404 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.01780933586347688, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 66] Epoch 59/60, Training Loss: 0.5518, Validation Loss: 0.4928\n",
      "[Trial 66] Early stopping after 59 epochs.\n",
      "[Trial 69] Epoch 53/60, Training Loss: 0.7290, Validation Loss: 0.5914\n",
      "[Trial 78] Epoch 9/60, Training Loss: 0.7912, Validation Loss: 0.6281\n",
      "[Trial 70] Epoch 53/60, Training Loss: 0.5836, Validation Loss: 0.4862\n",
      "[Trial 67] Epoch 56/60, Training Loss: 0.5695, Validation Loss: 0.4990\n",
      "[Trial 73] Epoch 24/60, Training Loss: 0.7470, Validation Loss: 0.6369\n",
      "[Trial 77] Epoch 11/60, Training Loss: 2.6419, Validation Loss: 1.9348\n",
      "[Trial 79] Epoch 5/60, Training Loss: 1.1323, Validation Loss: 1.0060\n",
      "[Trial 76] Epoch 16/60, Training Loss: 0.7241, Validation Loss: 0.6177\n",
      "[Trial 81] Epoch 2/60, Training Loss: 2.0811, Validation Loss: 1.5254\n",
      "[Trial 71] Epoch 48/60, Training Loss: 0.5867, Validation Loss: 0.4846\n",
      "[Trial 72] Epoch 25/60, Training Loss: 0.9943, Validation Loss: 1.0018\n",
      "[Trial 69] Epoch 54/60, Training Loss: 0.7520, Validation Loss: 0.7818\n",
      "[Trial 70] Epoch 54/60, Training Loss: 0.5744, Validation Loss: 0.4820\n",
      "[Trial 67] Epoch 57/60, Training Loss: 0.5665, Validation Loss: 0.4985\n",
      "[Trial 80] Epoch 3/60, Training Loss: 1.2785, Validation Loss: 0.9008\n",
      "[Trial 75] Epoch 16/60, Training Loss: 0.7586, Validation Loss: 0.6810\n",
      "[Trial 79] Epoch 6/60, Training Loss: 1.0280, Validation Loss: 0.9799\n",
      "[Trial 74] Epoch 19/60, Training Loss: 0.7669, Validation Loss: 0.6496\n",
      "[Trial 82] Epoch 2/60, Training Loss: 1.5716, Validation Loss: 1.0259\n",
      "[Trial 83] Epoch 1/60, Training Loss: 3.1048, Validation Loss: 2.1966\n",
      "[Trial 71] Epoch 49/60, Training Loss: 0.5830, Validation Loss: 0.5178\n",
      "[Trial 78] Epoch 10/60, Training Loss: 0.7685, Validation Loss: 0.6278\n",
      "[Trial 73] Epoch 25/60, Training Loss: 0.7442, Validation Loss: 0.6595\n",
      "[Trial 69] Epoch 55/60, Training Loss: 0.7388, Validation Loss: 0.5937\n",
      "[Trial 70] Epoch 55/60, Training Loss: 0.5780, Validation Loss: 0.4776\n",
      "[Trial 67] Epoch 58/60, Training Loss: 0.5642, Validation Loss: 0.4917\n",
      "[Trial 77] Epoch 12/60, Training Loss: 2.5417, Validation Loss: 1.8118\n",
      "[Trial 76] Epoch 17/60, Training Loss: 0.7186, Validation Loss: 0.5947\n",
      "[Trial 81] Epoch 3/60, Training Loss: 1.5275, Validation Loss: 1.4509\n",
      "[Trial 79] Epoch 7/60, Training Loss: 1.0034, Validation Loss: 0.9287\n",
      "[Trial 72] Epoch 26/60, Training Loss: 1.0007, Validation Loss: 0.8940\n",
      "[Trial 71] Epoch 50/60, Training Loss: 0.5813, Validation Loss: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:06:29,030] Trial 70 finished with value: 0.47763001223405205 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.021540311268966553, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 70] Epoch 56/60, Training Loss: 0.5661, Validation Loss: 0.4863\n",
      "[Trial 70] Early stopping after 56 epochs.\n",
      "[Trial 69] Epoch 56/60, Training Loss: 0.7663, Validation Loss: 0.6832\n",
      "[Trial 67] Epoch 59/60, Training Loss: 0.5649, Validation Loss: 0.5064\n",
      "[Trial 80] Epoch 4/60, Training Loss: 1.1028, Validation Loss: 0.8663\n",
      "[Trial 75] Epoch 17/60, Training Loss: 0.7480, Validation Loss: 0.7737\n",
      "[Trial 74] Epoch 20/60, Training Loss: 0.7908, Validation Loss: 0.7643\n",
      "[Trial 82] Epoch 3/60, Training Loss: 1.2531, Validation Loss: 0.8956\n",
      "[Trial 79] Epoch 8/60, Training Loss: 0.9870, Validation Loss: 0.7458\n",
      "[Trial 73] Epoch 26/60, Training Loss: 0.7481, Validation Loss: 0.5780\n",
      "[Trial 78] Epoch 11/60, Training Loss: 0.7785, Validation Loss: 0.6610\n",
      "[Trial 83] Epoch 2/60, Training Loss: 1.6315, Validation Loss: 1.4104\n",
      "[Trial 71] Epoch 51/60, Training Loss: 0.5804, Validation Loss: 0.4783\n",
      "[Trial 69] Epoch 57/60, Training Loss: 0.6930, Validation Loss: 0.5819\n",
      "[Trial 77] Epoch 13/60, Training Loss: 2.4505, Validation Loss: 1.7729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:07:35,875] Trial 67 finished with value: 0.4847136969367663 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.0157651366964584, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 67] Epoch 60/60, Training Loss: 0.5661, Validation Loss: 0.4847\n",
      "[Trial 76] Epoch 18/60, Training Loss: 0.6656, Validation Loss: 0.5741\n",
      "[Trial 81] Epoch 4/60, Training Loss: 1.3016, Validation Loss: 1.0471\n",
      "[Trial 72] Epoch 27/60, Training Loss: 0.9833, Validation Loss: 0.8311\n",
      "[Trial 79] Epoch 9/60, Training Loss: 0.8798, Validation Loss: 0.7856\n",
      "[Trial 84] Epoch 1/60, Training Loss: 3.1592, Validation Loss: 2.6898\n",
      "[Trial 80] Epoch 5/60, Training Loss: 1.0162, Validation Loss: 0.8511\n",
      "[Trial 71] Epoch 52/60, Training Loss: 0.5751, Validation Loss: 0.5090\n",
      "[Trial 69] Epoch 58/60, Training Loss: 0.6936, Validation Loss: 0.5747\n",
      "[Trial 74] Epoch 21/60, Training Loss: 0.7337, Validation Loss: 0.5933\n",
      "[Trial 75] Epoch 18/60, Training Loss: 0.6984, Validation Loss: 0.6165\n",
      "[Trial 73] Epoch 27/60, Training Loss: 0.7283, Validation Loss: 0.5919\n",
      "[Trial 82] Epoch 4/60, Training Loss: 1.1019, Validation Loss: 0.8497\n",
      "[Trial 78] Epoch 12/60, Training Loss: 0.7671, Validation Loss: 0.6617\n",
      "[Trial 79] Epoch 10/60, Training Loss: 0.8695, Validation Loss: 0.7694\n",
      "[Trial 83] Epoch 3/60, Training Loss: 1.3192, Validation Loss: 1.2840\n",
      "[Trial 77] Epoch 14/60, Training Loss: 2.3660, Validation Loss: 1.7032\n",
      "[Trial 85] Epoch 1/60, Training Loss: 3.1189, Validation Loss: 1.7959\n",
      "[Trial 69] Epoch 59/60, Training Loss: 0.6907, Validation Loss: 0.5648\n",
      "[Trial 71] Epoch 53/60, Training Loss: 0.5788, Validation Loss: 0.4919\n",
      "[Trial 76] Epoch 19/60, Training Loss: 0.6666, Validation Loss: 0.5649\n",
      "[Trial 81] Epoch 5/60, Training Loss: 1.2117, Validation Loss: 0.8650\n",
      "[Trial 72] Epoch 28/60, Training Loss: 0.9757, Validation Loss: 0.9000\n",
      "[Trial 84] Epoch 2/60, Training Loss: 1.7024, Validation Loss: 1.1040\n",
      "[Trial 79] Epoch 11/60, Training Loss: 0.8551, Validation Loss: 1.0390\n",
      "[Trial 80] Epoch 6/60, Training Loss: 0.9703, Validation Loss: 0.7890\n",
      "[Trial 74] Epoch 22/60, Training Loss: 0.7032, Validation Loss: 0.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:10:18,272] Trial 69 finished with value: 0.564839631319046 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.02422116860763843, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 69] Epoch 60/60, Training Loss: 0.6820, Validation Loss: 0.5700\n",
      "[Trial 71] Epoch 54/60, Training Loss: 0.5825, Validation Loss: 0.4905\n",
      "[Trial 73] Epoch 28/60, Training Loss: 0.7488, Validation Loss: 0.6011\n",
      "[Trial 75] Epoch 19/60, Training Loss: 0.6803, Validation Loss: 0.5945\n",
      "[Trial 78] Epoch 13/60, Training Loss: 0.7779, Validation Loss: 0.5897\n",
      "[Trial 82] Epoch 5/60, Training Loss: 1.0174, Validation Loss: 0.8545\n",
      "[Trial 83] Epoch 4/60, Training Loss: 1.1247, Validation Loss: 0.7850\n",
      "[Trial 79] Epoch 12/60, Training Loss: 0.7495, Validation Loss: 0.6019\n",
      "[Trial 77] Epoch 15/60, Training Loss: 2.2858, Validation Loss: 1.6846\n",
      "[Trial 85] Epoch 2/60, Training Loss: 1.6221, Validation Loss: 1.0797\n",
      "[Trial 76] Epoch 20/60, Training Loss: 0.6575, Validation Loss: 0.5606\n",
      "[Trial 71] Epoch 55/60, Training Loss: 0.5829, Validation Loss: 0.4999\n",
      "[Trial 81] Epoch 6/60, Training Loss: 1.1322, Validation Loss: 0.8652\n",
      "[Trial 72] Epoch 29/60, Training Loss: 0.9874, Validation Loss: 0.7981\n",
      "[Trial 84] Epoch 3/60, Training Loss: 1.3442, Validation Loss: 0.9302\n",
      "[Trial 80] Epoch 7/60, Training Loss: 0.9189, Validation Loss: 0.8370\n",
      "[Trial 79] Epoch 13/60, Training Loss: 0.7350, Validation Loss: 0.6538\n",
      "[Trial 74] Epoch 23/60, Training Loss: 0.7061, Validation Loss: 0.6341\n",
      "[Trial 73] Epoch 29/60, Training Loss: 0.7369, Validation Loss: 0.5682\n",
      "[Trial 86] Epoch 1/60, Training Loss: 3.2294, Validation Loss: 1.5105\n",
      "[Trial 75] Epoch 20/60, Training Loss: 0.6759, Validation Loss: 0.6318\n",
      "[Trial 71] Epoch 56/60, Training Loss: 0.5768, Validation Loss: 0.5113\n",
      "[Trial 78] Epoch 14/60, Training Loss: 0.7505, Validation Loss: 0.6137\n",
      "[Trial 82] Epoch 6/60, Training Loss: 0.9505, Validation Loss: 0.7918\n",
      "[Trial 83] Epoch 5/60, Training Loss: 1.0032, Validation Loss: 0.7854\n",
      "[Trial 77] Epoch 16/60, Training Loss: 2.2374, Validation Loss: 1.6859\n",
      "[Trial 85] Epoch 3/60, Training Loss: 1.3363, Validation Loss: 0.9711\n",
      "[Trial 79] Epoch 14/60, Training Loss: 0.7444, Validation Loss: 0.6429\n",
      "[Trial 76] Epoch 21/60, Training Loss: 0.6530, Validation Loss: 0.5819\n",
      "[Trial 72] Epoch 30/60, Training Loss: 0.9520, Validation Loss: 1.1965\n",
      "[Trial 81] Epoch 7/60, Training Loss: 1.0517, Validation Loss: 0.8268\n",
      "[Trial 71] Epoch 57/60, Training Loss: 0.5800, Validation Loss: 0.4941\n",
      "[Trial 84] Epoch 4/60, Training Loss: 1.1538, Validation Loss: 0.9157\n",
      "[Trial 80] Epoch 8/60, Training Loss: 0.8901, Validation Loss: 0.6997\n",
      "[Trial 74] Epoch 24/60, Training Loss: 0.7064, Validation Loss: 0.6156\n",
      "[Trial 73] Epoch 30/60, Training Loss: 0.7246, Validation Loss: 0.6698\n",
      "[Trial 79] Epoch 15/60, Training Loss: 0.7362, Validation Loss: 0.7034\n",
      "[Trial 86] Epoch 2/60, Training Loss: 1.6908, Validation Loss: 1.3747\n",
      "[Trial 75] Epoch 21/60, Training Loss: 0.6772, Validation Loss: 0.6638\n",
      "[Trial 78] Epoch 15/60, Training Loss: 0.7565, Validation Loss: 1.0732\n",
      "[Trial 82] Epoch 7/60, Training Loss: 0.9066, Validation Loss: 0.7974\n",
      "[Trial 71] Epoch 58/60, Training Loss: 0.5653, Validation Loss: 0.4683\n",
      "[Trial 83] Epoch 6/60, Training Loss: 0.9633, Validation Loss: 0.8156\n",
      "[Trial 77] Epoch 17/60, Training Loss: 2.1881, Validation Loss: 1.5761\n",
      "[Trial 85] Epoch 4/60, Training Loss: 1.1285, Validation Loss: 0.8283\n",
      "[Trial 76] Epoch 22/60, Training Loss: 0.6500, Validation Loss: 0.5449\n",
      "[Trial 79] Epoch 16/60, Training Loss: 0.6866, Validation Loss: 0.5756\n",
      "[Trial 72] Epoch 31/60, Training Loss: 0.9683, Validation Loss: 0.7628\n",
      "[Trial 81] Epoch 8/60, Training Loss: 1.0216, Validation Loss: 0.8703\n",
      "[Trial 84] Epoch 5/60, Training Loss: 1.0740, Validation Loss: 0.8582\n",
      "[Trial 71] Epoch 59/60, Training Loss: 0.5599, Validation Loss: 0.4888\n",
      "[Trial 74] Epoch 25/60, Training Loss: 0.7013, Validation Loss: 0.5683\n",
      "[Trial 73] Epoch 31/60, Training Loss: 0.7176, Validation Loss: 0.6225\n",
      "[Trial 80] Epoch 9/60, Training Loss: 0.8501, Validation Loss: 0.6592\n",
      "[Trial 86] Epoch 3/60, Training Loss: 1.3790, Validation Loss: 0.8827\n",
      "[Trial 79] Epoch 17/60, Training Loss: 0.6757, Validation Loss: 0.5788\n",
      "[Trial 75] Epoch 22/60, Training Loss: 0.6738, Validation Loss: 0.5878\n",
      "[Trial 78] Epoch 16/60, Training Loss: 0.7669, Validation Loss: 0.6231\n",
      "[Trial 82] Epoch 8/60, Training Loss: 0.8972, Validation Loss: 1.0528\n",
      "[Trial 77] Epoch 18/60, Training Loss: 2.1644, Validation Loss: 1.5733\n",
      "[Trial 85] Epoch 5/60, Training Loss: 1.0677, Validation Loss: 0.7520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:16:04,873] Trial 71 finished with value: 0.46834565649429954 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.003498339659434774, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 71] Epoch 60/60, Training Loss: 0.5672, Validation Loss: 0.5018\n",
      "[Trial 83] Epoch 7/60, Training Loss: 0.9416, Validation Loss: 0.6927\n",
      "[Trial 76] Epoch 23/60, Training Loss: 0.6488, Validation Loss: 0.5606\n",
      "[Trial 72] Epoch 32/60, Training Loss: 0.9764, Validation Loss: 0.8633\n",
      "[Trial 81] Epoch 9/60, Training Loss: 1.0217, Validation Loss: 0.8239\n",
      "[Trial 79] Epoch 18/60, Training Loss: 0.6714, Validation Loss: 0.5887\n",
      "[Trial 84] Epoch 6/60, Training Loss: 0.9959, Validation Loss: 0.8624\n",
      "[Trial 74] Epoch 26/60, Training Loss: 0.6959, Validation Loss: 0.5805\n",
      "[Trial 73] Epoch 32/60, Training Loss: 0.7215, Validation Loss: 0.6617\n",
      "[Trial 80] Epoch 10/60, Training Loss: 0.8301, Validation Loss: 0.6727\n",
      "[Trial 86] Epoch 4/60, Training Loss: 1.1616, Validation Loss: 0.8315\n",
      "[Trial 78] Epoch 17/60, Training Loss: 0.6793, Validation Loss: 0.5674\n",
      "[Trial 79] Epoch 19/60, Training Loss: 0.6629, Validation Loss: 0.5491\n",
      "[Trial 75] Epoch 23/60, Training Loss: 0.6636, Validation Loss: 0.5655\n",
      "[Trial 82] Epoch 9/60, Training Loss: 0.8745, Validation Loss: 0.6705\n",
      "[Trial 77] Epoch 19/60, Training Loss: 2.1276, Validation Loss: 1.5471\n",
      "[Trial 85] Epoch 6/60, Training Loss: 0.9493, Validation Loss: 0.8418\n",
      "[Trial 87] Epoch 1/60, Training Loss: 2.7759, Validation Loss: 1.3660\n",
      "[Trial 76] Epoch 24/60, Training Loss: 0.6506, Validation Loss: 0.5663\n",
      "[Trial 83] Epoch 8/60, Training Loss: 0.8760, Validation Loss: 0.7494\n",
      "[Trial 72] Epoch 33/60, Training Loss: 0.9585, Validation Loss: 1.0926\n",
      "[Trial 81] Epoch 10/60, Training Loss: 0.9510, Validation Loss: 0.8733\n",
      "[Trial 79] Epoch 20/60, Training Loss: 0.6674, Validation Loss: 0.5608\n",
      "[Trial 84] Epoch 7/60, Training Loss: 0.9506, Validation Loss: 0.7125\n",
      "[Trial 73] Epoch 33/60, Training Loss: 0.7340, Validation Loss: 0.6573\n",
      "[Trial 74] Epoch 27/60, Training Loss: 0.7023, Validation Loss: 0.5947\n",
      "[Trial 80] Epoch 11/60, Training Loss: 0.8158, Validation Loss: 0.7828\n",
      "[Trial 86] Epoch 5/60, Training Loss: 1.0881, Validation Loss: 0.7336\n",
      "[Trial 78] Epoch 18/60, Training Loss: 0.6712, Validation Loss: 0.5353\n",
      "[Trial 75] Epoch 24/60, Training Loss: 0.6671, Validation Loss: 0.6083\n",
      "[Trial 79] Epoch 21/60, Training Loss: 0.6629, Validation Loss: 0.5668\n",
      "[Trial 82] Epoch 10/60, Training Loss: 0.8381, Validation Loss: 0.7354\n",
      "[Trial 77] Epoch 20/60, Training Loss: 2.0804, Validation Loss: 1.5497\n",
      "[Trial 85] Epoch 7/60, Training Loss: 0.9547, Validation Loss: 0.7219\n",
      "[Trial 76] Epoch 25/60, Training Loss: 0.6406, Validation Loss: 0.5553\n",
      "[Trial 87] Epoch 2/60, Training Loss: 1.5276, Validation Loss: 1.1990\n",
      "[Trial 83] Epoch 9/60, Training Loss: 0.8559, Validation Loss: 0.7335\n",
      "[Trial 72] Epoch 34/60, Training Loss: 0.9784, Validation Loss: 1.0678\n",
      "[Trial 81] Epoch 11/60, Training Loss: 0.9557, Validation Loss: 0.9107\n",
      "[Trial 73] Epoch 34/60, Training Loss: 0.7333, Validation Loss: 0.5971\n",
      "[Trial 84] Epoch 8/60, Training Loss: 0.9093, Validation Loss: 0.7967\n",
      "[Trial 74] Epoch 28/60, Training Loss: 0.6953, Validation Loss: 0.5754\n",
      "[Trial 79] Epoch 22/60, Training Loss: 0.6686, Validation Loss: 0.5818\n",
      "[Trial 80] Epoch 12/60, Training Loss: 0.7994, Validation Loss: 0.7819\n",
      "[Trial 86] Epoch 6/60, Training Loss: 1.0072, Validation Loss: 0.7972\n",
      "[Trial 78] Epoch 19/60, Training Loss: 0.6732, Validation Loss: 0.5859\n",
      "[Trial 75] Epoch 25/60, Training Loss: 0.6595, Validation Loss: 0.5916\n",
      "[Trial 79] Epoch 23/60, Training Loss: 0.6397, Validation Loss: 0.5350\n",
      "[Trial 82] Epoch 11/60, Training Loss: 0.8253, Validation Loss: 0.6179\n",
      "[Trial 85] Epoch 8/60, Training Loss: 0.9110, Validation Loss: 0.7370\n",
      "[Trial 77] Epoch 21/60, Training Loss: 2.0216, Validation Loss: 1.4636\n",
      "[Trial 76] Epoch 26/60, Training Loss: 0.6275, Validation Loss: 0.5470\n",
      "[Trial 87] Epoch 3/60, Training Loss: 1.2213, Validation Loss: 0.8626\n",
      "[Trial 72] Epoch 35/60, Training Loss: 0.9287, Validation Loss: 0.7792\n",
      "[Trial 83] Epoch 10/60, Training Loss: 0.8294, Validation Loss: 0.6731\n",
      "[Trial 73] Epoch 35/60, Training Loss: 0.7206, Validation Loss: 0.6316\n",
      "[Trial 81] Epoch 12/60, Training Loss: 0.9555, Validation Loss: 0.9052\n",
      "[Trial 74] Epoch 29/60, Training Loss: 0.6928, Validation Loss: 0.6136\n",
      "[Trial 84] Epoch 9/60, Training Loss: 0.8646, Validation Loss: 0.7503\n",
      "[Trial 80] Epoch 13/60, Training Loss: 0.7149, Validation Loss: 0.5951\n",
      "[Trial 79] Epoch 24/60, Training Loss: 0.6291, Validation Loss: 0.5299\n",
      "[Trial 86] Epoch 7/60, Training Loss: 0.9445, Validation Loss: 0.8505\n",
      "[Trial 78] Epoch 20/60, Training Loss: 0.6585, Validation Loss: 0.5530\n",
      "[Trial 75] Epoch 26/60, Training Loss: 0.6607, Validation Loss: 0.5719\n",
      "[Trial 85] Epoch 9/60, Training Loss: 0.8757, Validation Loss: 0.6701\n",
      "[Trial 77] Epoch 22/60, Training Loss: 2.0090, Validation Loss: 1.5086\n",
      "[Trial 76] Epoch 27/60, Training Loss: 0.6160, Validation Loss: 0.5257\n",
      "[Trial 82] Epoch 12/60, Training Loss: 0.8265, Validation Loss: 0.6547\n",
      "[Trial 87] Epoch 4/60, Training Loss: 1.0640, Validation Loss: 0.8646\n",
      "[Trial 79] Epoch 25/60, Training Loss: 0.6293, Validation Loss: 0.5336\n",
      "[Trial 72] Epoch 36/60, Training Loss: 0.9493, Validation Loss: 0.7558\n",
      "[Trial 83] Epoch 11/60, Training Loss: 0.8238, Validation Loss: 0.8450\n",
      "[Trial 73] Epoch 36/60, Training Loss: 0.6754, Validation Loss: 0.5522\n",
      "[Trial 74] Epoch 30/60, Training Loss: 0.6959, Validation Loss: 0.6220\n",
      "[Trial 81] Epoch 13/60, Training Loss: 0.9260, Validation Loss: 0.8929\n",
      "[Trial 84] Epoch 10/60, Training Loss: 0.8527, Validation Loss: 0.7897\n",
      "[Trial 80] Epoch 14/60, Training Loss: 0.7161, Validation Loss: 0.6212\n",
      "[Trial 79] Epoch 26/60, Training Loss: 0.6249, Validation Loss: 0.5299\n",
      "[Trial 86] Epoch 8/60, Training Loss: 0.9178, Validation Loss: 0.7188\n",
      "[Trial 78] Epoch 21/60, Training Loss: 0.6632, Validation Loss: 0.5550\n",
      "[Trial 75] Epoch 27/60, Training Loss: 0.6594, Validation Loss: 0.6436\n",
      "[Trial 85] Epoch 10/60, Training Loss: 0.8465, Validation Loss: 0.6952\n",
      "[Trial 76] Epoch 28/60, Training Loss: 0.6138, Validation Loss: 0.5414\n",
      "[Trial 77] Epoch 23/60, Training Loss: 1.9898, Validation Loss: 1.4546\n",
      "[Trial 82] Epoch 13/60, Training Loss: 0.8030, Validation Loss: 0.6915\n",
      "[Trial 87] Epoch 5/60, Training Loss: 0.9983, Validation Loss: 0.8132\n",
      "[Trial 72] Epoch 37/60, Training Loss: 0.9095, Validation Loss: 0.9108\n",
      "[Trial 73] Epoch 37/60, Training Loss: 0.6618, Validation Loss: 0.5422\n",
      "[Trial 79] Epoch 27/60, Training Loss: 0.6566, Validation Loss: 0.6061\n",
      "[Trial 83] Epoch 12/60, Training Loss: 0.8268, Validation Loss: 0.7019\n",
      "[Trial 74] Epoch 31/60, Training Loss: 0.6952, Validation Loss: 0.5891\n",
      "[Trial 81] Epoch 14/60, Training Loss: 0.9289, Validation Loss: 0.7781\n",
      "[Trial 84] Epoch 11/60, Training Loss: 0.7401, Validation Loss: 0.6308\n",
      "[Trial 80] Epoch 15/60, Training Loss: 0.7112, Validation Loss: 0.6179\n",
      "[Trial 79] Epoch 28/60, Training Loss: 0.6207, Validation Loss: 0.5082\n",
      "[Trial 86] Epoch 9/60, Training Loss: 0.9209, Validation Loss: 0.7286\n",
      "[Trial 78] Epoch 22/60, Training Loss: 0.6384, Validation Loss: 0.5240\n",
      "[Trial 75] Epoch 28/60, Training Loss: 0.6523, Validation Loss: 0.5646\n",
      "[Trial 76] Epoch 29/60, Training Loss: 0.6091, Validation Loss: 0.5446\n",
      "[Trial 85] Epoch 11/60, Training Loss: 0.8473, Validation Loss: 0.8088\n",
      "[Trial 77] Epoch 24/60, Training Loss: 1.9384, Validation Loss: 1.4721\n",
      "[Trial 82] Epoch 14/60, Training Loss: 0.8057, Validation Loss: 0.7572\n",
      "[Trial 73] Epoch 38/60, Training Loss: 0.6724, Validation Loss: 0.5574\n",
      "[Trial 72] Epoch 38/60, Training Loss: 0.9104, Validation Loss: 0.7540\n",
      "[Trial 87] Epoch 6/60, Training Loss: 0.9556, Validation Loss: 0.6943\n",
      "[Trial 74] Epoch 32/60, Training Loss: 0.6604, Validation Loss: 0.5501\n",
      "[Trial 83] Epoch 13/60, Training Loss: 0.7845, Validation Loss: 0.8903\n",
      "[Trial 79] Epoch 29/60, Training Loss: 0.6108, Validation Loss: 0.5155\n",
      "[Trial 81] Epoch 15/60, Training Loss: 0.9077, Validation Loss: 1.0137\n",
      "[Trial 84] Epoch 12/60, Training Loss: 0.7357, Validation Loss: 0.6776\n",
      "[Trial 80] Epoch 16/60, Training Loss: 0.6979, Validation Loss: 0.6613\n",
      "[Trial 78] Epoch 23/60, Training Loss: 0.6279, Validation Loss: 0.5241\n",
      "[Trial 86] Epoch 10/60, Training Loss: 0.8833, Validation Loss: 0.9113\n",
      "[Trial 79] Epoch 30/60, Training Loss: 0.6058, Validation Loss: 0.5204\n",
      "[Trial 75] Epoch 29/60, Training Loss: 0.6519, Validation Loss: 0.6010\n",
      "[Trial 76] Epoch 30/60, Training Loss: 0.6096, Validation Loss: 0.5388\n",
      "[Trial 85] Epoch 12/60, Training Loss: 0.8532, Validation Loss: 0.7342\n",
      "[Trial 77] Epoch 25/60, Training Loss: 1.9082, Validation Loss: 1.4125\n",
      "[Trial 73] Epoch 39/60, Training Loss: 0.6669, Validation Loss: 0.5444\n",
      "[Trial 72] Epoch 39/60, Training Loss: 0.9118, Validation Loss: 0.8259\n",
      "[Trial 82] Epoch 15/60, Training Loss: 0.7167, Validation Loss: 0.6266\n",
      "[Trial 87] Epoch 7/60, Training Loss: 0.9106, Validation Loss: 0.7072\n",
      "[Trial 74] Epoch 33/60, Training Loss: 0.6574, Validation Loss: 0.5785\n",
      "[Trial 83] Epoch 14/60, Training Loss: 0.7014, Validation Loss: 0.5920\n",
      "[Trial 84] Epoch 13/60, Training Loss: 0.7294, Validation Loss: 0.6167\n",
      "[Trial 81] Epoch 16/60, Training Loss: 0.8890, Validation Loss: 0.7121\n",
      "[Trial 79] Epoch 31/60, Training Loss: 0.6108, Validation Loss: 0.5155\n",
      "[Trial 80] Epoch 17/60, Training Loss: 0.6436, Validation Loss: 0.5223\n",
      "[Trial 78] Epoch 24/60, Training Loss: 0.6287, Validation Loss: 0.5396\n",
      "[Trial 86] Epoch 11/60, Training Loss: 0.8735, Validation Loss: 0.7477\n",
      "[Trial 79] Epoch 32/60, Training Loss: 0.5997, Validation Loss: 0.5059\n",
      "[Trial 76] Epoch 31/60, Training Loss: 0.5990, Validation Loss: 0.5331\n",
      "[Trial 75] Epoch 30/60, Training Loss: 0.6544, Validation Loss: 0.5792\n",
      "[Trial 85] Epoch 13/60, Training Loss: 0.7334, Validation Loss: 0.5926\n",
      "[Trial 73] Epoch 40/60, Training Loss: 0.6676, Validation Loss: 0.5408\n",
      "[Trial 77] Epoch 26/60, Training Loss: 1.8943, Validation Loss: 1.4191\n",
      "[Trial 72] Epoch 40/60, Training Loss: 0.8917, Validation Loss: 0.8043\n",
      "[Trial 82] Epoch 16/60, Training Loss: 0.7070, Validation Loss: 0.5711\n",
      "[Trial 87] Epoch 8/60, Training Loss: 0.8724, Validation Loss: 0.6657\n",
      "[Trial 74] Epoch 34/60, Training Loss: 0.6575, Validation Loss: 0.5533\n",
      "[Trial 84] Epoch 14/60, Training Loss: 0.7278, Validation Loss: 0.6225\n",
      "[Trial 83] Epoch 15/60, Training Loss: 0.6930, Validation Loss: 0.6252\n",
      "[Trial 81] Epoch 17/60, Training Loss: 0.9028, Validation Loss: 0.7445\n",
      "[Trial 79] Epoch 33/60, Training Loss: 0.5957, Validation Loss: 0.4976\n",
      "[Trial 80] Epoch 18/60, Training Loss: 0.6406, Validation Loss: 0.5426\n",
      "[Trial 78] Epoch 25/60, Training Loss: 0.6264, Validation Loss: 0.5200\n",
      "[Trial 86] Epoch 12/60, Training Loss: 0.7528, Validation Loss: 0.6428\n",
      "[Trial 73] Epoch 41/60, Training Loss: 0.6664, Validation Loss: 0.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:31:06,248] Trial 76 finished with value: 0.525671282162269 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004004696220876566, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 76] Epoch 32/60, Training Loss: 0.5987, Validation Loss: 0.5288\n",
      "[Trial 76] Early stopping after 32 epochs.\n",
      "[Trial 85] Epoch 14/60, Training Loss: 0.7298, Validation Loss: 0.5899\n",
      "[Trial 75] Epoch 31/60, Training Loss: 0.6438, Validation Loss: 0.5740\n",
      "[Trial 79] Epoch 34/60, Training Loss: 0.5927, Validation Loss: 0.4965\n",
      "[Trial 77] Epoch 27/60, Training Loss: 1.9053, Validation Loss: 1.3641\n",
      "[Trial 72] Epoch 41/60, Training Loss: 0.9190, Validation Loss: 0.9852\n",
      "[Trial 74] Epoch 35/60, Training Loss: 0.6504, Validation Loss: 0.5877\n",
      "[Trial 87] Epoch 9/60, Training Loss: 0.8523, Validation Loss: 0.7153\n",
      "[Trial 82] Epoch 17/60, Training Loss: 0.7060, Validation Loss: 0.5690\n",
      "[Trial 84] Epoch 15/60, Training Loss: 0.7174, Validation Loss: 0.6097\n",
      "[Trial 81] Epoch 18/60, Training Loss: 0.8695, Validation Loss: 0.7579\n",
      "[Trial 83] Epoch 16/60, Training Loss: 0.6862, Validation Loss: 0.5784\n",
      "[Trial 80] Epoch 19/60, Training Loss: 0.6458, Validation Loss: 0.5483\n",
      "[Trial 79] Epoch 35/60, Training Loss: 0.6008, Validation Loss: 0.5060\n",
      "[Trial 78] Epoch 26/60, Training Loss: 0.6148, Validation Loss: 0.5255\n",
      "[Trial 86] Epoch 13/60, Training Loss: 0.7498, Validation Loss: 0.6026\n",
      "[Trial 73] Epoch 42/60, Training Loss: 0.6682, Validation Loss: 0.5593\n",
      "[Trial 88] Epoch 1/60, Training Loss: 3.1151, Validation Loss: 1.9511\n",
      "[Trial 85] Epoch 15/60, Training Loss: 0.7198, Validation Loss: 0.6561\n",
      "[Trial 77] Epoch 28/60, Training Loss: 1.8612, Validation Loss: 1.4606\n",
      "[Trial 72] Epoch 42/60, Training Loss: 1.0781, Validation Loss: 0.8206\n",
      "[Trial 75] Epoch 32/60, Training Loss: 0.6487, Validation Loss: 0.5567\n",
      "[Trial 74] Epoch 36/60, Training Loss: 0.6480, Validation Loss: 0.5541\n",
      "[Trial 79] Epoch 36/60, Training Loss: 0.5974, Validation Loss: 0.5020\n",
      "[Trial 87] Epoch 10/60, Training Loss: 0.8333, Validation Loss: 0.6974\n",
      "[Trial 82] Epoch 18/60, Training Loss: 0.7058, Validation Loss: 0.6125\n",
      "[Trial 84] Epoch 16/60, Training Loss: 0.7141, Validation Loss: 1.1972\n",
      "[Trial 81] Epoch 19/60, Training Loss: 0.8868, Validation Loss: 0.7492\n",
      "[Trial 83] Epoch 17/60, Training Loss: 0.6895, Validation Loss: 0.6535\n",
      "[Trial 80] Epoch 20/60, Training Loss: 0.6395, Validation Loss: 0.5705\n",
      "[Trial 79] Epoch 37/60, Training Loss: 0.5947, Validation Loss: 0.5079\n",
      "[Trial 78] Epoch 27/60, Training Loss: 0.6149, Validation Loss: 0.5260\n",
      "[Trial 73] Epoch 43/60, Training Loss: 0.6555, Validation Loss: 0.5416\n",
      "[Trial 86] Epoch 14/60, Training Loss: 0.7550, Validation Loss: 0.6293\n",
      "[Trial 88] Epoch 2/60, Training Loss: 1.6913, Validation Loss: 1.1643\n",
      "[Trial 85] Epoch 16/60, Training Loss: 0.7204, Validation Loss: 0.5791\n",
      "[Trial 77] Epoch 29/60, Training Loss: 1.8273, Validation Loss: 1.3794\n",
      "[Trial 72] Epoch 43/60, Training Loss: 0.9333, Validation Loss: 0.9541\n",
      "[Trial 74] Epoch 37/60, Training Loss: 0.6511, Validation Loss: 0.5529\n",
      "[Trial 75] Epoch 33/60, Training Loss: 0.6387, Validation Loss: 0.5780\n",
      "[Trial 87] Epoch 11/60, Training Loss: 0.8026, Validation Loss: 0.6689\n",
      "[Trial 82] Epoch 19/60, Training Loss: 0.6965, Validation Loss: 0.5868\n",
      "[Trial 79] Epoch 38/60, Training Loss: 0.6008, Validation Loss: 0.5059\n",
      "[Trial 84] Epoch 17/60, Training Loss: 0.7200, Validation Loss: 0.5951\n",
      "[Trial 81] Epoch 20/60, Training Loss: 0.8735, Validation Loss: 0.7902\n",
      "[Trial 83] Epoch 18/60, Training Loss: 0.6979, Validation Loss: 0.5972\n",
      "[Trial 80] Epoch 21/60, Training Loss: 0.6094, Validation Loss: 0.5108\n",
      "[Trial 79] Epoch 39/60, Training Loss: 0.5951, Validation Loss: 0.4945\n",
      "[Trial 73] Epoch 44/60, Training Loss: 0.6573, Validation Loss: 0.5388\n",
      "[Trial 78] Epoch 28/60, Training Loss: 0.6153, Validation Loss: 0.5109\n",
      "[Trial 86] Epoch 15/60, Training Loss: 0.7495, Validation Loss: 0.6130\n",
      "[Trial 88] Epoch 3/60, Training Loss: 1.3041, Validation Loss: 1.0413\n",
      "[Trial 85] Epoch 17/60, Training Loss: 0.7166, Validation Loss: 0.6516\n",
      "[Trial 72] Epoch 44/60, Training Loss: 0.9041, Validation Loss: 0.9660\n",
      "[Trial 74] Epoch 38/60, Training Loss: 0.6490, Validation Loss: 0.5533\n",
      "[Trial 77] Epoch 30/60, Training Loss: 1.8194, Validation Loss: 1.3335\n",
      "[Trial 75] Epoch 34/60, Training Loss: 0.6426, Validation Loss: 0.6473\n",
      "[Trial 87] Epoch 12/60, Training Loss: 0.7942, Validation Loss: 0.6560\n",
      "[Trial 82] Epoch 20/60, Training Loss: 0.6974, Validation Loss: 0.6017\n",
      "[Trial 84] Epoch 18/60, Training Loss: 0.6911, Validation Loss: 0.6212\n",
      "[Trial 79] Epoch 40/60, Training Loss: 0.5931, Validation Loss: 0.4995\n",
      "[Trial 81] Epoch 21/60, Training Loss: 0.8466, Validation Loss: 0.8150\n",
      "[Trial 83] Epoch 19/60, Training Loss: 0.6815, Validation Loss: 0.5684\n",
      "[Trial 80] Epoch 22/60, Training Loss: 0.6069, Validation Loss: 0.5245\n",
      "[Trial 73] Epoch 45/60, Training Loss: 0.6572, Validation Loss: 0.5452\n",
      "[Trial 78] Epoch 29/60, Training Loss: 0.6116, Validation Loss: 0.5168\n",
      "[Trial 79] Epoch 41/60, Training Loss: 0.5912, Validation Loss: 0.4967\n",
      "[Trial 86] Epoch 16/60, Training Loss: 0.7343, Validation Loss: 0.5978\n",
      "[Trial 85] Epoch 18/60, Training Loss: 0.6958, Validation Loss: 0.6019\n",
      "[Trial 88] Epoch 4/60, Training Loss: 1.1355, Validation Loss: 0.9356\n",
      "[Trial 74] Epoch 39/60, Training Loss: 0.6363, Validation Loss: 0.5503\n",
      "[Trial 72] Epoch 45/60, Training Loss: 0.7705, Validation Loss: 0.6153\n",
      "[Trial 77] Epoch 31/60, Training Loss: 1.8016, Validation Loss: 1.3838\n",
      "[Trial 75] Epoch 35/60, Training Loss: 0.6574, Validation Loss: 0.6051\n",
      "[Trial 87] Epoch 13/60, Training Loss: 0.8006, Validation Loss: 0.7098\n",
      "[Trial 82] Epoch 21/60, Training Loss: 0.6494, Validation Loss: 0.5420\n",
      "[Trial 84] Epoch 19/60, Training Loss: 0.6912, Validation Loss: 0.6410\n",
      "[Trial 81] Epoch 22/60, Training Loss: 0.8521, Validation Loss: 0.7043\n",
      "[Trial 79] Epoch 42/60, Training Loss: 0.5899, Validation Loss: 0.4939\n",
      "[Trial 80] Epoch 23/60, Training Loss: 0.6020, Validation Loss: 0.5134\n",
      "[Trial 83] Epoch 20/60, Training Loss: 0.6684, Validation Loss: 0.5766\n",
      "[Trial 73] Epoch 46/60, Training Loss: 0.6577, Validation Loss: 0.5513\n",
      "[Trial 78] Epoch 30/60, Training Loss: 0.6205, Validation Loss: 0.5290\n",
      "[Trial 86] Epoch 17/60, Training Loss: 0.7456, Validation Loss: 0.6124\n",
      "[Trial 74] Epoch 40/60, Training Loss: 0.6316, Validation Loss: 0.5432\n",
      "[Trial 79] Epoch 43/60, Training Loss: 0.5866, Validation Loss: 0.4918\n",
      "[Trial 85] Epoch 19/60, Training Loss: 0.6960, Validation Loss: 0.5868\n",
      "[Trial 88] Epoch 5/60, Training Loss: 1.0410, Validation Loss: 0.7777\n",
      "[Trial 72] Epoch 46/60, Training Loss: 0.7518, Validation Loss: 0.6072\n",
      "[Trial 77] Epoch 32/60, Training Loss: 1.7667, Validation Loss: 1.2925\n",
      "[Trial 75] Epoch 36/60, Training Loss: 0.6565, Validation Loss: 0.5755\n",
      "[Trial 87] Epoch 14/60, Training Loss: 0.7817, Validation Loss: 0.6306\n",
      "[Trial 84] Epoch 20/60, Training Loss: 0.6850, Validation Loss: 0.6449\n",
      "[Trial 82] Epoch 22/60, Training Loss: 0.6445, Validation Loss: 0.5571\n",
      "[Trial 81] Epoch 23/60, Training Loss: 0.8430, Validation Loss: 0.7109\n",
      "[Trial 80] Epoch 24/60, Training Loss: 0.5975, Validation Loss: 0.5156\n",
      "[Trial 79] Epoch 44/60, Training Loss: 0.5863, Validation Loss: 0.4981\n",
      "[Trial 83] Epoch 21/60, Training Loss: 0.6791, Validation Loss: 0.5555\n",
      "[Trial 73] Epoch 47/60, Training Loss: 0.6557, Validation Loss: 0.5533\n",
      "[Trial 78] Epoch 31/60, Training Loss: 0.6123, Validation Loss: 0.5236\n",
      "[Trial 74] Epoch 41/60, Training Loss: 0.6343, Validation Loss: 0.5507\n",
      "[Trial 86] Epoch 18/60, Training Loss: 0.7404, Validation Loss: 0.5949\n",
      "[Trial 85] Epoch 20/60, Training Loss: 0.6546, Validation Loss: 0.5759\n",
      "[Trial 72] Epoch 47/60, Training Loss: 0.7545, Validation Loss: 0.6945\n",
      "[Trial 88] Epoch 6/60, Training Loss: 0.9896, Validation Loss: 0.8075\n",
      "[Trial 77] Epoch 33/60, Training Loss: 1.7562, Validation Loss: 1.2912\n",
      "[Trial 79] Epoch 45/60, Training Loss: 0.5910, Validation Loss: 0.4941\n",
      "[Trial 75] Epoch 37/60, Training Loss: 0.6341, Validation Loss: 0.5538\n",
      "[Trial 87] Epoch 15/60, Training Loss: 0.7671, Validation Loss: 0.6433\n",
      "[Trial 84] Epoch 21/60, Training Loss: 0.6367, Validation Loss: 0.5866\n",
      "[Trial 82] Epoch 23/60, Training Loss: 0.6429, Validation Loss: 0.5470\n",
      "[Trial 81] Epoch 24/60, Training Loss: 0.8504, Validation Loss: 0.6638\n",
      "[Trial 80] Epoch 25/60, Training Loss: 0.5854, Validation Loss: 0.4997\n",
      "[Trial 73] Epoch 48/60, Training Loss: 0.6341, Validation Loss: 0.5265\n",
      "[Trial 83] Epoch 22/60, Training Loss: 0.6657, Validation Loss: 0.6054\n",
      "[Trial 79] Epoch 46/60, Training Loss: 0.5830, Validation Loss: 0.4884\n",
      "[Trial 78] Epoch 32/60, Training Loss: 0.6010, Validation Loss: 0.4995\n",
      "[Trial 74] Epoch 42/60, Training Loss: 0.6326, Validation Loss: 0.5504\n",
      "[Trial 72] Epoch 48/60, Training Loss: 0.7702, Validation Loss: 0.6562\n",
      "[Trial 86] Epoch 19/60, Training Loss: 0.7236, Validation Loss: 0.5610\n",
      "[Trial 85] Epoch 21/60, Training Loss: 0.6461, Validation Loss: 0.5580\n",
      "[Trial 88] Epoch 7/60, Training Loss: 0.9230, Validation Loss: 0.7506\n",
      "[Trial 77] Epoch 34/60, Training Loss: 1.7724, Validation Loss: 1.2704\n",
      "[Trial 79] Epoch 47/60, Training Loss: 0.5834, Validation Loss: 0.4892\n",
      "[Trial 75] Epoch 38/60, Training Loss: 0.6458, Validation Loss: 0.6509\n",
      "[Trial 87] Epoch 16/60, Training Loss: 0.7450, Validation Loss: 0.6124\n",
      "[Trial 84] Epoch 22/60, Training Loss: 0.6332, Validation Loss: 0.5401\n",
      "[Trial 82] Epoch 24/60, Training Loss: 0.6391, Validation Loss: 0.5539\n",
      "[Trial 81] Epoch 25/60, Training Loss: 0.8077, Validation Loss: 0.6767\n",
      "[Trial 80] Epoch 26/60, Training Loss: 0.5854, Validation Loss: 0.5012\n",
      "[Trial 73] Epoch 49/60, Training Loss: 0.6337, Validation Loss: 0.5300\n",
      "[Trial 83] Epoch 23/60, Training Loss: 0.6636, Validation Loss: 0.5814\n",
      "[Trial 79] Epoch 48/60, Training Loss: 0.5893, Validation Loss: 0.4960\n",
      "[Trial 78] Epoch 33/60, Training Loss: 0.5900, Validation Loss: 0.5037\n",
      "[Trial 74] Epoch 43/60, Training Loss: 0.6306, Validation Loss: 0.5419\n",
      "[Trial 72] Epoch 49/60, Training Loss: 0.7806, Validation Loss: 0.6399\n",
      "[Trial 85] Epoch 22/60, Training Loss: 0.6430, Validation Loss: 0.5609\n",
      "[Trial 88] Epoch 8/60, Training Loss: 0.9101, Validation Loss: 0.7259\n",
      "[Trial 86] Epoch 20/60, Training Loss: 0.7226, Validation Loss: 0.6031\n",
      "[Trial 77] Epoch 35/60, Training Loss: 1.7188, Validation Loss: 1.2455\n",
      "[Trial 79] Epoch 49/60, Training Loss: 0.5882, Validation Loss: 0.4889\n",
      "[Trial 75] Epoch 39/60, Training Loss: 0.6359, Validation Loss: 0.5684\n",
      "[Trial 87] Epoch 17/60, Training Loss: 0.7472, Validation Loss: 0.6244\n",
      "[Trial 84] Epoch 23/60, Training Loss: 0.6230, Validation Loss: 0.5775\n",
      "[Trial 82] Epoch 25/60, Training Loss: 0.6178, Validation Loss: 0.5254\n",
      "[Trial 73] Epoch 50/60, Training Loss: 0.6329, Validation Loss: 0.5283\n",
      "[Trial 81] Epoch 26/60, Training Loss: 0.8199, Validation Loss: 0.9255\n",
      "[Trial 80] Epoch 27/60, Training Loss: 0.5783, Validation Loss: 0.5009\n",
      "[Trial 83] Epoch 24/60, Training Loss: 0.6639, Validation Loss: 0.6423\n",
      "[Trial 78] Epoch 34/60, Training Loss: 0.5939, Validation Loss: 0.4931\n",
      "[Trial 79] Epoch 50/60, Training Loss: 0.5786, Validation Loss: 0.4845\n",
      "[Trial 74] Epoch 44/60, Training Loss: 0.6363, Validation Loss: 0.5376\n",
      "[Trial 72] Epoch 50/60, Training Loss: 0.7489, Validation Loss: 0.6864\n",
      "[Trial 85] Epoch 23/60, Training Loss: 0.6415, Validation Loss: 0.5900\n",
      "[Trial 88] Epoch 9/60, Training Loss: 0.8674, Validation Loss: 0.7583\n",
      "[Trial 86] Epoch 21/60, Training Loss: 0.7074, Validation Loss: 0.6213\n",
      "[Trial 77] Epoch 36/60, Training Loss: 1.7243, Validation Loss: 1.2613\n",
      "[Trial 84] Epoch 24/60, Training Loss: 0.6274, Validation Loss: 0.5424\n",
      "[Trial 87] Epoch 18/60, Training Loss: 0.7466, Validation Loss: 0.6037\n",
      "[Trial 75] Epoch 40/60, Training Loss: 0.6356, Validation Loss: 0.6260\n",
      "[Trial 79] Epoch 51/60, Training Loss: 0.5845, Validation Loss: 0.4910\n",
      "[Trial 73] Epoch 51/60, Training Loss: 0.6266, Validation Loss: 0.5176\n",
      "[Trial 82] Epoch 26/60, Training Loss: 0.6142, Validation Loss: 0.5315\n",
      "[Trial 81] Epoch 27/60, Training Loss: 0.8343, Validation Loss: 0.6737\n",
      "[Trial 80] Epoch 28/60, Training Loss: 0.5838, Validation Loss: 0.4948\n",
      "[Trial 83] Epoch 25/60, Training Loss: 0.6241, Validation Loss: 0.5444\n",
      "[Trial 78] Epoch 35/60, Training Loss: 0.5909, Validation Loss: 0.4923\n",
      "[Trial 74] Epoch 45/60, Training Loss: 0.6266, Validation Loss: 0.5383\n",
      "[Trial 79] Epoch 52/60, Training Loss: 0.5811, Validation Loss: 0.4906\n",
      "[Trial 72] Epoch 51/60, Training Loss: 0.7565, Validation Loss: 0.6142\n",
      "[Trial 85] Epoch 24/60, Training Loss: 0.6383, Validation Loss: 0.5404\n",
      "[Trial 88] Epoch 10/60, Training Loss: 0.8637, Validation Loss: 0.7083\n",
      "[Trial 86] Epoch 22/60, Training Loss: 0.7159, Validation Loss: 0.5659\n",
      "[Trial 77] Epoch 37/60, Training Loss: 1.7060, Validation Loss: 1.2716\n",
      "[Trial 84] Epoch 25/60, Training Loss: 0.6164, Validation Loss: 0.5557\n",
      "[Trial 87] Epoch 19/60, Training Loss: 0.7219, Validation Loss: 0.5934\n",
      "[Trial 75] Epoch 41/60, Training Loss: 0.6325, Validation Loss: 0.6305\n",
      "[Trial 73] Epoch 52/60, Training Loss: 0.6281, Validation Loss: 0.5059\n",
      "[Trial 79] Epoch 53/60, Training Loss: 0.5814, Validation Loss: 0.5013\n",
      "[Trial 82] Epoch 27/60, Training Loss: 0.6122, Validation Loss: 0.5043\n",
      "[Trial 81] Epoch 28/60, Training Loss: 0.7928, Validation Loss: 0.7015\n",
      "[Trial 80] Epoch 29/60, Training Loss: 0.5890, Validation Loss: 0.5015\n",
      "[Trial 74] Epoch 46/60, Training Loss: 0.6370, Validation Loss: 0.5391\n",
      "[Trial 83] Epoch 26/60, Training Loss: 0.6139, Validation Loss: 0.5465\n",
      "[Trial 78] Epoch 36/60, Training Loss: 0.5878, Validation Loss: 0.5087\n",
      "[Trial 72] Epoch 52/60, Training Loss: 0.7499, Validation Loss: 0.7008\n",
      "[Trial 85] Epoch 25/60, Training Loss: 0.6429, Validation Loss: 0.5257\n",
      "[Trial 88] Epoch 11/60, Training Loss: 0.8173, Validation Loss: 0.6588\n",
      "[Trial 79] Epoch 54/60, Training Loss: 0.5851, Validation Loss: 0.4949\n",
      "[Trial 86] Epoch 23/60, Training Loss: 0.6665, Validation Loss: 0.5492\n",
      "[Trial 77] Epoch 38/60, Training Loss: 1.6864, Validation Loss: 1.2257\n",
      "[Trial 73] Epoch 53/60, Training Loss: 0.6245, Validation Loss: 0.5196\n",
      "[Trial 84] Epoch 26/60, Training Loss: 0.5941, Validation Loss: 0.5424\n",
      "[Trial 87] Epoch 20/60, Training Loss: 0.7165, Validation Loss: 0.6888\n",
      "[Trial 75] Epoch 42/60, Training Loss: 0.6378, Validation Loss: 0.5744\n",
      "[Trial 80] Epoch 30/60, Training Loss: 0.5774, Validation Loss: 0.5166\n",
      "[Trial 82] Epoch 28/60, Training Loss: 0.6091, Validation Loss: 0.5198\n",
      "[Trial 81] Epoch 29/60, Training Loss: 0.8039, Validation Loss: 0.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 05:50:36,280] Trial 79 finished with value: 0.4845455840229988 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.003663132421872963, 'batch_size': 16, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 79] Epoch 55/60, Training Loss: 0.5826, Validation Loss: 0.4914\n",
      "[Trial 79] Early stopping after 55 epochs.\n",
      "[Trial 74] Epoch 47/60, Training Loss: 0.6282, Validation Loss: 0.5574\n",
      "[Trial 78] Epoch 37/60, Training Loss: 0.5877, Validation Loss: 0.4979\n",
      "[Trial 83] Epoch 27/60, Training Loss: 0.6143, Validation Loss: 0.5621\n",
      "[Trial 72] Epoch 53/60, Training Loss: 0.6942, Validation Loss: 0.5634\n",
      "[Trial 85] Epoch 26/60, Training Loss: 0.6312, Validation Loss: 0.5471\n",
      "[Trial 88] Epoch 12/60, Training Loss: 0.8174, Validation Loss: 0.6252\n",
      "[Trial 86] Epoch 24/60, Training Loss: 0.6507, Validation Loss: 0.5263\n",
      "[Trial 77] Epoch 39/60, Training Loss: 1.6816, Validation Loss: 1.2167\n",
      "[Trial 73] Epoch 54/60, Training Loss: 0.6259, Validation Loss: 0.5248\n",
      "[Trial 84] Epoch 27/60, Training Loss: 0.5959, Validation Loss: 0.5274\n",
      "[Trial 87] Epoch 21/60, Training Loss: 0.7144, Validation Loss: 0.7438\n",
      "[Trial 75] Epoch 43/60, Training Loss: 0.6378, Validation Loss: 0.6606\n",
      "[Trial 80] Epoch 31/60, Training Loss: 0.5771, Validation Loss: 0.5036\n",
      "[Trial 81] Epoch 30/60, Training Loss: 0.8140, Validation Loss: 0.8177\n",
      "[Trial 89] Epoch 1/60, Training Loss: 2.9100, Validation Loss: 1.3215\n",
      "[Trial 82] Epoch 29/60, Training Loss: 0.6137, Validation Loss: 0.5033\n",
      "[Trial 74] Epoch 48/60, Training Loss: 0.6256, Validation Loss: 0.5404\n",
      "[Trial 78] Epoch 38/60, Training Loss: 0.5841, Validation Loss: 0.4900\n",
      "[Trial 83] Epoch 28/60, Training Loss: 0.6059, Validation Loss: 0.5243\n",
      "[Trial 72] Epoch 54/60, Training Loss: 0.7024, Validation Loss: 0.6129\n",
      "[Trial 85] Epoch 27/60, Training Loss: 0.6341, Validation Loss: 0.5395\n",
      "[Trial 88] Epoch 13/60, Training Loss: 0.7965, Validation Loss: 0.6730\n",
      "[Trial 77] Epoch 40/60, Training Loss: 1.6665, Validation Loss: 1.2438\n",
      "[Trial 86] Epoch 25/60, Training Loss: 0.6664, Validation Loss: 0.5933\n",
      "[Trial 73] Epoch 55/60, Training Loss: 0.6276, Validation Loss: 0.5064\n",
      "[Trial 84] Epoch 28/60, Training Loss: 0.5856, Validation Loss: 0.5259\n",
      "[Trial 87] Epoch 22/60, Training Loss: 0.7183, Validation Loss: 0.7093\n",
      "[Trial 75] Epoch 44/60, Training Loss: 0.5995, Validation Loss: 0.5297\n",
      "[Trial 80] Epoch 32/60, Training Loss: 0.5767, Validation Loss: 0.4912\n",
      "[Trial 89] Epoch 2/60, Training Loss: 1.4559, Validation Loss: 1.0809\n",
      "[Trial 81] Epoch 31/60, Training Loss: 0.7109, Validation Loss: 0.5912\n",
      "[Trial 82] Epoch 30/60, Training Loss: 0.6134, Validation Loss: 0.5350\n",
      "[Trial 74] Epoch 49/60, Training Loss: 0.6249, Validation Loss: 0.5461\n",
      "[Trial 78] Epoch 39/60, Training Loss: 0.5879, Validation Loss: 0.5034\n",
      "[Trial 72] Epoch 55/60, Training Loss: 0.7008, Validation Loss: 0.6338\n",
      "[Trial 83] Epoch 29/60, Training Loss: 0.6099, Validation Loss: 0.5278\n",
      "[Trial 85] Epoch 28/60, Training Loss: 0.6334, Validation Loss: 0.5214\n",
      "[Trial 88] Epoch 14/60, Training Loss: 0.7889, Validation Loss: 0.6520\n",
      "[Trial 77] Epoch 41/60, Training Loss: 1.6524, Validation Loss: 1.1897\n",
      "[Trial 86] Epoch 26/60, Training Loss: 0.6495, Validation Loss: 0.5419\n",
      "[Trial 73] Epoch 56/60, Training Loss: 0.6254, Validation Loss: 0.5304\n",
      "[Trial 84] Epoch 29/60, Training Loss: 0.5853, Validation Loss: 0.5133\n",
      "[Trial 87] Epoch 23/60, Training Loss: 0.7094, Validation Loss: 0.6931\n",
      "[Trial 75] Epoch 45/60, Training Loss: 0.5919, Validation Loss: 0.5367\n",
      "[Trial 89] Epoch 3/60, Training Loss: 1.1665, Validation Loss: 0.9512\n",
      "[Trial 80] Epoch 33/60, Training Loss: 0.5692, Validation Loss: 0.5068\n",
      "[Trial 81] Epoch 32/60, Training Loss: 0.6895, Validation Loss: 0.6070\n",
      "[Trial 82] Epoch 31/60, Training Loss: 0.6033, Validation Loss: 0.5284\n",
      "[Trial 74] Epoch 50/60, Training Loss: 0.6271, Validation Loss: 0.5596\n",
      "[Trial 78] Epoch 40/60, Training Loss: 0.5825, Validation Loss: 0.4946\n",
      "[Trial 72] Epoch 56/60, Training Loss: 0.6813, Validation Loss: 0.5881\n",
      "[Trial 83] Epoch 30/60, Training Loss: 0.6020, Validation Loss: 0.5341\n",
      "[Trial 85] Epoch 29/60, Training Loss: 0.6245, Validation Loss: 0.5439\n",
      "[Trial 88] Epoch 15/60, Training Loss: 0.7777, Validation Loss: 0.6583\n",
      "[Trial 73] Epoch 57/60, Training Loss: 0.6244, Validation Loss: 0.5378\n",
      "[Trial 77] Epoch 42/60, Training Loss: 1.6457, Validation Loss: 1.1705\n",
      "[Trial 86] Epoch 27/60, Training Loss: 0.6482, Validation Loss: 0.5261\n",
      "[Trial 84] Epoch 30/60, Training Loss: 0.5799, Validation Loss: 0.5374\n",
      "[Trial 87] Epoch 24/60, Training Loss: 0.6954, Validation Loss: 0.5963\n",
      "[Trial 89] Epoch 4/60, Training Loss: 1.0636, Validation Loss: 0.7615\n",
      "[Trial 80] Epoch 34/60, Training Loss: 0.5672, Validation Loss: 0.4965\n",
      "[Trial 75] Epoch 46/60, Training Loss: 0.5933, Validation Loss: 0.5438\n",
      "[Trial 81] Epoch 33/60, Training Loss: 0.6896, Validation Loss: 0.5807\n",
      "[Trial 74] Epoch 51/60, Training Loss: 0.6239, Validation Loss: 0.5347\n",
      "[Trial 82] Epoch 32/60, Training Loss: 0.6051, Validation Loss: 0.5218\n",
      "[Trial 78] Epoch 41/60, Training Loss: 0.5837, Validation Loss: 0.4981\n",
      "[Trial 72] Epoch 57/60, Training Loss: 0.6894, Validation Loss: 0.6116\n",
      "[Trial 85] Epoch 30/60, Training Loss: 0.6260, Validation Loss: 0.5385\n",
      "[Trial 88] Epoch 16/60, Training Loss: 0.7751, Validation Loss: 0.6752\n",
      "[Trial 83] Epoch 31/60, Training Loss: 0.5978, Validation Loss: 0.5186\n",
      "[Trial 73] Epoch 58/60, Training Loss: 0.6209, Validation Loss: 0.5232\n",
      "[Trial 77] Epoch 43/60, Training Loss: 1.6329, Validation Loss: 1.1945\n",
      "[Trial 86] Epoch 28/60, Training Loss: 0.6449, Validation Loss: 0.5644\n",
      "[Trial 84] Epoch 31/60, Training Loss: 0.5834, Validation Loss: 0.5064\n",
      "[Trial 89] Epoch 5/60, Training Loss: 0.9555, Validation Loss: 0.8139\n",
      "[Trial 87] Epoch 25/60, Training Loss: 0.6860, Validation Loss: 0.5583\n",
      "[Trial 80] Epoch 35/60, Training Loss: 0.5721, Validation Loss: 0.4980\n",
      "[Trial 75] Epoch 47/60, Training Loss: 0.5900, Validation Loss: 0.5337\n",
      "[Trial 81] Epoch 34/60, Training Loss: 0.6939, Validation Loss: 0.5784\n",
      "[Trial 74] Epoch 52/60, Training Loss: 0.6130, Validation Loss: 0.5343\n",
      "[Trial 82] Epoch 33/60, Training Loss: 0.5958, Validation Loss: 0.5151\n",
      "[Trial 78] Epoch 42/60, Training Loss: 0.5753, Validation Loss: 0.4871\n",
      "[Trial 72] Epoch 58/60, Training Loss: 0.6780, Validation Loss: 0.5712\n",
      "[Trial 85] Epoch 31/60, Training Loss: 0.6173, Validation Loss: 0.5546\n",
      "[Trial 73] Epoch 59/60, Training Loss: 0.6077, Validation Loss: 0.5006\n",
      "[Trial 88] Epoch 17/60, Training Loss: 0.7450, Validation Loss: 0.6137\n",
      "[Trial 83] Epoch 32/60, Training Loss: 0.5982, Validation Loss: 0.5191\n",
      "[Trial 77] Epoch 44/60, Training Loss: 1.6151, Validation Loss: 1.1889\n",
      "[Trial 86] Epoch 29/60, Training Loss: 0.6471, Validation Loss: 0.5369\n",
      "[Trial 84] Epoch 32/60, Training Loss: 0.5805, Validation Loss: 0.5164\n",
      "[Trial 89] Epoch 6/60, Training Loss: 0.9278, Validation Loss: 0.8010\n",
      "[Trial 87] Epoch 26/60, Training Loss: 0.6989, Validation Loss: 0.6690\n",
      "[Trial 80] Epoch 36/60, Training Loss: 0.5661, Validation Loss: 0.4843\n",
      "[Trial 74] Epoch 53/60, Training Loss: 0.6146, Validation Loss: 0.5432\n",
      "[Trial 75] Epoch 48/60, Training Loss: 0.5898, Validation Loss: 0.5310\n",
      "[Trial 81] Epoch 35/60, Training Loss: 0.6859, Validation Loss: 0.5665\n",
      "[Trial 82] Epoch 34/60, Training Loss: 0.5929, Validation Loss: 0.5010\n",
      "[Trial 78] Epoch 43/60, Training Loss: 0.5787, Validation Loss: 0.4909\n",
      "[Trial 72] Epoch 59/60, Training Loss: 0.6872, Validation Loss: 0.6169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:01:08,593] Trial 73 finished with value: 0.500629111379385 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0038891533016969567, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 73] Epoch 60/60, Training Loss: 0.6054, Validation Loss: 0.5097\n",
      "[Trial 85] Epoch 32/60, Training Loss: 0.6008, Validation Loss: 0.5311\n",
      "[Trial 88] Epoch 18/60, Training Loss: 0.7274, Validation Loss: 0.6148\n",
      "[Trial 83] Epoch 33/60, Training Loss: 0.6009, Validation Loss: 0.5457\n",
      "[Trial 90] Epoch 1/60, Training Loss: 6.1935, Validation Loss: 2.2262\n",
      "[Trial 77] Epoch 45/60, Training Loss: 1.6136, Validation Loss: 1.1424\n",
      "[Trial 86] Epoch 30/60, Training Loss: 0.6414, Validation Loss: 0.5456\n",
      "[Trial 84] Epoch 33/60, Training Loss: 0.5880, Validation Loss: 0.5353\n",
      "[Trial 90] Epoch 2/60, Training Loss: 2.2680, Validation Loss: 1.7813\n",
      "[Trial 89] Epoch 7/60, Training Loss: 0.9005, Validation Loss: 0.7606\n",
      "[Trial 87] Epoch 27/60, Training Loss: 0.6817, Validation Loss: 0.5591\n",
      "[Trial 80] Epoch 37/60, Training Loss: 0.5626, Validation Loss: 0.4926\n",
      "[Trial 74] Epoch 54/60, Training Loss: 0.6156, Validation Loss: 0.5444\n",
      "[Trial 90] Epoch 3/60, Training Loss: 1.9007, Validation Loss: 1.3705\n",
      "[Trial 75] Epoch 49/60, Training Loss: 0.5891, Validation Loss: 0.5474\n",
      "[Trial 81] Epoch 36/60, Training Loss: 0.6909, Validation Loss: 0.6527\n",
      "[Trial 90] Epoch 4/60, Training Loss: 1.6157, Validation Loss: 1.1327\n",
      "[Trial 82] Epoch 35/60, Training Loss: 0.5929, Validation Loss: 0.5178\n",
      "[Trial 78] Epoch 44/60, Training Loss: 0.5677, Validation Loss: 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:02:39,658] Trial 72 finished with value: 0.5548588571449121 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.025388368078748565, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 72] Epoch 60/60, Training Loss: 0.6635, Validation Loss: 0.5549\n",
      "[Trial 90] Epoch 5/60, Training Loss: 1.4124, Validation Loss: 1.0508\n",
      "[Trial 85] Epoch 33/60, Training Loss: 0.6004, Validation Loss: 0.5070\n",
      "[Trial 88] Epoch 19/60, Training Loss: 0.7348, Validation Loss: 0.7405\n",
      "[Trial 91] Epoch 1/60, Training Loss: 6.0592, Validation Loss: 2.7153\n",
      "[Trial 83] Epoch 34/60, Training Loss: 0.5990, Validation Loss: 0.5225\n",
      "[Trial 90] Epoch 6/60, Training Loss: 1.2752, Validation Loss: 0.9966\n",
      "[Trial 77] Epoch 46/60, Training Loss: 1.5971, Validation Loss: 1.2062\n",
      "[Trial 91] Epoch 2/60, Training Loss: 2.3031, Validation Loss: 1.6916\n",
      "[Trial 86] Epoch 31/60, Training Loss: 0.6143, Validation Loss: 0.5222\n",
      "[Trial 84] Epoch 34/60, Training Loss: 0.5766, Validation Loss: 0.5178\n",
      "[Trial 90] Epoch 7/60, Training Loss: 1.1613, Validation Loss: 0.9294\n",
      "[Trial 89] Epoch 8/60, Training Loss: 0.8725, Validation Loss: 0.7870\n",
      "[Trial 91] Epoch 3/60, Training Loss: 1.9112, Validation Loss: 1.5478\n",
      "[Trial 74] Epoch 55/60, Training Loss: 0.6121, Validation Loss: 0.5377\n",
      "[Trial 87] Epoch 28/60, Training Loss: 0.6769, Validation Loss: 0.5590\n",
      "[Trial 80] Epoch 38/60, Training Loss: 0.5633, Validation Loss: 0.4821\n",
      "[Trial 90] Epoch 8/60, Training Loss: 1.0763, Validation Loss: 0.8265\n",
      "[Trial 75] Epoch 50/60, Training Loss: 0.5873, Validation Loss: 0.5541\n",
      "[Trial 91] Epoch 4/60, Training Loss: 1.6623, Validation Loss: 1.3626\n",
      "[Trial 81] Epoch 37/60, Training Loss: 0.6770, Validation Loss: 0.6448\n",
      "[Trial 90] Epoch 9/60, Training Loss: 1.0267, Validation Loss: 1.0189\n",
      "[Trial 82] Epoch 36/60, Training Loss: 0.5918, Validation Loss: 0.4965\n",
      "[Trial 78] Epoch 45/60, Training Loss: 0.5793, Validation Loss: 0.4862\n",
      "[Trial 91] Epoch 5/60, Training Loss: 1.4888, Validation Loss: 1.0517\n",
      "[Trial 90] Epoch 10/60, Training Loss: 0.9967, Validation Loss: 0.8110\n",
      "[Trial 85] Epoch 34/60, Training Loss: 0.5947, Validation Loss: 0.5217\n",
      "[Trial 88] Epoch 20/60, Training Loss: 0.7392, Validation Loss: 0.7176\n",
      "[Trial 91] Epoch 6/60, Training Loss: 1.3499, Validation Loss: 1.0513\n",
      "[Trial 77] Epoch 47/60, Training Loss: 1.5918, Validation Loss: 1.1636\n",
      "[Trial 90] Epoch 11/60, Training Loss: 0.9637, Validation Loss: 0.7643\n",
      "[Trial 83] Epoch 35/60, Training Loss: 0.5766, Validation Loss: 0.4976\n",
      "[Trial 91] Epoch 7/60, Training Loss: 1.2487, Validation Loss: 1.0266\n",
      "[Trial 86] Epoch 32/60, Training Loss: 0.6094, Validation Loss: 0.5278\n",
      "[Trial 84] Epoch 35/60, Training Loss: 0.5660, Validation Loss: 0.5187\n",
      "[Trial 89] Epoch 9/60, Training Loss: 0.8860, Validation Loss: 0.6734\n",
      "[Trial 90] Epoch 12/60, Training Loss: 0.9324, Validation Loss: 0.8016\n",
      "[Trial 74] Epoch 56/60, Training Loss: 0.6140, Validation Loss: 0.5261\n",
      "[Trial 91] Epoch 8/60, Training Loss: 1.1741, Validation Loss: 0.9208\n",
      "[Trial 87] Epoch 29/60, Training Loss: 0.6829, Validation Loss: 0.6519\n",
      "[Trial 80] Epoch 39/60, Training Loss: 0.5648, Validation Loss: 0.5010\n",
      "[Trial 90] Epoch 13/60, Training Loss: 0.8874, Validation Loss: 0.7095\n",
      "[Trial 75] Epoch 51/60, Training Loss: 0.5765, Validation Loss: 0.5263\n",
      "[Trial 91] Epoch 9/60, Training Loss: 1.0996, Validation Loss: 0.8799\n",
      "[Trial 81] Epoch 38/60, Training Loss: 0.6866, Validation Loss: 0.5784\n",
      "[Trial 90] Epoch 14/60, Training Loss: 0.8843, Validation Loss: 0.6802\n",
      "[Trial 78] Epoch 46/60, Training Loss: 0.5742, Validation Loss: 0.4981\n",
      "[Trial 82] Epoch 37/60, Training Loss: 0.5964, Validation Loss: 0.5156\n",
      "[Trial 91] Epoch 10/60, Training Loss: 0.9881, Validation Loss: 0.7996\n",
      "[Trial 85] Epoch 35/60, Training Loss: 0.5945, Validation Loss: 0.5150\n",
      "[Trial 90] Epoch 15/60, Training Loss: 0.8604, Validation Loss: 0.7051\n",
      "[Trial 88] Epoch 21/60, Training Loss: 0.7347, Validation Loss: 0.6485\n",
      "[Trial 91] Epoch 11/60, Training Loss: 0.9638, Validation Loss: 0.8303\n",
      "[Trial 77] Epoch 48/60, Training Loss: 1.5785, Validation Loss: 1.1416\n",
      "[Trial 90] Epoch 16/60, Training Loss: 0.8507, Validation Loss: 0.6748\n",
      "[Trial 83] Epoch 36/60, Training Loss: 0.5745, Validation Loss: 0.5059\n",
      "[Trial 91] Epoch 12/60, Training Loss: 0.9181, Validation Loss: 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:06:54,424] Trial 84 finished with value: 0.5064465038478374 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.003587616659258842, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 84] Epoch 36/60, Training Loss: 0.5662, Validation Loss: 0.5212\n",
      "[Trial 84] Early stopping after 36 epochs.\n",
      "[Trial 86] Epoch 33/60, Training Loss: 0.6142, Validation Loss: 0.5467\n",
      "[Trial 89] Epoch 10/60, Training Loss: 0.8304, Validation Loss: 0.7520\n",
      "[Trial 90] Epoch 17/60, Training Loss: 0.7924, Validation Loss: 0.6715\n",
      "[Trial 74] Epoch 57/60, Training Loss: 0.6119, Validation Loss: 0.5432\n",
      "[Trial 91] Epoch 13/60, Training Loss: 0.9057, Validation Loss: 0.7024\n",
      "[Trial 92] Epoch 1/60, Training Loss: 6.4730, Validation Loss: 2.7395\n",
      "[Trial 87] Epoch 30/60, Training Loss: 0.6745, Validation Loss: 0.6027\n",
      "[Trial 80] Epoch 40/60, Training Loss: 0.5615, Validation Loss: 0.4929\n",
      "[Trial 90] Epoch 18/60, Training Loss: 0.8066, Validation Loss: 0.7643\n",
      "[Trial 75] Epoch 52/60, Training Loss: 0.5661, Validation Loss: 0.5228\n",
      "[Trial 91] Epoch 14/60, Training Loss: 0.8991, Validation Loss: 0.7637\n",
      "[Trial 81] Epoch 39/60, Training Loss: 0.6859, Validation Loss: 0.6441\n",
      "[Trial 92] Epoch 2/60, Training Loss: 2.2752, Validation Loss: 1.6130\n",
      "[Trial 90] Epoch 19/60, Training Loss: 0.7951, Validation Loss: 0.7882\n",
      "[Trial 78] Epoch 47/60, Training Loss: 0.5736, Validation Loss: 0.4832\n",
      "[Trial 82] Epoch 38/60, Training Loss: 0.5847, Validation Loss: 0.5094\n",
      "[Trial 91] Epoch 15/60, Training Loss: 0.8832, Validation Loss: 0.7293\n",
      "[Trial 92] Epoch 3/60, Training Loss: 1.7404, Validation Loss: 1.4327\n",
      "[Trial 85] Epoch 36/60, Training Loss: 0.5897, Validation Loss: 0.5209\n",
      "[Trial 90] Epoch 20/60, Training Loss: 0.8281, Validation Loss: 0.7033\n",
      "[Trial 88] Epoch 22/60, Training Loss: 0.7211, Validation Loss: 0.7290\n",
      "[Trial 92] Epoch 4/60, Training Loss: 1.5339, Validation Loss: 1.1530\n",
      "[Trial 91] Epoch 16/60, Training Loss: 0.8419, Validation Loss: 0.6674\n",
      "[Trial 77] Epoch 49/60, Training Loss: 1.5615, Validation Loss: 1.1625\n",
      "[Trial 90] Epoch 21/60, Training Loss: 0.7470, Validation Loss: 0.6416\n",
      "[Trial 83] Epoch 37/60, Training Loss: 0.5671, Validation Loss: 0.5013\n",
      "[Trial 92] Epoch 5/60, Training Loss: 1.3382, Validation Loss: 1.0322\n",
      "[Trial 91] Epoch 17/60, Training Loss: 0.8329, Validation Loss: 0.7021\n",
      "[Trial 89] Epoch 11/60, Training Loss: 0.8176, Validation Loss: 0.7244\n",
      "[Trial 86] Epoch 34/60, Training Loss: 0.6130, Validation Loss: 0.5233\n",
      "[Trial 74] Epoch 58/60, Training Loss: 0.6110, Validation Loss: 0.5376\n",
      "[Trial 90] Epoch 22/60, Training Loss: 0.7738, Validation Loss: 0.6636\n",
      "[Trial 92] Epoch 6/60, Training Loss: 1.2640, Validation Loss: 1.0686\n",
      "[Trial 91] Epoch 18/60, Training Loss: 0.8204, Validation Loss: 0.7457\n",
      "[Trial 80] Epoch 41/60, Training Loss: 0.5631, Validation Loss: 0.4892\n",
      "[Trial 87] Epoch 31/60, Training Loss: 0.6607, Validation Loss: 0.5636\n",
      "[Trial 90] Epoch 23/60, Training Loss: 0.7382, Validation Loss: 0.5875\n",
      "[Trial 92] Epoch 7/60, Training Loss: 1.1316, Validation Loss: 0.8690\n",
      "[Trial 75] Epoch 53/60, Training Loss: 0.5742, Validation Loss: 0.5247\n",
      "[Trial 81] Epoch 40/60, Training Loss: 0.6722, Validation Loss: 0.5940\n",
      "[Trial 91] Epoch 19/60, Training Loss: 0.8067, Validation Loss: 0.6808\n",
      "[Trial 90] Epoch 24/60, Training Loss: 0.7556, Validation Loss: 0.6230\n",
      "[Trial 78] Epoch 48/60, Training Loss: 0.5711, Validation Loss: 0.4890\n",
      "[Trial 82] Epoch 39/60, Training Loss: 0.5894, Validation Loss: 0.5119\n",
      "[Trial 92] Epoch 8/60, Training Loss: 1.0776, Validation Loss: 0.8477\n",
      "[Trial 91] Epoch 20/60, Training Loss: 0.7349, Validation Loss: 0.6340\n",
      "[Trial 85] Epoch 37/60, Training Loss: 0.5838, Validation Loss: 0.5032\n",
      "[Trial 90] Epoch 25/60, Training Loss: 0.7315, Validation Loss: 0.6164\n",
      "[Trial 88] Epoch 23/60, Training Loss: 0.7097, Validation Loss: 0.5604\n",
      "[Trial 92] Epoch 9/60, Training Loss: 1.0213, Validation Loss: 0.8864\n",
      "[Trial 91] Epoch 21/60, Training Loss: 0.7133, Validation Loss: 0.6057\n",
      "[Trial 77] Epoch 50/60, Training Loss: 1.5499, Validation Loss: 1.1177\n",
      "[Trial 90] Epoch 26/60, Training Loss: 0.7382, Validation Loss: 0.6951\n",
      "[Trial 89] Epoch 12/60, Training Loss: 0.8230, Validation Loss: 0.7209\n",
      "[Trial 74] Epoch 59/60, Training Loss: 0.6195, Validation Loss: 0.5375\n",
      "[Trial 92] Epoch 10/60, Training Loss: 0.9639, Validation Loss: 0.7435\n",
      "[Trial 83] Epoch 38/60, Training Loss: 0.5740, Validation Loss: 0.5176\n",
      "[Trial 91] Epoch 22/60, Training Loss: 0.7117, Validation Loss: 0.5965\n",
      "[Trial 86] Epoch 35/60, Training Loss: 0.6043, Validation Loss: 0.5121\n",
      "[Trial 90] Epoch 27/60, Training Loss: 0.7189, Validation Loss: 0.6253\n",
      "[Trial 92] Epoch 11/60, Training Loss: 0.9141, Validation Loss: 0.7628\n",
      "[Trial 91] Epoch 23/60, Training Loss: 0.7156, Validation Loss: 0.6035\n",
      "[Trial 80] Epoch 42/60, Training Loss: 0.5640, Validation Loss: 0.4975\n",
      "[Trial 87] Epoch 32/60, Training Loss: 0.6068, Validation Loss: 0.5184\n",
      "[Trial 90] Epoch 28/60, Training Loss: 0.7292, Validation Loss: 0.5682\n",
      "[Trial 92] Epoch 12/60, Training Loss: 0.9340, Validation Loss: 0.7833\n",
      "[Trial 91] Epoch 24/60, Training Loss: 0.6965, Validation Loss: 0.6133\n",
      "[Trial 81] Epoch 41/60, Training Loss: 0.6813, Validation Loss: 0.5590\n",
      "[Trial 75] Epoch 54/60, Training Loss: 0.5633, Validation Loss: 0.5191\n",
      "[Trial 78] Epoch 49/60, Training Loss: 0.5728, Validation Loss: 0.4817\n",
      "[Trial 90] Epoch 29/60, Training Loss: 0.6920, Validation Loss: 0.5882\n",
      "[Trial 92] Epoch 13/60, Training Loss: 0.9102, Validation Loss: 0.7594\n",
      "[Trial 82] Epoch 40/60, Training Loss: 0.5840, Validation Loss: 0.4965\n",
      "[Trial 91] Epoch 25/60, Training Loss: 0.7066, Validation Loss: 0.5722\n",
      "[Trial 85] Epoch 38/60, Training Loss: 0.5831, Validation Loss: 0.5021\n",
      "[Trial 90] Epoch 30/60, Training Loss: 0.6826, Validation Loss: 0.5507\n",
      "[Trial 88] Epoch 24/60, Training Loss: 0.6967, Validation Loss: 0.6082\n",
      "[Trial 92] Epoch 14/60, Training Loss: 0.8021, Validation Loss: 0.6679\n",
      "[Trial 91] Epoch 26/60, Training Loss: 0.6945, Validation Loss: 0.5593\n",
      "[Trial 77] Epoch 51/60, Training Loss: 1.5455, Validation Loss: 1.1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:12:03,940] Trial 74 finished with value: 0.526102623840173 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0037685369728457105, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 74] Epoch 60/60, Training Loss: 0.6153, Validation Loss: 0.5375\n",
      "[Trial 90] Epoch 31/60, Training Loss: 0.7023, Validation Loss: 0.6138\n",
      "[Trial 89] Epoch 13/60, Training Loss: 0.8170, Validation Loss: 0.6340\n",
      "[Trial 92] Epoch 15/60, Training Loss: 0.8154, Validation Loss: 0.6493\n",
      "[Trial 91] Epoch 27/60, Training Loss: 0.6872, Validation Loss: 0.6017\n",
      "[Trial 83] Epoch 39/60, Training Loss: 0.5580, Validation Loss: 0.4909\n",
      "[Trial 86] Epoch 36/60, Training Loss: 0.5994, Validation Loss: 0.5184\n",
      "[Trial 90] Epoch 32/60, Training Loss: 0.7014, Validation Loss: 0.5827\n",
      "[Trial 93] Epoch 1/60, Training Loss: 6.3783, Validation Loss: 2.6280\n",
      "[Trial 92] Epoch 16/60, Training Loss: 0.7908, Validation Loss: 0.6378\n",
      "[Trial 91] Epoch 28/60, Training Loss: 0.6772, Validation Loss: 0.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:12:41,432] Trial 80 finished with value: 0.48214498460292815 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.003659788984119821, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 80] Epoch 43/60, Training Loss: 0.5624, Validation Loss: 0.4916\n",
      "[Trial 80] Early stopping after 43 epochs.\n",
      "[Trial 87] Epoch 33/60, Training Loss: 0.6175, Validation Loss: 0.5374\n",
      "[Trial 90] Epoch 33/60, Training Loss: 0.7042, Validation Loss: 0.6042\n",
      "[Trial 93] Epoch 2/60, Training Loss: 2.3634, Validation Loss: 1.7584\n",
      "[Trial 92] Epoch 17/60, Training Loss: 0.7653, Validation Loss: 0.6190\n",
      "[Trial 91] Epoch 29/60, Training Loss: 0.6867, Validation Loss: 0.5844\n",
      "[Trial 81] Epoch 42/60, Training Loss: 0.6834, Validation Loss: 0.7068\n",
      "[Trial 75] Epoch 55/60, Training Loss: 0.5656, Validation Loss: 0.5492\n",
      "[Trial 94] Epoch 1/60, Training Loss: 6.4318, Validation Loss: 2.4048\n",
      "[Trial 78] Epoch 50/60, Training Loss: 0.5709, Validation Loss: 0.4842\n",
      "[Trial 90] Epoch 34/60, Training Loss: 0.6723, Validation Loss: 0.5801\n",
      "[Trial 93] Epoch 3/60, Training Loss: 1.8819, Validation Loss: 1.4748\n",
      "[Trial 92] Epoch 18/60, Training Loss: 0.7579, Validation Loss: 0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:13:19,468] Trial 91 finished with value: 0.5593066891034444 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.007441641673892737, 'batch_size': 64, 'patience': 4}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 91] Epoch 30/60, Training Loss: 0.6417, Validation Loss: 0.5602\n",
      "[Trial 91] Early stopping after 30 epochs.\n",
      "[Trial 82] Epoch 41/60, Training Loss: 0.5802, Validation Loss: 0.4942\n",
      "[Trial 94] Epoch 2/60, Training Loss: 2.3261, Validation Loss: 1.7437\n",
      "[Trial 85] Epoch 39/60, Training Loss: 0.5786, Validation Loss: 0.4979\n",
      "[Trial 90] Epoch 35/60, Training Loss: 0.6628, Validation Loss: 0.5527\n",
      "[Trial 93] Epoch 4/60, Training Loss: 1.6523, Validation Loss: 1.2781\n",
      "[Trial 88] Epoch 25/60, Training Loss: 0.7144, Validation Loss: 0.6590\n",
      "[Trial 92] Epoch 19/60, Training Loss: 0.7428, Validation Loss: 0.6496\n",
      "[Trial 77] Epoch 52/60, Training Loss: 1.5419, Validation Loss: 1.1178\n",
      "[Trial 94] Epoch 3/60, Training Loss: 1.9416, Validation Loss: 1.5787\n",
      "[Trial 89] Epoch 14/60, Training Loss: 0.8079, Validation Loss: 0.8974\n",
      "[Trial 90] Epoch 36/60, Training Loss: 0.6629, Validation Loss: 0.5675\n",
      "[Trial 93] Epoch 5/60, Training Loss: 1.3922, Validation Loss: 1.1662\n",
      "[Trial 92] Epoch 20/60, Training Loss: 0.7597, Validation Loss: 0.6446\n",
      "[Trial 83] Epoch 40/60, Training Loss: 0.5626, Validation Loss: 0.5014\n",
      "[Trial 86] Epoch 37/60, Training Loss: 0.5916, Validation Loss: 0.5135\n",
      "[Trial 94] Epoch 4/60, Training Loss: 1.7085, Validation Loss: 1.2668\n",
      "[Trial 90] Epoch 37/60, Training Loss: 0.6337, Validation Loss: 0.5134\n",
      "[Trial 93] Epoch 6/60, Training Loss: 1.2632, Validation Loss: 1.0314\n",
      "[Trial 95] Epoch 1/60, Training Loss: 4.7108, Validation Loss: 2.0779\n",
      "[Trial 92] Epoch 21/60, Training Loss: 0.7159, Validation Loss: 0.6017\n",
      "[Trial 94] Epoch 5/60, Training Loss: 1.4528, Validation Loss: 1.0997\n",
      "[Trial 87] Epoch 34/60, Training Loss: 0.6092, Validation Loss: 0.5156\n",
      "[Trial 90] Epoch 38/60, Training Loss: 0.6218, Validation Loss: 0.5182\n",
      "[Trial 93] Epoch 7/60, Training Loss: 1.1683, Validation Loss: 0.9099\n",
      "[Trial 92] Epoch 22/60, Training Loss: 0.7011, Validation Loss: 0.5982\n",
      "[Trial 81] Epoch 43/60, Training Loss: 0.6693, Validation Loss: 0.6162\n",
      "[Trial 75] Epoch 56/60, Training Loss: 0.5640, Validation Loss: 0.5037\n",
      "[Trial 94] Epoch 6/60, Training Loss: 1.3326, Validation Loss: 1.0150\n",
      "[Trial 78] Epoch 51/60, Training Loss: 0.5775, Validation Loss: 0.4965\n",
      "[Trial 90] Epoch 39/60, Training Loss: 0.6154, Validation Loss: 0.5274\n",
      "[Trial 93] Epoch 8/60, Training Loss: 1.1101, Validation Loss: 0.9597\n",
      "[Trial 92] Epoch 23/60, Training Loss: 0.7006, Validation Loss: 0.5884\n",
      "[Trial 82] Epoch 42/60, Training Loss: 0.5781, Validation Loss: 0.4912\n",
      "[Trial 85] Epoch 40/60, Training Loss: 0.5822, Validation Loss: 0.5055\n",
      "[Trial 95] Epoch 2/60, Training Loss: 2.0864, Validation Loss: 1.7611\n",
      "[Trial 94] Epoch 7/60, Training Loss: 1.2499, Validation Loss: 1.0871\n",
      "[Trial 90] Epoch 40/60, Training Loss: 0.6210, Validation Loss: 0.5426\n",
      "[Trial 88] Epoch 26/60, Training Loss: 0.6923, Validation Loss: 0.6120\n",
      "[Trial 93] Epoch 9/60, Training Loss: 1.0769, Validation Loss: 0.8618\n",
      "[Trial 92] Epoch 24/60, Training Loss: 0.6980, Validation Loss: 0.5789\n",
      "[Trial 89] Epoch 15/60, Training Loss: 0.7962, Validation Loss: 0.7069\n",
      "[Trial 77] Epoch 53/60, Training Loss: 1.5204, Validation Loss: 1.1408\n",
      "[Trial 94] Epoch 8/60, Training Loss: 1.1347, Validation Loss: 0.9143\n",
      "[Trial 90] Epoch 41/60, Training Loss: 0.6149, Validation Loss: 0.5326\n",
      "[Trial 93] Epoch 10/60, Training Loss: 1.0135, Validation Loss: 0.8566\n",
      "[Trial 92] Epoch 25/60, Training Loss: 0.6994, Validation Loss: 0.5929\n",
      "[Trial 86] Epoch 38/60, Training Loss: 0.5962, Validation Loss: 0.5162\n",
      "[Trial 83] Epoch 41/60, Training Loss: 0.5567, Validation Loss: 0.5126\n",
      "[Trial 94] Epoch 9/60, Training Loss: 1.0754, Validation Loss: 0.8506\n",
      "[Trial 90] Epoch 42/60, Training Loss: 0.6077, Validation Loss: 0.5075\n",
      "[Trial 93] Epoch 11/60, Training Loss: 0.9657, Validation Loss: 0.8285\n",
      "[Trial 92] Epoch 26/60, Training Loss: 0.6847, Validation Loss: 0.5780\n",
      "[Trial 95] Epoch 3/60, Training Loss: 1.6093, Validation Loss: 1.5628\n",
      "[Trial 94] Epoch 10/60, Training Loss: 1.0056, Validation Loss: 0.8101\n",
      "[Trial 87] Epoch 35/60, Training Loss: 0.6077, Validation Loss: 0.5375\n",
      "[Trial 90] Epoch 43/60, Training Loss: 0.6181, Validation Loss: 0.5318\n",
      "[Trial 93] Epoch 12/60, Training Loss: 0.9161, Validation Loss: 0.7385\n",
      "[Trial 92] Epoch 27/60, Training Loss: 0.6885, Validation Loss: 0.5772\n",
      "[Trial 81] Epoch 44/60, Training Loss: 0.6690, Validation Loss: 0.5793\n",
      "[Trial 78] Epoch 52/60, Training Loss: 0.5668, Validation Loss: 0.4927\n",
      "[Trial 75] Epoch 57/60, Training Loss: 0.5655, Validation Loss: 0.5122\n",
      "[Trial 94] Epoch 11/60, Training Loss: 1.0021, Validation Loss: 0.7998\n",
      "[Trial 90] Epoch 44/60, Training Loss: 0.6188, Validation Loss: 0.5130\n",
      "[Trial 93] Epoch 13/60, Training Loss: 0.9084, Validation Loss: 0.7918\n",
      "[Trial 92] Epoch 28/60, Training Loss: 0.6943, Validation Loss: 0.5796\n",
      "[Trial 82] Epoch 43/60, Training Loss: 0.5784, Validation Loss: 0.4977\n",
      "[Trial 85] Epoch 41/60, Training Loss: 0.5787, Validation Loss: 0.5054\n",
      "[Trial 94] Epoch 12/60, Training Loss: 0.9557, Validation Loss: 0.8371\n",
      "[Trial 90] Epoch 45/60, Training Loss: 0.6101, Validation Loss: 0.5139\n",
      "[Trial 95] Epoch 4/60, Training Loss: 1.3485, Validation Loss: 1.5768\n",
      "[Trial 88] Epoch 27/60, Training Loss: 0.7046, Validation Loss: 0.7402\n",
      "[Trial 93] Epoch 14/60, Training Loss: 0.8705, Validation Loss: 0.7480\n",
      "[Trial 92] Epoch 29/60, Training Loss: 0.6850, Validation Loss: 0.5813\n",
      "[Trial 89] Epoch 16/60, Training Loss: 0.7871, Validation Loss: 0.6497\n",
      "[Trial 77] Epoch 54/60, Training Loss: 1.5259, Validation Loss: 1.1269\n",
      "[Trial 94] Epoch 13/60, Training Loss: 0.9395, Validation Loss: 0.7450\n",
      "[Trial 90] Epoch 46/60, Training Loss: 0.6056, Validation Loss: 0.5203\n",
      "[Trial 93] Epoch 15/60, Training Loss: 0.8665, Validation Loss: 0.8003\n",
      "[Trial 92] Epoch 30/60, Training Loss: 0.6675, Validation Loss: 0.5507\n",
      "[Trial 94] Epoch 14/60, Training Loss: 0.8744, Validation Loss: 0.7851\n",
      "[Trial 86] Epoch 39/60, Training Loss: 0.5937, Validation Loss: 0.5121\n",
      "[Trial 90] Epoch 47/60, Training Loss: 0.6050, Validation Loss: 0.5129\n",
      "[Trial 83] Epoch 42/60, Training Loss: 0.5584, Validation Loss: 0.5047\n",
      "[Trial 92] Epoch 31/60, Training Loss: 0.6721, Validation Loss: 0.5747\n",
      "[Trial 93] Epoch 16/60, Training Loss: 0.7906, Validation Loss: 0.6723\n",
      "[Trial 95] Epoch 5/60, Training Loss: 1.1223, Validation Loss: 1.4966\n",
      "[Trial 94] Epoch 15/60, Training Loss: 0.8607, Validation Loss: 0.7338\n",
      "[Trial 87] Epoch 36/60, Training Loss: 0.6032, Validation Loss: 0.5228\n",
      "[Trial 90] Epoch 48/60, Training Loss: 0.6163, Validation Loss: 0.5273\n",
      "[Trial 92] Epoch 32/60, Training Loss: 0.6630, Validation Loss: 0.5469\n",
      "[Trial 93] Epoch 17/60, Training Loss: 0.7664, Validation Loss: 0.6628\n",
      "[Trial 78] Epoch 53/60, Training Loss: 0.5651, Validation Loss: 0.4897\n",
      "[Trial 81] Epoch 45/60, Training Loss: 0.6667, Validation Loss: 0.6403\n",
      "[Trial 94] Epoch 16/60, Training Loss: 0.8458, Validation Loss: 0.6872\n",
      "[Trial 75] Epoch 58/60, Training Loss: 0.5649, Validation Loss: 0.5187\n",
      "[Trial 90] Epoch 49/60, Training Loss: 0.5888, Validation Loss: 0.4967\n",
      "[Trial 92] Epoch 33/60, Training Loss: 0.6577, Validation Loss: 0.5667\n",
      "[Trial 93] Epoch 18/60, Training Loss: 0.7694, Validation Loss: 0.6381\n",
      "[Trial 82] Epoch 44/60, Training Loss: 0.5815, Validation Loss: 0.4933\n",
      "[Trial 85] Epoch 42/60, Training Loss: 0.5767, Validation Loss: 0.5057\n",
      "[Trial 94] Epoch 17/60, Training Loss: 0.8365, Validation Loss: 0.6461\n",
      "[Trial 90] Epoch 50/60, Training Loss: 0.5838, Validation Loss: 0.5023\n",
      "[Trial 88] Epoch 28/60, Training Loss: 0.6888, Validation Loss: 0.5608\n",
      "[Trial 89] Epoch 17/60, Training Loss: 0.7646, Validation Loss: 0.7150\n",
      "[Trial 92] Epoch 34/60, Training Loss: 0.6616, Validation Loss: 0.5589\n",
      "[Trial 93] Epoch 19/60, Training Loss: 0.7428, Validation Loss: 0.6495\n",
      "[Trial 95] Epoch 6/60, Training Loss: 1.0283, Validation Loss: 1.0785\n",
      "[Trial 77] Epoch 55/60, Training Loss: 1.5010, Validation Loss: 1.0962\n",
      "[Trial 94] Epoch 18/60, Training Loss: 0.8212, Validation Loss: 0.6618\n",
      "[Trial 90] Epoch 51/60, Training Loss: 0.5769, Validation Loss: 0.4905\n",
      "[Trial 92] Epoch 35/60, Training Loss: 0.6635, Validation Loss: 0.5388\n",
      "[Trial 93] Epoch 20/60, Training Loss: 0.7516, Validation Loss: 0.6192\n",
      "[Trial 94] Epoch 19/60, Training Loss: 0.8190, Validation Loss: 0.6869\n",
      "[Trial 90] Epoch 52/60, Training Loss: 0.5747, Validation Loss: 0.4884\n",
      "[Trial 86] Epoch 40/60, Training Loss: 0.5914, Validation Loss: 0.5144\n",
      "[Trial 83] Epoch 43/60, Training Loss: 0.5509, Validation Loss: 0.4901\n",
      "[Trial 92] Epoch 36/60, Training Loss: 0.6509, Validation Loss: 0.5688\n",
      "[Trial 93] Epoch 21/60, Training Loss: 0.7428, Validation Loss: 0.6092\n",
      "[Trial 87] Epoch 37/60, Training Loss: 0.6117, Validation Loss: 0.5597\n",
      "[Trial 94] Epoch 20/60, Training Loss: 0.7836, Validation Loss: 0.7199\n",
      "[Trial 90] Epoch 53/60, Training Loss: 0.5730, Validation Loss: 0.4879\n",
      "[Trial 95] Epoch 7/60, Training Loss: 0.9876, Validation Loss: 1.2377\n",
      "[Trial 92] Epoch 37/60, Training Loss: 0.6559, Validation Loss: 0.5647\n",
      "[Trial 93] Epoch 22/60, Training Loss: 0.7518, Validation Loss: 0.6549\n",
      "[Trial 78] Epoch 54/60, Training Loss: 0.5640, Validation Loss: 0.4749\n",
      "[Trial 81] Epoch 46/60, Training Loss: 0.6622, Validation Loss: 0.7057\n",
      "[Trial 94] Epoch 21/60, Training Loss: 0.7312, Validation Loss: 0.5850\n",
      "[Trial 75] Epoch 59/60, Training Loss: 0.5626, Validation Loss: 0.5307\n",
      "[Trial 90] Epoch 54/60, Training Loss: 0.5805, Validation Loss: 0.4841\n",
      "[Trial 92] Epoch 38/60, Training Loss: 0.6520, Validation Loss: 0.5506\n",
      "[Trial 93] Epoch 23/60, Training Loss: 0.7567, Validation Loss: 0.6350\n",
      "[Trial 85] Epoch 43/60, Training Loss: 0.5747, Validation Loss: 0.4991\n",
      "[Trial 82] Epoch 45/60, Training Loss: 0.5857, Validation Loss: 0.4956\n",
      "[Trial 89] Epoch 18/60, Training Loss: 0.7689, Validation Loss: 0.6429\n",
      "[Trial 94] Epoch 22/60, Training Loss: 0.7236, Validation Loss: 0.6092\n",
      "[Trial 90] Epoch 55/60, Training Loss: 0.5759, Validation Loss: 0.4853\n",
      "[Trial 88] Epoch 29/60, Training Loss: 0.6889, Validation Loss: 0.5876\n",
      "[Trial 92] Epoch 39/60, Training Loss: 0.6221, Validation Loss: 0.5213\n",
      "[Trial 93] Epoch 24/60, Training Loss: 0.7345, Validation Loss: 0.6447\n",
      "[Trial 77] Epoch 56/60, Training Loss: 1.5098, Validation Loss: 1.1083\n",
      "[Trial 95] Epoch 8/60, Training Loss: 1.0599, Validation Loss: 0.8850\n",
      "[Trial 94] Epoch 23/60, Training Loss: 0.7203, Validation Loss: 0.6378\n",
      "[Trial 90] Epoch 56/60, Training Loss: 0.5726, Validation Loss: 0.4894\n",
      "[Trial 92] Epoch 40/60, Training Loss: 0.6138, Validation Loss: 0.5429\n",
      "[Trial 93] Epoch 25/60, Training Loss: 0.7060, Validation Loss: 0.5927\n",
      "[Trial 86] Epoch 41/60, Training Loss: 0.5893, Validation Loss: 0.4977\n",
      "[Trial 90] Epoch 57/60, Training Loss: 0.5760, Validation Loss: 0.4928\n",
      "[Trial 94] Epoch 24/60, Training Loss: 0.7056, Validation Loss: 0.5660\n",
      "[Trial 92] Epoch 41/60, Training Loss: 0.6158, Validation Loss: 0.5227\n",
      "[Trial 83] Epoch 44/60, Training Loss: 0.5552, Validation Loss: 0.5035\n",
      "[Trial 93] Epoch 26/60, Training Loss: 0.6832, Validation Loss: 0.5968\n",
      "[Trial 87] Epoch 38/60, Training Loss: 0.5986, Validation Loss: 0.5113\n",
      "[Trial 90] Epoch 58/60, Training Loss: 0.5751, Validation Loss: 0.4934\n",
      "[Trial 94] Epoch 25/60, Training Loss: 0.7031, Validation Loss: 0.5578\n",
      "[Trial 92] Epoch 42/60, Training Loss: 0.6239, Validation Loss: 0.5308\n",
      "[Trial 95] Epoch 9/60, Training Loss: 0.9406, Validation Loss: 0.9378\n",
      "[Trial 78] Epoch 55/60, Training Loss: 0.5620, Validation Loss: 0.4859\n",
      "[Trial 93] Epoch 27/60, Training Loss: 0.6806, Validation Loss: 0.5667\n",
      "[Trial 81] Epoch 47/60, Training Loss: 0.6856, Validation Loss: 0.6371\n",
      "[Trial 90] Epoch 59/60, Training Loss: 0.5717, Validation Loss: 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:22:11,713] Trial 75 finished with value: 0.5037202623983225 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.0036916357341713036, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 94] Epoch 26/60, Training Loss: 0.7020, Validation Loss: 0.5666\n",
      "[Trial 75] Epoch 60/60, Training Loss: 0.5671, Validation Loss: 0.5282\n",
      "[Trial 92] Epoch 43/60, Training Loss: 0.6073, Validation Loss: 0.5158\n",
      "[Trial 93] Epoch 28/60, Training Loss: 0.6840, Validation Loss: 0.5844\n",
      "[Trial 89] Epoch 19/60, Training Loss: 0.7590, Validation Loss: 0.6705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:22:27,343] Trial 85 finished with value: 0.4978992814819018 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0034295799064121535, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 85] Epoch 44/60, Training Loss: 0.5703, Validation Loss: 0.5120\n",
      "[Trial 85] Early stopping after 44 epochs.\n",
      "[Trial 82] Epoch 46/60, Training Loss: 0.5780, Validation Loss: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:22:32,340] Trial 90 finished with value: 0.484096239010493 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006943754864185656, 'batch_size': 64, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 90] Epoch 60/60, Training Loss: 0.5737, Validation Loss: 0.4909\n",
      "[Trial 88] Epoch 30/60, Training Loss: 0.6229, Validation Loss: 0.5386\n",
      "[Trial 94] Epoch 27/60, Training Loss: 0.6937, Validation Loss: 0.5763\n",
      "[Trial 92] Epoch 44/60, Training Loss: 0.6013, Validation Loss: 0.5120\n",
      "[Trial 77] Epoch 57/60, Training Loss: 1.4986, Validation Loss: 1.1003\n",
      "[Trial 93] Epoch 29/60, Training Loss: 0.6849, Validation Loss: 0.5912\n",
      "[Trial 95] Epoch 10/60, Training Loss: 0.8829, Validation Loss: 0.9197\n",
      "[Trial 94] Epoch 28/60, Training Loss: 0.6876, Validation Loss: 0.5610\n",
      "[Trial 92] Epoch 45/60, Training Loss: 0.6004, Validation Loss: 0.5153\n",
      "[Trial 93] Epoch 30/60, Training Loss: 0.6718, Validation Loss: 0.6027\n",
      "[Trial 96] Epoch 1/60, Training Loss: 4.2318, Validation Loss: 2.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:23:18,222] Trial 94 finished with value: 0.55781462987264 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.007450367656908293, 'batch_size': 64, 'patience': 4}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 94] Epoch 29/60, Training Loss: 0.6637, Validation Loss: 0.5661\n",
      "[Trial 94] Early stopping after 29 epochs.\n",
      "[Trial 86] Epoch 42/60, Training Loss: 0.5925, Validation Loss: 0.5058\n",
      "[Trial 92] Epoch 46/60, Training Loss: 0.6046, Validation Loss: 0.5134\n",
      "[Trial 83] Epoch 45/60, Training Loss: 0.5505, Validation Loss: 0.4905\n",
      "[Trial 97] Epoch 1/60, Training Loss: 3.6519, Validation Loss: 1.6467\n",
      "[Trial 93] Epoch 31/60, Training Loss: 0.6595, Validation Loss: 0.5549\n",
      "[Trial 87] Epoch 39/60, Training Loss: 0.6007, Validation Loss: 0.5056\n",
      "[Trial 98] Epoch 1/60, Training Loss: 8.8172, Validation Loss: 2.9116\n",
      "[Trial 92] Epoch 47/60, Training Loss: 0.6030, Validation Loss: 0.5110\n",
      "[Trial 78] Epoch 56/60, Training Loss: 0.5638, Validation Loss: 0.4834\n",
      "[Trial 93] Epoch 32/60, Training Loss: 0.6471, Validation Loss: 0.5464\n",
      "[Trial 95] Epoch 11/60, Training Loss: 0.7950, Validation Loss: 0.6735\n",
      "[Trial 81] Epoch 48/60, Training Loss: 0.6257, Validation Loss: 0.5142\n",
      "[Trial 92] Epoch 48/60, Training Loss: 0.5993, Validation Loss: 0.5143\n",
      "[Trial 89] Epoch 20/60, Training Loss: 0.6822, Validation Loss: 0.6187\n",
      "[Trial 93] Epoch 33/60, Training Loss: 0.6447, Validation Loss: 0.5575\n",
      "[Trial 99] Epoch 1/60, Training Loss: 5.0915, Validation Loss: 3.0457\n",
      "[Trial 96] Epoch 2/60, Training Loss: 2.1578, Validation Loss: 1.4895\n",
      "[Trial 82] Epoch 47/60, Training Loss: 0.5736, Validation Loss: 0.4908\n",
      "[Trial 88] Epoch 31/60, Training Loss: 0.6116, Validation Loss: 0.5906\n",
      "[Trial 92] Epoch 49/60, Training Loss: 0.5987, Validation Loss: 0.5177\n",
      "[Trial 97] Epoch 2/60, Training Loss: 1.8995, Validation Loss: 1.3367\n",
      "[Trial 77] Epoch 58/60, Training Loss: 1.4815, Validation Loss: 1.1083\n",
      "[Trial 98] Epoch 2/60, Training Loss: 2.5510, Validation Loss: 2.1341\n",
      "[Trial 93] Epoch 34/60, Training Loss: 0.6407, Validation Loss: 0.5547\n",
      "[Trial 92] Epoch 50/60, Training Loss: 0.5928, Validation Loss: 0.5055\n",
      "[Trial 95] Epoch 12/60, Training Loss: 0.7843, Validation Loss: 0.6452\n",
      "[Trial 93] Epoch 35/60, Training Loss: 0.6402, Validation Loss: 0.5647\n",
      "[Trial 86] Epoch 43/60, Training Loss: 0.5836, Validation Loss: 0.4939\n",
      "[Trial 92] Epoch 51/60, Training Loss: 0.5989, Validation Loss: 0.5166\n",
      "[Trial 83] Epoch 46/60, Training Loss: 0.5496, Validation Loss: 0.4883\n",
      "[Trial 93] Epoch 36/60, Training Loss: 0.6360, Validation Loss: 0.5347\n",
      "[Trial 99] Epoch 2/60, Training Loss: 2.1851, Validation Loss: 1.9722\n",
      "[Trial 87] Epoch 40/60, Training Loss: 0.5971, Validation Loss: 0.5173\n",
      "[Trial 96] Epoch 3/60, Training Loss: 1.9139, Validation Loss: 1.5831\n",
      "[Trial 97] Epoch 3/60, Training Loss: 1.6263, Validation Loss: 1.1190\n",
      "[Trial 92] Epoch 52/60, Training Loss: 0.5930, Validation Loss: 0.5087\n",
      "[Trial 98] Epoch 3/60, Training Loss: 2.0215, Validation Loss: 3.3103\n",
      "[Trial 78] Epoch 57/60, Training Loss: 0.5656, Validation Loss: 0.4846\n",
      "[Trial 93] Epoch 37/60, Training Loss: 0.6333, Validation Loss: 0.5461\n",
      "[Trial 81] Epoch 49/60, Training Loss: 0.6162, Validation Loss: 0.5306\n",
      "[Trial 95] Epoch 13/60, Training Loss: 0.7573, Validation Loss: 0.6531\n",
      "[Trial 89] Epoch 21/60, Training Loss: 0.6688, Validation Loss: 0.6386\n",
      "[Trial 92] Epoch 53/60, Training Loss: 0.5950, Validation Loss: 0.5065\n",
      "[Trial 93] Epoch 38/60, Training Loss: 0.6334, Validation Loss: 0.5367\n",
      "[Trial 88] Epoch 32/60, Training Loss: 0.6187, Validation Loss: 0.5443\n",
      "[Trial 82] Epoch 48/60, Training Loss: 0.5830, Validation Loss: 0.4972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:26:19,064] Trial 92 finished with value: 0.5055178741614024 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.007304381366324452, 'batch_size': 64, 'patience': 4}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 92] Epoch 54/60, Training Loss: 0.5852, Validation Loss: 0.5074\n",
      "[Trial 92] Early stopping after 54 epochs.\n",
      "[Trial 77] Epoch 59/60, Training Loss: 1.4868, Validation Loss: 1.1077\n",
      "[Trial 99] Epoch 3/60, Training Loss: 1.7150, Validation Loss: 1.5480\n",
      "[Trial 96] Epoch 4/60, Training Loss: 1.7507, Validation Loss: 1.3076\n",
      "[Trial 93] Epoch 39/60, Training Loss: 0.6276, Validation Loss: 0.5450\n",
      "[Trial 97] Epoch 4/60, Training Loss: 1.4763, Validation Loss: 1.0799\n",
      "[Trial 98] Epoch 4/60, Training Loss: 1.7131, Validation Loss: 2.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:26:52,292] Trial 93 finished with value: 0.5346538702646891 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.00756514504207101, 'batch_size': 64, 'patience': 4}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 93] Epoch 40/60, Training Loss: 0.6298, Validation Loss: 0.5386\n",
      "[Trial 93] Early stopping after 40 epochs.\n",
      "[Trial 95] Epoch 14/60, Training Loss: 0.7541, Validation Loss: 0.7218\n",
      "[Trial 86] Epoch 44/60, Training Loss: 0.5868, Validation Loss: 0.5123\n",
      "[Trial 83] Epoch 47/60, Training Loss: 0.5524, Validation Loss: 0.4822\n",
      "[Trial 87] Epoch 41/60, Training Loss: 0.5897, Validation Loss: 0.5444\n",
      "[Trial 100] Epoch 1/60, Training Loss: 8.1992, Validation Loss: 2.5469\n",
      "[Trial 99] Epoch 4/60, Training Loss: 1.4247, Validation Loss: 1.2615\n",
      "[Trial 78] Epoch 58/60, Training Loss: 0.5625, Validation Loss: 0.4790\n",
      "[Trial 96] Epoch 5/60, Training Loss: 1.6795, Validation Loss: 1.1624\n",
      "[Trial 97] Epoch 5/60, Training Loss: 1.3542, Validation Loss: 1.0354\n",
      "[Trial 89] Epoch 22/60, Training Loss: 0.6729, Validation Loss: 0.7001\n",
      "[Trial 81] Epoch 50/60, Training Loss: 0.6171, Validation Loss: 0.5350\n",
      "[Trial 98] Epoch 5/60, Training Loss: 1.4517, Validation Loss: 1.2662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:27:52,314] Trial 95 finished with value: 0.645164322356383 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.012779703231665421, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 95] Epoch 15/60, Training Loss: 0.7679, Validation Loss: 0.6604\n",
      "[Trial 95] Early stopping after 15 epochs.\n",
      "[Trial 101] Epoch 1/60, Training Loss: 4.4947, Validation Loss: 1.9570\n",
      "[Trial 88] Epoch 33/60, Training Loss: 0.6178, Validation Loss: 0.4985\n",
      "[Trial 82] Epoch 49/60, Training Loss: 0.5795, Validation Loss: 0.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:28:14,513] Trial 77 finished with value: 1.096200387676557 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 1.1759720179344414e-05, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 77] Epoch 60/60, Training Loss: 1.4886, Validation Loss: 1.1104\n",
      "[Trial 77] Early stopping after 60 epochs.\n",
      "[Trial 100] Epoch 2/60, Training Loss: 2.5247, Validation Loss: 2.3772\n",
      "[Trial 99] Epoch 5/60, Training Loss: 1.2758, Validation Loss: 1.1051\n",
      "[Trial 97] Epoch 6/60, Training Loss: 1.2739, Validation Loss: 1.0273\n",
      "[Trial 96] Epoch 6/60, Training Loss: 1.5153, Validation Loss: 1.1460\n",
      "[Trial 98] Epoch 6/60, Training Loss: 1.2726, Validation Loss: 1.0367\n",
      "[Trial 102] Epoch 1/60, Training Loss: 3.8704, Validation Loss: 1.9238\n",
      "[Trial 86] Epoch 45/60, Training Loss: 0.5863, Validation Loss: 0.5016\n",
      "[Trial 101] Epoch 2/60, Training Loss: 2.1822, Validation Loss: 1.7303\n",
      "[Trial 83] Epoch 48/60, Training Loss: 0.5515, Validation Loss: 0.4877\n",
      "[Trial 87] Epoch 42/60, Training Loss: 0.5988, Validation Loss: 0.5282\n",
      "[Trial 103] Epoch 1/60, Training Loss: 3.9958, Validation Loss: 2.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:29:21,709] Trial 78 finished with value: 0.47488293374578155 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0037595180658528678, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 78] Epoch 59/60, Training Loss: 0.5628, Validation Loss: 0.4801\n",
      "[Trial 78] Early stopping after 59 epochs.\n",
      "[Trial 100] Epoch 3/60, Training Loss: 1.9026, Validation Loss: 1.4713\n",
      "[Trial 89] Epoch 23/60, Training Loss: 0.6728, Validation Loss: 0.5816\n",
      "[Trial 99] Epoch 6/60, Training Loss: 1.1285, Validation Loss: 1.0205\n",
      "[Trial 81] Epoch 51/60, Training Loss: 0.6163, Validation Loss: 0.5634\n",
      "[Trial 97] Epoch 7/60, Training Loss: 1.1988, Validation Loss: 0.9734\n",
      "[Trial 96] Epoch 7/60, Training Loss: 1.4285, Validation Loss: 1.2573\n",
      "[Trial 98] Epoch 7/60, Training Loss: 1.1299, Validation Loss: 3.4289\n",
      "[Trial 88] Epoch 34/60, Training Loss: 0.6086, Validation Loss: 0.5099\n",
      "[Trial 102] Epoch 2/60, Training Loss: 2.0896, Validation Loss: 1.4862\n",
      "[Trial 82] Epoch 50/60, Training Loss: 0.5737, Validation Loss: 0.4949\n",
      "[Trial 101] Epoch 3/60, Training Loss: 1.9270, Validation Loss: 1.4249\n",
      "[Trial 104] Epoch 1/60, Training Loss: 4.6429, Validation Loss: 2.1679\n",
      "[Trial 103] Epoch 2/60, Training Loss: 2.0592, Validation Loss: 1.5584\n",
      "[Trial 100] Epoch 4/60, Training Loss: 1.5057, Validation Loss: 1.1154\n",
      "[Trial 99] Epoch 7/60, Training Loss: 1.0047, Validation Loss: 0.9292\n",
      "[Trial 97] Epoch 8/60, Training Loss: 1.1363, Validation Loss: 0.8604\n",
      "[Trial 96] Epoch 8/60, Training Loss: 1.3633, Validation Loss: 0.9998\n",
      "[Trial 86] Epoch 46/60, Training Loss: 0.5825, Validation Loss: 0.5078\n",
      "[Trial 98] Epoch 8/60, Training Loss: 1.1731, Validation Loss: 1.5102\n",
      "[Trial 87] Epoch 43/60, Training Loss: 0.5907, Validation Loss: 0.5082\n",
      "[Trial 83] Epoch 49/60, Training Loss: 0.5504, Validation Loss: 0.4870\n",
      "[Trial 102] Epoch 3/60, Training Loss: 1.8991, Validation Loss: 1.3997\n",
      "[Trial 101] Epoch 4/60, Training Loss: 1.7777, Validation Loss: 1.2143\n",
      "[Trial 89] Epoch 24/60, Training Loss: 0.6690, Validation Loss: 0.6067\n",
      "[Trial 104] Epoch 2/60, Training Loss: 2.2421, Validation Loss: 1.6385\n",
      "[Trial 103] Epoch 3/60, Training Loss: 1.8619, Validation Loss: 1.3726\n",
      "[Trial 81] Epoch 52/60, Training Loss: 0.6132, Validation Loss: 0.5328\n",
      "[Trial 100] Epoch 5/60, Training Loss: 1.3058, Validation Loss: 1.5246\n",
      "[Trial 99] Epoch 8/60, Training Loss: 0.9581, Validation Loss: 0.8083\n",
      "[Trial 97] Epoch 9/60, Training Loss: 1.0677, Validation Loss: 0.9102\n",
      "[Trial 88] Epoch 35/60, Training Loss: 0.6131, Validation Loss: 0.5106\n",
      "[Trial 96] Epoch 9/60, Training Loss: 1.2268, Validation Loss: 0.9767\n",
      "[Trial 98] Epoch 9/60, Training Loss: 1.0243, Validation Loss: 0.8905\n",
      "[Trial 82] Epoch 51/60, Training Loss: 0.5724, Validation Loss: 0.4829\n",
      "[Trial 102] Epoch 4/60, Training Loss: 1.7307, Validation Loss: 1.1656\n",
      "[Trial 101] Epoch 5/60, Training Loss: 1.6602, Validation Loss: 1.2670\n",
      "[Trial 104] Epoch 3/60, Training Loss: 1.9227, Validation Loss: 1.4273\n",
      "[Trial 103] Epoch 4/60, Training Loss: 1.7129, Validation Loss: 1.3877\n",
      "[Trial 100] Epoch 6/60, Training Loss: 1.2040, Validation Loss: 1.2430\n",
      "[Trial 86] Epoch 47/60, Training Loss: 0.5802, Validation Loss: 0.5101\n",
      "[Trial 99] Epoch 9/60, Training Loss: 0.9618, Validation Loss: 0.9371\n",
      "[Trial 97] Epoch 10/60, Training Loss: 1.0346, Validation Loss: 0.8840\n",
      "[Trial 87] Epoch 44/60, Training Loss: 0.5967, Validation Loss: 0.5058\n",
      "[Trial 83] Epoch 50/60, Training Loss: 0.5484, Validation Loss: 0.5084\n",
      "[Trial 96] Epoch 10/60, Training Loss: 1.1289, Validation Loss: 0.9289\n",
      "[Trial 98] Epoch 10/60, Training Loss: 0.9226, Validation Loss: 0.8336\n",
      "[Trial 89] Epoch 25/60, Training Loss: 0.6518, Validation Loss: 0.5526\n",
      "[Trial 102] Epoch 5/60, Training Loss: 1.5985, Validation Loss: 1.1597\n",
      "[Trial 101] Epoch 6/60, Training Loss: 1.5425, Validation Loss: 1.1829\n",
      "[Trial 81] Epoch 53/60, Training Loss: 0.6133, Validation Loss: 0.5242\n",
      "[Trial 104] Epoch 4/60, Training Loss: 1.7815, Validation Loss: 1.3519\n",
      "[Trial 103] Epoch 5/60, Training Loss: 1.5741, Validation Loss: 1.0951\n",
      "[Trial 100] Epoch 7/60, Training Loss: 1.1218, Validation Loss: 0.8404\n",
      "[Trial 88] Epoch 36/60, Training Loss: 0.6111, Validation Loss: 0.5398\n",
      "[Trial 99] Epoch 10/60, Training Loss: 0.9432, Validation Loss: 0.7976\n",
      "[Trial 97] Epoch 11/60, Training Loss: 0.9487, Validation Loss: 0.7918\n",
      "[Trial 82] Epoch 52/60, Training Loss: 0.5760, Validation Loss: 0.4929\n",
      "[Trial 98] Epoch 11/60, Training Loss: 0.9013, Validation Loss: 0.8488\n",
      "[Trial 96] Epoch 11/60, Training Loss: 1.0817, Validation Loss: 0.9356\n",
      "[Trial 102] Epoch 6/60, Training Loss: 1.4341, Validation Loss: 0.9979\n",
      "[Trial 101] Epoch 7/60, Training Loss: 1.4693, Validation Loss: 1.1846\n",
      "[Trial 104] Epoch 5/60, Training Loss: 1.7089, Validation Loss: 1.2870\n",
      "[Trial 103] Epoch 6/60, Training Loss: 1.4413, Validation Loss: 1.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:34:49,251] Trial 86 finished with value: 0.4938953620692094 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.003476618038096326, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 86] Epoch 48/60, Training Loss: 0.5867, Validation Loss: 0.5091\n",
      "[Trial 86] Early stopping after 48 epochs.\n",
      "[Trial 100] Epoch 8/60, Training Loss: 0.9845, Validation Loss: 0.6906\n",
      "[Trial 87] Epoch 45/60, Training Loss: 0.5918, Validation Loss: 0.5048\n",
      "[Trial 97] Epoch 12/60, Training Loss: 0.9322, Validation Loss: 0.7475\n",
      "[Trial 83] Epoch 51/60, Training Loss: 0.5471, Validation Loss: 0.4861\n",
      "[Trial 99] Epoch 11/60, Training Loss: 0.9027, Validation Loss: 0.7890\n",
      "[Trial 89] Epoch 26/60, Training Loss: 0.6613, Validation Loss: 0.5469\n",
      "[Trial 98] Epoch 12/60, Training Loss: 0.8801, Validation Loss: 1.0767\n",
      "[Trial 96] Epoch 12/60, Training Loss: 1.0250, Validation Loss: 0.8332\n",
      "[Trial 102] Epoch 7/60, Training Loss: 1.3102, Validation Loss: 1.0751\n",
      "[Trial 81] Epoch 54/60, Training Loss: 0.6120, Validation Loss: 0.5267\n",
      "[Trial 101] Epoch 8/60, Training Loss: 1.3567, Validation Loss: 1.0434\n",
      "[Trial 88] Epoch 37/60, Training Loss: 0.6014, Validation Loss: 0.5241\n",
      "[Trial 104] Epoch 6/60, Training Loss: 1.6019, Validation Loss: 1.1120\n",
      "[Trial 103] Epoch 7/60, Training Loss: 1.3699, Validation Loss: 1.0249\n",
      "[Trial 100] Epoch 9/60, Training Loss: 0.9453, Validation Loss: 0.9376\n",
      "[Trial 105] Epoch 1/60, Training Loss: 4.9405, Validation Loss: 1.9787\n",
      "[Trial 82] Epoch 53/60, Training Loss: 0.5759, Validation Loss: 0.4918\n",
      "[Trial 97] Epoch 13/60, Training Loss: 0.9067, Validation Loss: 0.7188\n",
      "[Trial 99] Epoch 12/60, Training Loss: 0.8672, Validation Loss: 0.8720\n",
      "[Trial 98] Epoch 13/60, Training Loss: 0.8450, Validation Loss: 0.9310\n",
      "[Trial 96] Epoch 13/60, Training Loss: 0.9877, Validation Loss: 0.7130\n",
      "[Trial 102] Epoch 8/60, Training Loss: 1.2147, Validation Loss: 0.9394\n",
      "[Trial 101] Epoch 9/60, Training Loss: 1.2785, Validation Loss: 1.0546\n",
      "[Trial 87] Epoch 46/60, Training Loss: 0.5873, Validation Loss: 0.4948\n",
      "[Trial 104] Epoch 7/60, Training Loss: 1.5136, Validation Loss: 1.3383\n",
      "[Trial 89] Epoch 27/60, Training Loss: 0.6481, Validation Loss: 0.5633\n",
      "[Trial 100] Epoch 10/60, Training Loss: 0.9473, Validation Loss: 0.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:37:02,235] Trial 83 finished with value: 0.4821868690351645 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0034600317758086427, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 83] Epoch 52/60, Training Loss: 0.5469, Validation Loss: 0.4946\n",
      "[Trial 83] Early stopping after 52 epochs.\n",
      "[Trial 103] Epoch 8/60, Training Loss: 1.2427, Validation Loss: 0.9710\n",
      "[Trial 105] Epoch 2/60, Training Loss: 2.0814, Validation Loss: 2.6382\n",
      "[Trial 97] Epoch 14/60, Training Loss: 0.8897, Validation Loss: 0.7296\n",
      "[Trial 99] Epoch 13/60, Training Loss: 0.8664, Validation Loss: 1.3056\n",
      "[Trial 98] Epoch 14/60, Training Loss: 0.7769, Validation Loss: 0.7744\n",
      "[Trial 81] Epoch 55/60, Training Loss: 0.5919, Validation Loss: 0.5121\n",
      "[Trial 96] Epoch 14/60, Training Loss: 0.9588, Validation Loss: 0.7306\n",
      "[Trial 102] Epoch 9/60, Training Loss: 1.1095, Validation Loss: 0.8996\n",
      "[Trial 88] Epoch 38/60, Training Loss: 0.6068, Validation Loss: 0.5068\n",
      "[Trial 101] Epoch 10/60, Training Loss: 1.2105, Validation Loss: 0.9692\n",
      "[Trial 82] Epoch 54/60, Training Loss: 0.5752, Validation Loss: 0.5011\n",
      "[Trial 104] Epoch 8/60, Training Loss: 1.4546, Validation Loss: 1.0305\n",
      "[Trial 100] Epoch 11/60, Training Loss: 0.9045, Validation Loss: 0.7781\n",
      "[Trial 106] Epoch 1/60, Training Loss: 4.5366, Validation Loss: 2.3345\n",
      "[Trial 103] Epoch 9/60, Training Loss: 1.1751, Validation Loss: 0.9267\n",
      "[Trial 105] Epoch 3/60, Training Loss: 1.6714, Validation Loss: 1.2530\n",
      "[Trial 97] Epoch 15/60, Training Loss: 0.8666, Validation Loss: 0.7086\n",
      "[Trial 99] Epoch 14/60, Training Loss: 0.8861, Validation Loss: 0.7697\n",
      "[Trial 98] Epoch 15/60, Training Loss: 0.7616, Validation Loss: 0.6318\n",
      "[Trial 96] Epoch 15/60, Training Loss: 0.9111, Validation Loss: 0.7066\n",
      "[Trial 102] Epoch 10/60, Training Loss: 1.0610, Validation Loss: 0.7853\n",
      "[Trial 87] Epoch 47/60, Training Loss: 0.5898, Validation Loss: 0.5648\n",
      "[Trial 89] Epoch 28/60, Training Loss: 0.6409, Validation Loss: 0.5665\n",
      "[Trial 101] Epoch 11/60, Training Loss: 1.1256, Validation Loss: 0.8919\n",
      "[Trial 104] Epoch 9/60, Training Loss: 1.4020, Validation Loss: 1.2243\n",
      "[Trial 100] Epoch 12/60, Training Loss: 0.8814, Validation Loss: 1.6820\n",
      "[Trial 106] Epoch 2/60, Training Loss: 1.9417, Validation Loss: 1.4975\n",
      "[Trial 103] Epoch 10/60, Training Loss: 1.0910, Validation Loss: 0.7858\n",
      "[Trial 105] Epoch 4/60, Training Loss: 1.3551, Validation Loss: 1.1752\n",
      "[Trial 97] Epoch 16/60, Training Loss: 0.8513, Validation Loss: 0.6909\n",
      "[Trial 81] Epoch 56/60, Training Loss: 0.5905, Validation Loss: 0.5243\n",
      "[Trial 99] Epoch 15/60, Training Loss: 0.7640, Validation Loss: 0.6321\n",
      "[Trial 88] Epoch 39/60, Training Loss: 0.5986, Validation Loss: 0.5122\n",
      "[Trial 98] Epoch 16/60, Training Loss: 0.7400, Validation Loss: 0.7644\n",
      "[Trial 102] Epoch 11/60, Training Loss: 0.9983, Validation Loss: 0.7818\n",
      "[Trial 96] Epoch 16/60, Training Loss: 0.8899, Validation Loss: 0.8002\n",
      "[Trial 82] Epoch 55/60, Training Loss: 0.5747, Validation Loss: 0.5058\n",
      "[Trial 101] Epoch 12/60, Training Loss: 1.0673, Validation Loss: 0.8295\n",
      "[Trial 104] Epoch 10/60, Training Loss: 1.3619, Validation Loss: 0.9828\n",
      "[Trial 100] Epoch 13/60, Training Loss: 0.9302, Validation Loss: 0.7358\n",
      "[Trial 106] Epoch 3/60, Training Loss: 1.4905, Validation Loss: 1.5489\n",
      "[Trial 103] Epoch 11/60, Training Loss: 1.0244, Validation Loss: 0.8092\n",
      "[Trial 105] Epoch 5/60, Training Loss: 1.1988, Validation Loss: 1.2489\n",
      "[Trial 97] Epoch 17/60, Training Loss: 0.8400, Validation Loss: 0.6783\n",
      "[Trial 99] Epoch 16/60, Training Loss: 0.7362, Validation Loss: 0.6545\n",
      "[Trial 89] Epoch 29/60, Training Loss: 0.6552, Validation Loss: 0.6119\n",
      "[Trial 87] Epoch 48/60, Training Loss: 0.5948, Validation Loss: 0.5524\n",
      "[Trial 98] Epoch 17/60, Training Loss: 0.7394, Validation Loss: 0.5997\n",
      "[Trial 102] Epoch 12/60, Training Loss: 0.9535, Validation Loss: 0.8675\n",
      "[Trial 96] Epoch 17/60, Training Loss: 0.8683, Validation Loss: 0.6931\n",
      "[Trial 101] Epoch 13/60, Training Loss: 0.9998, Validation Loss: 0.8048\n",
      "[Trial 104] Epoch 11/60, Training Loss: 1.2765, Validation Loss: 1.0914\n",
      "[Trial 100] Epoch 14/60, Training Loss: 0.8540, Validation Loss: 1.0646\n",
      "[Trial 81] Epoch 57/60, Training Loss: 0.5885, Validation Loss: 0.5084\n",
      "[Trial 106] Epoch 4/60, Training Loss: 1.2758, Validation Loss: 1.3082\n",
      "[Trial 103] Epoch 12/60, Training Loss: 0.9736, Validation Loss: 0.7220\n",
      "[Trial 97] Epoch 18/60, Training Loss: 0.8377, Validation Loss: 0.6924\n",
      "[Trial 105] Epoch 6/60, Training Loss: 1.1588, Validation Loss: 1.0078\n",
      "[Trial 88] Epoch 40/60, Training Loss: 0.5734, Validation Loss: 0.4801\n",
      "[Trial 99] Epoch 17/60, Training Loss: 0.7295, Validation Loss: 0.6391\n",
      "[Trial 98] Epoch 18/60, Training Loss: 0.7221, Validation Loss: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:41:55,430] Trial 82 finished with value: 0.48289956226944925 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.003849289984335911, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 82] Epoch 56/60, Training Loss: 0.5674, Validation Loss: 0.4932\n",
      "[Trial 82] Early stopping after 56 epochs.\n",
      "[Trial 102] Epoch 13/60, Training Loss: 0.9517, Validation Loss: 0.7823\n",
      "[Trial 96] Epoch 18/60, Training Loss: 0.8656, Validation Loss: 0.7427\n",
      "[Trial 101] Epoch 14/60, Training Loss: 0.9699, Validation Loss: 0.8003\n",
      "[Trial 104] Epoch 12/60, Training Loss: 1.2416, Validation Loss: 1.0066\n",
      "[Trial 100] Epoch 15/60, Training Loss: 0.7709, Validation Loss: 0.8022\n",
      "[Trial 106] Epoch 5/60, Training Loss: 1.2003, Validation Loss: 1.1487\n",
      "[Trial 89] Epoch 30/60, Training Loss: 0.6558, Validation Loss: 0.5703\n",
      "[Trial 103] Epoch 13/60, Training Loss: 0.9516, Validation Loss: 0.8025\n",
      "[Trial 97] Epoch 19/60, Training Loss: 0.8393, Validation Loss: 0.7080\n",
      "[Trial 105] Epoch 7/60, Training Loss: 1.0011, Validation Loss: 0.9167\n",
      "[Trial 87] Epoch 49/60, Training Loss: 0.5888, Validation Loss: 0.5398\n",
      "[Trial 99] Epoch 18/60, Training Loss: 0.6853, Validation Loss: 0.5846\n",
      "[Trial 98] Epoch 19/60, Training Loss: 0.7461, Validation Loss: 0.6831\n",
      "[Trial 107] Epoch 1/60, Training Loss: 5.0084, Validation Loss: 1.8694\n",
      "[Trial 102] Epoch 14/60, Training Loss: 0.9168, Validation Loss: 0.8444\n",
      "[Trial 96] Epoch 19/60, Training Loss: 0.8457, Validation Loss: 0.6379\n",
      "[Trial 101] Epoch 15/60, Training Loss: 0.9399, Validation Loss: 0.7862\n",
      "[Trial 81] Epoch 58/60, Training Loss: 0.5867, Validation Loss: 0.5028\n",
      "[Trial 104] Epoch 13/60, Training Loss: 1.1891, Validation Loss: 1.0270\n",
      "[Trial 88] Epoch 41/60, Training Loss: 0.5702, Validation Loss: 0.4972\n",
      "[Trial 100] Epoch 16/60, Training Loss: 0.7652, Validation Loss: 0.6336\n",
      "[Trial 106] Epoch 6/60, Training Loss: 1.0512, Validation Loss: 0.9179\n",
      "[Trial 97] Epoch 20/60, Training Loss: 0.8009, Validation Loss: 0.6444\n",
      "[Trial 103] Epoch 14/60, Training Loss: 0.9134, Validation Loss: 0.9144\n",
      "[Trial 105] Epoch 8/60, Training Loss: 0.9572, Validation Loss: 0.7822\n",
      "[Trial 99] Epoch 19/60, Training Loss: 0.6771, Validation Loss: 0.6562\n",
      "[Trial 98] Epoch 20/60, Training Loss: 0.7145, Validation Loss: 0.7300\n",
      "[Trial 107] Epoch 2/60, Training Loss: 2.1754, Validation Loss: 2.8483\n",
      "[Trial 102] Epoch 15/60, Training Loss: 0.8859, Validation Loss: 0.7862\n",
      "[Trial 96] Epoch 20/60, Training Loss: 0.8288, Validation Loss: 0.6043\n",
      "[Trial 89] Epoch 31/60, Training Loss: 0.6509, Validation Loss: 0.6380\n",
      "[Trial 101] Epoch 16/60, Training Loss: 0.9049, Validation Loss: 0.7757\n",
      "[Trial 104] Epoch 14/60, Training Loss: 1.1554, Validation Loss: 0.9509\n",
      "[Trial 87] Epoch 50/60, Training Loss: 0.5883, Validation Loss: 0.5009\n",
      "[Trial 100] Epoch 17/60, Training Loss: 0.7397, Validation Loss: 0.6213\n",
      "[Trial 106] Epoch 7/60, Training Loss: 1.0270, Validation Loss: 0.8910\n",
      "[Trial 97] Epoch 21/60, Training Loss: 0.7770, Validation Loss: 0.6239\n",
      "[Trial 103] Epoch 15/60, Training Loss: 0.9346, Validation Loss: 0.7309\n",
      "[Trial 105] Epoch 9/60, Training Loss: 0.9347, Validation Loss: 0.7328\n",
      "[Trial 99] Epoch 20/60, Training Loss: 0.6616, Validation Loss: 0.5720\n",
      "[Trial 98] Epoch 21/60, Training Loss: 0.6696, Validation Loss: 0.5934\n",
      "[Trial 107] Epoch 3/60, Training Loss: 1.7639, Validation Loss: 1.9367\n",
      "[Trial 102] Epoch 16/60, Training Loss: 0.8004, Validation Loss: 0.6243\n",
      "[Trial 81] Epoch 59/60, Training Loss: 0.5912, Validation Loss: 0.5183\n",
      "[Trial 96] Epoch 21/60, Training Loss: 0.8218, Validation Loss: 0.7129\n",
      "[Trial 88] Epoch 42/60, Training Loss: 0.5694, Validation Loss: 0.4870\n",
      "[Trial 101] Epoch 17/60, Training Loss: 0.8831, Validation Loss: 0.8301\n",
      "[Trial 104] Epoch 15/60, Training Loss: 1.0956, Validation Loss: 0.8769\n",
      "[Trial 100] Epoch 18/60, Training Loss: 0.7275, Validation Loss: 0.7610\n",
      "[Trial 106] Epoch 8/60, Training Loss: 0.9542, Validation Loss: 0.9184\n",
      "[Trial 97] Epoch 22/60, Training Loss: 0.7798, Validation Loss: 0.6092\n",
      "[Trial 103] Epoch 16/60, Training Loss: 0.8815, Validation Loss: 0.7127\n",
      "[Trial 105] Epoch 10/60, Training Loss: 0.8990, Validation Loss: 0.9777\n",
      "[Trial 99] Epoch 21/60, Training Loss: 0.6603, Validation Loss: 0.5860\n",
      "[Trial 98] Epoch 22/60, Training Loss: 0.6509, Validation Loss: 0.5677\n",
      "[Trial 89] Epoch 32/60, Training Loss: 0.6436, Validation Loss: 0.5709\n",
      "[Trial 102] Epoch 17/60, Training Loss: 0.7927, Validation Loss: 0.7340\n",
      "[Trial 107] Epoch 4/60, Training Loss: 1.3915, Validation Loss: 0.9844\n",
      "[Trial 96] Epoch 22/60, Training Loss: 0.8187, Validation Loss: 0.6504\n",
      "[Trial 87] Epoch 51/60, Training Loss: 0.5842, Validation Loss: 0.5509\n",
      "[Trial 101] Epoch 18/60, Training Loss: 0.8693, Validation Loss: 0.6932\n",
      "[Trial 104] Epoch 16/60, Training Loss: 1.0409, Validation Loss: 0.8678\n",
      "[Trial 100] Epoch 19/60, Training Loss: 0.7466, Validation Loss: 0.7779\n",
      "[Trial 97] Epoch 23/60, Training Loss: 0.7492, Validation Loss: 0.6044\n",
      "[Trial 106] Epoch 9/60, Training Loss: 0.8977, Validation Loss: 0.8472\n",
      "[Trial 103] Epoch 17/60, Training Loss: 0.8497, Validation Loss: 0.7064\n",
      "[Trial 105] Epoch 11/60, Training Loss: 0.8763, Validation Loss: 0.6684\n",
      "[Trial 99] Epoch 22/60, Training Loss: 0.6585, Validation Loss: 0.5746\n",
      "[Trial 98] Epoch 23/60, Training Loss: 0.6632, Validation Loss: 0.5644\n",
      "[Trial 88] Epoch 43/60, Training Loss: 0.5679, Validation Loss: 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:47:36,927] Trial 81 finished with value: 0.5008932920793693 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.014318942236936059, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 81] Epoch 60/60, Training Loss: 0.5840, Validation Loss: 0.5009\n",
      "[Trial 102] Epoch 18/60, Training Loss: 0.8365, Validation Loss: 0.6552\n",
      "[Trial 107] Epoch 5/60, Training Loss: 1.1816, Validation Loss: 0.9378\n",
      "[Trial 96] Epoch 23/60, Training Loss: 0.7379, Validation Loss: 0.5853\n",
      "[Trial 104] Epoch 17/60, Training Loss: 0.9907, Validation Loss: 0.7582\n",
      "[Trial 101] Epoch 19/60, Training Loss: 0.8556, Validation Loss: 0.7443\n",
      "[Trial 100] Epoch 20/60, Training Loss: 0.7613, Validation Loss: 0.6002\n",
      "[Trial 97] Epoch 24/60, Training Loss: 0.7534, Validation Loss: 0.6205\n",
      "[Trial 106] Epoch 10/60, Training Loss: 0.8749, Validation Loss: 0.7364\n",
      "[Trial 89] Epoch 33/60, Training Loss: 0.6044, Validation Loss: 0.5038\n",
      "[Trial 103] Epoch 18/60, Training Loss: 0.8320, Validation Loss: 0.7442\n",
      "[Trial 105] Epoch 12/60, Training Loss: 0.8421, Validation Loss: 0.6882\n",
      "[Trial 99] Epoch 23/60, Training Loss: 0.6392, Validation Loss: 0.5678\n",
      "[Trial 98] Epoch 24/60, Training Loss: 0.6639, Validation Loss: 0.6730\n",
      "[Trial 87] Epoch 52/60, Training Loss: 0.5909, Validation Loss: 0.5180\n",
      "[Trial 108] Epoch 1/60, Training Loss: 4.1294, Validation Loss: 2.1520\n",
      "[Trial 102] Epoch 19/60, Training Loss: 0.7663, Validation Loss: 0.6483\n",
      "[Trial 107] Epoch 6/60, Training Loss: 1.0836, Validation Loss: 3.3558\n",
      "[Trial 96] Epoch 24/60, Training Loss: 0.7258, Validation Loss: 0.6090\n",
      "[Trial 104] Epoch 18/60, Training Loss: 0.9857, Validation Loss: 0.7857\n",
      "[Trial 101] Epoch 20/60, Training Loss: 0.8426, Validation Loss: 0.6600\n",
      "[Trial 100] Epoch 21/60, Training Loss: 0.7178, Validation Loss: 0.6660\n",
      "[Trial 97] Epoch 25/60, Training Loss: 0.7483, Validation Loss: 0.6011\n",
      "[Trial 106] Epoch 11/60, Training Loss: 0.8411, Validation Loss: 0.7883\n",
      "[Trial 103] Epoch 19/60, Training Loss: 0.8210, Validation Loss: 0.7539\n",
      "[Trial 88] Epoch 44/60, Training Loss: 0.5664, Validation Loss: 0.4829\n",
      "[Trial 99] Epoch 24/60, Training Loss: 0.6283, Validation Loss: 0.5433\n",
      "[Trial 105] Epoch 13/60, Training Loss: 0.8418, Validation Loss: 0.9878\n",
      "[Trial 98] Epoch 25/60, Training Loss: 0.6649, Validation Loss: 0.5355\n",
      "[Trial 108] Epoch 2/60, Training Loss: 2.0948, Validation Loss: 1.7589\n",
      "[Trial 102] Epoch 20/60, Training Loss: 0.7521, Validation Loss: 0.6217\n",
      "[Trial 107] Epoch 7/60, Training Loss: 1.0724, Validation Loss: 1.0143\n",
      "[Trial 96] Epoch 25/60, Training Loss: 0.7337, Validation Loss: 0.5593\n",
      "[Trial 104] Epoch 19/60, Training Loss: 0.9354, Validation Loss: 0.7704\n",
      "[Trial 89] Epoch 34/60, Training Loss: 0.6021, Validation Loss: 0.5228\n",
      "[Trial 101] Epoch 21/60, Training Loss: 0.8012, Validation Loss: 0.7017\n",
      "[Trial 100] Epoch 22/60, Training Loss: 0.7170, Validation Loss: 0.5958\n",
      "[Trial 97] Epoch 26/60, Training Loss: 0.7444, Validation Loss: 0.5957\n",
      "[Trial 106] Epoch 12/60, Training Loss: 0.8181, Validation Loss: 0.6992\n",
      "[Trial 103] Epoch 20/60, Training Loss: 0.7946, Validation Loss: 0.6911\n",
      "[Trial 87] Epoch 53/60, Training Loss: 0.5621, Validation Loss: 0.4845\n",
      "[Trial 99] Epoch 25/60, Training Loss: 0.6261, Validation Loss: 0.5684\n",
      "[Trial 105] Epoch 14/60, Training Loss: 0.8748, Validation Loss: 0.8527\n",
      "[Trial 98] Epoch 26/60, Training Loss: 0.6401, Validation Loss: 0.6055\n",
      "[Trial 108] Epoch 3/60, Training Loss: 1.9037, Validation Loss: 1.5270\n",
      "[Trial 102] Epoch 21/60, Training Loss: 0.7500, Validation Loss: 0.5845\n",
      "[Trial 107] Epoch 8/60, Training Loss: 0.9918, Validation Loss: 1.0380\n",
      "[Trial 104] Epoch 20/60, Training Loss: 0.9135, Validation Loss: 0.7791\n",
      "[Trial 96] Epoch 26/60, Training Loss: 0.7189, Validation Loss: 0.5755\n",
      "[Trial 101] Epoch 22/60, Training Loss: 0.8042, Validation Loss: 0.7585\n",
      "[Trial 100] Epoch 23/60, Training Loss: 0.6985, Validation Loss: 0.5961\n",
      "[Trial 88] Epoch 45/60, Training Loss: 0.5623, Validation Loss: 0.4788\n",
      "[Trial 97] Epoch 27/60, Training Loss: 0.7346, Validation Loss: 0.6130\n",
      "[Trial 106] Epoch 13/60, Training Loss: 0.8009, Validation Loss: 0.7704\n",
      "[Trial 103] Epoch 21/60, Training Loss: 0.8009, Validation Loss: 0.7663\n",
      "[Trial 99] Epoch 26/60, Training Loss: 0.6265, Validation Loss: 0.5446\n",
      "[Trial 105] Epoch 15/60, Training Loss: 0.8118, Validation Loss: 0.8145\n",
      "[Trial 98] Epoch 27/60, Training Loss: 0.6528, Validation Loss: 0.5377\n",
      "[Trial 108] Epoch 4/60, Training Loss: 1.7243, Validation Loss: 1.3726\n",
      "[Trial 102] Epoch 22/60, Training Loss: 0.7405, Validation Loss: 0.7275\n",
      "[Trial 89] Epoch 35/60, Training Loss: 0.6042, Validation Loss: 0.5150\n",
      "[Trial 107] Epoch 9/60, Training Loss: 0.9589, Validation Loss: 0.9556\n",
      "[Trial 104] Epoch 21/60, Training Loss: 0.8984, Validation Loss: 0.7244\n",
      "[Trial 96] Epoch 27/60, Training Loss: 0.7166, Validation Loss: 0.5587\n",
      "[Trial 101] Epoch 23/60, Training Loss: 0.7560, Validation Loss: 0.6043\n",
      "[Trial 100] Epoch 24/60, Training Loss: 0.7162, Validation Loss: 0.6627\n",
      "[Trial 97] Epoch 28/60, Training Loss: 0.7309, Validation Loss: 0.6100\n",
      "[Trial 87] Epoch 54/60, Training Loss: 0.5560, Validation Loss: 0.4948\n",
      "[Trial 106] Epoch 14/60, Training Loss: 0.8078, Validation Loss: 1.0795\n",
      "[Trial 103] Epoch 22/60, Training Loss: 0.7969, Validation Loss: 0.6874\n",
      "[Trial 99] Epoch 27/60, Training Loss: 0.6034, Validation Loss: 0.5239\n",
      "[Trial 105] Epoch 16/60, Training Loss: 0.7996, Validation Loss: 0.7587\n",
      "[Trial 98] Epoch 28/60, Training Loss: 0.6411, Validation Loss: 0.6160\n",
      "[Trial 102] Epoch 23/60, Training Loss: 0.7504, Validation Loss: 0.6246\n",
      "[Trial 108] Epoch 5/60, Training Loss: 1.6066, Validation Loss: 1.1867\n",
      "[Trial 107] Epoch 10/60, Training Loss: 0.8861, Validation Loss: 0.6847\n",
      "[Trial 88] Epoch 46/60, Training Loss: 0.5617, Validation Loss: 0.4962\n",
      "[Trial 104] Epoch 22/60, Training Loss: 0.8783, Validation Loss: 0.6853\n",
      "[Trial 96] Epoch 28/60, Training Loss: 0.7103, Validation Loss: 0.5919\n",
      "[Trial 100] Epoch 25/60, Training Loss: 0.7123, Validation Loss: 0.6559\n",
      "[Trial 101] Epoch 24/60, Training Loss: 0.7489, Validation Loss: 0.6406\n",
      "[Trial 97] Epoch 29/60, Training Loss: 0.7091, Validation Loss: 0.5713\n",
      "[Trial 106] Epoch 15/60, Training Loss: 0.8289, Validation Loss: 0.6557\n",
      "[Trial 103] Epoch 23/60, Training Loss: 0.7806, Validation Loss: 0.7681\n",
      "[Trial 89] Epoch 36/60, Training Loss: 0.5975, Validation Loss: 0.5222\n",
      "[Trial 99] Epoch 28/60, Training Loss: 0.6050, Validation Loss: 0.5194\n",
      "[Trial 105] Epoch 17/60, Training Loss: 0.7072, Validation Loss: 0.5750\n",
      "[Trial 98] Epoch 29/60, Training Loss: 0.6133, Validation Loss: 0.5160\n",
      "[Trial 102] Epoch 24/60, Training Loss: 0.7507, Validation Loss: 0.6351\n",
      "[Trial 108] Epoch 6/60, Training Loss: 1.4539, Validation Loss: 1.0961\n",
      "[Trial 107] Epoch 11/60, Training Loss: 0.8343, Validation Loss: 0.8785\n",
      "[Trial 104] Epoch 23/60, Training Loss: 0.8475, Validation Loss: 0.7077\n",
      "[Trial 87] Epoch 55/60, Training Loss: 0.5526, Validation Loss: 0.4805\n",
      "[Trial 100] Epoch 26/60, Training Loss: 0.7178, Validation Loss: 0.5911\n",
      "[Trial 96] Epoch 29/60, Training Loss: 0.7051, Validation Loss: 0.5421\n",
      "[Trial 101] Epoch 25/60, Training Loss: 0.7322, Validation Loss: 0.5990\n",
      "[Trial 97] Epoch 30/60, Training Loss: 0.7085, Validation Loss: 0.5716\n",
      "[Trial 106] Epoch 16/60, Training Loss: 0.7630, Validation Loss: 0.9498\n",
      "[Trial 103] Epoch 24/60, Training Loss: 0.8240, Validation Loss: 0.6223\n",
      "[Trial 99] Epoch 29/60, Training Loss: 0.6035, Validation Loss: 0.5271\n",
      "[Trial 98] Epoch 30/60, Training Loss: 0.6085, Validation Loss: 0.5310\n",
      "[Trial 105] Epoch 18/60, Training Loss: 0.6966, Validation Loss: 0.7256\n",
      "[Trial 88] Epoch 47/60, Training Loss: 0.5599, Validation Loss: 0.4744\n",
      "[Trial 102] Epoch 25/60, Training Loss: 0.7174, Validation Loss: 0.5599\n",
      "[Trial 108] Epoch 7/60, Training Loss: 1.3570, Validation Loss: 1.0074\n",
      "[Trial 104] Epoch 24/60, Training Loss: 0.8586, Validation Loss: 0.7448\n",
      "[Trial 107] Epoch 12/60, Training Loss: 0.8382, Validation Loss: 0.9090\n",
      "[Trial 100] Epoch 27/60, Training Loss: 0.7223, Validation Loss: 0.5766\n",
      "[Trial 96] Epoch 30/60, Training Loss: 0.6974, Validation Loss: 0.6384\n",
      "[Trial 97] Epoch 31/60, Training Loss: 0.7018, Validation Loss: 0.5747\n",
      "[Trial 89] Epoch 37/60, Training Loss: 0.5975, Validation Loss: 0.5043\n",
      "[Trial 101] Epoch 26/60, Training Loss: 0.7346, Validation Loss: 0.6215\n",
      "[Trial 106] Epoch 17/60, Training Loss: 0.7950, Validation Loss: 0.8531\n",
      "[Trial 103] Epoch 25/60, Training Loss: 0.7532, Validation Loss: 1.0910\n",
      "[Trial 99] Epoch 30/60, Training Loss: 0.6025, Validation Loss: 0.5144\n",
      "[Trial 98] Epoch 31/60, Training Loss: 0.6095, Validation Loss: 0.5184\n",
      "[Trial 105] Epoch 19/60, Training Loss: 0.7473, Validation Loss: 0.7716\n",
      "[Trial 102] Epoch 26/60, Training Loss: 0.7266, Validation Loss: 0.6073\n",
      "[Trial 87] Epoch 56/60, Training Loss: 0.5528, Validation Loss: 0.4838\n",
      "[Trial 108] Epoch 8/60, Training Loss: 1.2550, Validation Loss: 1.0060\n",
      "[Trial 104] Epoch 25/60, Training Loss: 0.8324, Validation Loss: 0.7098\n",
      "[Trial 107] Epoch 13/60, Training Loss: 0.8375, Validation Loss: 0.6244\n",
      "[Trial 100] Epoch 28/60, Training Loss: 0.7111, Validation Loss: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 06:57:20,900] Trial 97 finished with value: 0.5712815617521604 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.0005777684221593278, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 97] Epoch 32/60, Training Loss: 0.6981, Validation Loss: 0.5722\n",
      "[Trial 97] Early stopping after 32 epochs.\n",
      "[Trial 96] Epoch 31/60, Training Loss: 0.7054, Validation Loss: 0.5925\n",
      "[Trial 101] Epoch 27/60, Training Loss: 0.7283, Validation Loss: 0.5826\n",
      "[Trial 106] Epoch 18/60, Training Loss: 0.7667, Validation Loss: 0.8663\n",
      "[Trial 88] Epoch 48/60, Training Loss: 0.5669, Validation Loss: 0.4950\n",
      "[Trial 99] Epoch 31/60, Training Loss: 0.5956, Validation Loss: 0.5251\n",
      "[Trial 103] Epoch 26/60, Training Loss: 0.7558, Validation Loss: 0.6417\n",
      "[Trial 98] Epoch 32/60, Training Loss: 0.6152, Validation Loss: 0.7856\n",
      "[Trial 105] Epoch 20/60, Training Loss: 0.7164, Validation Loss: 0.6399\n",
      "[Trial 102] Epoch 27/60, Training Loss: 0.7223, Validation Loss: 0.5722\n",
      "[Trial 109] Epoch 1/60, Training Loss: 6.5524, Validation Loss: 3.1212\n",
      "[Trial 108] Epoch 9/60, Training Loss: 1.1648, Validation Loss: 0.9111\n",
      "[Trial 89] Epoch 38/60, Training Loss: 0.5998, Validation Loss: 0.5148\n",
      "[Trial 104] Epoch 26/60, Training Loss: 0.8246, Validation Loss: 0.6644\n",
      "[Trial 107] Epoch 14/60, Training Loss: 0.7971, Validation Loss: 0.8808\n",
      "[Trial 100] Epoch 29/60, Training Loss: 0.7577, Validation Loss: 0.7210\n",
      "[Trial 101] Epoch 28/60, Training Loss: 0.7291, Validation Loss: 0.5999\n",
      "[Trial 96] Epoch 32/60, Training Loss: 0.6795, Validation Loss: 0.5305\n",
      "[Trial 106] Epoch 19/60, Training Loss: 0.7661, Validation Loss: 0.7318\n",
      "[Trial 109] Epoch 2/60, Training Loss: 2.4130, Validation Loss: 2.0091\n",
      "[Trial 99] Epoch 32/60, Training Loss: 0.6011, Validation Loss: 0.5254\n",
      "[Trial 103] Epoch 27/60, Training Loss: 0.7224, Validation Loss: 0.5843\n",
      "[Trial 87] Epoch 57/60, Training Loss: 0.5580, Validation Loss: 0.4864\n",
      "[Trial 98] Epoch 33/60, Training Loss: 0.5903, Validation Loss: 0.4986\n",
      "[Trial 105] Epoch 21/60, Training Loss: 0.6976, Validation Loss: 0.5764\n",
      "[Trial 102] Epoch 28/60, Training Loss: 0.7101, Validation Loss: 0.5936\n",
      "[Trial 108] Epoch 10/60, Training Loss: 1.1088, Validation Loss: 0.9719\n",
      "[Trial 104] Epoch 27/60, Training Loss: 0.8076, Validation Loss: 0.7093\n",
      "[Trial 109] Epoch 3/60, Training Loss: 1.9687, Validation Loss: 1.3787\n",
      "[Trial 100] Epoch 30/60, Training Loss: 0.6976, Validation Loss: 0.6801\n",
      "[Trial 107] Epoch 15/60, Training Loss: 0.7920, Validation Loss: 0.6725\n",
      "[Trial 101] Epoch 29/60, Training Loss: 0.7203, Validation Loss: 0.5982\n",
      "[Trial 88] Epoch 49/60, Training Loss: 0.5605, Validation Loss: 0.4790\n",
      "[Trial 96] Epoch 33/60, Training Loss: 0.6592, Validation Loss: 0.5298\n",
      "[Trial 106] Epoch 20/60, Training Loss: 0.7533, Validation Loss: 0.6781\n",
      "[Trial 99] Epoch 33/60, Training Loss: 0.5908, Validation Loss: 0.5128\n",
      "[Trial 103] Epoch 28/60, Training Loss: 0.7393, Validation Loss: 0.6194\n",
      "[Trial 98] Epoch 34/60, Training Loss: 0.5848, Validation Loss: 0.4878\n",
      "[Trial 89] Epoch 39/60, Training Loss: 0.5943, Validation Loss: 0.5161\n",
      "[Trial 109] Epoch 4/60, Training Loss: 1.8293, Validation Loss: 1.1909\n",
      "[Trial 105] Epoch 22/60, Training Loss: 0.6819, Validation Loss: 0.5674\n",
      "[Trial 102] Epoch 29/60, Training Loss: 0.7089, Validation Loss: 0.6754\n",
      "[Trial 108] Epoch 11/60, Training Loss: 1.0506, Validation Loss: 0.8562\n",
      "[Trial 104] Epoch 28/60, Training Loss: 0.8405, Validation Loss: 0.9589\n",
      "[Trial 100] Epoch 31/60, Training Loss: 0.7147, Validation Loss: 0.7988\n",
      "[Trial 107] Epoch 16/60, Training Loss: 0.7750, Validation Loss: 0.9768\n",
      "[Trial 109] Epoch 5/60, Training Loss: 1.5225, Validation Loss: 1.2660\n",
      "[Trial 101] Epoch 30/60, Training Loss: 0.6839, Validation Loss: 0.5649\n",
      "[Trial 96] Epoch 34/60, Training Loss: 0.6576, Validation Loss: 0.5392\n",
      "[Trial 87] Epoch 58/60, Training Loss: 0.5562, Validation Loss: 0.4938\n",
      "[Trial 106] Epoch 21/60, Training Loss: 0.6710, Validation Loss: 0.6564\n",
      "[Trial 99] Epoch 34/60, Training Loss: 0.5862, Validation Loss: 0.5133\n",
      "[Trial 98] Epoch 35/60, Training Loss: 0.5866, Validation Loss: 0.5144\n",
      "[Trial 103] Epoch 29/60, Training Loss: 0.7147, Validation Loss: 0.5862\n",
      "[Trial 105] Epoch 23/60, Training Loss: 0.6833, Validation Loss: 0.6275\n",
      "[Trial 102] Epoch 30/60, Training Loss: 0.6742, Validation Loss: 0.5524\n",
      "[Trial 109] Epoch 6/60, Training Loss: 1.2929, Validation Loss: 1.3218\n",
      "[Trial 108] Epoch 12/60, Training Loss: 1.0218, Validation Loss: 0.8416\n",
      "[Trial 104] Epoch 29/60, Training Loss: 0.8978, Validation Loss: 0.6344\n",
      "[Trial 88] Epoch 50/60, Training Loss: 0.5583, Validation Loss: 0.4749\n",
      "[Trial 100] Epoch 32/60, Training Loss: 0.7165, Validation Loss: 0.7028\n",
      "[Trial 107] Epoch 17/60, Training Loss: 0.7838, Validation Loss: 0.6241\n",
      "[Trial 89] Epoch 40/60, Training Loss: 0.5725, Validation Loss: 0.5140\n",
      "[Trial 101] Epoch 31/60, Training Loss: 0.6773, Validation Loss: 0.5714\n",
      "[Trial 96] Epoch 35/60, Training Loss: 0.6503, Validation Loss: 0.5161\n",
      "[Trial 106] Epoch 22/60, Training Loss: 0.6819, Validation Loss: 0.6032\n",
      "[Trial 109] Epoch 7/60, Training Loss: 1.1997, Validation Loss: 0.8635\n",
      "[Trial 99] Epoch 35/60, Training Loss: 0.5828, Validation Loss: 0.5113\n",
      "[Trial 98] Epoch 36/60, Training Loss: 0.5803, Validation Loss: 0.5022\n",
      "[Trial 103] Epoch 30/60, Training Loss: 0.7080, Validation Loss: 0.8447\n",
      "[Trial 102] Epoch 31/60, Training Loss: 0.6576, Validation Loss: 0.5548\n",
      "[Trial 105] Epoch 24/60, Training Loss: 0.7007, Validation Loss: 0.8784\n",
      "[Trial 108] Epoch 13/60, Training Loss: 0.9848, Validation Loss: 0.7332\n",
      "[Trial 104] Epoch 30/60, Training Loss: 0.7903, Validation Loss: 0.6647\n",
      "[Trial 109] Epoch 8/60, Training Loss: 1.1260, Validation Loss: 0.8954\n",
      "[Trial 100] Epoch 33/60, Training Loss: 0.7021, Validation Loss: 0.6262\n",
      "[Trial 87] Epoch 59/60, Training Loss: 0.5568, Validation Loss: 0.4743\n",
      "[Trial 107] Epoch 18/60, Training Loss: 0.7505, Validation Loss: 0.7963\n",
      "[Trial 101] Epoch 32/60, Training Loss: 0.6835, Validation Loss: 0.5418\n",
      "[Trial 96] Epoch 36/60, Training Loss: 0.6561, Validation Loss: 0.5268\n",
      "[Trial 106] Epoch 23/60, Training Loss: 0.6516, Validation Loss: 0.5895\n",
      "[Trial 99] Epoch 36/60, Training Loss: 0.5856, Validation Loss: 0.5175\n",
      "[Trial 98] Epoch 37/60, Training Loss: 0.5717, Validation Loss: 0.4929\n",
      "[Trial 103] Epoch 31/60, Training Loss: 0.7285, Validation Loss: 0.6101\n",
      "[Trial 109] Epoch 9/60, Training Loss: 1.0681, Validation Loss: 0.8704\n",
      "[Trial 102] Epoch 32/60, Training Loss: 0.6558, Validation Loss: 0.5496\n",
      "[Trial 88] Epoch 51/60, Training Loss: 0.5625, Validation Loss: 0.4819\n",
      "[Trial 105] Epoch 25/60, Training Loss: 0.7011, Validation Loss: 0.7103\n",
      "[Trial 108] Epoch 14/60, Training Loss: 0.9311, Validation Loss: 0.7462\n",
      "[Trial 104] Epoch 31/60, Training Loss: 0.7717, Validation Loss: 0.6103\n",
      "[Trial 89] Epoch 41/60, Training Loss: 0.5709, Validation Loss: 0.5030\n",
      "[Trial 100] Epoch 34/60, Training Loss: 0.6487, Validation Loss: 0.6279\n",
      "[Trial 109] Epoch 10/60, Training Loss: 0.9705, Validation Loss: 0.7827\n",
      "[Trial 107] Epoch 19/60, Training Loss: 0.7446, Validation Loss: 1.5709\n",
      "[Trial 101] Epoch 33/60, Training Loss: 0.6781, Validation Loss: 0.5599\n",
      "[Trial 96] Epoch 37/60, Training Loss: 0.6455, Validation Loss: 0.5344\n",
      "[Trial 106] Epoch 24/60, Training Loss: 0.6569, Validation Loss: 0.6252\n",
      "[Trial 99] Epoch 37/60, Training Loss: 0.5812, Validation Loss: 0.5116\n",
      "[Trial 98] Epoch 38/60, Training Loss: 0.5624, Validation Loss: 0.4779\n",
      "[Trial 103] Epoch 32/60, Training Loss: 0.6570, Validation Loss: 0.5389\n",
      "[Trial 102] Epoch 33/60, Training Loss: 0.6559, Validation Loss: 0.5541\n",
      "[Trial 105] Epoch 26/60, Training Loss: 0.6962, Validation Loss: 0.7504\n",
      "[Trial 109] Epoch 11/60, Training Loss: 0.9591, Validation Loss: 0.8467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:05:05,202] Trial 87 finished with value: 0.47434246465563773 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.003580919065095608, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 87] Epoch 60/60, Training Loss: 0.5522, Validation Loss: 0.4819\n",
      "[Trial 104] Epoch 32/60, Training Loss: 0.7597, Validation Loss: 0.6391\n",
      "[Trial 108] Epoch 15/60, Training Loss: 0.9366, Validation Loss: 0.6915\n",
      "[Trial 100] Epoch 35/60, Training Loss: 0.6475, Validation Loss: 0.5552\n",
      "[Trial 107] Epoch 20/60, Training Loss: 0.7722, Validation Loss: 0.6237\n",
      "[Trial 101] Epoch 34/60, Training Loss: 0.6825, Validation Loss: 0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:05:45,364] Trial 96 finished with value: 0.5161404112974802 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.000575328792741501, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 96] Epoch 38/60, Training Loss: 0.6343, Validation Loss: 0.5168\n",
      "[Trial 96] Early stopping after 38 epochs.\n",
      "[Trial 106] Epoch 25/60, Training Loss: 0.6517, Validation Loss: 0.5540\n",
      "[Trial 109] Epoch 12/60, Training Loss: 0.9268, Validation Loss: 0.8285\n",
      "[Trial 88] Epoch 52/60, Training Loss: 0.5562, Validation Loss: 0.4821\n",
      "[Trial 99] Epoch 38/60, Training Loss: 0.5840, Validation Loss: 0.5106\n",
      "[Trial 98] Epoch 39/60, Training Loss: 0.5690, Validation Loss: 0.4802\n",
      "[Trial 89] Epoch 42/60, Training Loss: 0.5727, Validation Loss: 0.4936\n",
      "[Trial 103] Epoch 33/60, Training Loss: 0.6495, Validation Loss: 0.5360\n",
      "[Trial 102] Epoch 34/60, Training Loss: 0.6508, Validation Loss: 0.5285\n",
      "[Trial 105] Epoch 27/60, Training Loss: 0.6895, Validation Loss: 0.5941\n",
      "[Trial 104] Epoch 33/60, Training Loss: 0.7560, Validation Loss: 0.6671\n",
      "[Trial 110] Epoch 1/60, Training Loss: 4.8192, Validation Loss: 2.4213\n",
      "[Trial 108] Epoch 16/60, Training Loss: 0.8842, Validation Loss: 0.6680\n",
      "[Trial 100] Epoch 36/60, Training Loss: 0.6342, Validation Loss: 0.6324\n",
      "[Trial 109] Epoch 13/60, Training Loss: 0.8925, Validation Loss: 0.7686\n",
      "[Trial 107] Epoch 21/60, Training Loss: 0.7365, Validation Loss: 0.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:06:50,460] Trial 101 finished with value: 0.5417801961302757 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0005000114952852739, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 101] Epoch 35/60, Training Loss: 0.6619, Validation Loss: 0.5422\n",
      "[Trial 101] Early stopping after 35 epochs.\n",
      "[Trial 111] Epoch 1/60, Training Loss: 4.5917, Validation Loss: 2.2064\n",
      "[Trial 106] Epoch 26/60, Training Loss: 0.6702, Validation Loss: 0.6101\n",
      "[Trial 98] Epoch 40/60, Training Loss: 0.5634, Validation Loss: 0.4887\n",
      "[Trial 99] Epoch 39/60, Training Loss: 0.5851, Validation Loss: 0.5081\n",
      "[Trial 103] Epoch 34/60, Training Loss: 0.6492, Validation Loss: 0.5431\n",
      "[Trial 109] Epoch 14/60, Training Loss: 0.8675, Validation Loss: 0.6908\n",
      "[Trial 102] Epoch 35/60, Training Loss: 0.6463, Validation Loss: 0.5423\n",
      "[Trial 105] Epoch 28/60, Training Loss: 0.6307, Validation Loss: 0.5650\n",
      "[Trial 104] Epoch 34/60, Training Loss: 0.7560, Validation Loss: 0.6791\n",
      "[Trial 110] Epoch 2/60, Training Loss: 2.2086, Validation Loss: 1.5542\n",
      "[Trial 108] Epoch 17/60, Training Loss: 0.8712, Validation Loss: 0.7522\n",
      "[Trial 100] Epoch 37/60, Training Loss: 0.6283, Validation Loss: 0.5583\n",
      "[Trial 88] Epoch 53/60, Training Loss: 0.5594, Validation Loss: 0.4936\n",
      "[Trial 109] Epoch 15/60, Training Loss: 0.8308, Validation Loss: 0.7082\n",
      "[Trial 89] Epoch 43/60, Training Loss: 0.5665, Validation Loss: 0.4966\n",
      "[Trial 107] Epoch 22/60, Training Loss: 0.7065, Validation Loss: 0.6081\n",
      "[Trial 112] Epoch 1/60, Training Loss: 4.9797, Validation Loss: 2.2528\n",
      "[Trial 106] Epoch 27/60, Training Loss: 0.6920, Validation Loss: 0.5984\n",
      "[Trial 111] Epoch 2/60, Training Loss: 1.9740, Validation Loss: 1.7351\n",
      "[Trial 98] Epoch 41/60, Training Loss: 0.5723, Validation Loss: 0.4921\n",
      "[Trial 99] Epoch 40/60, Training Loss: 0.5752, Validation Loss: 0.5029\n",
      "[Trial 103] Epoch 35/60, Training Loss: 0.6481, Validation Loss: 0.5497\n",
      "[Trial 102] Epoch 36/60, Training Loss: 0.6438, Validation Loss: 0.5370\n",
      "[Trial 104] Epoch 35/60, Training Loss: 0.7405, Validation Loss: 0.6037\n",
      "[Trial 105] Epoch 29/60, Training Loss: 0.6346, Validation Loss: 0.5297\n",
      "[Trial 109] Epoch 16/60, Training Loss: 0.8187, Validation Loss: 0.6965\n",
      "[Trial 110] Epoch 3/60, Training Loss: 1.7928, Validation Loss: 1.7029\n",
      "[Trial 108] Epoch 18/60, Training Loss: 0.8681, Validation Loss: 0.8401\n",
      "[Trial 100] Epoch 38/60, Training Loss: 0.6289, Validation Loss: 0.5827\n",
      "[Trial 112] Epoch 2/60, Training Loss: 1.9300, Validation Loss: 2.0138\n",
      "[Trial 107] Epoch 23/60, Training Loss: 0.7323, Validation Loss: 0.7674\n",
      "[Trial 106] Epoch 28/60, Training Loss: 0.6664, Validation Loss: 0.5866\n",
      "[Trial 111] Epoch 3/60, Training Loss: 1.5413, Validation Loss: 1.3902\n",
      "[Trial 109] Epoch 17/60, Training Loss: 0.8120, Validation Loss: 0.6790\n",
      "[Trial 98] Epoch 42/60, Training Loss: 0.5518, Validation Loss: 0.4701\n",
      "[Trial 99] Epoch 41/60, Training Loss: 0.5837, Validation Loss: 0.4974\n",
      "[Trial 103] Epoch 36/60, Training Loss: 0.6485, Validation Loss: 0.5403\n",
      "[Trial 102] Epoch 37/60, Training Loss: 0.6574, Validation Loss: 0.5661\n",
      "[Trial 104] Epoch 36/60, Training Loss: 0.7332, Validation Loss: 0.6813\n",
      "[Trial 105] Epoch 30/60, Training Loss: 0.6242, Validation Loss: 0.5616\n",
      "[Trial 108] Epoch 19/60, Training Loss: 0.8911, Validation Loss: 0.6999\n",
      "[Trial 110] Epoch 4/60, Training Loss: 1.4519, Validation Loss: 1.0840\n",
      "[Trial 89] Epoch 44/60, Training Loss: 0.5622, Validation Loss: 0.4877\n",
      "[Trial 100] Epoch 39/60, Training Loss: 0.6294, Validation Loss: 0.5607\n",
      "[Trial 88] Epoch 54/60, Training Loss: 0.5387, Validation Loss: 0.4675\n",
      "[Trial 109] Epoch 18/60, Training Loss: 0.7803, Validation Loss: 0.7221\n",
      "[Trial 112] Epoch 3/60, Training Loss: 1.5308, Validation Loss: 1.2982\n",
      "[Trial 107] Epoch 24/60, Training Loss: 0.7208, Validation Loss: 0.6911\n",
      "[Trial 106] Epoch 29/60, Training Loss: 0.6522, Validation Loss: 0.5569\n",
      "[Trial 111] Epoch 4/60, Training Loss: 1.3305, Validation Loss: 1.0110\n",
      "[Trial 98] Epoch 43/60, Training Loss: 0.5539, Validation Loss: 0.4784\n",
      "[Trial 99] Epoch 42/60, Training Loss: 0.5883, Validation Loss: 0.5062\n",
      "[Trial 103] Epoch 37/60, Training Loss: 0.6435, Validation Loss: 0.5352\n",
      "[Trial 109] Epoch 19/60, Training Loss: 0.7937, Validation Loss: 0.8382\n",
      "[Trial 102] Epoch 38/60, Training Loss: 0.6425, Validation Loss: 0.5455\n",
      "[Trial 104] Epoch 37/60, Training Loss: 0.7398, Validation Loss: 0.6301\n",
      "[Trial 105] Epoch 31/60, Training Loss: 0.6238, Validation Loss: 0.5716\n",
      "[Trial 108] Epoch 20/60, Training Loss: 0.8423, Validation Loss: 0.8243\n",
      "[Trial 100] Epoch 40/60, Training Loss: 0.6288, Validation Loss: 0.5721\n",
      "[Trial 110] Epoch 5/60, Training Loss: 1.2215, Validation Loss: 1.2393\n",
      "[Trial 109] Epoch 20/60, Training Loss: 0.7768, Validation Loss: 0.6437\n",
      "[Trial 112] Epoch 4/60, Training Loss: 1.3470, Validation Loss: 0.9562\n",
      "[Trial 107] Epoch 25/60, Training Loss: 0.7086, Validation Loss: 0.6988\n",
      "[Trial 106] Epoch 30/60, Training Loss: 0.6580, Validation Loss: 0.6358\n",
      "[Trial 111] Epoch 5/60, Training Loss: 1.1785, Validation Loss: 0.8789\n",
      "[Trial 98] Epoch 44/60, Training Loss: 0.5532, Validation Loss: 0.4722\n",
      "[Trial 99] Epoch 43/60, Training Loss: 0.5808, Validation Loss: 0.4997\n",
      "[Trial 89] Epoch 45/60, Training Loss: 0.5691, Validation Loss: 0.4896\n",
      "[Trial 103] Epoch 38/60, Training Loss: 0.6377, Validation Loss: 0.5407\n",
      "[Trial 102] Epoch 39/60, Training Loss: 0.6199, Validation Loss: 0.5082\n",
      "[Trial 88] Epoch 55/60, Training Loss: 0.5445, Validation Loss: 0.4761\n",
      "[Trial 104] Epoch 38/60, Training Loss: 0.7364, Validation Loss: 0.6574\n",
      "[Trial 105] Epoch 32/60, Training Loss: 0.6493, Validation Loss: 0.5741\n",
      "[Trial 109] Epoch 21/60, Training Loss: 0.7455, Validation Loss: 0.6097\n",
      "[Trial 100] Epoch 41/60, Training Loss: 0.6277, Validation Loss: 0.5334\n",
      "[Trial 108] Epoch 21/60, Training Loss: 0.8355, Validation Loss: 0.7896\n",
      "[Trial 110] Epoch 6/60, Training Loss: 1.0953, Validation Loss: 0.9058\n",
      "[Trial 112] Epoch 5/60, Training Loss: 1.1736, Validation Loss: 2.3459\n",
      "[Trial 107] Epoch 26/60, Training Loss: 0.7043, Validation Loss: 0.5831\n",
      "[Trial 106] Epoch 31/60, Training Loss: 0.6093, Validation Loss: 0.5158\n",
      "[Trial 111] Epoch 6/60, Training Loss: 1.0693, Validation Loss: 0.9809\n",
      "[Trial 109] Epoch 22/60, Training Loss: 0.7393, Validation Loss: 0.5978\n",
      "[Trial 98] Epoch 45/60, Training Loss: 0.5671, Validation Loss: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:13:06,566] Trial 99 finished with value: 0.497419232626756 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.005284029543408422, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 99] Epoch 44/60, Training Loss: 0.5762, Validation Loss: 0.5089\n",
      "[Trial 99] Early stopping after 44 epochs.\n",
      "[Trial 103] Epoch 39/60, Training Loss: 0.6324, Validation Loss: 0.5243\n",
      "[Trial 102] Epoch 40/60, Training Loss: 0.6229, Validation Loss: 0.5230\n",
      "[Trial 104] Epoch 39/60, Training Loss: 0.7265, Validation Loss: 0.6940\n",
      "[Trial 105] Epoch 33/60, Training Loss: 0.6281, Validation Loss: 0.5262\n",
      "[Trial 100] Epoch 42/60, Training Loss: 0.6129, Validation Loss: 0.5626\n",
      "[Trial 108] Epoch 22/60, Training Loss: 0.7629, Validation Loss: 0.6134\n",
      "[Trial 110] Epoch 7/60, Training Loss: 1.0387, Validation Loss: 1.0292\n",
      "[Trial 109] Epoch 23/60, Training Loss: 0.7355, Validation Loss: 0.5857\n",
      "[Trial 89] Epoch 46/60, Training Loss: 0.5673, Validation Loss: 0.4855\n",
      "[Trial 112] Epoch 6/60, Training Loss: 1.1252, Validation Loss: 0.9895\n",
      "[Trial 106] Epoch 32/60, Training Loss: 0.5978, Validation Loss: 0.5477\n",
      "[Trial 111] Epoch 7/60, Training Loss: 0.9929, Validation Loss: 0.9977\n",
      "[Trial 107] Epoch 27/60, Training Loss: 0.6820, Validation Loss: 0.6414\n",
      "[Trial 88] Epoch 56/60, Training Loss: 0.5416, Validation Loss: 0.4581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:14:16,201] Trial 98 finished with value: 0.4701389541228612 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.012535469389134118, 'batch_size': 16, 'patience': 4}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 98] Epoch 46/60, Training Loss: 0.5513, Validation Loss: 0.4835\n",
      "[Trial 98] Early stopping after 46 epochs.\n",
      "[Trial 113] Epoch 1/60, Training Loss: 3.5696, Validation Loss: 1.5837\n",
      "[Trial 103] Epoch 40/60, Training Loss: 0.6369, Validation Loss: 0.5822\n",
      "[Trial 102] Epoch 41/60, Training Loss: 0.6175, Validation Loss: 0.5189\n",
      "[Trial 104] Epoch 40/60, Training Loss: 0.7482, Validation Loss: 0.6859\n",
      "[Trial 109] Epoch 24/60, Training Loss: 0.7319, Validation Loss: 0.6007\n",
      "[Trial 105] Epoch 34/60, Training Loss: 0.6170, Validation Loss: 0.5654\n",
      "[Trial 100] Epoch 43/60, Training Loss: 0.6156, Validation Loss: 0.5644\n",
      "[Trial 108] Epoch 23/60, Training Loss: 0.7451, Validation Loss: 0.5718\n",
      "[Trial 110] Epoch 8/60, Training Loss: 0.9842, Validation Loss: 0.9561\n",
      "[Trial 112] Epoch 7/60, Training Loss: 1.0146, Validation Loss: 0.8837\n",
      "[Trial 109] Epoch 25/60, Training Loss: 0.7208, Validation Loss: 0.6030\n",
      "[Trial 111] Epoch 8/60, Training Loss: 0.9702, Validation Loss: 0.8379\n",
      "[Trial 106] Epoch 33/60, Training Loss: 0.6011, Validation Loss: 0.5182\n",
      "[Trial 107] Epoch 28/60, Training Loss: 0.6978, Validation Loss: 0.7247\n",
      "[Trial 114] Epoch 1/60, Training Loss: 5.6268, Validation Loss: 2.7467\n",
      "[Trial 113] Epoch 2/60, Training Loss: 1.8572, Validation Loss: 1.4274\n",
      "[Trial 103] Epoch 41/60, Training Loss: 0.6343, Validation Loss: 0.5593\n",
      "[Trial 104] Epoch 41/60, Training Loss: 0.6977, Validation Loss: 0.5937\n",
      "[Trial 102] Epoch 42/60, Training Loss: 0.6160, Validation Loss: 0.5092\n",
      "[Trial 105] Epoch 35/60, Training Loss: 0.6230, Validation Loss: 0.5614\n",
      "[Trial 100] Epoch 44/60, Training Loss: 0.6034, Validation Loss: 0.5496\n",
      "[Trial 89] Epoch 47/60, Training Loss: 0.5656, Validation Loss: 0.5174\n",
      "[Trial 109] Epoch 26/60, Training Loss: 0.7028, Validation Loss: 0.5901\n",
      "[Trial 108] Epoch 24/60, Training Loss: 0.7507, Validation Loss: 0.9324\n",
      "[Trial 110] Epoch 9/60, Training Loss: 0.9039, Validation Loss: 0.7081\n",
      "[Trial 88] Epoch 57/60, Training Loss: 0.5404, Validation Loss: 0.4695\n",
      "[Trial 112] Epoch 8/60, Training Loss: 0.9621, Validation Loss: 1.1287\n",
      "[Trial 111] Epoch 9/60, Training Loss: 0.9076, Validation Loss: 0.6550\n",
      "[Trial 106] Epoch 34/60, Training Loss: 0.5982, Validation Loss: 0.5395\n",
      "[Trial 107] Epoch 29/60, Training Loss: 0.6663, Validation Loss: 0.5463\n",
      "[Trial 114] Epoch 2/60, Training Loss: 2.3367, Validation Loss: 1.8915\n",
      "[Trial 113] Epoch 3/60, Training Loss: 1.5385, Validation Loss: 1.2640\n",
      "[Trial 109] Epoch 27/60, Training Loss: 0.6985, Validation Loss: 0.5601\n",
      "[Trial 103] Epoch 42/60, Training Loss: 0.6377, Validation Loss: 0.5490\n",
      "[Trial 104] Epoch 42/60, Training Loss: 0.6899, Validation Loss: 0.5633\n",
      "[Trial 102] Epoch 43/60, Training Loss: 0.6174, Validation Loss: 0.5169\n",
      "[Trial 100] Epoch 45/60, Training Loss: 0.6057, Validation Loss: 0.5669\n",
      "[Trial 105] Epoch 36/60, Training Loss: 0.6263, Validation Loss: 0.7391\n",
      "[Trial 108] Epoch 25/60, Training Loss: 0.7713, Validation Loss: 0.6009\n",
      "[Trial 110] Epoch 10/60, Training Loss: 0.8820, Validation Loss: 1.2148\n",
      "[Trial 109] Epoch 28/60, Training Loss: 0.7134, Validation Loss: 0.6265\n",
      "[Trial 112] Epoch 9/60, Training Loss: 0.9293, Validation Loss: 0.8572\n",
      "[Trial 111] Epoch 10/60, Training Loss: 0.8857, Validation Loss: 0.8296\n",
      "[Trial 106] Epoch 35/60, Training Loss: 0.5973, Validation Loss: 0.5571\n",
      "[Trial 107] Epoch 30/60, Training Loss: 0.6745, Validation Loss: 0.5926\n",
      "[Trial 114] Epoch 3/60, Training Loss: 1.8408, Validation Loss: 1.7994\n",
      "[Trial 113] Epoch 4/60, Training Loss: 1.3834, Validation Loss: 1.0956\n",
      "[Trial 89] Epoch 48/60, Training Loss: 0.5612, Validation Loss: 0.5063\n",
      "[Trial 104] Epoch 43/60, Training Loss: 0.6753, Validation Loss: 0.5652\n",
      "[Trial 103] Epoch 43/60, Training Loss: 0.6390, Validation Loss: 0.5725\n",
      "[Trial 102] Epoch 44/60, Training Loss: 0.6103, Validation Loss: 0.5160\n",
      "[Trial 109] Epoch 29/60, Training Loss: 0.7074, Validation Loss: 0.6234\n",
      "[Trial 100] Epoch 46/60, Training Loss: 0.6156, Validation Loss: 0.5983\n",
      "[Trial 105] Epoch 37/60, Training Loss: 0.6287, Validation Loss: 0.5313\n",
      "[Trial 88] Epoch 58/60, Training Loss: 0.5391, Validation Loss: 0.4624\n",
      "[Trial 108] Epoch 26/60, Training Loss: 0.7408, Validation Loss: 0.5870\n",
      "[Trial 110] Epoch 11/60, Training Loss: 0.9806, Validation Loss: 0.6825\n",
      "[Trial 112] Epoch 10/60, Training Loss: 0.8868, Validation Loss: 0.9720\n",
      "[Trial 106] Epoch 36/60, Training Loss: 0.6216, Validation Loss: 0.5912\n",
      "[Trial 111] Epoch 11/60, Training Loss: 0.8958, Validation Loss: 0.6985\n",
      "[Trial 109] Epoch 30/60, Training Loss: 0.6916, Validation Loss: 0.5844\n",
      "[Trial 107] Epoch 31/60, Training Loss: 0.6863, Validation Loss: 1.0323\n",
      "[Trial 114] Epoch 4/60, Training Loss: 1.4674, Validation Loss: 2.3218\n",
      "[Trial 113] Epoch 5/60, Training Loss: 1.2637, Validation Loss: 1.0605\n",
      "[Trial 104] Epoch 44/60, Training Loss: 0.6753, Validation Loss: 0.5718\n",
      "[Trial 103] Epoch 44/60, Training Loss: 0.6245, Validation Loss: 0.4986\n",
      "[Trial 102] Epoch 45/60, Training Loss: 0.6154, Validation Loss: 0.5008\n",
      "[Trial 100] Epoch 47/60, Training Loss: 0.6323, Validation Loss: 0.5409\n",
      "[Trial 105] Epoch 38/60, Training Loss: 0.6221, Validation Loss: 0.6088\n",
      "[Trial 108] Epoch 27/60, Training Loss: 0.7341, Validation Loss: 0.5722\n",
      "[Trial 109] Epoch 31/60, Training Loss: 0.6959, Validation Loss: 0.5850\n",
      "[Trial 110] Epoch 12/60, Training Loss: 0.8431, Validation Loss: 0.7356\n",
      "[Trial 89] Epoch 49/60, Training Loss: 0.5545, Validation Loss: 0.4821\n",
      "[Trial 112] Epoch 11/60, Training Loss: 0.8744, Validation Loss: 0.7971\n",
      "[Trial 106] Epoch 37/60, Training Loss: 0.5844, Validation Loss: 0.5203\n",
      "[Trial 111] Epoch 12/60, Training Loss: 0.8278, Validation Loss: 0.7020\n",
      "[Trial 107] Epoch 32/60, Training Loss: 0.7024, Validation Loss: 0.6085\n",
      "[Trial 113] Epoch 6/60, Training Loss: 1.1760, Validation Loss: 0.9733\n",
      "[Trial 114] Epoch 5/60, Training Loss: 1.2598, Validation Loss: 0.8742\n",
      "[Trial 104] Epoch 45/60, Training Loss: 0.6712, Validation Loss: 0.6125\n",
      "[Trial 109] Epoch 32/60, Training Loss: 0.6915, Validation Loss: 0.5819\n",
      "[Trial 102] Epoch 46/60, Training Loss: 0.6153, Validation Loss: 0.5076\n",
      "[Trial 103] Epoch 45/60, Training Loss: 0.6075, Validation Loss: 0.5097\n",
      "[Trial 88] Epoch 59/60, Training Loss: 0.5423, Validation Loss: 0.4624\n",
      "[Trial 100] Epoch 48/60, Training Loss: 0.5884, Validation Loss: 0.5309\n",
      "[Trial 105] Epoch 39/60, Training Loss: 0.5924, Validation Loss: 0.5125\n",
      "[Trial 108] Epoch 28/60, Training Loss: 0.7110, Validation Loss: 0.5660\n",
      "[Trial 110] Epoch 13/60, Training Loss: 0.8241, Validation Loss: 0.7019\n",
      "[Trial 109] Epoch 33/60, Training Loss: 0.6280, Validation Loss: 0.5211\n",
      "[Trial 112] Epoch 12/60, Training Loss: 0.8504, Validation Loss: 0.8676\n",
      "[Trial 106] Epoch 38/60, Training Loss: 0.5823, Validation Loss: 0.4941\n",
      "[Trial 111] Epoch 13/60, Training Loss: 0.7984, Validation Loss: 1.0780\n",
      "[Trial 113] Epoch 7/60, Training Loss: 1.1003, Validation Loss: 0.8434\n",
      "[Trial 107] Epoch 33/60, Training Loss: 0.6849, Validation Loss: 0.9662\n",
      "[Trial 114] Epoch 6/60, Training Loss: 1.1133, Validation Loss: 1.3081\n",
      "[Trial 104] Epoch 46/60, Training Loss: 0.6896, Validation Loss: 0.5633\n",
      "[Trial 102] Epoch 47/60, Training Loss: 0.6134, Validation Loss: 0.5027\n",
      "[Trial 103] Epoch 46/60, Training Loss: 0.6062, Validation Loss: 0.5254\n",
      "[Trial 100] Epoch 49/60, Training Loss: 0.5817, Validation Loss: 0.5379\n",
      "[Trial 109] Epoch 34/60, Training Loss: 0.6163, Validation Loss: 0.5115\n",
      "[Trial 89] Epoch 50/60, Training Loss: 0.5593, Validation Loss: 0.4811\n",
      "[Trial 105] Epoch 40/60, Training Loss: 0.5921, Validation Loss: 0.5152\n",
      "[Trial 108] Epoch 29/60, Training Loss: 0.7200, Validation Loss: 0.5642\n",
      "[Trial 110] Epoch 14/60, Training Loss: 0.7978, Validation Loss: 0.7812\n",
      "[Trial 112] Epoch 13/60, Training Loss: 0.8138, Validation Loss: 0.6361\n",
      "[Trial 106] Epoch 39/60, Training Loss: 0.5774, Validation Loss: 0.5161\n",
      "[Trial 111] Epoch 14/60, Training Loss: 0.8428, Validation Loss: 0.7816\n",
      "[Trial 109] Epoch 35/60, Training Loss: 0.6149, Validation Loss: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:22:46,132] Trial 88 finished with value: 0.45812261079748473 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.003460442489922144, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 88] Epoch 60/60, Training Loss: 0.5373, Validation Loss: 0.4678\n",
      "[Trial 113] Epoch 8/60, Training Loss: 1.0665, Validation Loss: 0.8029\n",
      "[Trial 114] Epoch 7/60, Training Loss: 1.1484, Validation Loss: 1.0378\n",
      "[Trial 107] Epoch 34/60, Training Loss: 0.7128, Validation Loss: 0.6586\n",
      "[Trial 104] Epoch 47/60, Training Loss: 0.6694, Validation Loss: 0.5514\n",
      "[Trial 102] Epoch 48/60, Training Loss: 0.6092, Validation Loss: 0.5145\n",
      "[Trial 103] Epoch 47/60, Training Loss: 0.6006, Validation Loss: 0.5076\n",
      "[Trial 100] Epoch 50/60, Training Loss: 0.5788, Validation Loss: 0.5141\n",
      "[Trial 105] Epoch 41/60, Training Loss: 0.5922, Validation Loss: 0.5084\n",
      "[Trial 108] Epoch 30/60, Training Loss: 0.7185, Validation Loss: 0.5839\n",
      "[Trial 109] Epoch 36/60, Training Loss: 0.6293, Validation Loss: 0.5209\n",
      "[Trial 110] Epoch 15/60, Training Loss: 0.8128, Validation Loss: 0.7911\n",
      "[Trial 112] Epoch 14/60, Training Loss: 0.7707, Validation Loss: 0.6420\n",
      "[Trial 106] Epoch 40/60, Training Loss: 0.5713, Validation Loss: 0.4851\n",
      "[Trial 111] Epoch 15/60, Training Loss: 0.8326, Validation Loss: 0.8282\n",
      "[Trial 113] Epoch 9/60, Training Loss: 0.9974, Validation Loss: 0.8141\n",
      "[Trial 115] Epoch 1/60, Training Loss: 13.2756, Validation Loss: 2.8173\n",
      "[Trial 89] Epoch 51/60, Training Loss: 0.5614, Validation Loss: 0.4862\n",
      "[Trial 114] Epoch 8/60, Training Loss: 1.0119, Validation Loss: 0.8533\n",
      "[Trial 104] Epoch 48/60, Training Loss: 0.6530, Validation Loss: 0.5368\n",
      "[Trial 107] Epoch 35/60, Training Loss: 0.6061, Validation Loss: 0.5048\n",
      "[Trial 102] Epoch 49/60, Training Loss: 0.6058, Validation Loss: 0.5081\n",
      "[Trial 109] Epoch 37/60, Training Loss: 0.6060, Validation Loss: 0.5207\n",
      "[Trial 103] Epoch 48/60, Training Loss: 0.6098, Validation Loss: 0.4940\n",
      "[Trial 100] Epoch 51/60, Training Loss: 0.5776, Validation Loss: 0.5127\n",
      "[Trial 105] Epoch 42/60, Training Loss: 0.5966, Validation Loss: 0.5490\n",
      "[Trial 108] Epoch 31/60, Training Loss: 0.7072, Validation Loss: 0.5909\n",
      "[Trial 110] Epoch 16/60, Training Loss: 0.7971, Validation Loss: 0.8092\n",
      "[Trial 112] Epoch 15/60, Training Loss: 0.7809, Validation Loss: 1.4687\n",
      "[Trial 109] Epoch 38/60, Training Loss: 0.5985, Validation Loss: 0.5087\n",
      "[Trial 106] Epoch 41/60, Training Loss: 0.5737, Validation Loss: 0.5378\n",
      "[Trial 111] Epoch 16/60, Training Loss: 0.7239, Validation Loss: 0.5857\n",
      "[Trial 113] Epoch 10/60, Training Loss: 0.9690, Validation Loss: 0.8327\n",
      "[Trial 115] Epoch 2/60, Training Loss: 2.8337, Validation Loss: 4.4100\n",
      "[Trial 104] Epoch 49/60, Training Loss: 0.6583, Validation Loss: 0.5563\n",
      "[Trial 114] Epoch 9/60, Training Loss: 0.9560, Validation Loss: 0.7405\n",
      "[Trial 107] Epoch 36/60, Training Loss: 0.5943, Validation Loss: 0.5570\n",
      "[Trial 102] Epoch 50/60, Training Loss: 0.5983, Validation Loss: 0.5074\n",
      "[Trial 103] Epoch 49/60, Training Loss: 0.6010, Validation Loss: 0.4975\n",
      "[Trial 100] Epoch 52/60, Training Loss: 0.5769, Validation Loss: 0.5340\n",
      "[Trial 109] Epoch 39/60, Training Loss: 0.6097, Validation Loss: 0.5287\n",
      "[Trial 105] Epoch 43/60, Training Loss: 0.5847, Validation Loss: 0.5179\n",
      "[Trial 108] Epoch 32/60, Training Loss: 0.7117, Validation Loss: 0.6057\n",
      "[Trial 89] Epoch 52/60, Training Loss: 0.5579, Validation Loss: 0.4823\n",
      "[Trial 110] Epoch 17/60, Training Loss: 0.7896, Validation Loss: 0.9227\n",
      "[Trial 112] Epoch 16/60, Training Loss: 0.9006, Validation Loss: 0.6103\n",
      "[Trial 106] Epoch 42/60, Training Loss: 0.5664, Validation Loss: 0.5039\n",
      "[Trial 111] Epoch 17/60, Training Loss: 0.7172, Validation Loss: 0.6617\n",
      "[Trial 113] Epoch 11/60, Training Loss: 0.9697, Validation Loss: 0.7368\n",
      "[Trial 109] Epoch 40/60, Training Loss: 0.6097, Validation Loss: 0.5629\n",
      "[Trial 115] Epoch 3/60, Training Loss: 2.5370, Validation Loss: 2.5703\n",
      "[Trial 104] Epoch 50/60, Training Loss: 0.6676, Validation Loss: 0.5640\n",
      "[Trial 114] Epoch 10/60, Training Loss: 0.8892, Validation Loss: 0.6872\n",
      "[Trial 107] Epoch 37/60, Training Loss: 0.6015, Validation Loss: 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:26:42,940] Trial 102 finished with value: 0.5007724935809771 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0007887790119799214, 'batch_size': 16, 'patience': 6}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 102] Epoch 51/60, Training Loss: 0.5988, Validation Loss: 0.5012\n",
      "[Trial 102] Early stopping after 51 epochs.\n",
      "[Trial 103] Epoch 50/60, Training Loss: 0.5984, Validation Loss: 0.5232\n",
      "[Trial 100] Epoch 53/60, Training Loss: 0.5861, Validation Loss: 0.5313\n",
      "[Trial 105] Epoch 44/60, Training Loss: 0.5721, Validation Loss: 0.5061\n",
      "[Trial 108] Epoch 33/60, Training Loss: 0.7096, Validation Loss: 0.5565\n",
      "[Trial 109] Epoch 41/60, Training Loss: 0.6066, Validation Loss: 0.5097\n",
      "[Trial 112] Epoch 17/60, Training Loss: 0.7824, Validation Loss: 0.7374\n",
      "[Trial 110] Epoch 18/60, Training Loss: 0.7080, Validation Loss: 0.5572\n",
      "[Trial 106] Epoch 43/60, Training Loss: 0.5889, Validation Loss: 0.5654\n",
      "[Trial 111] Epoch 18/60, Training Loss: 0.7161, Validation Loss: 0.6954\n",
      "[Trial 113] Epoch 12/60, Training Loss: 0.9077, Validation Loss: 0.8674\n",
      "[Trial 104] Epoch 51/60, Training Loss: 0.6746, Validation Loss: 0.6309\n",
      "[Trial 115] Epoch 4/60, Training Loss: 2.0929, Validation Loss: 3.2725\n",
      "[Trial 114] Epoch 11/60, Training Loss: 0.9060, Validation Loss: 1.0851\n",
      "[Trial 107] Epoch 38/60, Training Loss: 0.5919, Validation Loss: 0.5037\n",
      "[Trial 116] Epoch 1/60, Training Loss: 5.1335, Validation Loss: 2.5111\n",
      "[Trial 103] Epoch 51/60, Training Loss: 0.5980, Validation Loss: 0.4987\n",
      "[Trial 109] Epoch 42/60, Training Loss: 0.5989, Validation Loss: 0.5074\n",
      "[Trial 100] Epoch 54/60, Training Loss: 0.5875, Validation Loss: 0.5087\n",
      "[Trial 89] Epoch 53/60, Training Loss: 0.5577, Validation Loss: 0.4883\n",
      "[Trial 105] Epoch 45/60, Training Loss: 0.5747, Validation Loss: 0.4949\n",
      "[Trial 108] Epoch 34/60, Training Loss: 0.6893, Validation Loss: 0.5487\n",
      "[Trial 112] Epoch 18/60, Training Loss: 0.7852, Validation Loss: 0.6352\n",
      "[Trial 110] Epoch 19/60, Training Loss: 0.6779, Validation Loss: 0.6256\n",
      "[Trial 106] Epoch 44/60, Training Loss: 0.5964, Validation Loss: 0.5893\n",
      "[Trial 109] Epoch 43/60, Training Loss: 0.6095, Validation Loss: 0.5432\n",
      "[Trial 111] Epoch 19/60, Training Loss: 0.7321, Validation Loss: 0.5717\n",
      "[Trial 113] Epoch 13/60, Training Loss: 0.9179, Validation Loss: 0.7719\n",
      "[Trial 104] Epoch 52/60, Training Loss: 0.6692, Validation Loss: 0.5753\n",
      "[Trial 115] Epoch 5/60, Training Loss: 1.9446, Validation Loss: 1.8149\n",
      "[Trial 114] Epoch 12/60, Training Loss: 0.9308, Validation Loss: 0.7911\n",
      "[Trial 107] Epoch 39/60, Training Loss: 0.5925, Validation Loss: 0.4887\n",
      "[Trial 116] Epoch 2/60, Training Loss: 2.2899, Validation Loss: 1.6694\n",
      "[Trial 103] Epoch 52/60, Training Loss: 0.5917, Validation Loss: 0.4913\n",
      "[Trial 100] Epoch 55/60, Training Loss: 0.5696, Validation Loss: 0.4987\n",
      "[Trial 109] Epoch 44/60, Training Loss: 0.6048, Validation Loss: 0.5449\n",
      "[Trial 105] Epoch 46/60, Training Loss: 0.5696, Validation Loss: 0.5107\n",
      "[Trial 108] Epoch 35/60, Training Loss: 0.6813, Validation Loss: 0.5429\n",
      "[Trial 112] Epoch 19/60, Training Loss: 0.7489, Validation Loss: 0.6369\n",
      "[Trial 110] Epoch 20/60, Training Loss: 0.6697, Validation Loss: 0.5516\n",
      "[Trial 106] Epoch 45/60, Training Loss: 0.5722, Validation Loss: 0.4890\n",
      "[Trial 111] Epoch 20/60, Training Loss: 0.6837, Validation Loss: 0.6448\n",
      "[Trial 113] Epoch 14/60, Training Loss: 0.8757, Validation Loss: 0.7227\n",
      "[Trial 104] Epoch 53/60, Training Loss: 0.6545, Validation Loss: 0.5708\n",
      "[Trial 89] Epoch 54/60, Training Loss: 0.5569, Validation Loss: 0.4930\n",
      "[Trial 115] Epoch 6/60, Training Loss: 1.5816, Validation Loss: 2.0575\n",
      "[Trial 109] Epoch 45/60, Training Loss: 0.6059, Validation Loss: 0.5051\n",
      "[Trial 114] Epoch 13/60, Training Loss: 0.8533, Validation Loss: 0.6984\n",
      "[Trial 116] Epoch 3/60, Training Loss: 1.9848, Validation Loss: 1.3689\n",
      "[Trial 107] Epoch 40/60, Training Loss: 0.5965, Validation Loss: 0.6289\n",
      "[Trial 103] Epoch 53/60, Training Loss: 0.5831, Validation Loss: 0.5083\n",
      "[Trial 100] Epoch 56/60, Training Loss: 0.5738, Validation Loss: 0.5068\n",
      "[Trial 105] Epoch 47/60, Training Loss: 0.5785, Validation Loss: 0.5263\n",
      "[Trial 108] Epoch 36/60, Training Loss: 0.6772, Validation Loss: 0.5467\n",
      "[Trial 109] Epoch 46/60, Training Loss: 0.6106, Validation Loss: 0.5146\n",
      "[Trial 112] Epoch 20/60, Training Loss: 0.7316, Validation Loss: 1.0912\n",
      "[Trial 106] Epoch 46/60, Training Loss: 0.5599, Validation Loss: 0.4777\n",
      "[Trial 110] Epoch 21/60, Training Loss: 0.6885, Validation Loss: 0.6967\n",
      "[Trial 111] Epoch 21/60, Training Loss: 0.6826, Validation Loss: 0.6542\n",
      "[Trial 113] Epoch 15/60, Training Loss: 0.8426, Validation Loss: 0.6895\n",
      "[Trial 104] Epoch 54/60, Training Loss: 0.6322, Validation Loss: 0.5308\n",
      "[Trial 115] Epoch 7/60, Training Loss: 1.4218, Validation Loss: 1.5191\n",
      "[Trial 114] Epoch 14/60, Training Loss: 0.8049, Validation Loss: 0.7410\n",
      "[Trial 116] Epoch 4/60, Training Loss: 1.4966, Validation Loss: 1.6995\n",
      "[Trial 107] Epoch 41/60, Training Loss: 0.6270, Validation Loss: 0.5303\n",
      "[Trial 103] Epoch 54/60, Training Loss: 0.5838, Validation Loss: 0.4959\n",
      "[Trial 100] Epoch 57/60, Training Loss: 0.5869, Validation Loss: 0.5149\n",
      "[Trial 109] Epoch 47/60, Training Loss: 0.6073, Validation Loss: 0.5232\n",
      "[Trial 105] Epoch 48/60, Training Loss: 0.5912, Validation Loss: 0.5014\n",
      "[Trial 108] Epoch 37/60, Training Loss: 0.6763, Validation Loss: 0.5429\n",
      "[Trial 89] Epoch 55/60, Training Loss: 0.5567, Validation Loss: 0.4989\n",
      "[Trial 112] Epoch 21/60, Training Loss: 0.7466, Validation Loss: 0.5977\n",
      "[Trial 106] Epoch 47/60, Training Loss: 0.5535, Validation Loss: 0.4839\n",
      "[Trial 111] Epoch 22/60, Training Loss: 0.6831, Validation Loss: 0.5590\n",
      "[Trial 110] Epoch 22/60, Training Loss: 0.7116, Validation Loss: 0.9756\n",
      "[Trial 109] Epoch 48/60, Training Loss: 0.5997, Validation Loss: 0.5156\n",
      "[Trial 113] Epoch 16/60, Training Loss: 0.8363, Validation Loss: 0.7544\n",
      "[Trial 104] Epoch 55/60, Training Loss: 0.6305, Validation Loss: 0.5347\n",
      "[Trial 115] Epoch 8/60, Training Loss: 1.2973, Validation Loss: 1.0457\n",
      "[Trial 114] Epoch 15/60, Training Loss: 0.7241, Validation Loss: 0.6347\n",
      "[Trial 116] Epoch 5/60, Training Loss: 1.3404, Validation Loss: 1.4174\n",
      "[Trial 100] Epoch 58/60, Training Loss: 0.5821, Validation Loss: 0.5464\n",
      "[Trial 103] Epoch 55/60, Training Loss: 0.5854, Validation Loss: 0.5153\n",
      "[Trial 107] Epoch 42/60, Training Loss: 0.6028, Validation Loss: 0.5849\n",
      "[Trial 109] Epoch 49/60, Training Loss: 0.5998, Validation Loss: 0.5991\n",
      "[Trial 105] Epoch 49/60, Training Loss: 0.5746, Validation Loss: 0.4991\n",
      "[Trial 108] Epoch 38/60, Training Loss: 0.6758, Validation Loss: 0.5659\n",
      "[Trial 112] Epoch 22/60, Training Loss: 0.7236, Validation Loss: 0.9427\n",
      "[Trial 106] Epoch 48/60, Training Loss: 0.5502, Validation Loss: 0.4937\n",
      "[Trial 111] Epoch 23/60, Training Loss: 0.6858, Validation Loss: 0.8005\n",
      "[Trial 110] Epoch 23/60, Training Loss: 0.7039, Validation Loss: 0.5716\n",
      "[Trial 113] Epoch 17/60, Training Loss: 0.8334, Validation Loss: 0.8097\n",
      "[Trial 104] Epoch 56/60, Training Loss: 0.6326, Validation Loss: 0.5415\n",
      "[Trial 115] Epoch 9/60, Training Loss: 1.1699, Validation Loss: 1.9291\n",
      "[Trial 114] Epoch 16/60, Training Loss: 0.7249, Validation Loss: 0.7545\n",
      "[Trial 109] Epoch 50/60, Training Loss: 0.6086, Validation Loss: 0.5398\n",
      "[Trial 100] Epoch 59/60, Training Loss: 0.5768, Validation Loss: 0.5331\n",
      "[Trial 116] Epoch 6/60, Training Loss: 1.2067, Validation Loss: 1.0175\n",
      "[Trial 103] Epoch 56/60, Training Loss: 0.5872, Validation Loss: 0.4900\n",
      "[Trial 107] Epoch 43/60, Training Loss: 0.6081, Validation Loss: 0.5143\n",
      "[Trial 89] Epoch 56/60, Training Loss: 0.5609, Validation Loss: 0.4977\n",
      "[Trial 105] Epoch 50/60, Training Loss: 0.5773, Validation Loss: 0.5085\n",
      "[Trial 108] Epoch 39/60, Training Loss: 0.6842, Validation Loss: 0.5653\n",
      "[Trial 109] Epoch 51/60, Training Loss: 0.5707, Validation Loss: 0.4829\n",
      "[Trial 112] Epoch 23/60, Training Loss: 0.8030, Validation Loss: 0.7466\n",
      "[Trial 106] Epoch 49/60, Training Loss: 0.5512, Validation Loss: 0.4911\n",
      "[Trial 111] Epoch 24/60, Training Loss: 0.7390, Validation Loss: 0.6374\n",
      "[Trial 113] Epoch 18/60, Training Loss: 0.8137, Validation Loss: 0.7139\n",
      "[Trial 104] Epoch 57/60, Training Loss: 0.6196, Validation Loss: 0.5173\n",
      "[Trial 110] Epoch 24/60, Training Loss: 0.6749, Validation Loss: 0.8952\n",
      "[Trial 115] Epoch 10/60, Training Loss: 1.3113, Validation Loss: 0.8916\n",
      "[Trial 114] Epoch 17/60, Training Loss: 0.7186, Validation Loss: 0.7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:35:33,339] Trial 100 finished with value: 0.4981227348248164 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.012263520634692864, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 100] Epoch 60/60, Training Loss: 0.5714, Validation Loss: 0.4981\n",
      "[Trial 116] Epoch 7/60, Training Loss: 1.0282, Validation Loss: 0.8931\n",
      "[Trial 103] Epoch 57/60, Training Loss: 0.5884, Validation Loss: 0.5197\n",
      "[Trial 107] Epoch 44/60, Training Loss: 0.6017, Validation Loss: 0.5354\n",
      "[Trial 109] Epoch 52/60, Training Loss: 0.5623, Validation Loss: 0.4817\n",
      "[Trial 105] Epoch 51/60, Training Loss: 0.5672, Validation Loss: 0.5035\n",
      "[Trial 108] Epoch 40/60, Training Loss: 0.6776, Validation Loss: 0.5382\n",
      "[Trial 112] Epoch 24/60, Training Loss: 0.7941, Validation Loss: 0.5825\n",
      "[Trial 106] Epoch 50/60, Training Loss: 0.5581, Validation Loss: 0.4974\n",
      "[Trial 111] Epoch 25/60, Training Loss: 0.6744, Validation Loss: 0.5930\n",
      "[Trial 113] Epoch 19/60, Training Loss: 0.7999, Validation Loss: 0.7880\n",
      "[Trial 104] Epoch 58/60, Training Loss: 0.6235, Validation Loss: 0.5321\n",
      "[Trial 109] Epoch 53/60, Training Loss: 0.5590, Validation Loss: 0.4789\n",
      "[Trial 110] Epoch 25/60, Training Loss: 0.6913, Validation Loss: 1.2048\n",
      "[Trial 89] Epoch 57/60, Training Loss: 0.5432, Validation Loss: 0.4776\n",
      "[Trial 115] Epoch 11/60, Training Loss: 1.1218, Validation Loss: 1.6850\n",
      "[Trial 114] Epoch 18/60, Training Loss: 0.7368, Validation Loss: 0.6710\n",
      "[Trial 117] Epoch 1/60, Training Loss: 5.0154, Validation Loss: 1.7105\n",
      "[Trial 116] Epoch 8/60, Training Loss: 0.9961, Validation Loss: 0.7638\n",
      "[Trial 103] Epoch 58/60, Training Loss: 0.5898, Validation Loss: 0.4913\n",
      "[Trial 107] Epoch 45/60, Training Loss: 0.5610, Validation Loss: 0.4828\n",
      "[Trial 109] Epoch 54/60, Training Loss: 0.5603, Validation Loss: 0.4815\n",
      "[Trial 105] Epoch 52/60, Training Loss: 0.5637, Validation Loss: 0.4825\n",
      "[Trial 108] Epoch 41/60, Training Loss: 0.6808, Validation Loss: 0.5594\n",
      "[Trial 112] Epoch 25/60, Training Loss: 0.7053, Validation Loss: 0.6545\n",
      "[Trial 106] Epoch 51/60, Training Loss: 0.5555, Validation Loss: 0.4935\n",
      "[Trial 111] Epoch 26/60, Training Loss: 0.6807, Validation Loss: 0.5912\n",
      "[Trial 113] Epoch 20/60, Training Loss: 0.7966, Validation Loss: 0.6833\n",
      "[Trial 104] Epoch 59/60, Training Loss: 0.6226, Validation Loss: 0.5444\n",
      "[Trial 110] Epoch 26/60, Training Loss: 0.7207, Validation Loss: 0.5412\n",
      "[Trial 115] Epoch 12/60, Training Loss: 1.1129, Validation Loss: 1.5998\n",
      "[Trial 114] Epoch 19/60, Training Loss: 0.7158, Validation Loss: 0.7825\n",
      "[Trial 109] Epoch 55/60, Training Loss: 0.5594, Validation Loss: 0.4905\n",
      "[Trial 117] Epoch 2/60, Training Loss: 1.9788, Validation Loss: 1.7813\n",
      "[Trial 116] Epoch 9/60, Training Loss: 0.9531, Validation Loss: 0.9766\n",
      "[Trial 103] Epoch 59/60, Training Loss: 0.5830, Validation Loss: 0.4917\n",
      "[Trial 107] Epoch 46/60, Training Loss: 0.5585, Validation Loss: 0.4767\n",
      "[Trial 105] Epoch 53/60, Training Loss: 0.5577, Validation Loss: 0.4812\n",
      "[Trial 89] Epoch 58/60, Training Loss: 0.5461, Validation Loss: 0.4846\n",
      "[Trial 108] Epoch 42/60, Training Loss: 0.6987, Validation Loss: 0.6121\n",
      "[Trial 112] Epoch 26/60, Training Loss: 0.6906, Validation Loss: 0.5652\n",
      "[Trial 109] Epoch 56/60, Training Loss: 0.5558, Validation Loss: 0.4747\n",
      "[Trial 106] Epoch 52/60, Training Loss: 0.5461, Validation Loss: 0.4849\n",
      "[Trial 111] Epoch 27/60, Training Loss: 0.6669, Validation Loss: 0.5379\n",
      "[Trial 113] Epoch 21/60, Training Loss: 0.7892, Validation Loss: 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:38:55,965] Trial 104 finished with value: 0.5172826915979385 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0004422091305098901, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 104] Epoch 60/60, Training Loss: 0.6253, Validation Loss: 0.5249\n",
      "[Trial 110] Epoch 27/60, Training Loss: 0.6495, Validation Loss: 0.5740\n",
      "[Trial 115] Epoch 13/60, Training Loss: 1.0994, Validation Loss: 2.2983\n",
      "[Trial 114] Epoch 20/60, Training Loss: 0.6860, Validation Loss: 0.5710\n",
      "[Trial 117] Epoch 3/60, Training Loss: 1.6706, Validation Loss: 1.2171\n",
      "[Trial 116] Epoch 10/60, Training Loss: 0.9343, Validation Loss: 1.2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:39:24,894] Trial 103 finished with value: 0.49002763132254284 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0007230641865747381, 'batch_size': 16, 'patience': 6}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 103] Epoch 60/60, Training Loss: 0.5783, Validation Loss: 0.4993\n",
      "[Trial 109] Epoch 57/60, Training Loss: 0.5531, Validation Loss: 0.4755\n",
      "[Trial 107] Epoch 47/60, Training Loss: 0.5706, Validation Loss: 0.5151\n",
      "[Trial 105] Epoch 54/60, Training Loss: 0.5588, Validation Loss: 0.4975\n",
      "[Trial 112] Epoch 27/60, Training Loss: 0.6777, Validation Loss: 0.8618\n",
      "[Trial 108] Epoch 43/60, Training Loss: 0.6975, Validation Loss: 0.5349\n",
      "[Trial 106] Epoch 53/60, Training Loss: 0.5459, Validation Loss: 0.4852\n",
      "[Trial 111] Epoch 28/60, Training Loss: 0.6532, Validation Loss: 0.5884\n",
      "[Trial 113] Epoch 22/60, Training Loss: 0.8255, Validation Loss: 0.8876\n",
      "[Trial 118] Epoch 1/60, Training Loss: 10.3841, Validation Loss: 2.2299\n",
      "[Trial 109] Epoch 58/60, Training Loss: 0.5599, Validation Loss: 0.5139\n",
      "[Trial 110] Epoch 28/60, Training Loss: 0.6541, Validation Loss: 0.7482\n",
      "[Trial 115] Epoch 14/60, Training Loss: 1.0281, Validation Loss: 0.7914\n",
      "[Trial 114] Epoch 21/60, Training Loss: 0.6667, Validation Loss: 0.5469\n",
      "[Trial 117] Epoch 4/60, Training Loss: 1.3411, Validation Loss: 1.5896\n",
      "[Trial 119] Epoch 1/60, Training Loss: 4.8201, Validation Loss: 2.4304\n",
      "[Trial 116] Epoch 11/60, Training Loss: 0.9124, Validation Loss: 1.1414\n",
      "[Trial 89] Epoch 59/60, Training Loss: 0.5421, Validation Loss: 0.4801\n",
      "[Trial 107] Epoch 48/60, Training Loss: 0.5676, Validation Loss: 0.5101\n",
      "[Trial 109] Epoch 59/60, Training Loss: 0.5647, Validation Loss: 0.4893\n",
      "[Trial 105] Epoch 55/60, Training Loss: 0.5538, Validation Loss: 0.4861\n",
      "[Trial 112] Epoch 28/60, Training Loss: 0.6881, Validation Loss: 0.7775\n",
      "[Trial 108] Epoch 44/60, Training Loss: 0.6683, Validation Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:41:22,610] Trial 106 finished with value: 0.4777392332752546 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.005278742609881735, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 106] Epoch 54/60, Training Loss: 0.5518, Validation Loss: 0.4866\n",
      "[Trial 106] Early stopping after 54 epochs.\n",
      "[Trial 118] Epoch 2/60, Training Loss: 2.2809, Validation Loss: 2.0422\n",
      "[Trial 113] Epoch 23/60, Training Loss: 0.8040, Validation Loss: 0.7329\n",
      "[Trial 111] Epoch 29/60, Training Loss: 0.6594, Validation Loss: 0.7930\n",
      "[Trial 110] Epoch 29/60, Training Loss: 0.6753, Validation Loss: 0.5737\n",
      "[Trial 115] Epoch 15/60, Training Loss: 1.0218, Validation Loss: 0.8862\n",
      "[Trial 117] Epoch 5/60, Training Loss: 1.1828, Validation Loss: 1.9097\n",
      "[Trial 114] Epoch 22/60, Training Loss: 0.6474, Validation Loss: 0.5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:41:53,293] Trial 109 finished with value: 0.47474536101023357 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.004819447519600177, 'batch_size': 32, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 109] Epoch 60/60, Training Loss: 0.5587, Validation Loss: 0.4810\n",
      "[Trial 119] Epoch 2/60, Training Loss: 1.9589, Validation Loss: 1.6788\n",
      "[Trial 116] Epoch 12/60, Training Loss: 0.9212, Validation Loss: 0.9028\n",
      "[Trial 107] Epoch 49/60, Training Loss: 0.5694, Validation Loss: 0.5230\n",
      "[Trial 105] Epoch 56/60, Training Loss: 0.5476, Validation Loss: 0.4776\n",
      "[Trial 112] Epoch 29/60, Training Loss: 0.6992, Validation Loss: 0.9579\n",
      "[Trial 108] Epoch 45/60, Training Loss: 0.6720, Validation Loss: 0.5414\n",
      "[Trial 118] Epoch 3/60, Training Loss: 1.7938, Validation Loss: 1.6525\n",
      "[Trial 113] Epoch 24/60, Training Loss: 0.7724, Validation Loss: 1.0457\n",
      "[Trial 120] Epoch 1/60, Training Loss: 8537582.3400, Validation Loss: 60.0377\n",
      "[Trial 111] Epoch 30/60, Training Loss: 0.6659, Validation Loss: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:42:52,592] Trial 89 finished with value: 0.47761008019248646 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006829941098273749, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 89] Epoch 60/60, Training Loss: 0.5457, Validation Loss: 0.4850\n",
      "[Trial 110] Epoch 30/60, Training Loss: 0.6509, Validation Loss: 0.5887\n",
      "[Trial 117] Epoch 6/60, Training Loss: 1.1324, Validation Loss: 1.5291\n",
      "[Trial 115] Epoch 16/60, Training Loss: 0.9825, Validation Loss: 0.8162\n",
      "[Trial 114] Epoch 23/60, Training Loss: 0.6454, Validation Loss: 0.5622\n",
      "[Trial 121] Epoch 1/60, Training Loss: 4.2140, Validation Loss: 2.0663\n",
      "[Trial 119] Epoch 3/60, Training Loss: 1.5491, Validation Loss: 2.2266\n",
      "[Trial 116] Epoch 13/60, Training Loss: 0.8268, Validation Loss: 0.9245\n",
      "[Trial 107] Epoch 50/60, Training Loss: 0.5682, Validation Loss: 0.5196\n",
      "[Trial 112] Epoch 30/60, Training Loss: 0.7331, Validation Loss: 0.5884\n",
      "[Trial 105] Epoch 57/60, Training Loss: 0.5508, Validation Loss: 0.4830\n",
      "[Trial 108] Epoch 46/60, Training Loss: 0.6628, Validation Loss: 0.5506\n",
      "[Trial 118] Epoch 4/60, Training Loss: 1.5646, Validation Loss: 2.0920\n",
      "[Trial 113] Epoch 25/60, Training Loss: 0.7736, Validation Loss: 0.6877\n",
      "[Trial 111] Epoch 31/60, Training Loss: 0.6821, Validation Loss: 0.5493\n",
      "[Trial 120] Epoch 2/60, Training Loss: 66.0429, Validation Loss: 140.3363\n",
      "[Trial 122] Epoch 1/60, Training Loss: 4.4264, Validation Loss: 1.8076\n",
      "[Trial 117] Epoch 7/60, Training Loss: 1.0288, Validation Loss: 1.0942\n",
      "[Trial 110] Epoch 31/60, Training Loss: 0.6414, Validation Loss: 0.5350\n",
      "[Trial 115] Epoch 17/60, Training Loss: 0.9109, Validation Loss: 0.8758\n",
      "[Trial 114] Epoch 24/60, Training Loss: 0.6467, Validation Loss: 0.5419\n",
      "[Trial 119] Epoch 4/60, Training Loss: 1.4125, Validation Loss: 3.3371\n",
      "[Trial 121] Epoch 2/60, Training Loss: 2.2124, Validation Loss: 1.7985\n",
      "[Trial 116] Epoch 14/60, Training Loss: 0.8428, Validation Loss: 0.8181\n",
      "[Trial 107] Epoch 51/60, Training Loss: 0.5554, Validation Loss: 0.5013\n",
      "[Trial 112] Epoch 31/60, Training Loss: 0.6797, Validation Loss: 0.6758\n",
      "[Trial 105] Epoch 58/60, Training Loss: 0.5529, Validation Loss: 0.4913\n",
      "[Trial 108] Epoch 47/60, Training Loss: 0.6565, Validation Loss: 0.5437\n",
      "[Trial 118] Epoch 5/60, Training Loss: 1.4239, Validation Loss: 1.2612\n",
      "[Trial 113] Epoch 26/60, Training Loss: 0.7341, Validation Loss: 0.6005\n",
      "[Trial 111] Epoch 32/60, Training Loss: 0.6605, Validation Loss: 0.6116\n",
      "[Trial 120] Epoch 3/60, Training Loss: 358.2862, Validation Loss: 20.6684\n",
      "[Trial 122] Epoch 2/60, Training Loss: 1.9918, Validation Loss: 1.3878\n",
      "[Trial 117] Epoch 8/60, Training Loss: 0.9727, Validation Loss: 1.1703\n",
      "[Trial 115] Epoch 18/60, Training Loss: 0.9362, Validation Loss: 0.9626\n",
      "[Trial 110] Epoch 32/60, Training Loss: 0.6348, Validation Loss: 0.6357\n",
      "[Trial 114] Epoch 25/60, Training Loss: 0.6498, Validation Loss: 0.5288\n",
      "[Trial 119] Epoch 5/60, Training Loss: 1.2204, Validation Loss: 1.0882\n",
      "[Trial 121] Epoch 3/60, Training Loss: 1.8957, Validation Loss: 1.8236\n",
      "[Trial 116] Epoch 15/60, Training Loss: 0.7224, Validation Loss: 0.5942\n",
      "[Trial 107] Epoch 52/60, Training Loss: 0.5389, Validation Loss: 0.4616\n",
      "[Trial 112] Epoch 32/60, Training Loss: 0.7050, Validation Loss: 0.8279\n",
      "[Trial 105] Epoch 59/60, Training Loss: 0.5591, Validation Loss: 0.4870\n",
      "[Trial 108] Epoch 48/60, Training Loss: 0.6572, Validation Loss: 0.5509\n",
      "[Trial 118] Epoch 6/60, Training Loss: 1.2407, Validation Loss: 1.1326\n",
      "[Trial 113] Epoch 27/60, Training Loss: 0.7291, Validation Loss: 0.6319\n",
      "[Trial 111] Epoch 33/60, Training Loss: 0.6542, Validation Loss: 0.6326\n",
      "[Trial 122] Epoch 3/60, Training Loss: 1.5730, Validation Loss: 1.1154\n",
      "[Trial 120] Epoch 4/60, Training Loss: 2671060643.3569, Validation Loss: 2223.4068\n",
      "[Trial 117] Epoch 9/60, Training Loss: 0.9465, Validation Loss: 0.8783\n",
      "[Trial 115] Epoch 19/60, Training Loss: 0.9227, Validation Loss: 0.8442\n",
      "[Trial 114] Epoch 26/60, Training Loss: 0.6333, Validation Loss: 0.5613\n",
      "[Trial 110] Epoch 33/60, Training Loss: 0.6469, Validation Loss: 0.5818\n",
      "[Trial 119] Epoch 6/60, Training Loss: 1.1258, Validation Loss: 1.3473\n",
      "[Trial 121] Epoch 4/60, Training Loss: 1.5409, Validation Loss: 1.1661\n",
      "[Trial 116] Epoch 16/60, Training Loss: 0.7135, Validation Loss: 0.6532\n",
      "[Trial 107] Epoch 53/60, Training Loss: 0.5526, Validation Loss: 0.4685\n",
      "[Trial 112] Epoch 33/60, Training Loss: 0.6254, Validation Loss: 0.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:47:51,898] Trial 105 finished with value: 0.47755245516697564 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.005223763395504372, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 105] Epoch 60/60, Training Loss: 0.5563, Validation Loss: 0.4950\n",
      "[Trial 118] Epoch 7/60, Training Loss: 1.1929, Validation Loss: 1.4673\n",
      "[Trial 108] Epoch 49/60, Training Loss: 0.6369, Validation Loss: 0.5107\n",
      "[Trial 111] Epoch 34/60, Training Loss: 0.6081, Validation Loss: 0.5601\n",
      "[Trial 113] Epoch 28/60, Training Loss: 0.7408, Validation Loss: 0.7001\n",
      "[Trial 122] Epoch 4/60, Training Loss: 1.3900, Validation Loss: 1.3873\n",
      "[Trial 120] Epoch 5/60, Training Loss: 125534303902.2784, Validation Loss: 668.4593\n",
      "[Trial 117] Epoch 10/60, Training Loss: 0.8636, Validation Loss: 0.7192\n",
      "[Trial 115] Epoch 20/60, Training Loss: 0.9285, Validation Loss: 0.7321\n",
      "[Trial 119] Epoch 7/60, Training Loss: 1.0283, Validation Loss: 0.7593\n",
      "[Trial 114] Epoch 27/60, Training Loss: 0.6084, Validation Loss: 0.5414\n",
      "[Trial 110] Epoch 34/60, Training Loss: 0.6398, Validation Loss: 0.5541\n",
      "[Trial 121] Epoch 5/60, Training Loss: 1.3197, Validation Loss: 1.1394\n",
      "[Trial 116] Epoch 17/60, Training Loss: 0.7038, Validation Loss: 0.6088\n",
      "[Trial 107] Epoch 54/60, Training Loss: 0.5380, Validation Loss: 0.4630\n",
      "[Trial 112] Epoch 34/60, Training Loss: 0.6064, Validation Loss: 0.5054\n",
      "[Trial 118] Epoch 8/60, Training Loss: 1.1037, Validation Loss: 1.9507\n",
      "[Trial 123] Epoch 1/60, Training Loss: 7.6951, Validation Loss: 2.4250\n",
      "[Trial 108] Epoch 50/60, Training Loss: 0.6310, Validation Loss: 0.5133\n",
      "[Trial 111] Epoch 35/60, Training Loss: 0.6132, Validation Loss: 0.5309\n",
      "[Trial 113] Epoch 29/60, Training Loss: 0.7343, Validation Loss: 0.9065\n",
      "[Trial 122] Epoch 5/60, Training Loss: 1.2534, Validation Loss: 1.0480\n",
      "[Trial 117] Epoch 11/60, Training Loss: 0.8300, Validation Loss: 0.6575\n",
      "[Trial 120] Epoch 6/60, Training Loss: 144603030.5667, Validation Loss: 821.8725\n",
      "[Trial 119] Epoch 8/60, Training Loss: 0.9776, Validation Loss: 0.8081\n",
      "[Trial 115] Epoch 21/60, Training Loss: 0.9021, Validation Loss: 1.6758\n",
      "[Trial 114] Epoch 28/60, Training Loss: 0.5984, Validation Loss: 0.4827\n",
      "[Trial 110] Epoch 35/60, Training Loss: 0.6382, Validation Loss: 0.5821\n",
      "[Trial 121] Epoch 6/60, Training Loss: 1.1473, Validation Loss: 1.4212\n",
      "[Trial 116] Epoch 18/60, Training Loss: 0.7072, Validation Loss: 0.9063\n",
      "[Trial 107] Epoch 55/60, Training Loss: 0.5477, Validation Loss: 0.4732\n",
      "[Trial 112] Epoch 35/60, Training Loss: 0.6029, Validation Loss: 0.5232\n",
      "[Trial 118] Epoch 9/60, Training Loss: 1.0949, Validation Loss: 1.2695\n",
      "[Trial 123] Epoch 2/60, Training Loss: 2.8622, Validation Loss: 1.6830\n",
      "[Trial 111] Epoch 36/60, Training Loss: 0.5991, Validation Loss: 0.5362\n",
      "[Trial 108] Epoch 51/60, Training Loss: 0.6233, Validation Loss: 0.4993\n",
      "[Trial 113] Epoch 30/60, Training Loss: 0.7562, Validation Loss: 0.5914\n",
      "[Trial 122] Epoch 6/60, Training Loss: 1.1268, Validation Loss: 1.0870\n",
      "[Trial 117] Epoch 12/60, Training Loss: 0.8276, Validation Loss: 0.9906\n",
      "[Trial 120] Epoch 7/60, Training Loss: 110982825.2100, Validation Loss: 638.0900\n",
      "[Trial 119] Epoch 9/60, Training Loss: 0.9316, Validation Loss: 1.9536\n",
      "[Trial 115] Epoch 22/60, Training Loss: 0.9455, Validation Loss: 1.1718\n",
      "[Trial 110] Epoch 36/60, Training Loss: 0.6315, Validation Loss: 0.5950\n",
      "[Trial 114] Epoch 29/60, Training Loss: 0.5980, Validation Loss: 0.4911\n",
      "[Trial 121] Epoch 7/60, Training Loss: 1.0898, Validation Loss: 0.8008\n",
      "[Trial 116] Epoch 19/60, Training Loss: 0.7311, Validation Loss: 0.6226\n",
      "[Trial 107] Epoch 56/60, Training Loss: 0.5387, Validation Loss: 0.4578\n",
      "[Trial 112] Epoch 36/60, Training Loss: 0.6099, Validation Loss: 0.5670\n",
      "[Trial 118] Epoch 10/60, Training Loss: 1.0386, Validation Loss: 1.4819\n",
      "[Trial 111] Epoch 37/60, Training Loss: 0.5853, Validation Loss: 0.5020\n",
      "[Trial 123] Epoch 3/60, Training Loss: 2.0880, Validation Loss: 2.3757\n",
      "[Trial 108] Epoch 52/60, Training Loss: 0.6210, Validation Loss: 0.4915\n",
      "[Trial 113] Epoch 31/60, Training Loss: 0.7112, Validation Loss: 0.8081\n",
      "[Trial 122] Epoch 7/60, Training Loss: 1.1331, Validation Loss: 1.0010\n",
      "[Trial 117] Epoch 13/60, Training Loss: 0.8197, Validation Loss: 0.7377\n",
      "[Trial 120] Epoch 8/60, Training Loss: 697.7288, Validation Loss: 689.0127\n",
      "[Trial 119] Epoch 10/60, Training Loss: 1.0136, Validation Loss: 0.8010\n",
      "[Trial 115] Epoch 23/60, Training Loss: 0.9110, Validation Loss: 0.7333\n",
      "[Trial 110] Epoch 37/60, Training Loss: 0.6546, Validation Loss: 0.7049\n",
      "[Trial 114] Epoch 30/60, Training Loss: 0.6017, Validation Loss: 0.5118\n",
      "[Trial 116] Epoch 20/60, Training Loss: 0.6985, Validation Loss: 0.8085\n",
      "[Trial 121] Epoch 8/60, Training Loss: 0.9847, Validation Loss: 1.0264\n",
      "[Trial 107] Epoch 57/60, Training Loss: 0.5300, Validation Loss: 0.4467\n",
      "[Trial 112] Epoch 37/60, Training Loss: 0.6206, Validation Loss: 0.5242\n",
      "[Trial 118] Epoch 11/60, Training Loss: 1.0103, Validation Loss: 0.8676\n",
      "[Trial 111] Epoch 38/60, Training Loss: 0.5870, Validation Loss: 0.5255\n",
      "[Trial 123] Epoch 4/60, Training Loss: 1.7770, Validation Loss: 1.3286\n",
      "[Trial 122] Epoch 8/60, Training Loss: 1.0456, Validation Loss: 0.8818\n",
      "[Trial 113] Epoch 32/60, Training Loss: 0.7386, Validation Loss: 0.6333\n",
      "[Trial 108] Epoch 53/60, Training Loss: 0.6213, Validation Loss: 0.5070\n",
      "[Trial 117] Epoch 14/60, Training Loss: 0.7747, Validation Loss: 0.6834\n",
      "[Trial 120] Epoch 9/60, Training Loss: 8448068.9391, Validation Loss: 665.5731\n",
      "[Trial 119] Epoch 11/60, Training Loss: 0.8618, Validation Loss: 0.7830\n",
      "[Trial 115] Epoch 24/60, Training Loss: 0.8775, Validation Loss: 1.0331\n",
      "[Trial 110] Epoch 38/60, Training Loss: 0.6195, Validation Loss: 0.5190\n",
      "[Trial 114] Epoch 31/60, Training Loss: 0.5963, Validation Loss: 0.5034\n",
      "[Trial 116] Epoch 21/60, Training Loss: 0.6909, Validation Loss: 0.6179\n",
      "[Trial 121] Epoch 9/60, Training Loss: 0.9506, Validation Loss: 0.9516\n",
      "[Trial 118] Epoch 12/60, Training Loss: 0.9434, Validation Loss: 0.8899\n",
      "[Trial 112] Epoch 38/60, Training Loss: 0.6174, Validation Loss: 0.5693\n",
      "[Trial 107] Epoch 58/60, Training Loss: 0.5310, Validation Loss: 0.4453\n",
      "[Trial 111] Epoch 39/60, Training Loss: 0.5975, Validation Loss: 0.5734\n",
      "[Trial 122] Epoch 9/60, Training Loss: 1.0106, Validation Loss: 0.8798\n",
      "[Trial 113] Epoch 33/60, Training Loss: 0.7187, Validation Loss: 0.6237\n",
      "[Trial 123] Epoch 5/60, Training Loss: 1.4738, Validation Loss: 1.2342\n",
      "[Trial 108] Epoch 54/60, Training Loss: 0.6199, Validation Loss: 0.5087\n",
      "[Trial 117] Epoch 15/60, Training Loss: 0.7664, Validation Loss: 1.2363\n",
      "[Trial 119] Epoch 12/60, Training Loss: 0.8622, Validation Loss: 0.8631\n",
      "[Trial 120] Epoch 10/60, Training Loss: 694.8078, Validation Loss: 714.9094\n",
      "[Trial 115] Epoch 25/60, Training Loss: 0.9007, Validation Loss: 0.9641\n",
      "[Trial 110] Epoch 39/60, Training Loss: 0.5973, Validation Loss: 0.5178\n",
      "[Trial 114] Epoch 32/60, Training Loss: 0.6086, Validation Loss: 0.5235\n",
      "[Trial 116] Epoch 22/60, Training Loss: 0.6420, Validation Loss: 0.5371\n",
      "[Trial 121] Epoch 10/60, Training Loss: 0.9398, Validation Loss: 0.8262\n",
      "[Trial 118] Epoch 13/60, Training Loss: 0.9681, Validation Loss: 0.9899\n",
      "[Trial 112] Epoch 39/60, Training Loss: 0.6218, Validation Loss: 0.6349\n",
      "[Trial 107] Epoch 59/60, Training Loss: 0.5348, Validation Loss: 0.4642\n",
      "[Trial 111] Epoch 40/60, Training Loss: 0.5952, Validation Loss: 0.5090\n",
      "[Trial 122] Epoch 10/60, Training Loss: 0.9444, Validation Loss: 0.7478\n",
      "[Trial 113] Epoch 34/60, Training Loss: 0.6952, Validation Loss: 0.6265\n",
      "[Trial 117] Epoch 16/60, Training Loss: 0.8080, Validation Loss: 0.7899\n",
      "[Trial 123] Epoch 6/60, Training Loss: 1.2559, Validation Loss: 1.4825\n",
      "[Trial 108] Epoch 55/60, Training Loss: 0.6156, Validation Loss: 0.5050\n",
      "[Trial 119] Epoch 13/60, Training Loss: 0.8875, Validation Loss: 0.7116\n",
      "[Trial 120] Epoch 11/60, Training Loss: 28165.1733, Validation Loss: 693.4922\n",
      "[Trial 115] Epoch 26/60, Training Loss: 0.8777, Validation Loss: 0.8143\n",
      "[Trial 110] Epoch 40/60, Training Loss: 0.5827, Validation Loss: 0.5006\n",
      "[Trial 114] Epoch 33/60, Training Loss: 0.6005, Validation Loss: 0.5312\n",
      "[Trial 116] Epoch 23/60, Training Loss: 0.6332, Validation Loss: 0.5369\n",
      "[Trial 121] Epoch 11/60, Training Loss: 0.8784, Validation Loss: 0.8011\n",
      "[Trial 118] Epoch 14/60, Training Loss: 0.9119, Validation Loss: 0.8611\n",
      "[Trial 112] Epoch 40/60, Training Loss: 0.6387, Validation Loss: 0.5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:57:11,306] Trial 107 finished with value: 0.4453338841597239 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.005245214835557372, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 107] Epoch 60/60, Training Loss: 0.5382, Validation Loss: 0.4820\n",
      "[Trial 111] Epoch 41/60, Training Loss: 0.5906, Validation Loss: 0.6213\n",
      "[Trial 122] Epoch 11/60, Training Loss: 0.8882, Validation Loss: 0.8195\n",
      "[Trial 113] Epoch 35/60, Training Loss: 0.6934, Validation Loss: 0.6742\n",
      "[Trial 117] Epoch 17/60, Training Loss: 0.7589, Validation Loss: 0.6514\n",
      "[Trial 108] Epoch 56/60, Training Loss: 0.6198, Validation Loss: 0.5016\n",
      "[Trial 123] Epoch 7/60, Training Loss: 1.1806, Validation Loss: 1.5719\n",
      "[Trial 119] Epoch 14/60, Training Loss: 0.8221, Validation Loss: 1.1341\n",
      "[Trial 120] Epoch 12/60, Training Loss: 672.5863, Validation Loss: 706.4002\n",
      "[Trial 115] Epoch 27/60, Training Loss: 0.7440, Validation Loss: 0.6639\n",
      "[Trial 114] Epoch 34/60, Training Loss: 0.5827, Validation Loss: 0.4798\n",
      "[Trial 110] Epoch 41/60, Training Loss: 0.6019, Validation Loss: 0.6166\n",
      "[Trial 116] Epoch 24/60, Training Loss: 0.6390, Validation Loss: 0.6229\n",
      "[Trial 118] Epoch 15/60, Training Loss: 0.8962, Validation Loss: 1.0887\n",
      "[Trial 121] Epoch 12/60, Training Loss: 0.8843, Validation Loss: 0.8535\n",
      "[Trial 112] Epoch 41/60, Training Loss: 0.5769, Validation Loss: 0.5027\n",
      "[Trial 124] Epoch 1/60, Training Loss: 4.5543, Validation Loss: 3.5594\n",
      "[Trial 111] Epoch 42/60, Training Loss: 0.5934, Validation Loss: 0.5428\n",
      "[Trial 122] Epoch 12/60, Training Loss: 0.8880, Validation Loss: 0.9086\n",
      "[Trial 113] Epoch 36/60, Training Loss: 0.6935, Validation Loss: 0.6214\n",
      "[Trial 117] Epoch 18/60, Training Loss: 0.7371, Validation Loss: 0.7075\n",
      "[Trial 108] Epoch 57/60, Training Loss: 0.6214, Validation Loss: 0.5185\n",
      "[Trial 123] Epoch 8/60, Training Loss: 1.0801, Validation Loss: 1.0916\n",
      "[Trial 119] Epoch 15/60, Training Loss: 0.8180, Validation Loss: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 07:59:18,062] Trial 120 finished with value: 20.66835117340088 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.03352012673960748, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 120] Epoch 13/60, Training Loss: 657.8346, Validation Loss: 686.1882\n",
      "[Trial 120] Early stopping after 13 epochs.\n",
      "[Trial 115] Epoch 28/60, Training Loss: 0.7358, Validation Loss: 0.7903\n",
      "[Trial 114] Epoch 35/60, Training Loss: 0.5695, Validation Loss: 0.4875\n",
      "[Trial 110] Epoch 42/60, Training Loss: 0.6070, Validation Loss: 0.5049\n",
      "[Trial 118] Epoch 16/60, Training Loss: 0.8837, Validation Loss: 0.7232\n",
      "[Trial 116] Epoch 25/60, Training Loss: 0.6556, Validation Loss: 0.6023\n",
      "[Trial 112] Epoch 42/60, Training Loss: 0.5756, Validation Loss: 0.4997\n",
      "[Trial 121] Epoch 13/60, Training Loss: 0.8635, Validation Loss: 0.8591\n",
      "[Trial 111] Epoch 43/60, Training Loss: 0.5913, Validation Loss: 0.5536\n",
      "[Trial 124] Epoch 2/60, Training Loss: 2.3029, Validation Loss: 1.7821\n",
      "[Trial 122] Epoch 13/60, Training Loss: 0.8537, Validation Loss: 0.6676\n",
      "[Trial 113] Epoch 37/60, Training Loss: 0.6420, Validation Loss: 0.5722\n",
      "[Trial 117] Epoch 19/60, Training Loss: 0.7540, Validation Loss: 0.8169\n",
      "[Trial 108] Epoch 58/60, Training Loss: 0.6003, Validation Loss: 0.4857\n",
      "[Trial 123] Epoch 9/60, Training Loss: 0.9919, Validation Loss: 1.2665\n",
      "[Trial 119] Epoch 16/60, Training Loss: 0.7857, Validation Loss: 0.6485\n",
      "[Trial 125] Epoch 1/60, Training Loss: 4.1265, Validation Loss: 2.5154\n",
      "[Trial 115] Epoch 29/60, Training Loss: 0.7748, Validation Loss: 0.8111\n",
      "[Trial 114] Epoch 36/60, Training Loss: 0.5743, Validation Loss: 0.4825\n",
      "[Trial 110] Epoch 43/60, Training Loss: 0.5786, Validation Loss: 0.5227\n",
      "[Trial 118] Epoch 17/60, Training Loss: 0.9149, Validation Loss: 1.0208\n",
      "[Trial 116] Epoch 26/60, Training Loss: 0.6419, Validation Loss: 0.5595\n",
      "[Trial 112] Epoch 43/60, Training Loss: 0.5729, Validation Loss: 0.4854\n",
      "[Trial 121] Epoch 14/60, Training Loss: 0.7514, Validation Loss: 0.6004\n",
      "[Trial 122] Epoch 14/60, Training Loss: 0.8334, Validation Loss: 0.7267\n",
      "[Trial 111] Epoch 44/60, Training Loss: 0.5675, Validation Loss: 0.5037\n",
      "[Trial 124] Epoch 3/60, Training Loss: 2.0090, Validation Loss: 2.0413\n",
      "[Trial 117] Epoch 20/60, Training Loss: 0.7484, Validation Loss: 0.6678\n",
      "[Trial 113] Epoch 38/60, Training Loss: 0.6372, Validation Loss: 0.5312\n",
      "[Trial 108] Epoch 59/60, Training Loss: 0.6006, Validation Loss: 0.4917\n",
      "[Trial 123] Epoch 10/60, Training Loss: 0.9772, Validation Loss: 0.8969\n",
      "[Trial 119] Epoch 17/60, Training Loss: 0.7803, Validation Loss: 1.0244\n",
      "[Trial 125] Epoch 2/60, Training Loss: 1.9419, Validation Loss: 1.6122\n",
      "[Trial 115] Epoch 30/60, Training Loss: 0.7731, Validation Loss: 0.8404\n",
      "[Trial 114] Epoch 37/60, Training Loss: 0.5769, Validation Loss: 0.5256\n",
      "[Trial 118] Epoch 18/60, Training Loss: 0.8264, Validation Loss: 0.8700\n",
      "[Trial 110] Epoch 44/60, Training Loss: 0.5782, Validation Loss: 0.4925\n",
      "[Trial 116] Epoch 27/60, Training Loss: 0.6234, Validation Loss: 0.5388\n",
      "[Trial 112] Epoch 44/60, Training Loss: 0.5745, Validation Loss: 0.4987\n",
      "[Trial 121] Epoch 15/60, Training Loss: 0.7436, Validation Loss: 0.6117\n",
      "[Trial 122] Epoch 15/60, Training Loss: 0.8252, Validation Loss: 0.6064\n",
      "[Trial 111] Epoch 45/60, Training Loss: 0.5615, Validation Loss: 0.4879\n",
      "[Trial 117] Epoch 21/60, Training Loss: 0.7255, Validation Loss: 0.9671\n",
      "[Trial 113] Epoch 39/60, Training Loss: 0.6401, Validation Loss: 0.6313\n",
      "[Trial 124] Epoch 4/60, Training Loss: 1.7170, Validation Loss: 1.6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:03:02,451] Trial 108 finished with value: 0.4856591398517291 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0006748513184332116, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 108] Epoch 60/60, Training Loss: 0.5917, Validation Loss: 0.4907\n",
      "[Trial 123] Epoch 11/60, Training Loss: 0.9210, Validation Loss: 0.8293\n",
      "[Trial 119] Epoch 18/60, Training Loss: 0.8061, Validation Loss: 0.6161\n",
      "[Trial 125] Epoch 3/60, Training Loss: 1.5739, Validation Loss: 1.3506\n",
      "[Trial 115] Epoch 31/60, Training Loss: 0.7953, Validation Loss: 0.6895\n",
      "[Trial 118] Epoch 19/60, Training Loss: 0.8601, Validation Loss: 0.9729\n",
      "[Trial 114] Epoch 38/60, Training Loss: 0.5909, Validation Loss: 0.5130\n",
      "[Trial 110] Epoch 45/60, Training Loss: 0.5891, Validation Loss: 0.6328\n",
      "[Trial 116] Epoch 28/60, Training Loss: 0.6261, Validation Loss: 0.6016\n",
      "[Trial 112] Epoch 45/60, Training Loss: 0.5813, Validation Loss: 0.4722\n",
      "[Trial 122] Epoch 16/60, Training Loss: 0.8140, Validation Loss: 0.6365\n",
      "[Trial 121] Epoch 16/60, Training Loss: 0.7268, Validation Loss: 0.6471\n",
      "[Trial 111] Epoch 46/60, Training Loss: 0.5527, Validation Loss: 0.4808\n",
      "[Trial 117] Epoch 22/60, Training Loss: 0.7608, Validation Loss: 0.6558\n",
      "[Trial 113] Epoch 40/60, Training Loss: 0.6512, Validation Loss: 0.5303\n",
      "[Trial 124] Epoch 5/60, Training Loss: 1.4650, Validation Loss: 0.9881\n",
      "[Trial 126] Epoch 1/60, Training Loss: 11.1166, Validation Loss: 2.9588\n",
      "[Trial 119] Epoch 19/60, Training Loss: 0.7468, Validation Loss: 0.6253\n",
      "[Trial 123] Epoch 12/60, Training Loss: 0.9200, Validation Loss: 1.1564\n",
      "[Trial 125] Epoch 4/60, Training Loss: 1.3790, Validation Loss: 2.4575\n",
      "[Trial 115] Epoch 32/60, Training Loss: 0.7395, Validation Loss: 0.6962\n",
      "[Trial 118] Epoch 20/60, Training Loss: 0.8712, Validation Loss: 1.2844\n",
      "[Trial 114] Epoch 39/60, Training Loss: 0.5716, Validation Loss: 0.4757\n",
      "[Trial 110] Epoch 46/60, Training Loss: 0.6099, Validation Loss: 0.4989\n",
      "[Trial 112] Epoch 46/60, Training Loss: 0.5657, Validation Loss: 0.4825\n",
      "[Trial 116] Epoch 29/60, Training Loss: 0.6334, Validation Loss: 0.5696\n",
      "[Trial 122] Epoch 17/60, Training Loss: 0.8016, Validation Loss: 0.6858\n",
      "[Trial 111] Epoch 47/60, Training Loss: 0.5520, Validation Loss: 0.4873\n",
      "[Trial 121] Epoch 17/60, Training Loss: 0.7273, Validation Loss: 0.5923\n",
      "[Trial 117] Epoch 23/60, Training Loss: 0.7501, Validation Loss: 0.7434\n",
      "[Trial 113] Epoch 41/60, Training Loss: 0.6296, Validation Loss: 0.5572\n",
      "[Trial 124] Epoch 6/60, Training Loss: 1.2298, Validation Loss: 0.9923\n",
      "[Trial 126] Epoch 2/60, Training Loss: 2.4476, Validation Loss: 2.0519\n",
      "[Trial 119] Epoch 20/60, Training Loss: 0.7477, Validation Loss: 0.8292\n",
      "[Trial 123] Epoch 13/60, Training Loss: 0.8880, Validation Loss: 0.8178\n",
      "[Trial 125] Epoch 5/60, Training Loss: 1.4001, Validation Loss: 1.1912\n",
      "[Trial 115] Epoch 33/60, Training Loss: 0.7670, Validation Loss: 0.7949\n",
      "[Trial 118] Epoch 21/60, Training Loss: 0.8547, Validation Loss: 1.2650\n",
      "[Trial 114] Epoch 40/60, Training Loss: 0.5588, Validation Loss: 0.4668\n",
      "[Trial 110] Epoch 47/60, Training Loss: 0.5747, Validation Loss: 0.5038\n",
      "[Trial 112] Epoch 47/60, Training Loss: 0.5647, Validation Loss: 0.5285\n",
      "[Trial 116] Epoch 30/60, Training Loss: 0.5936, Validation Loss: 0.4973\n",
      "[Trial 122] Epoch 18/60, Training Loss: 0.7835, Validation Loss: 0.8300\n",
      "[Trial 111] Epoch 48/60, Training Loss: 0.5552, Validation Loss: 0.4735\n",
      "[Trial 117] Epoch 24/60, Training Loss: 0.6468, Validation Loss: 0.5411\n",
      "[Trial 121] Epoch 18/60, Training Loss: 0.7196, Validation Loss: 0.5786\n",
      "[Trial 113] Epoch 42/60, Training Loss: 0.6380, Validation Loss: 0.5652\n",
      "[Trial 124] Epoch 7/60, Training Loss: 1.1159, Validation Loss: 1.1700\n",
      "[Trial 126] Epoch 3/60, Training Loss: 1.9270, Validation Loss: 1.3470\n",
      "[Trial 119] Epoch 21/60, Training Loss: 0.7614, Validation Loss: 0.5970\n",
      "[Trial 123] Epoch 14/60, Training Loss: 0.8505, Validation Loss: 0.7346\n",
      "[Trial 125] Epoch 6/60, Training Loss: 1.1986, Validation Loss: 0.9350\n",
      "[Trial 115] Epoch 34/60, Training Loss: 0.6848, Validation Loss: 0.6150\n",
      "[Trial 118] Epoch 22/60, Training Loss: 0.8857, Validation Loss: 0.9406\n",
      "[Trial 114] Epoch 41/60, Training Loss: 0.5619, Validation Loss: 0.4854\n",
      "[Trial 112] Epoch 48/60, Training Loss: 0.5742, Validation Loss: 0.5012\n",
      "[Trial 110] Epoch 48/60, Training Loss: 0.5724, Validation Loss: 0.4941\n",
      "[Trial 116] Epoch 31/60, Training Loss: 0.5854, Validation Loss: 0.5052\n",
      "[Trial 122] Epoch 19/60, Training Loss: 0.7764, Validation Loss: 0.6733\n",
      "[Trial 111] Epoch 49/60, Training Loss: 0.5584, Validation Loss: 0.5009\n",
      "[Trial 117] Epoch 25/60, Training Loss: 0.6328, Validation Loss: 0.6696\n",
      "[Trial 121] Epoch 19/60, Training Loss: 0.7245, Validation Loss: 0.8289\n",
      "[Trial 113] Epoch 43/60, Training Loss: 0.6289, Validation Loss: 0.5668\n",
      "[Trial 124] Epoch 8/60, Training Loss: 1.0795, Validation Loss: 0.9696\n",
      "[Trial 126] Epoch 4/60, Training Loss: 1.6107, Validation Loss: 1.7500\n",
      "[Trial 119] Epoch 22/60, Training Loss: 0.7375, Validation Loss: 1.0550\n",
      "[Trial 123] Epoch 15/60, Training Loss: 0.8088, Validation Loss: 0.8388\n",
      "[Trial 125] Epoch 7/60, Training Loss: 1.0815, Validation Loss: 0.8883\n",
      "[Trial 118] Epoch 23/60, Training Loss: 0.7261, Validation Loss: 0.6456\n",
      "[Trial 115] Epoch 35/60, Training Loss: 0.6690, Validation Loss: 0.6260\n",
      "[Trial 114] Epoch 42/60, Training Loss: 0.5606, Validation Loss: 0.4786\n",
      "[Trial 112] Epoch 49/60, Training Loss: 0.5656, Validation Loss: 0.5291\n",
      "[Trial 110] Epoch 49/60, Training Loss: 0.5752, Validation Loss: 0.4897\n",
      "[Trial 122] Epoch 20/60, Training Loss: 0.7698, Validation Loss: 0.7144\n",
      "[Trial 116] Epoch 32/60, Training Loss: 0.5862, Validation Loss: 0.5050\n",
      "[Trial 111] Epoch 50/60, Training Loss: 0.5663, Validation Loss: 0.4895\n",
      "[Trial 117] Epoch 26/60, Training Loss: 0.6502, Validation Loss: 0.6243\n",
      "[Trial 113] Epoch 44/60, Training Loss: 0.6236, Validation Loss: 0.5456\n",
      "[Trial 121] Epoch 20/60, Training Loss: 0.7631, Validation Loss: 0.6705\n",
      "[Trial 124] Epoch 9/60, Training Loss: 0.9981, Validation Loss: 0.7189\n",
      "[Trial 126] Epoch 5/60, Training Loss: 1.3865, Validation Loss: 1.1541\n",
      "[Trial 119] Epoch 23/60, Training Loss: 0.7755, Validation Loss: 1.0295\n",
      "[Trial 123] Epoch 16/60, Training Loss: 0.8347, Validation Loss: 0.9023\n",
      "[Trial 125] Epoch 8/60, Training Loss: 1.0299, Validation Loss: 1.1498\n",
      "[Trial 118] Epoch 24/60, Training Loss: 0.7004, Validation Loss: 0.6137\n",
      "[Trial 115] Epoch 36/60, Training Loss: 0.6613, Validation Loss: 0.5665\n",
      "[Trial 114] Epoch 43/60, Training Loss: 0.5595, Validation Loss: 0.4860\n",
      "[Trial 112] Epoch 50/60, Training Loss: 0.5678, Validation Loss: 0.5252\n",
      "[Trial 122] Epoch 21/60, Training Loss: 0.7703, Validation Loss: 1.5875\n",
      "[Trial 110] Epoch 50/60, Training Loss: 0.5719, Validation Loss: 0.5243\n",
      "[Trial 116] Epoch 33/60, Training Loss: 0.5861, Validation Loss: 0.5020\n",
      "[Trial 117] Epoch 27/60, Training Loss: 0.6363, Validation Loss: 0.6898\n",
      "[Trial 111] Epoch 51/60, Training Loss: 0.5527, Validation Loss: 0.4872\n",
      "[Trial 113] Epoch 45/60, Training Loss: 0.6289, Validation Loss: 0.5662\n",
      "[Trial 121] Epoch 21/60, Training Loss: 0.7562, Validation Loss: 0.6996\n",
      "[Trial 119] Epoch 24/60, Training Loss: 0.7758, Validation Loss: 0.6966\n",
      "[Trial 126] Epoch 6/60, Training Loss: 1.2773, Validation Loss: 1.3728\n",
      "[Trial 124] Epoch 10/60, Training Loss: 0.9437, Validation Loss: 0.8370\n",
      "[Trial 123] Epoch 17/60, Training Loss: 0.8618, Validation Loss: 0.8989\n",
      "[Trial 125] Epoch 9/60, Training Loss: 0.9926, Validation Loss: 0.8413\n",
      "[Trial 118] Epoch 25/60, Training Loss: 0.7111, Validation Loss: 0.6859\n",
      "[Trial 115] Epoch 37/60, Training Loss: 0.6661, Validation Loss: 0.5991\n",
      "[Trial 114] Epoch 44/60, Training Loss: 0.5628, Validation Loss: 0.4704\n",
      "[Trial 112] Epoch 51/60, Training Loss: 0.5615, Validation Loss: 0.4977\n",
      "[Trial 122] Epoch 22/60, Training Loss: 0.7176, Validation Loss: 0.5697\n",
      "[Trial 117] Epoch 28/60, Training Loss: 0.6358, Validation Loss: 0.5545\n",
      "[Trial 110] Epoch 51/60, Training Loss: 0.5854, Validation Loss: 0.5393\n",
      "[Trial 116] Epoch 34/60, Training Loss: 0.5842, Validation Loss: 0.5029\n",
      "[Trial 111] Epoch 52/60, Training Loss: 0.5523, Validation Loss: 0.4830\n",
      "[Trial 113] Epoch 46/60, Training Loss: 0.6501, Validation Loss: 0.5233\n",
      "[Trial 121] Epoch 22/60, Training Loss: 0.7571, Validation Loss: 0.5982\n",
      "[Trial 119] Epoch 25/60, Training Loss: 0.7231, Validation Loss: 0.6186\n",
      "[Trial 126] Epoch 7/60, Training Loss: 1.2538, Validation Loss: 0.8498\n",
      "[Trial 124] Epoch 11/60, Training Loss: 0.9776, Validation Loss: 1.0750\n",
      "[Trial 125] Epoch 10/60, Training Loss: 0.9286, Validation Loss: 0.8021\n",
      "[Trial 123] Epoch 18/60, Training Loss: 0.7882, Validation Loss: 0.9565\n",
      "[Trial 118] Epoch 26/60, Training Loss: 0.7499, Validation Loss: 0.5906\n",
      "[Trial 115] Epoch 38/60, Training Loss: 0.6664, Validation Loss: 0.5998\n",
      "[Trial 114] Epoch 45/60, Training Loss: 0.5573, Validation Loss: 0.4722\n",
      "[Trial 112] Epoch 52/60, Training Loss: 0.5480, Validation Loss: 0.4738\n",
      "[Trial 122] Epoch 23/60, Training Loss: 0.7104, Validation Loss: 0.5585\n",
      "[Trial 117] Epoch 29/60, Training Loss: 0.6110, Validation Loss: 0.5213\n",
      "[Trial 111] Epoch 53/60, Training Loss: 0.5519, Validation Loss: 0.4726\n",
      "[Trial 116] Epoch 35/60, Training Loss: 0.5886, Validation Loss: 0.5936\n",
      "[Trial 110] Epoch 52/60, Training Loss: 0.5725, Validation Loss: 0.4979\n",
      "[Trial 113] Epoch 47/60, Training Loss: 0.6295, Validation Loss: 0.6211\n",
      "[Trial 121] Epoch 23/60, Training Loss: 0.6972, Validation Loss: 0.5647\n",
      "[Trial 119] Epoch 26/60, Training Loss: 0.7083, Validation Loss: 0.7897\n",
      "[Trial 126] Epoch 8/60, Training Loss: 1.1903, Validation Loss: 1.2738\n",
      "[Trial 124] Epoch 12/60, Training Loss: 0.9459, Validation Loss: 0.7983\n",
      "[Trial 125] Epoch 11/60, Training Loss: 0.9157, Validation Loss: 1.1459\n",
      "[Trial 118] Epoch 27/60, Training Loss: 0.7055, Validation Loss: 0.6001\n",
      "[Trial 123] Epoch 19/60, Training Loss: 0.8047, Validation Loss: 1.0763\n",
      "[Trial 115] Epoch 39/60, Training Loss: 0.6683, Validation Loss: 0.5863\n",
      "[Trial 112] Epoch 53/60, Training Loss: 0.5425, Validation Loss: 0.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:14:43,568] Trial 114 finished with value: 0.4667625814676285 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0051868826842678024, 'batch_size': 16, 'patience': 6}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 114] Epoch 46/60, Training Loss: 0.5526, Validation Loss: 0.4750\n",
      "[Trial 114] Early stopping after 46 epochs.\n",
      "[Trial 122] Epoch 24/60, Training Loss: 0.6521, Validation Loss: 0.5614\n",
      "[Trial 117] Epoch 30/60, Training Loss: 0.6172, Validation Loss: 0.7042\n",
      "[Trial 111] Epoch 54/60, Training Loss: 0.5509, Validation Loss: 0.5085\n",
      "[Trial 116] Epoch 36/60, Training Loss: 0.5923, Validation Loss: 0.4949\n",
      "[Trial 110] Epoch 53/60, Training Loss: 0.5648, Validation Loss: 0.5813\n",
      "[Trial 113] Epoch 48/60, Training Loss: 0.6313, Validation Loss: 0.5708\n",
      "[Trial 121] Epoch 24/60, Training Loss: 0.7098, Validation Loss: 0.8352\n",
      "[Trial 119] Epoch 27/60, Training Loss: 0.7269, Validation Loss: 0.6678\n",
      "[Trial 126] Epoch 9/60, Training Loss: 1.1374, Validation Loss: 1.0057\n",
      "[Trial 124] Epoch 13/60, Training Loss: 0.8859, Validation Loss: 0.8034\n",
      "[Trial 118] Epoch 28/60, Training Loss: 0.7108, Validation Loss: 0.6315\n",
      "[Trial 125] Epoch 12/60, Training Loss: 0.9559, Validation Loss: 0.6849\n",
      "[Trial 123] Epoch 20/60, Training Loss: 0.8335, Validation Loss: 0.8992\n",
      "[Trial 115] Epoch 40/60, Training Loss: 0.6828, Validation Loss: 0.6756\n",
      "[Trial 112] Epoch 54/60, Training Loss: 0.5391, Validation Loss: 0.4800\n",
      "[Trial 122] Epoch 25/60, Training Loss: 0.6511, Validation Loss: 0.5176\n",
      "[Trial 127] Epoch 1/60, Training Loss: 7.8325, Validation Loss: 3.2026\n",
      "[Trial 117] Epoch 31/60, Training Loss: 0.6412, Validation Loss: 0.6676\n",
      "[Trial 111] Epoch 55/60, Training Loss: 0.5689, Validation Loss: 0.5020\n",
      "[Trial 116] Epoch 37/60, Training Loss: 0.5860, Validation Loss: 0.5456\n",
      "[Trial 110] Epoch 54/60, Training Loss: 0.6049, Validation Loss: 0.5761\n",
      "[Trial 113] Epoch 49/60, Training Loss: 0.6331, Validation Loss: 0.5593\n",
      "[Trial 119] Epoch 28/60, Training Loss: 0.6532, Validation Loss: 0.6363\n",
      "[Trial 121] Epoch 25/60, Training Loss: 0.7293, Validation Loss: 0.6446\n",
      "[Trial 126] Epoch 10/60, Training Loss: 1.0793, Validation Loss: 1.0896\n",
      "[Trial 124] Epoch 14/60, Training Loss: 0.8558, Validation Loss: 0.7661\n",
      "[Trial 118] Epoch 29/60, Training Loss: 0.7170, Validation Loss: 0.8803\n",
      "[Trial 125] Epoch 13/60, Training Loss: 0.8452, Validation Loss: 0.6620\n",
      "[Trial 123] Epoch 21/60, Training Loss: 0.7353, Validation Loss: 0.6745\n",
      "[Trial 115] Epoch 41/60, Training Loss: 0.7100, Validation Loss: 0.5900\n",
      "[Trial 122] Epoch 26/60, Training Loss: 0.6598, Validation Loss: 0.5661\n",
      "[Trial 112] Epoch 55/60, Training Loss: 0.5471, Validation Loss: 0.4589\n",
      "[Trial 117] Epoch 32/60, Training Loss: 0.6333, Validation Loss: 0.5660\n",
      "[Trial 127] Epoch 2/60, Training Loss: 2.6401, Validation Loss: 3.2061\n",
      "[Trial 111] Epoch 56/60, Training Loss: 0.5621, Validation Loss: 0.4955\n",
      "[Trial 116] Epoch 38/60, Training Loss: 0.5814, Validation Loss: 0.5036\n",
      "[Trial 113] Epoch 50/60, Training Loss: 0.6196, Validation Loss: 0.5571\n",
      "[Trial 110] Epoch 55/60, Training Loss: 0.5719, Validation Loss: 0.5101\n",
      "[Trial 119] Epoch 29/60, Training Loss: 0.6499, Validation Loss: 0.6290\n",
      "[Trial 121] Epoch 26/60, Training Loss: 0.6939, Validation Loss: 0.6094\n",
      "[Trial 126] Epoch 11/60, Training Loss: 1.0444, Validation Loss: 0.9425\n",
      "[Trial 118] Epoch 30/60, Training Loss: 0.7489, Validation Loss: 0.5777\n",
      "[Trial 124] Epoch 15/60, Training Loss: 0.8368, Validation Loss: 0.8786\n",
      "[Trial 125] Epoch 14/60, Training Loss: 0.8200, Validation Loss: 0.6569\n",
      "[Trial 123] Epoch 22/60, Training Loss: 0.7171, Validation Loss: 0.6796\n",
      "[Trial 115] Epoch 42/60, Training Loss: 0.6541, Validation Loss: 0.5929\n",
      "[Trial 122] Epoch 27/60, Training Loss: 0.6718, Validation Loss: 0.8803\n",
      "[Trial 112] Epoch 56/60, Training Loss: 0.5438, Validation Loss: 0.4796\n",
      "[Trial 117] Epoch 33/60, Training Loss: 0.6133, Validation Loss: 0.5575\n",
      "[Trial 127] Epoch 3/60, Training Loss: 1.9873, Validation Loss: 1.6642\n",
      "[Trial 111] Epoch 57/60, Training Loss: 0.5471, Validation Loss: 0.4761\n",
      "[Trial 116] Epoch 39/60, Training Loss: 0.5893, Validation Loss: 0.5088\n",
      "[Trial 113] Epoch 51/60, Training Loss: 0.6250, Validation Loss: 0.5636\n",
      "[Trial 110] Epoch 56/60, Training Loss: 0.5462, Validation Loss: 0.4697\n",
      "[Trial 119] Epoch 30/60, Training Loss: 0.6446, Validation Loss: 0.5645\n",
      "[Trial 126] Epoch 12/60, Training Loss: 0.9849, Validation Loss: 0.8487\n",
      "[Trial 121] Epoch 27/60, Training Loss: 0.6830, Validation Loss: 0.6539\n",
      "[Trial 118] Epoch 31/60, Training Loss: 0.6879, Validation Loss: 0.6448\n",
      "[Trial 124] Epoch 16/60, Training Loss: 0.7684, Validation Loss: 0.6394\n",
      "[Trial 125] Epoch 15/60, Training Loss: 0.8094, Validation Loss: 0.6921\n",
      "[Trial 123] Epoch 23/60, Training Loss: 0.6798, Validation Loss: 0.5973\n",
      "[Trial 115] Epoch 43/60, Training Loss: 0.6269, Validation Loss: 0.5442\n",
      "[Trial 122] Epoch 28/60, Training Loss: 0.6925, Validation Loss: 0.7206\n",
      "[Trial 112] Epoch 57/60, Training Loss: 0.5417, Validation Loss: 0.4638\n",
      "[Trial 117] Epoch 34/60, Training Loss: 0.6092, Validation Loss: 0.6002\n",
      "[Trial 127] Epoch 4/60, Training Loss: 1.7513, Validation Loss: 4.3612\n",
      "[Trial 111] Epoch 58/60, Training Loss: 0.5459, Validation Loss: 0.4959\n",
      "[Trial 113] Epoch 52/60, Training Loss: 0.6131, Validation Loss: 0.5126\n",
      "[Trial 116] Epoch 40/60, Training Loss: 0.5842, Validation Loss: 0.5430\n",
      "[Trial 110] Epoch 57/60, Training Loss: 0.5549, Validation Loss: 0.4710\n",
      "[Trial 119] Epoch 31/60, Training Loss: 0.6537, Validation Loss: 0.5474\n",
      "[Trial 126] Epoch 13/60, Training Loss: 0.9758, Validation Loss: 1.0526\n",
      "[Trial 121] Epoch 28/60, Training Loss: 0.6995, Validation Loss: 0.5694\n",
      "[Trial 118] Epoch 32/60, Training Loss: 0.6925, Validation Loss: 0.6772\n",
      "[Trial 125] Epoch 16/60, Training Loss: 0.8378, Validation Loss: 1.9234\n",
      "[Trial 124] Epoch 17/60, Training Loss: 0.7369, Validation Loss: 0.6326\n",
      "[Trial 123] Epoch 24/60, Training Loss: 0.6820, Validation Loss: 0.6084\n",
      "[Trial 115] Epoch 44/60, Training Loss: 0.6343, Validation Loss: 0.5572\n",
      "[Trial 122] Epoch 29/60, Training Loss: 0.6869, Validation Loss: 0.6387\n",
      "[Trial 112] Epoch 58/60, Training Loss: 0.5382, Validation Loss: 0.4668\n",
      "[Trial 117] Epoch 35/60, Training Loss: 0.6198, Validation Loss: 0.6741\n",
      "[Trial 127] Epoch 5/60, Training Loss: 1.4631, Validation Loss: 1.1265\n",
      "[Trial 111] Epoch 59/60, Training Loss: 0.5476, Validation Loss: 0.4801\n",
      "[Trial 113] Epoch 53/60, Training Loss: 0.6118, Validation Loss: 0.5383\n",
      "[Trial 116] Epoch 41/60, Training Loss: 0.5763, Validation Loss: 0.4794\n",
      "[Trial 110] Epoch 58/60, Training Loss: 0.5518, Validation Loss: 0.4711\n",
      "[Trial 119] Epoch 32/60, Training Loss: 0.6381, Validation Loss: 0.6314\n",
      "[Trial 126] Epoch 14/60, Training Loss: 0.9493, Validation Loss: 0.8825\n",
      "[Trial 121] Epoch 29/60, Training Loss: 0.6779, Validation Loss: 0.5447\n",
      "[Trial 118] Epoch 33/60, Training Loss: 0.6696, Validation Loss: 0.5860\n",
      "[Trial 125] Epoch 17/60, Training Loss: 0.8941, Validation Loss: 1.1972\n",
      "[Trial 124] Epoch 18/60, Training Loss: 0.7347, Validation Loss: 0.6137\n",
      "[Trial 123] Epoch 25/60, Training Loss: 0.6999, Validation Loss: 0.6150\n",
      "[Trial 122] Epoch 30/60, Training Loss: 0.6650, Validation Loss: 0.5368\n",
      "[Trial 115] Epoch 45/60, Training Loss: 0.6246, Validation Loss: 0.5602\n",
      "[Trial 117] Epoch 36/60, Training Loss: 0.5818, Validation Loss: 0.5009\n",
      "[Trial 112] Epoch 59/60, Training Loss: 0.5418, Validation Loss: 0.4651\n",
      "[Trial 127] Epoch 6/60, Training Loss: 1.1921, Validation Loss: 1.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:23:01,197] Trial 111 finished with value: 0.46956305801868437 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.005377119336433769, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 111] Epoch 60/60, Training Loss: 0.5350, Validation Loss: 0.4696\n",
      "[Trial 113] Epoch 54/60, Training Loss: 0.6083, Validation Loss: 0.5160\n",
      "[Trial 116] Epoch 42/60, Training Loss: 0.5719, Validation Loss: 0.5164\n",
      "[Trial 119] Epoch 33/60, Training Loss: 0.6465, Validation Loss: 0.5656\n",
      "[Trial 110] Epoch 59/60, Training Loss: 0.5424, Validation Loss: 0.4668\n",
      "[Trial 126] Epoch 15/60, Training Loss: 0.9281, Validation Loss: 1.2863\n",
      "[Trial 118] Epoch 34/60, Training Loss: 0.7054, Validation Loss: 0.9006\n",
      "[Trial 121] Epoch 30/60, Training Loss: 0.6602, Validation Loss: 0.5584\n",
      "[Trial 125] Epoch 18/60, Training Loss: 0.8650, Validation Loss: 0.7744\n",
      "[Trial 124] Epoch 19/60, Training Loss: 0.7543, Validation Loss: 0.6190\n",
      "[Trial 122] Epoch 31/60, Training Loss: 0.6374, Validation Loss: 0.6986\n",
      "[Trial 117] Epoch 37/60, Training Loss: 0.5612, Validation Loss: 0.4975\n",
      "[Trial 123] Epoch 26/60, Training Loss: 0.6875, Validation Loss: 0.7082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:24:11,983] Trial 112 finished with value: 0.45892184376716616 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.005329999480418873, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 112] Epoch 60/60, Training Loss: 0.5393, Validation Loss: 0.4699\n",
      "[Trial 115] Epoch 46/60, Training Loss: 0.6242, Validation Loss: 0.5248\n",
      "[Trial 127] Epoch 7/60, Training Loss: 1.1008, Validation Loss: 1.1500\n",
      "[Trial 128] Epoch 1/60, Training Loss: 5.0679, Validation Loss: 2.3856\n",
      "[Trial 113] Epoch 55/60, Training Loss: 0.6059, Validation Loss: 0.5384\n",
      "[Trial 116] Epoch 43/60, Training Loss: 0.5720, Validation Loss: 0.4920\n",
      "[Trial 119] Epoch 34/60, Training Loss: 0.6456, Validation Loss: 0.6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:24:47,133] Trial 110 finished with value: 0.466750014324983 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0052165585344907065, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 110] Epoch 60/60, Training Loss: 0.5500, Validation Loss: 0.4833\n",
      "[Trial 126] Epoch 16/60, Training Loss: 0.9516, Validation Loss: 2.6681\n",
      "[Trial 118] Epoch 35/60, Training Loss: 0.7512, Validation Loss: 0.7859\n",
      "[Trial 121] Epoch 31/60, Training Loss: 0.6518, Validation Loss: 0.5725\n",
      "[Trial 125] Epoch 19/60, Training Loss: 0.7935, Validation Loss: 0.6967\n",
      "[Trial 124] Epoch 20/60, Training Loss: 0.7428, Validation Loss: 0.6693\n",
      "[Trial 122] Epoch 32/60, Training Loss: 0.6094, Validation Loss: 0.4944\n",
      "[Trial 117] Epoch 38/60, Training Loss: 0.5655, Validation Loss: 0.5457\n",
      "[Trial 123] Epoch 27/60, Training Loss: 0.7136, Validation Loss: 0.5800\n",
      "[Trial 115] Epoch 47/60, Training Loss: 0.6170, Validation Loss: 0.5273\n",
      "[Trial 129] Epoch 1/60, Training Loss: 4.3084, Validation Loss: 2.3142\n",
      "[Trial 127] Epoch 8/60, Training Loss: 1.0657, Validation Loss: 0.8305\n",
      "[Trial 113] Epoch 56/60, Training Loss: 0.6110, Validation Loss: 0.5312\n",
      "[Trial 128] Epoch 2/60, Training Loss: 2.2697, Validation Loss: 2.1136\n",
      "[Trial 116] Epoch 44/60, Training Loss: 0.5707, Validation Loss: 0.5042\n",
      "[Trial 119] Epoch 35/60, Training Loss: 0.6366, Validation Loss: 0.5285\n",
      "[Trial 130] Epoch 1/60, Training Loss: 8.7531, Validation Loss: 2.2125\n",
      "[Trial 126] Epoch 17/60, Training Loss: 1.0093, Validation Loss: 1.2769\n",
      "[Trial 118] Epoch 36/60, Training Loss: 0.7292, Validation Loss: 0.6186\n",
      "[Trial 121] Epoch 32/60, Training Loss: 0.6635, Validation Loss: 0.5853\n",
      "[Trial 125] Epoch 20/60, Training Loss: 0.7814, Validation Loss: 0.6931\n",
      "[Trial 122] Epoch 33/60, Training Loss: 0.5992, Validation Loss: 0.4970\n",
      "[Trial 117] Epoch 39/60, Training Loss: 0.5874, Validation Loss: 0.6308\n",
      "[Trial 124] Epoch 21/60, Training Loss: 0.7316, Validation Loss: 0.6845\n",
      "[Trial 115] Epoch 48/60, Training Loss: 0.6192, Validation Loss: 0.5777\n",
      "[Trial 123] Epoch 28/60, Training Loss: 0.6897, Validation Loss: 0.9504\n",
      "[Trial 129] Epoch 2/60, Training Loss: 2.1524, Validation Loss: 1.3197\n",
      "[Trial 127] Epoch 9/60, Training Loss: 0.9672, Validation Loss: 1.2172\n",
      "[Trial 113] Epoch 57/60, Training Loss: 0.6003, Validation Loss: 0.5259\n",
      "[Trial 128] Epoch 3/60, Training Loss: 1.8107, Validation Loss: 2.3841\n",
      "[Trial 116] Epoch 45/60, Training Loss: 0.5750, Validation Loss: 0.5411\n",
      "[Trial 119] Epoch 36/60, Training Loss: 0.6276, Validation Loss: 0.5503\n",
      "[Trial 118] Epoch 37/60, Training Loss: 0.6392, Validation Loss: 0.5665\n",
      "[Trial 126] Epoch 18/60, Training Loss: 0.9349, Validation Loss: 0.9794\n",
      "[Trial 130] Epoch 2/60, Training Loss: 2.6193, Validation Loss: 10.8263\n",
      "[Trial 121] Epoch 33/60, Training Loss: 0.6697, Validation Loss: 0.5744\n",
      "[Trial 125] Epoch 21/60, Training Loss: 0.6867, Validation Loss: 0.5626\n",
      "[Trial 122] Epoch 34/60, Training Loss: 0.5962, Validation Loss: 0.6145\n",
      "[Trial 117] Epoch 40/60, Training Loss: 0.6181, Validation Loss: 0.5982\n",
      "[Trial 124] Epoch 22/60, Training Loss: 0.7409, Validation Loss: 0.6070\n",
      "[Trial 115] Epoch 49/60, Training Loss: 0.6259, Validation Loss: 0.5461\n",
      "[Trial 123] Epoch 29/60, Training Loss: 0.7040, Validation Loss: 0.6419\n",
      "[Trial 129] Epoch 3/60, Training Loss: 1.6815, Validation Loss: 1.1982\n",
      "[Trial 127] Epoch 10/60, Training Loss: 0.9647, Validation Loss: 1.0938\n",
      "[Trial 113] Epoch 58/60, Training Loss: 0.6075, Validation Loss: 0.5224\n",
      "[Trial 128] Epoch 4/60, Training Loss: 1.4356, Validation Loss: 1.5481\n",
      "[Trial 116] Epoch 46/60, Training Loss: 0.5724, Validation Loss: 0.5473\n",
      "[Trial 119] Epoch 37/60, Training Loss: 0.6282, Validation Loss: 0.5585\n",
      "[Trial 118] Epoch 38/60, Training Loss: 0.6187, Validation Loss: 0.5348\n",
      "[Trial 126] Epoch 19/60, Training Loss: 0.7768, Validation Loss: 0.6316\n",
      "[Trial 130] Epoch 3/60, Training Loss: 2.1594, Validation Loss: 4.3444\n",
      "[Trial 121] Epoch 34/60, Training Loss: 0.6615, Validation Loss: 0.6816\n",
      "[Trial 125] Epoch 22/60, Training Loss: 0.6808, Validation Loss: 0.6051\n",
      "[Trial 122] Epoch 35/60, Training Loss: 0.6009, Validation Loss: 0.4865\n",
      "[Trial 117] Epoch 41/60, Training Loss: 0.5759, Validation Loss: 0.5547\n",
      "[Trial 124] Epoch 23/60, Training Loss: 0.7332, Validation Loss: 0.5976\n",
      "[Trial 115] Epoch 50/60, Training Loss: 0.6200, Validation Loss: 0.5476\n",
      "[Trial 123] Epoch 30/60, Training Loss: 0.6766, Validation Loss: 0.6091\n",
      "[Trial 129] Epoch 4/60, Training Loss: 1.4493, Validation Loss: 1.2715\n",
      "[Trial 113] Epoch 59/60, Training Loss: 0.5842, Validation Loss: 0.5128\n",
      "[Trial 127] Epoch 11/60, Training Loss: 0.9361, Validation Loss: 1.1519\n",
      "[Trial 119] Epoch 38/60, Training Loss: 0.6336, Validation Loss: 0.5611\n",
      "[Trial 128] Epoch 5/60, Training Loss: 1.2275, Validation Loss: 1.4575\n",
      "[Trial 116] Epoch 47/60, Training Loss: 0.5751, Validation Loss: 0.5113\n",
      "[Trial 118] Epoch 39/60, Training Loss: 0.6294, Validation Loss: 0.5264\n",
      "[Trial 126] Epoch 20/60, Training Loss: 0.7391, Validation Loss: 0.6327\n",
      "[Trial 130] Epoch 4/60, Training Loss: 1.5840, Validation Loss: 1.1955\n",
      "[Trial 121] Epoch 35/60, Training Loss: 0.6598, Validation Loss: 0.5864\n",
      "[Trial 125] Epoch 23/60, Training Loss: 0.6924, Validation Loss: 0.6081\n",
      "[Trial 122] Epoch 36/60, Training Loss: 0.5915, Validation Loss: 0.5000\n",
      "[Trial 117] Epoch 42/60, Training Loss: 0.5711, Validation Loss: 0.5317\n",
      "[Trial 124] Epoch 24/60, Training Loss: 0.7207, Validation Loss: 0.6860\n",
      "[Trial 115] Epoch 51/60, Training Loss: 0.6181, Validation Loss: 0.5479\n",
      "[Trial 129] Epoch 5/60, Training Loss: 1.2738, Validation Loss: 0.9949\n",
      "[Trial 123] Epoch 31/60, Training Loss: 0.6704, Validation Loss: 0.7855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:31:22,118] Trial 113 finished with value: 0.5029063497980436 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.0008478925474903553, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 113] Epoch 60/60, Training Loss: 0.5867, Validation Loss: 0.5029\n",
      "[Trial 127] Epoch 12/60, Training Loss: 0.8968, Validation Loss: 1.4144\n",
      "[Trial 119] Epoch 39/60, Training Loss: 0.6250, Validation Loss: 0.5548\n",
      "[Trial 128] Epoch 6/60, Training Loss: 1.1698, Validation Loss: 1.2123\n",
      "[Trial 116] Epoch 48/60, Training Loss: 0.5630, Validation Loss: 0.4828\n",
      "[Trial 118] Epoch 40/60, Training Loss: 0.6333, Validation Loss: 0.6275\n",
      "[Trial 126] Epoch 21/60, Training Loss: 0.7534, Validation Loss: 0.6449\n",
      "[Trial 130] Epoch 5/60, Training Loss: 1.3375, Validation Loss: 1.9909\n",
      "[Trial 121] Epoch 36/60, Training Loss: 0.6107, Validation Loss: 0.5207\n",
      "[Trial 125] Epoch 24/60, Training Loss: 0.6672, Validation Loss: 0.5523\n",
      "[Trial 122] Epoch 37/60, Training Loss: 0.5953, Validation Loss: 0.4833\n",
      "[Trial 117] Epoch 43/60, Training Loss: 0.5595, Validation Loss: 0.5597\n",
      "[Trial 124] Epoch 25/60, Training Loss: 0.7274, Validation Loss: 0.6313\n",
      "[Trial 115] Epoch 52/60, Training Loss: 0.6178, Validation Loss: 0.5462\n",
      "[Trial 129] Epoch 6/60, Training Loss: 1.1486, Validation Loss: 1.0531\n",
      "[Trial 123] Epoch 32/60, Training Loss: 0.6879, Validation Loss: 0.5799\n",
      "[Trial 131] Epoch 1/60, Training Loss: 4.1878, Validation Loss: 1.9897\n",
      "[Trial 127] Epoch 13/60, Training Loss: 0.8143, Validation Loss: 0.6830\n",
      "[Trial 119] Epoch 40/60, Training Loss: 0.6341, Validation Loss: 0.5950\n",
      "[Trial 128] Epoch 7/60, Training Loss: 1.0363, Validation Loss: 1.1760\n",
      "[Trial 116] Epoch 49/60, Training Loss: 0.5576, Validation Loss: 0.4774\n",
      "[Trial 118] Epoch 41/60, Training Loss: 0.6480, Validation Loss: 0.5213\n",
      "[Trial 126] Epoch 22/60, Training Loss: 0.7562, Validation Loss: 0.8254\n",
      "[Trial 130] Epoch 6/60, Training Loss: 1.2913, Validation Loss: 0.8899\n",
      "[Trial 125] Epoch 25/60, Training Loss: 0.6777, Validation Loss: 0.5781\n",
      "[Trial 121] Epoch 37/60, Training Loss: 0.6076, Validation Loss: 0.5378\n",
      "[Trial 122] Epoch 38/60, Training Loss: 0.5911, Validation Loss: 0.4910\n",
      "[Trial 117] Epoch 44/60, Training Loss: 0.5435, Validation Loss: 0.4788\n",
      "[Trial 115] Epoch 53/60, Training Loss: 0.5934, Validation Loss: 0.5221\n",
      "[Trial 124] Epoch 26/60, Training Loss: 0.7172, Validation Loss: 0.6719\n",
      "[Trial 129] Epoch 7/60, Training Loss: 1.0636, Validation Loss: 0.9182\n",
      "[Trial 123] Epoch 33/60, Training Loss: 0.6821, Validation Loss: 0.5715\n",
      "[Trial 131] Epoch 2/60, Training Loss: 2.2158, Validation Loss: 1.8967\n",
      "[Trial 127] Epoch 14/60, Training Loss: 0.7861, Validation Loss: 0.6434\n",
      "[Trial 119] Epoch 41/60, Training Loss: 0.6301, Validation Loss: 0.5711\n",
      "[Trial 118] Epoch 42/60, Training Loss: 0.6339, Validation Loss: 0.6526\n",
      "[Trial 116] Epoch 50/60, Training Loss: 0.5467, Validation Loss: 0.4740\n",
      "[Trial 128] Epoch 8/60, Training Loss: 0.9862, Validation Loss: 0.9056\n",
      "[Trial 126] Epoch 23/60, Training Loss: 0.7804, Validation Loss: 0.7303\n",
      "[Trial 130] Epoch 7/60, Training Loss: 1.1038, Validation Loss: 0.9758\n",
      "[Trial 125] Epoch 26/60, Training Loss: 0.6720, Validation Loss: 0.5620\n",
      "[Trial 122] Epoch 39/60, Training Loss: 0.5980, Validation Loss: 0.5638\n",
      "[Trial 117] Epoch 45/60, Training Loss: 0.5414, Validation Loss: 0.4956\n",
      "[Trial 121] Epoch 38/60, Training Loss: 0.6297, Validation Loss: 0.5252\n",
      "[Trial 115] Epoch 54/60, Training Loss: 0.5962, Validation Loss: 0.5396\n",
      "[Trial 124] Epoch 27/60, Training Loss: 0.7242, Validation Loss: 0.6832\n",
      "[Trial 129] Epoch 8/60, Training Loss: 1.0633, Validation Loss: 1.4864\n",
      "[Trial 123] Epoch 34/60, Training Loss: 0.6771, Validation Loss: 0.6915\n",
      "[Trial 127] Epoch 15/60, Training Loss: 0.7739, Validation Loss: 0.8336\n",
      "[Trial 131] Epoch 3/60, Training Loss: 1.8791, Validation Loss: 1.6913\n",
      "[Trial 119] Epoch 42/60, Training Loss: 0.5926, Validation Loss: 0.5191\n",
      "[Trial 118] Epoch 43/60, Training Loss: 0.6443, Validation Loss: 0.5559\n",
      "[Trial 116] Epoch 51/60, Training Loss: 0.5497, Validation Loss: 0.4825\n",
      "[Trial 128] Epoch 9/60, Training Loss: 0.9326, Validation Loss: 0.7281\n",
      "[Trial 126] Epoch 24/60, Training Loss: 0.7663, Validation Loss: 0.7190\n",
      "[Trial 130] Epoch 8/60, Training Loss: 1.0497, Validation Loss: 1.8018\n",
      "[Trial 125] Epoch 27/60, Training Loss: 0.6603, Validation Loss: 0.5550\n",
      "[Trial 122] Epoch 40/60, Training Loss: 0.6124, Validation Loss: 0.4789\n",
      "[Trial 117] Epoch 46/60, Training Loss: 0.5471, Validation Loss: 0.5171\n",
      "[Trial 121] Epoch 39/60, Training Loss: 0.5967, Validation Loss: 0.4915\n",
      "[Trial 115] Epoch 55/60, Training Loss: 0.5943, Validation Loss: 0.5376\n",
      "[Trial 124] Epoch 28/60, Training Loss: 0.7148, Validation Loss: 0.7086\n",
      "[Trial 119] Epoch 43/60, Training Loss: 0.5822, Validation Loss: 0.4909\n",
      "[Trial 129] Epoch 9/60, Training Loss: 1.1102, Validation Loss: 0.8946\n",
      "[Trial 123] Epoch 35/60, Training Loss: 0.6853, Validation Loss: 0.7969\n",
      "[Trial 127] Epoch 16/60, Training Loss: 0.7664, Validation Loss: 0.6208\n",
      "[Trial 131] Epoch 4/60, Training Loss: 1.5547, Validation Loss: 1.2947\n",
      "[Trial 118] Epoch 44/60, Training Loss: 0.6329, Validation Loss: 0.5514\n",
      "[Trial 116] Epoch 52/60, Training Loss: 0.5490, Validation Loss: 0.4870\n",
      "[Trial 128] Epoch 10/60, Training Loss: 0.8976, Validation Loss: 0.7962\n",
      "[Trial 126] Epoch 25/60, Training Loss: 0.7565, Validation Loss: 0.6486\n",
      "[Trial 122] Epoch 41/60, Training Loss: 0.5932, Validation Loss: 0.6069\n",
      "[Trial 117] Epoch 47/60, Training Loss: 0.5400, Validation Loss: 0.4905\n",
      "[Trial 125] Epoch 28/60, Training Loss: 0.6689, Validation Loss: 0.5916\n",
      "[Trial 130] Epoch 9/60, Training Loss: 1.0039, Validation Loss: 1.8372\n",
      "[Trial 121] Epoch 40/60, Training Loss: 0.5930, Validation Loss: 0.5204\n",
      "[Trial 115] Epoch 56/60, Training Loss: 0.5932, Validation Loss: 0.5248\n",
      "[Trial 119] Epoch 44/60, Training Loss: 0.5811, Validation Loss: 0.5303\n",
      "[Trial 129] Epoch 10/60, Training Loss: 0.9892, Validation Loss: 1.8231\n",
      "[Trial 124] Epoch 29/60, Training Loss: 0.7134, Validation Loss: 0.5659\n",
      "[Trial 127] Epoch 17/60, Training Loss: 0.7409, Validation Loss: 0.9162\n",
      "[Trial 118] Epoch 45/60, Training Loss: 0.6110, Validation Loss: 0.5463\n",
      "[Trial 123] Epoch 36/60, Training Loss: 0.6727, Validation Loss: 0.9033\n",
      "[Trial 131] Epoch 5/60, Training Loss: 1.2964, Validation Loss: 1.3714\n",
      "[Trial 116] Epoch 53/60, Training Loss: 0.5554, Validation Loss: 0.4818\n",
      "[Trial 126] Epoch 26/60, Training Loss: 0.6760, Validation Loss: 0.5833\n",
      "[Trial 128] Epoch 11/60, Training Loss: 0.8404, Validation Loss: 0.9405\n",
      "[Trial 117] Epoch 48/60, Training Loss: 0.5379, Validation Loss: 0.4853\n",
      "[Trial 122] Epoch 42/60, Training Loss: 0.5952, Validation Loss: 0.5107\n",
      "[Trial 125] Epoch 29/60, Training Loss: 0.6671, Validation Loss: 0.5859\n",
      "[Trial 130] Epoch 10/60, Training Loss: 0.9557, Validation Loss: 0.7315\n",
      "[Trial 121] Epoch 41/60, Training Loss: 0.5954, Validation Loss: 0.5284\n",
      "[Trial 119] Epoch 45/60, Training Loss: 0.5952, Validation Loss: 0.5413\n",
      "[Trial 115] Epoch 57/60, Training Loss: 0.5997, Validation Loss: 0.5316\n",
      "[Trial 118] Epoch 46/60, Training Loss: 0.6223, Validation Loss: 0.5424\n",
      "[Trial 129] Epoch 11/60, Training Loss: 1.0555, Validation Loss: 0.8139\n",
      "[Trial 127] Epoch 18/60, Training Loss: 0.7709, Validation Loss: 0.6255\n",
      "[Trial 124] Epoch 30/60, Training Loss: 0.6846, Validation Loss: 0.6146\n",
      "[Trial 131] Epoch 6/60, Training Loss: 1.1802, Validation Loss: 1.5227\n",
      "[Trial 123] Epoch 37/60, Training Loss: 0.6604, Validation Loss: 0.5989\n",
      "[Trial 116] Epoch 54/60, Training Loss: 0.5538, Validation Loss: 0.4882\n",
      "[Trial 126] Epoch 27/60, Training Loss: 0.6754, Validation Loss: 0.5889\n",
      "[Trial 128] Epoch 12/60, Training Loss: 0.8684, Validation Loss: 0.9686\n",
      "[Trial 117] Epoch 49/60, Training Loss: 0.5394, Validation Loss: 0.4746\n",
      "[Trial 122] Epoch 43/60, Training Loss: 0.5872, Validation Loss: 0.5007\n",
      "[Trial 125] Epoch 30/60, Training Loss: 0.6653, Validation Loss: 0.5784\n",
      "[Trial 130] Epoch 11/60, Training Loss: 0.9104, Validation Loss: 1.2478\n",
      "[Trial 121] Epoch 42/60, Training Loss: 0.5931, Validation Loss: 0.5170\n",
      "[Trial 119] Epoch 46/60, Training Loss: 0.5864, Validation Loss: 0.5211\n",
      "[Trial 115] Epoch 58/60, Training Loss: 0.5904, Validation Loss: 0.5233\n",
      "[Trial 118] Epoch 47/60, Training Loss: 0.6149, Validation Loss: 0.5279\n",
      "[Trial 129] Epoch 12/60, Training Loss: 0.8937, Validation Loss: 0.7655\n",
      "[Trial 127] Epoch 19/60, Training Loss: 0.7625, Validation Loss: 0.9464\n",
      "[Trial 124] Epoch 31/60, Training Loss: 0.7009, Validation Loss: 0.6056\n",
      "[Trial 131] Epoch 7/60, Training Loss: 1.1489, Validation Loss: 1.0374\n",
      "[Trial 123] Epoch 38/60, Training Loss: 0.6610, Validation Loss: 0.5790\n",
      "[Trial 116] Epoch 55/60, Training Loss: 0.5531, Validation Loss: 0.4760\n",
      "[Trial 126] Epoch 28/60, Training Loss: 0.6708, Validation Loss: 0.5519\n",
      "[Trial 128] Epoch 13/60, Training Loss: 0.8545, Validation Loss: 0.7258\n",
      "[Trial 117] Epoch 50/60, Training Loss: 0.5385, Validation Loss: 0.4912\n",
      "[Trial 122] Epoch 44/60, Training Loss: 0.5791, Validation Loss: 0.5065\n",
      "[Trial 125] Epoch 31/60, Training Loss: 0.6209, Validation Loss: 0.5135\n",
      "[Trial 130] Epoch 12/60, Training Loss: 0.9055, Validation Loss: 0.7494\n",
      "[Trial 121] Epoch 43/60, Training Loss: 0.5914, Validation Loss: 0.5304\n",
      "[Trial 119] Epoch 47/60, Training Loss: 0.5804, Validation Loss: 0.5167\n",
      "[Trial 118] Epoch 48/60, Training Loss: 0.5804, Validation Loss: 0.5052\n",
      "[Trial 115] Epoch 59/60, Training Loss: 0.5917, Validation Loss: 0.5251\n",
      "[Trial 127] Epoch 20/60, Training Loss: 0.7872, Validation Loss: 0.6077\n",
      "[Trial 129] Epoch 13/60, Training Loss: 0.9013, Validation Loss: 0.7260\n",
      "[Trial 131] Epoch 8/60, Training Loss: 1.0251, Validation Loss: 1.0564\n",
      "[Trial 124] Epoch 32/60, Training Loss: 0.6939, Validation Loss: 0.9626\n",
      "[Trial 123] Epoch 39/60, Training Loss: 0.6598, Validation Loss: 0.6571\n",
      "[Trial 126] Epoch 29/60, Training Loss: 0.6696, Validation Loss: 0.7568\n",
      "[Trial 116] Epoch 56/60, Training Loss: 0.5452, Validation Loss: 0.4840\n",
      "[Trial 128] Epoch 14/60, Training Loss: 0.7957, Validation Loss: 0.6779\n",
      "[Trial 117] Epoch 51/60, Training Loss: 0.5359, Validation Loss: 0.4831\n",
      "[Trial 122] Epoch 45/60, Training Loss: 0.5785, Validation Loss: 0.5153\n",
      "[Trial 125] Epoch 32/60, Training Loss: 0.6158, Validation Loss: 0.5383\n",
      "[Trial 130] Epoch 13/60, Training Loss: 0.8589, Validation Loss: 0.8263\n",
      "[Trial 121] Epoch 44/60, Training Loss: 0.5883, Validation Loss: 0.5240\n",
      "[Trial 119] Epoch 48/60, Training Loss: 0.5775, Validation Loss: 0.5078\n",
      "[Trial 118] Epoch 49/60, Training Loss: 0.5756, Validation Loss: 0.4970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:43:58,279] Trial 115 finished with value: 0.5140264764428139 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.011257111550302701, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 115] Epoch 60/60, Training Loss: 0.5828, Validation Loss: 0.5140\n",
      "[Trial 127] Epoch 21/60, Training Loss: 0.7298, Validation Loss: 0.6428\n",
      "[Trial 129] Epoch 14/60, Training Loss: 0.8425, Validation Loss: 0.7021\n",
      "[Trial 131] Epoch 9/60, Training Loss: 0.9947, Validation Loss: 0.8704\n",
      "[Trial 123] Epoch 40/60, Training Loss: 0.6259, Validation Loss: 0.5272\n",
      "[Trial 124] Epoch 33/60, Training Loss: 0.6966, Validation Loss: 0.6339\n",
      "[Trial 126] Epoch 30/60, Training Loss: 0.7148, Validation Loss: 0.5539\n",
      "[Trial 116] Epoch 57/60, Training Loss: 0.5363, Validation Loss: 0.4753\n",
      "[Trial 128] Epoch 15/60, Training Loss: 0.8055, Validation Loss: 0.6295\n",
      "[Trial 117] Epoch 52/60, Training Loss: 0.5322, Validation Loss: 0.4882\n",
      "[Trial 122] Epoch 46/60, Training Loss: 0.5874, Validation Loss: 0.5097\n",
      "[Trial 125] Epoch 33/60, Training Loss: 0.6181, Validation Loss: 0.5318\n",
      "[Trial 121] Epoch 45/60, Training Loss: 0.6009, Validation Loss: 0.5455\n",
      "[Trial 130] Epoch 14/60, Training Loss: 0.9466, Validation Loss: 0.7390\n",
      "[Trial 119] Epoch 49/60, Training Loss: 0.5757, Validation Loss: 0.5060\n",
      "[Trial 118] Epoch 50/60, Training Loss: 0.5714, Validation Loss: 0.4852\n",
      "[Trial 132] Epoch 1/60, Training Loss: 4.9723, Validation Loss: 2.7926\n",
      "[Trial 127] Epoch 22/60, Training Loss: 0.7044, Validation Loss: 0.7327\n",
      "[Trial 129] Epoch 15/60, Training Loss: 0.8275, Validation Loss: 0.6417\n",
      "[Trial 131] Epoch 10/60, Training Loss: 0.9313, Validation Loss: 1.2984\n",
      "[Trial 123] Epoch 41/60, Training Loss: 0.6204, Validation Loss: 0.6045\n",
      "[Trial 124] Epoch 34/60, Training Loss: 0.6928, Validation Loss: 0.6276\n",
      "[Trial 126] Epoch 31/60, Training Loss: 0.6691, Validation Loss: 0.6617\n",
      "[Trial 116] Epoch 58/60, Training Loss: 0.5409, Validation Loss: 0.4736\n",
      "[Trial 117] Epoch 53/60, Training Loss: 0.5314, Validation Loss: 0.4818\n",
      "[Trial 122] Epoch 47/60, Training Loss: 0.5575, Validation Loss: 0.4712\n",
      "[Trial 128] Epoch 16/60, Training Loss: 0.7726, Validation Loss: 0.6715\n",
      "[Trial 125] Epoch 34/60, Training Loss: 0.6155, Validation Loss: 0.5416\n",
      "[Trial 121] Epoch 46/60, Training Loss: 0.5752, Validation Loss: 0.4902\n",
      "[Trial 130] Epoch 15/60, Training Loss: 0.8361, Validation Loss: 1.1476\n",
      "[Trial 119] Epoch 50/60, Training Loss: 0.5691, Validation Loss: 0.4984\n",
      "[Trial 118] Epoch 51/60, Training Loss: 0.5764, Validation Loss: 0.4992\n",
      "[Trial 132] Epoch 2/60, Training Loss: 2.2074, Validation Loss: 1.7972\n",
      "[Trial 127] Epoch 23/60, Training Loss: 0.7000, Validation Loss: 1.1166\n",
      "[Trial 129] Epoch 16/60, Training Loss: 0.8152, Validation Loss: 0.6894\n",
      "[Trial 131] Epoch 11/60, Training Loss: 0.9331, Validation Loss: 0.9860\n",
      "[Trial 126] Epoch 32/60, Training Loss: 0.6765, Validation Loss: 0.7414\n",
      "[Trial 123] Epoch 42/60, Training Loss: 0.6227, Validation Loss: 0.5661\n",
      "[Trial 124] Epoch 35/60, Training Loss: 0.6765, Validation Loss: 0.6653\n",
      "[Trial 116] Epoch 59/60, Training Loss: 0.5392, Validation Loss: 0.4726\n",
      "[Trial 117] Epoch 54/60, Training Loss: 0.5288, Validation Loss: 0.4770\n",
      "[Trial 122] Epoch 48/60, Training Loss: 0.5591, Validation Loss: 0.4747\n",
      "[Trial 128] Epoch 17/60, Training Loss: 0.7651, Validation Loss: 0.6106\n",
      "[Trial 125] Epoch 35/60, Training Loss: 0.6099, Validation Loss: 0.5354\n",
      "[Trial 121] Epoch 47/60, Training Loss: 0.5675, Validation Loss: 0.4917\n",
      "[Trial 119] Epoch 51/60, Training Loss: 0.5632, Validation Loss: 0.5153\n",
      "[Trial 118] Epoch 52/60, Training Loss: 0.5725, Validation Loss: 0.5415\n",
      "[Trial 130] Epoch 16/60, Training Loss: 0.8675, Validation Loss: 0.6602\n",
      "[Trial 132] Epoch 3/60, Training Loss: 1.9285, Validation Loss: 1.6120\n",
      "[Trial 127] Epoch 24/60, Training Loss: 0.7395, Validation Loss: 0.6655\n",
      "[Trial 129] Epoch 17/60, Training Loss: 0.8072, Validation Loss: 0.7353\n",
      "[Trial 126] Epoch 33/60, Training Loss: 0.6718, Validation Loss: 0.6276\n",
      "[Trial 131] Epoch 12/60, Training Loss: 0.9092, Validation Loss: 0.7220\n",
      "[Trial 123] Epoch 43/60, Training Loss: 0.6071, Validation Loss: 0.5363\n",
      "[Trial 124] Epoch 36/60, Training Loss: 0.6636, Validation Loss: 0.5629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:48:35,827] Trial 116 finished with value: 0.4713731894890467 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.004818279201654646, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 116] Epoch 60/60, Training Loss: 0.5379, Validation Loss: 0.4714\n",
      "[Trial 117] Epoch 55/60, Training Loss: 0.5347, Validation Loss: 0.4779\n",
      "[Trial 122] Epoch 49/60, Training Loss: 0.5502, Validation Loss: 0.5308\n",
      "[Trial 128] Epoch 18/60, Training Loss: 0.7677, Validation Loss: 0.6478\n",
      "[Trial 125] Epoch 36/60, Training Loss: 0.6151, Validation Loss: 0.5230\n",
      "[Trial 119] Epoch 52/60, Training Loss: 0.5622, Validation Loss: 0.4807\n",
      "[Trial 118] Epoch 53/60, Training Loss: 0.5968, Validation Loss: 0.5288\n",
      "[Trial 121] Epoch 48/60, Training Loss: 0.5789, Validation Loss: 0.5030\n",
      "[Trial 130] Epoch 17/60, Training Loss: 0.7993, Validation Loss: 0.6375\n",
      "[Trial 132] Epoch 4/60, Training Loss: 1.6654, Validation Loss: 1.4917\n",
      "[Trial 127] Epoch 25/60, Training Loss: 0.6498, Validation Loss: 0.5238\n",
      "[Trial 129] Epoch 18/60, Training Loss: 0.8107, Validation Loss: 0.6653\n",
      "[Trial 126] Epoch 34/60, Training Loss: 0.6609, Validation Loss: 0.5538\n",
      "[Trial 131] Epoch 13/60, Training Loss: 0.8646, Validation Loss: 1.1135\n",
      "[Trial 123] Epoch 44/60, Training Loss: 0.6059, Validation Loss: 0.5483\n",
      "[Trial 117] Epoch 56/60, Training Loss: 0.5240, Validation Loss: 0.4720\n",
      "[Trial 133] Epoch 1/60, Training Loss: 4.5299, Validation Loss: 2.3083\n",
      "[Trial 124] Epoch 37/60, Training Loss: 0.6435, Validation Loss: 0.5743\n",
      "[Trial 122] Epoch 50/60, Training Loss: 0.5614, Validation Loss: 0.4714\n",
      "[Trial 128] Epoch 19/60, Training Loss: 0.7424, Validation Loss: 1.5055\n",
      "[Trial 125] Epoch 37/60, Training Loss: 0.6151, Validation Loss: 0.5184\n",
      "[Trial 119] Epoch 53/60, Training Loss: 0.5567, Validation Loss: 0.4803\n",
      "[Trial 118] Epoch 54/60, Training Loss: 0.6074, Validation Loss: 0.5487\n",
      "[Trial 121] Epoch 49/60, Training Loss: 0.5698, Validation Loss: 0.4870\n",
      "[Trial 130] Epoch 18/60, Training Loss: 0.7839, Validation Loss: 0.7837\n",
      "[Trial 127] Epoch 26/60, Training Loss: 0.6427, Validation Loss: 0.5903\n",
      "[Trial 132] Epoch 5/60, Training Loss: 1.3958, Validation Loss: 1.0436\n",
      "[Trial 129] Epoch 19/60, Training Loss: 0.7740, Validation Loss: 0.6467\n",
      "[Trial 126] Epoch 35/60, Training Loss: 0.6225, Validation Loss: 0.5655\n",
      "[Trial 131] Epoch 14/60, Training Loss: 0.8709, Validation Loss: 0.7068\n",
      "[Trial 117] Epoch 57/60, Training Loss: 0.5278, Validation Loss: 0.4755\n",
      "[Trial 123] Epoch 45/60, Training Loss: 0.6054, Validation Loss: 0.5360\n",
      "[Trial 122] Epoch 51/60, Training Loss: 0.5609, Validation Loss: 0.4716\n",
      "[Trial 133] Epoch 2/60, Training Loss: 2.3994, Validation Loss: 2.7510\n",
      "[Trial 124] Epoch 38/60, Training Loss: 0.6250, Validation Loss: 0.5683\n",
      "[Trial 125] Epoch 38/60, Training Loss: 0.5917, Validation Loss: 0.5106\n",
      "[Trial 128] Epoch 20/60, Training Loss: 0.8193, Validation Loss: 1.5271\n",
      "[Trial 119] Epoch 54/60, Training Loss: 0.5649, Validation Loss: 0.4865\n",
      "[Trial 118] Epoch 55/60, Training Loss: 0.5877, Validation Loss: 0.5237\n",
      "[Trial 121] Epoch 50/60, Training Loss: 0.5668, Validation Loss: 0.5005\n",
      "[Trial 130] Epoch 19/60, Training Loss: 0.8008, Validation Loss: 0.9196\n",
      "[Trial 127] Epoch 27/60, Training Loss: 0.6492, Validation Loss: 0.5643\n",
      "[Trial 132] Epoch 6/60, Training Loss: 1.2378, Validation Loss: 1.1429\n",
      "[Trial 126] Epoch 36/60, Training Loss: 0.6377, Validation Loss: 0.5437\n",
      "[Trial 129] Epoch 20/60, Training Loss: 0.7698, Validation Loss: 0.6153\n",
      "[Trial 117] Epoch 58/60, Training Loss: 0.5172, Validation Loss: 0.4660\n",
      "[Trial 131] Epoch 15/60, Training Loss: 0.8210, Validation Loss: 0.7335\n",
      "[Trial 122] Epoch 52/60, Training Loss: 0.5527, Validation Loss: 0.4674\n",
      "[Trial 123] Epoch 46/60, Training Loss: 0.6101, Validation Loss: 0.5962\n",
      "[Trial 133] Epoch 3/60, Training Loss: 2.0223, Validation Loss: 1.7782\n",
      "[Trial 124] Epoch 39/60, Training Loss: 0.6364, Validation Loss: 0.5373\n",
      "[Trial 125] Epoch 39/60, Training Loss: 0.5955, Validation Loss: 0.5123\n",
      "[Trial 128] Epoch 21/60, Training Loss: 0.7974, Validation Loss: 0.9089\n",
      "[Trial 119] Epoch 55/60, Training Loss: 0.5545, Validation Loss: 0.4817\n",
      "[Trial 118] Epoch 56/60, Training Loss: 0.5835, Validation Loss: 0.5004\n",
      "[Trial 121] Epoch 51/60, Training Loss: 0.5626, Validation Loss: 0.4738\n",
      "[Trial 130] Epoch 20/60, Training Loss: 0.8043, Validation Loss: 1.0094\n",
      "[Trial 127] Epoch 28/60, Training Loss: 0.6371, Validation Loss: 0.5756\n",
      "[Trial 126] Epoch 37/60, Training Loss: 0.6243, Validation Loss: 0.5344\n",
      "[Trial 132] Epoch 7/60, Training Loss: 1.1327, Validation Loss: 1.1725\n",
      "[Trial 129] Epoch 21/60, Training Loss: 0.7428, Validation Loss: 0.7489\n",
      "[Trial 117] Epoch 59/60, Training Loss: 0.5180, Validation Loss: 0.4715\n",
      "[Trial 122] Epoch 53/60, Training Loss: 0.5480, Validation Loss: 0.4849\n",
      "[Trial 131] Epoch 16/60, Training Loss: 0.8411, Validation Loss: 0.8216\n",
      "[Trial 123] Epoch 47/60, Training Loss: 0.5795, Validation Loss: 0.4951\n",
      "[Trial 133] Epoch 4/60, Training Loss: 1.7599, Validation Loss: 1.6489\n",
      "[Trial 124] Epoch 40/60, Training Loss: 0.6163, Validation Loss: 0.5269\n",
      "[Trial 125] Epoch 40/60, Training Loss: 0.5861, Validation Loss: 0.5008\n",
      "[Trial 128] Epoch 22/60, Training Loss: 0.7423, Validation Loss: 0.6589\n",
      "[Trial 118] Epoch 57/60, Training Loss: 0.5537, Validation Loss: 0.4891\n",
      "[Trial 119] Epoch 56/60, Training Loss: 0.5582, Validation Loss: 0.4777\n",
      "[Trial 121] Epoch 52/60, Training Loss: 0.5560, Validation Loss: 0.4806\n",
      "[Trial 130] Epoch 21/60, Training Loss: 0.8364, Validation Loss: 0.7346\n",
      "[Trial 127] Epoch 29/60, Training Loss: 0.6441, Validation Loss: 0.5976\n",
      "[Trial 126] Epoch 38/60, Training Loss: 0.6266, Validation Loss: 0.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:55:32,970] Trial 117 finished with value: 0.4660262405872345 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.005167191017809623, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 117] Epoch 60/60, Training Loss: 0.5178, Validation Loss: 0.4719\n",
      "[Trial 132] Epoch 8/60, Training Loss: 1.0839, Validation Loss: 0.9073\n",
      "[Trial 129] Epoch 22/60, Training Loss: 0.8144, Validation Loss: 1.0951\n",
      "[Trial 122] Epoch 54/60, Training Loss: 0.5576, Validation Loss: 0.4739\n",
      "[Trial 131] Epoch 17/60, Training Loss: 0.7966, Validation Loss: 0.7711\n",
      "[Trial 123] Epoch 48/60, Training Loss: 0.5790, Validation Loss: 0.5125\n",
      "[Trial 133] Epoch 5/60, Training Loss: 1.4918, Validation Loss: 1.2692\n",
      "[Trial 124] Epoch 41/60, Training Loss: 0.6291, Validation Loss: 0.5582\n",
      "[Trial 125] Epoch 41/60, Training Loss: 0.5902, Validation Loss: 0.5139\n",
      "[Trial 128] Epoch 23/60, Training Loss: 0.7281, Validation Loss: 0.9144\n",
      "[Trial 118] Epoch 58/60, Training Loss: 0.5473, Validation Loss: 0.4771\n",
      "[Trial 119] Epoch 57/60, Training Loss: 0.5589, Validation Loss: 0.4826\n",
      "[Trial 121] Epoch 53/60, Training Loss: 0.5575, Validation Loss: 0.4869\n",
      "[Trial 130] Epoch 22/60, Training Loss: 0.7467, Validation Loss: 0.7586\n",
      "[Trial 126] Epoch 39/60, Training Loss: 0.6210, Validation Loss: 0.5510\n",
      "[Trial 127] Epoch 30/60, Training Loss: 0.6093, Validation Loss: 0.5601\n",
      "[Trial 134] Epoch 1/60, Training Loss: 4.5269, Validation Loss: 2.8831\n",
      "[Trial 122] Epoch 55/60, Training Loss: 0.5514, Validation Loss: 0.4613\n",
      "[Trial 132] Epoch 9/60, Training Loss: 1.0100, Validation Loss: 0.9500\n",
      "[Trial 129] Epoch 23/60, Training Loss: 0.7871, Validation Loss: 0.6705\n",
      "[Trial 131] Epoch 18/60, Training Loss: 0.8146, Validation Loss: 0.9741\n",
      "[Trial 123] Epoch 49/60, Training Loss: 0.5802, Validation Loss: 0.5000\n",
      "[Trial 133] Epoch 6/60, Training Loss: 1.2896, Validation Loss: 1.1754\n",
      "[Trial 124] Epoch 42/60, Training Loss: 0.6223, Validation Loss: 0.5410\n",
      "[Trial 125] Epoch 42/60, Training Loss: 0.5832, Validation Loss: 0.4992\n",
      "[Trial 118] Epoch 59/60, Training Loss: 0.5523, Validation Loss: 0.5032\n",
      "[Trial 119] Epoch 58/60, Training Loss: 0.5520, Validation Loss: 0.4778\n",
      "[Trial 128] Epoch 24/60, Training Loss: 0.6765, Validation Loss: 0.5704\n",
      "[Trial 121] Epoch 54/60, Training Loss: 0.5578, Validation Loss: 0.4956\n",
      "[Trial 126] Epoch 40/60, Training Loss: 0.6158, Validation Loss: 0.5566\n",
      "[Trial 130] Epoch 23/60, Training Loss: 0.7587, Validation Loss: 0.9054\n",
      "[Trial 134] Epoch 2/60, Training Loss: 1.9862, Validation Loss: 1.5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:58:23,409] Trial 127 finished with value: 0.5237844919164976 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.00892575166909255, 'batch_size': 16, 'patience': 6}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 127] Epoch 31/60, Training Loss: 0.6060, Validation Loss: 0.5255\n",
      "[Trial 127] Early stopping after 31 epochs.\n",
      "[Trial 122] Epoch 56/60, Training Loss: 0.5478, Validation Loss: 0.4862\n",
      "[Trial 132] Epoch 10/60, Training Loss: 0.9823, Validation Loss: 0.8380\n",
      "[Trial 129] Epoch 24/60, Training Loss: 0.7227, Validation Loss: 0.6296\n",
      "[Trial 131] Epoch 19/60, Training Loss: 0.8262, Validation Loss: 0.6608\n",
      "[Trial 123] Epoch 50/60, Training Loss: 0.5706, Validation Loss: 0.4946\n",
      "[Trial 133] Epoch 7/60, Training Loss: 1.1693, Validation Loss: 0.8691\n",
      "[Trial 125] Epoch 43/60, Training Loss: 0.5815, Validation Loss: 0.5000\n",
      "[Trial 124] Epoch 43/60, Training Loss: 0.6249, Validation Loss: 0.5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 08:58:58,502] Trial 118 finished with value: 0.4771375462412834 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.004881243518558937, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 118] Epoch 60/60, Training Loss: 0.5561, Validation Loss: 0.5088\n",
      "[Trial 119] Epoch 59/60, Training Loss: 0.5587, Validation Loss: 0.4947\n",
      "[Trial 128] Epoch 25/60, Training Loss: 0.6506, Validation Loss: 0.5724\n",
      "[Trial 121] Epoch 55/60, Training Loss: 0.5547, Validation Loss: 0.4771\n",
      "[Trial 134] Epoch 3/60, Training Loss: 1.5875, Validation Loss: 2.7122\n",
      "[Trial 126] Epoch 41/60, Training Loss: 0.6220, Validation Loss: 0.5340\n",
      "[Trial 135] Epoch 1/60, Training Loss: 4.2115, Validation Loss: 2.3654\n",
      "[Trial 122] Epoch 57/60, Training Loss: 0.5454, Validation Loss: 0.4638\n",
      "[Trial 130] Epoch 24/60, Training Loss: 0.6943, Validation Loss: 0.6815\n",
      "[Trial 129] Epoch 25/60, Training Loss: 0.7170, Validation Loss: 0.6843\n",
      "[Trial 132] Epoch 11/60, Training Loss: 0.9129, Validation Loss: 0.9669\n",
      "[Trial 131] Epoch 20/60, Training Loss: 0.7607, Validation Loss: 0.9157\n",
      "[Trial 123] Epoch 51/60, Training Loss: 0.5712, Validation Loss: 0.4846\n",
      "[Trial 133] Epoch 8/60, Training Loss: 1.1174, Validation Loss: 0.9461\n",
      "[Trial 125] Epoch 44/60, Training Loss: 0.5842, Validation Loss: 0.5212\n",
      "[Trial 136] Epoch 1/60, Training Loss: 4.4468, Validation Loss: 2.6176\n",
      "[Trial 124] Epoch 44/60, Training Loss: 0.6234, Validation Loss: 0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:00:26,066] Trial 119 finished with value: 0.4776964008808136 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.004776809329108695, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 119] Epoch 60/60, Training Loss: 0.5582, Validation Loss: 0.4908\n",
      "[Trial 128] Epoch 26/60, Training Loss: 0.6531, Validation Loss: 0.5425\n",
      "[Trial 121] Epoch 56/60, Training Loss: 0.5512, Validation Loss: 0.4746\n",
      "[Trial 134] Epoch 4/60, Training Loss: 1.4175, Validation Loss: 1.7495\n",
      "[Trial 135] Epoch 2/60, Training Loss: 1.9370, Validation Loss: 1.7271\n",
      "[Trial 122] Epoch 58/60, Training Loss: 0.5491, Validation Loss: 0.4636\n",
      "[Trial 126] Epoch 42/60, Training Loss: 0.6197, Validation Loss: 0.5400\n",
      "[Trial 130] Epoch 25/60, Training Loss: 0.6555, Validation Loss: 0.5693\n",
      "[Trial 129] Epoch 26/60, Training Loss: 0.7329, Validation Loss: 0.7457\n",
      "[Trial 132] Epoch 12/60, Training Loss: 0.9251, Validation Loss: 0.7490\n",
      "[Trial 131] Epoch 21/60, Training Loss: 0.8092, Validation Loss: 0.6717\n",
      "[Trial 123] Epoch 52/60, Training Loss: 0.5718, Validation Loss: 0.4970\n",
      "[Trial 125] Epoch 45/60, Training Loss: 0.5912, Validation Loss: 0.4948\n",
      "[Trial 133] Epoch 9/60, Training Loss: 1.0884, Validation Loss: 1.2405\n",
      "[Trial 136] Epoch 2/60, Training Loss: 1.9910, Validation Loss: 1.4302\n",
      "[Trial 137] Epoch 1/60, Training Loss: 4.2301, Validation Loss: 2.0945\n",
      "[Trial 124] Epoch 45/60, Training Loss: 0.6264, Validation Loss: 0.5665\n",
      "[Trial 128] Epoch 27/60, Training Loss: 0.6558, Validation Loss: 0.7280\n",
      "[Trial 121] Epoch 57/60, Training Loss: 0.5558, Validation Loss: 0.4733\n",
      "[Trial 134] Epoch 5/60, Training Loss: 1.3326, Validation Loss: 1.2651\n",
      "[Trial 122] Epoch 59/60, Training Loss: 0.5491, Validation Loss: 0.4671\n",
      "[Trial 135] Epoch 3/60, Training Loss: 1.5941, Validation Loss: 1.6959\n",
      "[Trial 126] Epoch 43/60, Training Loss: 0.6133, Validation Loss: 0.5587\n",
      "[Trial 130] Epoch 26/60, Training Loss: 0.6606, Validation Loss: 0.5932\n",
      "[Trial 129] Epoch 27/60, Training Loss: 0.6496, Validation Loss: 0.5217\n",
      "[Trial 132] Epoch 13/60, Training Loss: 0.8579, Validation Loss: 0.8607\n",
      "[Trial 131] Epoch 22/60, Training Loss: 0.7275, Validation Loss: 0.6415\n",
      "[Trial 123] Epoch 53/60, Training Loss: 0.5748, Validation Loss: 0.5071\n",
      "[Trial 125] Epoch 46/60, Training Loss: 0.5771, Validation Loss: 0.4883\n",
      "[Trial 136] Epoch 3/60, Training Loss: 1.5837, Validation Loss: 1.2830\n",
      "[Trial 137] Epoch 2/60, Training Loss: 1.8873, Validation Loss: 1.4015\n",
      "[Trial 133] Epoch 10/60, Training Loss: 1.0941, Validation Loss: 0.9949\n",
      "[Trial 124] Epoch 46/60, Training Loss: 0.6350, Validation Loss: 0.5891\n",
      "[Trial 128] Epoch 28/60, Training Loss: 0.6770, Validation Loss: 0.5388\n",
      "[Trial 121] Epoch 58/60, Training Loss: 0.5516, Validation Loss: 0.4771\n",
      "[Trial 134] Epoch 6/60, Training Loss: 1.1094, Validation Loss: 0.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:04:02,390] Trial 122 finished with value: 0.45175078709920247 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0027032156617006896, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 122] Epoch 60/60, Training Loss: 0.5464, Validation Loss: 0.4518\n",
      "[Trial 135] Epoch 4/60, Training Loss: 1.3936, Validation Loss: 0.9335\n",
      "[Trial 126] Epoch 44/60, Training Loss: 0.6229, Validation Loss: 0.5589\n",
      "[Trial 130] Epoch 27/60, Training Loss: 0.6550, Validation Loss: 0.5869\n",
      "[Trial 129] Epoch 28/60, Training Loss: 0.6376, Validation Loss: 0.5260\n",
      "[Trial 132] Epoch 14/60, Training Loss: 0.8451, Validation Loss: 0.8249\n",
      "[Trial 136] Epoch 4/60, Training Loss: 1.3946, Validation Loss: 1.1805\n",
      "[Trial 131] Epoch 23/60, Training Loss: 0.7459, Validation Loss: 0.7763\n",
      "[Trial 125] Epoch 47/60, Training Loss: 0.5873, Validation Loss: 0.4967\n",
      "[Trial 137] Epoch 3/60, Training Loss: 1.5633, Validation Loss: 1.1048\n",
      "[Trial 123] Epoch 54/60, Training Loss: 0.5759, Validation Loss: 0.5276\n",
      "[Trial 133] Epoch 11/60, Training Loss: 0.9832, Validation Loss: 0.8354\n",
      "[Trial 124] Epoch 47/60, Training Loss: 0.6241, Validation Loss: 0.5824\n",
      "[Trial 128] Epoch 29/60, Training Loss: 0.6505, Validation Loss: 0.6124\n",
      "[Trial 134] Epoch 7/60, Training Loss: 1.0299, Validation Loss: 0.9789\n",
      "[Trial 138] Epoch 1/60, Training Loss: 4.6995, Validation Loss: 2.2122\n",
      "[Trial 135] Epoch 5/60, Training Loss: 1.2540, Validation Loss: 1.6087\n",
      "[Trial 121] Epoch 59/60, Training Loss: 0.5566, Validation Loss: 0.4865\n",
      "[Trial 126] Epoch 45/60, Training Loss: 0.6287, Validation Loss: 0.5558\n",
      "[Trial 129] Epoch 29/60, Training Loss: 0.6456, Validation Loss: 0.5925\n",
      "[Trial 130] Epoch 28/60, Training Loss: 0.6551, Validation Loss: 0.6319\n",
      "[Trial 132] Epoch 15/60, Training Loss: 0.8524, Validation Loss: 1.2116\n",
      "[Trial 136] Epoch 5/60, Training Loss: 1.2558, Validation Loss: 1.6513\n",
      "[Trial 125] Epoch 48/60, Training Loss: 0.5789, Validation Loss: 0.5006\n",
      "[Trial 137] Epoch 4/60, Training Loss: 1.3259, Validation Loss: 1.2728\n",
      "[Trial 131] Epoch 24/60, Training Loss: 0.7597, Validation Loss: 0.6761\n",
      "[Trial 123] Epoch 55/60, Training Loss: 0.5725, Validation Loss: 0.4928\n",
      "[Trial 133] Epoch 12/60, Training Loss: 0.9361, Validation Loss: 0.7986\n",
      "[Trial 124] Epoch 48/60, Training Loss: 0.6243, Validation Loss: 0.5282\n",
      "[Trial 128] Epoch 30/60, Training Loss: 0.6530, Validation Loss: 0.6117\n",
      "[Trial 138] Epoch 2/60, Training Loss: 2.0215, Validation Loss: 2.7121\n",
      "[Trial 134] Epoch 8/60, Training Loss: 0.9942, Validation Loss: 0.8814\n",
      "[Trial 135] Epoch 6/60, Training Loss: 1.1173, Validation Loss: 0.8589\n",
      "[Trial 126] Epoch 46/60, Training Loss: 0.6196, Validation Loss: 0.5096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:06:59,659] Trial 121 finished with value: 0.47332869917154313 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.002619171674752894, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 121] Epoch 60/60, Training Loss: 0.5540, Validation Loss: 0.4916\n",
      "[Trial 129] Epoch 30/60, Training Loss: 0.6580, Validation Loss: 0.5228\n",
      "[Trial 130] Epoch 29/60, Training Loss: 0.6781, Validation Loss: 0.6146\n",
      "[Trial 132] Epoch 16/60, Training Loss: 0.9752, Validation Loss: 0.8065\n",
      "[Trial 136] Epoch 6/60, Training Loss: 1.2971, Validation Loss: 2.5600\n",
      "[Trial 137] Epoch 5/60, Training Loss: 1.2515, Validation Loss: 1.3159\n",
      "[Trial 125] Epoch 49/60, Training Loss: 0.5753, Validation Loss: 0.5036\n",
      "[Trial 131] Epoch 25/60, Training Loss: 0.7289, Validation Loss: 1.2493\n",
      "[Trial 123] Epoch 56/60, Training Loss: 0.5702, Validation Loss: 0.4941\n",
      "[Trial 133] Epoch 13/60, Training Loss: 0.9138, Validation Loss: 0.7101\n",
      "[Trial 124] Epoch 49/60, Training Loss: 0.6104, Validation Loss: 0.5369\n",
      "[Trial 128] Epoch 31/60, Training Loss: 0.6562, Validation Loss: 0.5723\n",
      "[Trial 138] Epoch 3/60, Training Loss: 1.6596, Validation Loss: 1.4418\n",
      "[Trial 134] Epoch 9/60, Training Loss: 0.9624, Validation Loss: 1.3698\n",
      "[Trial 135] Epoch 7/60, Training Loss: 1.0092, Validation Loss: 0.9402\n",
      "[Trial 139] Epoch 1/60, Training Loss: 3.1839, Validation Loss: 1.5999\n",
      "[Trial 126] Epoch 47/60, Training Loss: 0.6096, Validation Loss: 0.5394\n",
      "[Trial 129] Epoch 31/60, Training Loss: 0.6424, Validation Loss: 0.5171\n",
      "[Trial 136] Epoch 7/60, Training Loss: 1.1794, Validation Loss: 1.0219\n",
      "[Trial 132] Epoch 17/60, Training Loss: 0.8400, Validation Loss: 0.6953\n",
      "[Trial 130] Epoch 30/60, Training Loss: 0.6602, Validation Loss: 0.6376\n",
      "[Trial 137] Epoch 6/60, Training Loss: 1.1314, Validation Loss: 0.9790\n",
      "[Trial 125] Epoch 50/60, Training Loss: 0.5796, Validation Loss: 0.5080\n",
      "[Trial 131] Epoch 26/60, Training Loss: 0.7565, Validation Loss: 0.6204\n",
      "[Trial 123] Epoch 57/60, Training Loss: 0.5660, Validation Loss: 0.5026\n",
      "[Trial 133] Epoch 14/60, Training Loss: 0.9049, Validation Loss: 0.8172\n",
      "[Trial 124] Epoch 50/60, Training Loss: 0.5906, Validation Loss: 0.5147\n",
      "[Trial 128] Epoch 32/60, Training Loss: 0.6503, Validation Loss: 0.5870\n",
      "[Trial 138] Epoch 4/60, Training Loss: 1.4160, Validation Loss: 1.5586\n",
      "[Trial 139] Epoch 2/60, Training Loss: 1.7373, Validation Loss: 1.3594\n",
      "[Trial 134] Epoch 10/60, Training Loss: 0.9415, Validation Loss: 3.0797\n",
      "[Trial 135] Epoch 8/60, Training Loss: 0.9950, Validation Loss: 1.1680\n",
      "[Trial 126] Epoch 48/60, Training Loss: 0.6089, Validation Loss: 0.5188\n",
      "[Trial 136] Epoch 8/60, Training Loss: 0.9831, Validation Loss: 0.8374\n",
      "[Trial 129] Epoch 32/60, Training Loss: 0.6323, Validation Loss: 0.5367\n",
      "[Trial 137] Epoch 7/60, Training Loss: 1.0582, Validation Loss: 0.7945\n",
      "[Trial 132] Epoch 18/60, Training Loss: 0.7654, Validation Loss: 0.7379\n",
      "[Trial 125] Epoch 51/60, Training Loss: 0.5776, Validation Loss: 0.5028\n",
      "[Trial 130] Epoch 31/60, Training Loss: 0.6586, Validation Loss: 0.7056\n",
      "[Trial 131] Epoch 27/60, Training Loss: 0.7169, Validation Loss: 0.6225\n",
      "[Trial 123] Epoch 58/60, Training Loss: 0.5616, Validation Loss: 0.4794\n",
      "[Trial 133] Epoch 15/60, Training Loss: 0.9378, Validation Loss: 0.9743\n",
      "[Trial 124] Epoch 51/60, Training Loss: 0.5943, Validation Loss: 0.5114\n",
      "[Trial 128] Epoch 33/60, Training Loss: 0.6708, Validation Loss: 0.5921\n",
      "[Trial 139] Epoch 3/60, Training Loss: 1.3887, Validation Loss: 0.9769\n",
      "[Trial 138] Epoch 5/60, Training Loss: 1.3136, Validation Loss: 2.4019\n",
      "[Trial 135] Epoch 9/60, Training Loss: 0.9548, Validation Loss: 1.0762\n",
      "[Trial 134] Epoch 11/60, Training Loss: 1.0669, Validation Loss: 0.7773\n",
      "[Trial 126] Epoch 49/60, Training Loss: 0.6012, Validation Loss: 0.5500\n",
      "[Trial 136] Epoch 9/60, Training Loss: 0.9667, Validation Loss: 0.7434\n",
      "[Trial 137] Epoch 8/60, Training Loss: 0.9807, Validation Loss: 1.0078\n",
      "[Trial 129] Epoch 33/60, Training Loss: 0.6283, Validation Loss: 0.5104\n",
      "[Trial 125] Epoch 52/60, Training Loss: 0.5849, Validation Loss: 0.5184\n",
      "[Trial 132] Epoch 19/60, Training Loss: 0.7696, Validation Loss: 0.7042\n",
      "[Trial 130] Epoch 32/60, Training Loss: 0.6108, Validation Loss: 0.5436\n",
      "[Trial 131] Epoch 28/60, Training Loss: 0.6854, Validation Loss: 0.6768\n",
      "[Trial 123] Epoch 59/60, Training Loss: 0.5560, Validation Loss: 0.4824\n",
      "[Trial 133] Epoch 16/60, Training Loss: 0.9304, Validation Loss: 0.8048\n",
      "[Trial 124] Epoch 52/60, Training Loss: 0.5892, Validation Loss: 0.5228\n",
      "[Trial 139] Epoch 4/60, Training Loss: 1.1940, Validation Loss: 0.9873\n",
      "[Trial 128] Epoch 34/60, Training Loss: 0.6395, Validation Loss: 0.5312\n",
      "[Trial 138] Epoch 6/60, Training Loss: 1.2110, Validation Loss: 0.9883\n",
      "[Trial 135] Epoch 10/60, Training Loss: 0.8943, Validation Loss: 1.0090\n",
      "[Trial 134] Epoch 12/60, Training Loss: 0.8799, Validation Loss: 0.7500\n",
      "[Trial 126] Epoch 50/60, Training Loss: 0.6257, Validation Loss: 0.5204\n",
      "[Trial 136] Epoch 10/60, Training Loss: 0.9232, Validation Loss: 0.7244\n",
      "[Trial 137] Epoch 9/60, Training Loss: 0.9570, Validation Loss: 0.9997\n",
      "[Trial 129] Epoch 34/60, Training Loss: 0.6470, Validation Loss: 0.7162\n",
      "[Trial 125] Epoch 53/60, Training Loss: 0.5685, Validation Loss: 0.4852\n",
      "[Trial 132] Epoch 20/60, Training Loss: 0.7673, Validation Loss: 0.6137\n",
      "[Trial 130] Epoch 33/60, Training Loss: 0.6064, Validation Loss: 0.5286\n",
      "[Trial 131] Epoch 29/60, Training Loss: 0.6927, Validation Loss: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:13:23,788] Trial 123 finished with value: 0.47943413704633714 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.00905107284099197, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 123] Epoch 60/60, Training Loss: 0.5527, Validation Loss: 0.4808\n",
      "[Trial 133] Epoch 17/60, Training Loss: 0.8686, Validation Loss: 0.7910\n",
      "[Trial 139] Epoch 5/60, Training Loss: 1.0985, Validation Loss: 0.8579\n",
      "[Trial 124] Epoch 53/60, Training Loss: 0.5889, Validation Loss: 0.5392\n",
      "[Trial 138] Epoch 7/60, Training Loss: 1.1221, Validation Loss: 1.1807\n",
      "[Trial 128] Epoch 35/60, Training Loss: 0.6321, Validation Loss: 0.6684\n",
      "[Trial 135] Epoch 11/60, Training Loss: 0.8980, Validation Loss: 0.8822\n",
      "[Trial 134] Epoch 13/60, Training Loss: 0.8283, Validation Loss: 0.8873\n",
      "[Trial 126] Epoch 51/60, Training Loss: 0.6053, Validation Loss: 0.5200\n",
      "[Trial 136] Epoch 11/60, Training Loss: 0.9167, Validation Loss: 1.0219\n",
      "[Trial 137] Epoch 10/60, Training Loss: 0.9186, Validation Loss: 0.9176\n",
      "[Trial 129] Epoch 35/60, Training Loss: 0.6577, Validation Loss: 0.5382\n",
      "[Trial 125] Epoch 54/60, Training Loss: 0.5599, Validation Loss: 0.4832\n",
      "[Trial 132] Epoch 21/60, Training Loss: 0.7353, Validation Loss: 0.8932\n",
      "[Trial 130] Epoch 34/60, Training Loss: 0.6030, Validation Loss: 0.5420\n",
      "[Trial 131] Epoch 30/60, Training Loss: 0.7007, Validation Loss: 0.7492\n",
      "[Trial 140] Epoch 1/60, Training Loss: 4.6371, Validation Loss: 2.8283\n",
      "[Trial 139] Epoch 6/60, Training Loss: 0.9970, Validation Loss: 0.8089\n",
      "[Trial 133] Epoch 18/60, Training Loss: 0.8406, Validation Loss: 0.6758\n",
      "[Trial 138] Epoch 8/60, Training Loss: 1.0733, Validation Loss: 0.9693\n",
      "[Trial 124] Epoch 54/60, Training Loss: 0.5948, Validation Loss: 0.5394\n",
      "[Trial 135] Epoch 12/60, Training Loss: 0.8306, Validation Loss: 0.6657\n",
      "[Trial 134] Epoch 14/60, Training Loss: 0.8104, Validation Loss: 0.9602\n",
      "[Trial 128] Epoch 36/60, Training Loss: 0.6627, Validation Loss: 0.5518\n",
      "[Trial 126] Epoch 52/60, Training Loss: 0.6073, Validation Loss: 0.5479\n",
      "[Trial 136] Epoch 12/60, Training Loss: 0.8760, Validation Loss: 0.8346\n",
      "[Trial 137] Epoch 11/60, Training Loss: 0.8868, Validation Loss: 0.8987\n",
      "[Trial 125] Epoch 55/60, Training Loss: 0.5660, Validation Loss: 0.4929\n",
      "[Trial 129] Epoch 36/60, Training Loss: 0.6321, Validation Loss: 0.5447\n",
      "[Trial 132] Epoch 22/60, Training Loss: 0.7849, Validation Loss: 1.3612\n",
      "[Trial 130] Epoch 35/60, Training Loss: 0.6102, Validation Loss: 0.5348\n",
      "[Trial 139] Epoch 7/60, Training Loss: 0.9645, Validation Loss: 0.9275\n",
      "[Trial 131] Epoch 31/60, Training Loss: 0.6890, Validation Loss: 0.6176\n",
      "[Trial 140] Epoch 2/60, Training Loss: 2.0084, Validation Loss: 1.4075\n",
      "[Trial 133] Epoch 19/60, Training Loss: 0.8039, Validation Loss: 0.7300\n",
      "[Trial 138] Epoch 9/60, Training Loss: 1.0433, Validation Loss: 0.9065\n",
      "[Trial 135] Epoch 13/60, Training Loss: 0.8105, Validation Loss: 2.3543\n",
      "[Trial 124] Epoch 55/60, Training Loss: 0.5924, Validation Loss: 0.5155\n",
      "[Trial 134] Epoch 15/60, Training Loss: 0.8178, Validation Loss: 0.7905\n",
      "[Trial 128] Epoch 37/60, Training Loss: 0.6219, Validation Loss: 0.6025\n",
      "[Trial 126] Epoch 53/60, Training Loss: 0.5906, Validation Loss: 0.5077\n",
      "[Trial 136] Epoch 13/60, Training Loss: 0.8625, Validation Loss: 0.7711\n",
      "[Trial 137] Epoch 12/60, Training Loss: 0.8669, Validation Loss: 0.8117\n",
      "[Trial 125] Epoch 56/60, Training Loss: 0.5655, Validation Loss: 0.4807\n",
      "[Trial 129] Epoch 37/60, Training Loss: 0.6435, Validation Loss: 0.5288\n",
      "[Trial 132] Epoch 23/60, Training Loss: 0.7772, Validation Loss: 0.6619\n",
      "[Trial 139] Epoch 8/60, Training Loss: 0.9381, Validation Loss: 0.7508\n",
      "[Trial 130] Epoch 36/60, Training Loss: 0.6086, Validation Loss: 0.6413\n",
      "[Trial 140] Epoch 3/60, Training Loss: 1.6054, Validation Loss: 1.3835\n",
      "[Trial 131] Epoch 32/60, Training Loss: 0.6946, Validation Loss: 0.6365\n",
      "[Trial 133] Epoch 20/60, Training Loss: 0.8120, Validation Loss: 0.8694\n",
      "[Trial 138] Epoch 10/60, Training Loss: 0.9545, Validation Loss: 0.9526\n",
      "[Trial 135] Epoch 14/60, Training Loss: 0.8485, Validation Loss: 0.6702\n",
      "[Trial 134] Epoch 16/60, Training Loss: 0.8154, Validation Loss: 0.7616\n",
      "[Trial 124] Epoch 56/60, Training Loss: 0.5851, Validation Loss: 0.5104\n",
      "[Trial 128] Epoch 38/60, Training Loss: 0.6498, Validation Loss: 0.6313\n",
      "[Trial 126] Epoch 54/60, Training Loss: 0.5826, Validation Loss: 0.5140\n",
      "[Trial 136] Epoch 14/60, Training Loss: 0.8270, Validation Loss: 1.0006\n",
      "[Trial 137] Epoch 13/60, Training Loss: 0.8359, Validation Loss: 0.9036\n",
      "[Trial 125] Epoch 57/60, Training Loss: 0.5681, Validation Loss: 0.4947\n",
      "[Trial 139] Epoch 9/60, Training Loss: 0.8775, Validation Loss: 0.8120\n",
      "[Trial 129] Epoch 38/60, Training Loss: 0.6466, Validation Loss: 0.6651\n",
      "[Trial 132] Epoch 24/60, Training Loss: 0.7407, Validation Loss: 0.6852\n",
      "[Trial 140] Epoch 4/60, Training Loss: 1.4377, Validation Loss: 1.1530\n",
      "[Trial 130] Epoch 37/60, Training Loss: 0.6088, Validation Loss: 0.5046\n",
      "[Trial 131] Epoch 33/60, Training Loss: 0.6741, Validation Loss: 0.6016\n",
      "[Trial 133] Epoch 21/60, Training Loss: 0.8345, Validation Loss: 0.7996\n",
      "[Trial 138] Epoch 11/60, Training Loss: 0.8978, Validation Loss: 0.8945\n",
      "[Trial 135] Epoch 15/60, Training Loss: 0.7867, Validation Loss: 0.7811\n",
      "[Trial 134] Epoch 17/60, Training Loss: 0.7670, Validation Loss: 0.6277\n",
      "[Trial 124] Epoch 57/60, Training Loss: 0.5823, Validation Loss: 0.5128\n",
      "[Trial 126] Epoch 55/60, Training Loss: 0.5860, Validation Loss: 0.5151\n",
      "[Trial 128] Epoch 39/60, Training Loss: 0.6355, Validation Loss: 0.5839\n",
      "[Trial 136] Epoch 15/60, Training Loss: 0.8258, Validation Loss: 0.6696\n",
      "[Trial 137] Epoch 14/60, Training Loss: 0.7517, Validation Loss: 0.7376\n",
      "[Trial 139] Epoch 10/60, Training Loss: 0.8577, Validation Loss: 0.8406\n",
      "[Trial 125] Epoch 58/60, Training Loss: 0.5590, Validation Loss: 0.4848\n",
      "[Trial 129] Epoch 39/60, Training Loss: 0.6932, Validation Loss: 0.5045\n",
      "[Trial 132] Epoch 25/60, Training Loss: 0.7216, Validation Loss: 0.6074\n",
      "[Trial 140] Epoch 5/60, Training Loss: 1.2665, Validation Loss: 0.9962\n",
      "[Trial 131] Epoch 34/60, Training Loss: 0.6771, Validation Loss: 0.6216\n",
      "[Trial 130] Epoch 38/60, Training Loss: 0.5947, Validation Loss: 0.5029\n",
      "[Trial 138] Epoch 12/60, Training Loss: 0.9196, Validation Loss: 0.7024\n",
      "[Trial 133] Epoch 22/60, Training Loss: 0.8037, Validation Loss: 0.7986\n",
      "[Trial 135] Epoch 16/60, Training Loss: 0.7731, Validation Loss: 0.9313\n",
      "[Trial 134] Epoch 18/60, Training Loss: 0.7377, Validation Loss: 0.7870\n",
      "[Trial 126] Epoch 56/60, Training Loss: 0.5913, Validation Loss: 0.5310\n",
      "[Trial 124] Epoch 58/60, Training Loss: 0.5823, Validation Loss: 0.5168\n",
      "[Trial 128] Epoch 40/60, Training Loss: 0.6415, Validation Loss: 0.6480\n",
      "[Trial 136] Epoch 16/60, Training Loss: 0.7796, Validation Loss: 0.6651\n",
      "[Trial 137] Epoch 15/60, Training Loss: 0.7441, Validation Loss: 0.6192\n",
      "[Trial 139] Epoch 11/60, Training Loss: 0.8741, Validation Loss: 0.7522\n",
      "[Trial 125] Epoch 59/60, Training Loss: 0.5569, Validation Loss: 0.4846\n",
      "[Trial 129] Epoch 40/60, Training Loss: 0.6210, Validation Loss: 0.5004\n",
      "[Trial 132] Epoch 26/60, Training Loss: 0.6982, Validation Loss: 0.6566\n",
      "[Trial 140] Epoch 6/60, Training Loss: 1.2024, Validation Loss: 0.9605\n",
      "[Trial 131] Epoch 35/60, Training Loss: 0.6738, Validation Loss: 0.6484\n",
      "[Trial 130] Epoch 39/60, Training Loss: 0.5876, Validation Loss: 0.5726\n",
      "[Trial 138] Epoch 13/60, Training Loss: 0.8937, Validation Loss: 1.1412\n",
      "[Trial 135] Epoch 17/60, Training Loss: 0.7756, Validation Loss: 0.6692\n",
      "[Trial 133] Epoch 23/60, Training Loss: 0.7964, Validation Loss: 0.6046\n",
      "[Trial 134] Epoch 19/60, Training Loss: 0.7758, Validation Loss: 0.7340\n",
      "[Trial 126] Epoch 57/60, Training Loss: 0.5840, Validation Loss: 0.5272\n",
      "[Trial 124] Epoch 59/60, Training Loss: 0.5816, Validation Loss: 0.4957\n",
      "[Trial 128] Epoch 41/60, Training Loss: 0.5960, Validation Loss: 0.5272\n",
      "[Trial 136] Epoch 17/60, Training Loss: 0.7734, Validation Loss: 0.6358\n",
      "[Trial 137] Epoch 16/60, Training Loss: 0.7203, Validation Loss: 0.7365\n",
      "[Trial 139] Epoch 12/60, Training Loss: 0.8343, Validation Loss: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:22:56,901] Trial 125 finished with value: 0.4806960254907608 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.0028712434146943256, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 125] Epoch 60/60, Training Loss: 0.5620, Validation Loss: 0.4901\n",
      "[Trial 129] Epoch 41/60, Training Loss: 0.6165, Validation Loss: 0.5163\n",
      "[Trial 132] Epoch 27/60, Training Loss: 0.7173, Validation Loss: 0.5859\n",
      "[Trial 140] Epoch 7/60, Training Loss: 1.0948, Validation Loss: 0.9975\n",
      "[Trial 138] Epoch 14/60, Training Loss: 0.8679, Validation Loss: 0.7379\n",
      "[Trial 131] Epoch 36/60, Training Loss: 0.6705, Validation Loss: 0.6025\n",
      "[Trial 130] Epoch 40/60, Training Loss: 0.5942, Validation Loss: 0.5214\n",
      "[Trial 135] Epoch 18/60, Training Loss: 0.7508, Validation Loss: 0.6401\n",
      "[Trial 134] Epoch 20/60, Training Loss: 0.7356, Validation Loss: 0.6268\n",
      "[Trial 133] Epoch 24/60, Training Loss: 0.7752, Validation Loss: 0.5972\n",
      "[Trial 126] Epoch 58/60, Training Loss: 0.5863, Validation Loss: 0.5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:23:52,319] Trial 124 finished with value: 0.4956743329763412 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0028022736669280957, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 124] Epoch 60/60, Training Loss: 0.5811, Validation Loss: 0.5071\n",
      "[Trial 128] Epoch 42/60, Training Loss: 0.5835, Validation Loss: 0.5578\n",
      "[Trial 136] Epoch 18/60, Training Loss: 0.7688, Validation Loss: 0.8246\n",
      "[Trial 137] Epoch 17/60, Training Loss: 0.7251, Validation Loss: 0.6191\n",
      "[Trial 139] Epoch 13/60, Training Loss: 0.8628, Validation Loss: 0.6853\n",
      "[Trial 141] Epoch 1/60, Training Loss: 4.5343, Validation Loss: 1.7556\n",
      "[Trial 129] Epoch 42/60, Training Loss: 0.6173, Validation Loss: 0.5149\n",
      "[Trial 132] Epoch 28/60, Training Loss: 0.6916, Validation Loss: 0.5804\n",
      "[Trial 140] Epoch 8/60, Training Loss: 1.0731, Validation Loss: 0.9622\n",
      "[Trial 138] Epoch 15/60, Training Loss: 0.8372, Validation Loss: 0.7187\n",
      "[Trial 131] Epoch 37/60, Training Loss: 0.6678, Validation Loss: 0.6877\n",
      "[Trial 135] Epoch 19/60, Training Loss: 0.7520, Validation Loss: 0.6692\n",
      "[Trial 130] Epoch 41/60, Training Loss: 0.6028, Validation Loss: 0.6717\n",
      "[Trial 134] Epoch 21/60, Training Loss: 0.7228, Validation Loss: 0.6310\n",
      "[Trial 133] Epoch 25/60, Training Loss: 0.7569, Validation Loss: 0.7727\n",
      "[Trial 126] Epoch 59/60, Training Loss: 0.5831, Validation Loss: 0.5130\n",
      "[Trial 142] Epoch 1/60, Training Loss: 4.3484, Validation Loss: 1.6196\n",
      "[Trial 136] Epoch 19/60, Training Loss: 0.7690, Validation Loss: 0.7017\n",
      "[Trial 139] Epoch 14/60, Training Loss: 0.7828, Validation Loss: 0.6858\n",
      "[Trial 137] Epoch 18/60, Training Loss: 0.7016, Validation Loss: 0.5608\n",
      "[Trial 128] Epoch 43/60, Training Loss: 0.5880, Validation Loss: 0.5207\n",
      "[Trial 141] Epoch 2/60, Training Loss: 1.9923, Validation Loss: 1.5669\n",
      "[Trial 129] Epoch 43/60, Training Loss: 0.6199, Validation Loss: 0.5602\n",
      "[Trial 132] Epoch 29/60, Training Loss: 0.6795, Validation Loss: 0.5953\n",
      "[Trial 140] Epoch 9/60, Training Loss: 0.9933, Validation Loss: 0.9330\n",
      "[Trial 138] Epoch 16/60, Training Loss: 0.8323, Validation Loss: 0.7659\n",
      "[Trial 135] Epoch 20/60, Training Loss: 0.7267, Validation Loss: 0.7532\n",
      "[Trial 131] Epoch 38/60, Training Loss: 0.6731, Validation Loss: 0.6511\n",
      "[Trial 134] Epoch 22/60, Training Loss: 0.7208, Validation Loss: 0.5962\n",
      "[Trial 130] Epoch 42/60, Training Loss: 0.6189, Validation Loss: 0.5829\n",
      "[Trial 133] Epoch 26/60, Training Loss: 0.7923, Validation Loss: 0.6295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:26:37,818] Trial 126 finished with value: 0.4920207068324089 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.009672453237337038, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 126] Epoch 60/60, Training Loss: 0.5661, Validation Loss: 0.4920\n",
      "[Trial 139] Epoch 15/60, Training Loss: 0.7762, Validation Loss: 0.7135\n",
      "[Trial 136] Epoch 20/60, Training Loss: 0.7423, Validation Loss: 0.6236\n",
      "[Trial 142] Epoch 2/60, Training Loss: 1.9440, Validation Loss: 1.2888\n",
      "[Trial 137] Epoch 19/60, Training Loss: 0.6893, Validation Loss: 0.6233\n",
      "[Trial 128] Epoch 44/60, Training Loss: 0.5902, Validation Loss: 0.5294\n",
      "[Trial 141] Epoch 3/60, Training Loss: 1.5919, Validation Loss: 1.2850\n",
      "[Trial 129] Epoch 44/60, Training Loss: 0.6210, Validation Loss: 0.5219\n",
      "[Trial 138] Epoch 17/60, Training Loss: 0.8170, Validation Loss: 0.6510\n",
      "[Trial 132] Epoch 30/60, Training Loss: 0.6858, Validation Loss: 0.5570\n",
      "[Trial 140] Epoch 10/60, Training Loss: 0.9440, Validation Loss: 0.6960\n",
      "[Trial 135] Epoch 21/60, Training Loss: 0.7338, Validation Loss: 0.7089\n",
      "[Trial 134] Epoch 23/60, Training Loss: 0.7176, Validation Loss: 0.6163\n",
      "[Trial 131] Epoch 39/60, Training Loss: 0.6675, Validation Loss: 0.5920\n",
      "[Trial 130] Epoch 43/60, Training Loss: 0.6194, Validation Loss: 0.5028\n",
      "[Trial 133] Epoch 27/60, Training Loss: 0.7409, Validation Loss: 0.6174\n",
      "[Trial 139] Epoch 16/60, Training Loss: 0.7594, Validation Loss: 0.6465\n",
      "[Trial 143] Epoch 1/60, Training Loss: 4.2240, Validation Loss: 1.9657\n",
      "[Trial 136] Epoch 21/60, Training Loss: 0.7534, Validation Loss: 0.6249\n",
      "[Trial 137] Epoch 20/60, Training Loss: 0.7078, Validation Loss: 0.6966\n",
      "[Trial 142] Epoch 3/60, Training Loss: 1.5871, Validation Loss: 1.1401\n",
      "[Trial 128] Epoch 45/60, Training Loss: 0.5856, Validation Loss: 0.5032\n",
      "[Trial 141] Epoch 4/60, Training Loss: 1.3794, Validation Loss: 1.2479\n",
      "[Trial 129] Epoch 45/60, Training Loss: 0.6202, Validation Loss: 0.5220\n",
      "[Trial 138] Epoch 18/60, Training Loss: 0.7880, Validation Loss: 0.7303\n",
      "[Trial 140] Epoch 11/60, Training Loss: 0.9218, Validation Loss: 1.0092\n",
      "[Trial 132] Epoch 31/60, Training Loss: 0.7041, Validation Loss: 0.7931\n",
      "[Trial 135] Epoch 22/60, Training Loss: 0.7348, Validation Loss: 0.6323\n",
      "[Trial 134] Epoch 24/60, Training Loss: 0.6933, Validation Loss: 0.6105\n",
      "[Trial 131] Epoch 40/60, Training Loss: 0.6536, Validation Loss: 0.6349\n",
      "[Trial 139] Epoch 17/60, Training Loss: 0.7440, Validation Loss: 0.7874\n",
      "[Trial 130] Epoch 44/60, Training Loss: 0.5998, Validation Loss: 0.5899\n",
      "[Trial 133] Epoch 28/60, Training Loss: 0.7395, Validation Loss: 0.6017\n",
      "[Trial 143] Epoch 2/60, Training Loss: 1.9123, Validation Loss: 2.0638\n",
      "[Trial 136] Epoch 22/60, Training Loss: 0.7231, Validation Loss: 0.7127\n",
      "[Trial 137] Epoch 21/60, Training Loss: 0.6939, Validation Loss: 0.5883\n",
      "[Trial 142] Epoch 4/60, Training Loss: 1.3812, Validation Loss: 1.0822\n",
      "[Trial 128] Epoch 46/60, Training Loss: 0.5849, Validation Loss: 0.5976\n",
      "[Trial 141] Epoch 5/60, Training Loss: 1.3110, Validation Loss: 1.3701\n",
      "[Trial 138] Epoch 19/60, Training Loss: 0.8069, Validation Loss: 0.6310\n",
      "[Trial 129] Epoch 46/60, Training Loss: 0.6070, Validation Loss: 0.4822\n",
      "[Trial 140] Epoch 12/60, Training Loss: 0.9259, Validation Loss: 0.7565\n",
      "[Trial 135] Epoch 23/60, Training Loss: 0.6967, Validation Loss: 0.6027\n",
      "[Trial 132] Epoch 32/60, Training Loss: 0.7128, Validation Loss: 0.6671\n",
      "[Trial 134] Epoch 25/60, Training Loss: 0.6852, Validation Loss: 0.6460\n",
      "[Trial 139] Epoch 18/60, Training Loss: 0.7405, Validation Loss: 0.6237\n",
      "[Trial 131] Epoch 41/60, Training Loss: 0.6612, Validation Loss: 0.7002\n",
      "[Trial 130] Epoch 45/60, Training Loss: 0.6068, Validation Loss: 0.5799\n",
      "[Trial 136] Epoch 23/60, Training Loss: 0.7221, Validation Loss: 0.6174\n",
      "[Trial 133] Epoch 29/60, Training Loss: 0.7260, Validation Loss: 0.6066\n",
      "[Trial 143] Epoch 3/60, Training Loss: 1.6174, Validation Loss: 1.1758\n",
      "[Trial 137] Epoch 22/60, Training Loss: 0.6786, Validation Loss: 0.5870\n",
      "[Trial 142] Epoch 5/60, Training Loss: 1.2391, Validation Loss: 1.1552\n",
      "[Trial 128] Epoch 47/60, Training Loss: 0.5856, Validation Loss: 0.5424\n",
      "[Trial 141] Epoch 6/60, Training Loss: 1.2408, Validation Loss: 1.1566\n",
      "[Trial 138] Epoch 20/60, Training Loss: 0.7459, Validation Loss: 0.6748\n",
      "[Trial 129] Epoch 47/60, Training Loss: 0.6150, Validation Loss: 0.4914\n",
      "[Trial 135] Epoch 24/60, Training Loss: 0.7280, Validation Loss: 0.7678\n",
      "[Trial 140] Epoch 13/60, Training Loss: 0.8721, Validation Loss: 0.7883\n",
      "[Trial 132] Epoch 33/60, Training Loss: 0.7152, Validation Loss: 0.5917\n",
      "[Trial 134] Epoch 26/60, Training Loss: 0.6809, Validation Loss: 0.7297\n",
      "[Trial 139] Epoch 19/60, Training Loss: 0.7204, Validation Loss: 0.6491\n",
      "[Trial 131] Epoch 42/60, Training Loss: 0.6701, Validation Loss: 0.5765\n",
      "[Trial 136] Epoch 24/60, Training Loss: 0.7192, Validation Loss: 0.7316\n",
      "[Trial 137] Epoch 23/60, Training Loss: 0.6790, Validation Loss: 0.8014\n",
      "[Trial 130] Epoch 46/60, Training Loss: 0.5902, Validation Loss: 0.5288\n",
      "[Trial 143] Epoch 4/60, Training Loss: 1.3650, Validation Loss: 1.1993\n",
      "[Trial 133] Epoch 30/60, Training Loss: 0.7249, Validation Loss: 0.6581\n",
      "[Trial 142] Epoch 6/60, Training Loss: 1.1608, Validation Loss: 2.0574\n",
      "[Trial 128] Epoch 48/60, Training Loss: 0.5786, Validation Loss: 0.4857\n",
      "[Trial 141] Epoch 7/60, Training Loss: 1.0893, Validation Loss: 0.9602\n",
      "[Trial 138] Epoch 21/60, Training Loss: 0.7723, Validation Loss: 0.6499\n",
      "[Trial 135] Epoch 25/60, Training Loss: 0.7015, Validation Loss: 0.9548\n",
      "[Trial 129] Epoch 48/60, Training Loss: 0.6049, Validation Loss: 0.4926\n",
      "[Trial 140] Epoch 14/60, Training Loss: 0.8673, Validation Loss: 0.8352\n",
      "[Trial 139] Epoch 20/60, Training Loss: 0.6986, Validation Loss: 0.7447\n",
      "[Trial 134] Epoch 27/60, Training Loss: 0.7071, Validation Loss: 0.7924\n",
      "[Trial 132] Epoch 34/60, Training Loss: 0.6722, Validation Loss: 0.6905\n",
      "[Trial 131] Epoch 43/60, Training Loss: 0.6370, Validation Loss: 0.5891\n",
      "[Trial 136] Epoch 25/60, Training Loss: 0.7061, Validation Loss: 0.6740\n",
      "[Trial 137] Epoch 24/60, Training Loss: 0.7048, Validation Loss: 0.6269\n",
      "[Trial 143] Epoch 5/60, Training Loss: 1.2519, Validation Loss: 1.5443\n",
      "[Trial 133] Epoch 31/60, Training Loss: 0.6698, Validation Loss: 0.5371\n",
      "[Trial 130] Epoch 47/60, Training Loss: 0.5915, Validation Loss: 0.5227\n",
      "[Trial 142] Epoch 7/60, Training Loss: 1.1475, Validation Loss: 1.0377\n",
      "[Trial 128] Epoch 49/60, Training Loss: 0.5828, Validation Loss: 0.5120\n",
      "[Trial 141] Epoch 8/60, Training Loss: 1.0700, Validation Loss: 0.7900\n",
      "[Trial 138] Epoch 22/60, Training Loss: 0.7436, Validation Loss: 0.7563\n",
      "[Trial 135] Epoch 26/60, Training Loss: 0.7164, Validation Loss: 0.6084\n",
      "[Trial 139] Epoch 21/60, Training Loss: 0.7127, Validation Loss: 0.6845\n",
      "[Trial 129] Epoch 49/60, Training Loss: 0.6126, Validation Loss: 0.6379\n",
      "[Trial 140] Epoch 15/60, Training Loss: 0.8612, Validation Loss: 0.7177\n",
      "[Trial 134] Epoch 28/60, Training Loss: 0.7004, Validation Loss: 0.6702\n",
      "[Trial 132] Epoch 35/60, Training Loss: 0.6730, Validation Loss: 0.5886\n",
      "[Trial 131] Epoch 44/60, Training Loss: 0.6473, Validation Loss: 0.6142\n",
      "[Trial 136] Epoch 26/60, Training Loss: 0.7192, Validation Loss: 0.7183\n",
      "[Trial 137] Epoch 25/60, Training Loss: 0.6336, Validation Loss: 0.5660\n",
      "[Trial 143] Epoch 6/60, Training Loss: 1.1620, Validation Loss: 0.9930\n",
      "[Trial 133] Epoch 32/60, Training Loss: 0.6667, Validation Loss: 0.5830\n",
      "[Trial 130] Epoch 48/60, Training Loss: 0.5967, Validation Loss: 0.5680\n",
      "[Trial 142] Epoch 8/60, Training Loss: 1.0465, Validation Loss: 1.5948\n",
      "[Trial 128] Epoch 50/60, Training Loss: 0.5795, Validation Loss: 0.5203\n",
      "[Trial 141] Epoch 9/60, Training Loss: 1.0219, Validation Loss: 0.9179\n",
      "[Trial 138] Epoch 23/60, Training Loss: 0.7640, Validation Loss: 0.9625\n",
      "[Trial 139] Epoch 22/60, Training Loss: 0.6963, Validation Loss: 0.6352\n",
      "[Trial 135] Epoch 27/60, Training Loss: 0.6801, Validation Loss: 1.0703\n",
      "[Trial 140] Epoch 16/60, Training Loss: 0.8099, Validation Loss: 0.6832\n",
      "[Trial 134] Epoch 29/60, Training Loss: 0.6269, Validation Loss: 0.5440[Trial 129] Epoch 50/60, Training Loss: 0.6085, Validation Loss: 0.5768\n",
      "\n",
      "[Trial 132] Epoch 36/60, Training Loss: 0.6644, Validation Loss: 0.5641\n",
      "[Trial 136] Epoch 27/60, Training Loss: 0.7254, Validation Loss: 0.5845\n",
      "[Trial 131] Epoch 45/60, Training Loss: 0.6378, Validation Loss: 0.6586\n",
      "[Trial 137] Epoch 26/60, Training Loss: 0.6203, Validation Loss: 0.5827\n",
      "[Trial 143] Epoch 7/60, Training Loss: 1.1199, Validation Loss: 0.9644\n",
      "[Trial 133] Epoch 33/60, Training Loss: 0.6688, Validation Loss: 0.5436\n",
      "[Trial 142] Epoch 9/60, Training Loss: 1.1107, Validation Loss: 0.8745\n",
      "[Trial 130] Epoch 49/60, Training Loss: 0.5948, Validation Loss: 0.5608\n",
      "[Trial 128] Epoch 51/60, Training Loss: 0.5855, Validation Loss: 0.5228\n",
      "[Trial 138] Epoch 24/60, Training Loss: 0.8208, Validation Loss: 0.6943\n",
      "[Trial 141] Epoch 10/60, Training Loss: 0.9888, Validation Loss: 1.0907\n",
      "[Trial 139] Epoch 23/60, Training Loss: 0.6914, Validation Loss: 0.5840\n",
      "[Trial 135] Epoch 28/60, Training Loss: 0.7214, Validation Loss: 0.6459\n",
      "[Trial 134] Epoch 30/60, Training Loss: 0.6166, Validation Loss: 0.6162\n",
      "[Trial 140] Epoch 17/60, Training Loss: 0.8180, Validation Loss: 1.3013\n",
      "[Trial 129] Epoch 51/60, Training Loss: 0.6065, Validation Loss: 0.5370\n",
      "[Trial 132] Epoch 37/60, Training Loss: 0.6069, Validation Loss: 0.5299\n",
      "[Trial 136] Epoch 28/60, Training Loss: 0.6879, Validation Loss: 0.6354\n",
      "[Trial 137] Epoch 27/60, Training Loss: 0.6400, Validation Loss: 0.6020\n",
      "[Trial 131] Epoch 46/60, Training Loss: 0.6522, Validation Loss: 0.9027\n",
      "[Trial 143] Epoch 8/60, Training Loss: 1.0317, Validation Loss: 1.0285\n",
      "[Trial 133] Epoch 34/60, Training Loss: 0.6449, Validation Loss: 0.5353\n",
      "[Trial 142] Epoch 10/60, Training Loss: 0.9396, Validation Loss: 0.8152\n",
      "[Trial 130] Epoch 50/60, Training Loss: 0.5640, Validation Loss: 0.4802\n",
      "[Trial 128] Epoch 52/60, Training Loss: 0.5852, Validation Loss: 0.5121\n",
      "[Trial 139] Epoch 24/60, Training Loss: 0.7020, Validation Loss: 0.6148\n",
      "[Trial 138] Epoch 25/60, Training Loss: 0.7921, Validation Loss: 0.6481\n",
      "[Trial 141] Epoch 11/60, Training Loss: 0.9975, Validation Loss: 0.9326\n",
      "[Trial 135] Epoch 29/60, Training Loss: 0.6673, Validation Loss: 0.7673\n",
      "[Trial 134] Epoch 31/60, Training Loss: 0.6164, Validation Loss: 0.6179\n",
      "[Trial 140] Epoch 18/60, Training Loss: 0.8907, Validation Loss: 1.1357\n",
      "[Trial 129] Epoch 52/60, Training Loss: 0.6158, Validation Loss: 0.4850\n",
      "[Trial 132] Epoch 38/60, Training Loss: 0.6096, Validation Loss: 0.6205\n",
      "[Trial 136] Epoch 29/60, Training Loss: 0.7081, Validation Loss: 0.6937\n",
      "[Trial 137] Epoch 28/60, Training Loss: 0.6347, Validation Loss: 0.5241\n",
      "[Trial 131] Epoch 47/60, Training Loss: 0.6709, Validation Loss: 0.5983\n",
      "[Trial 143] Epoch 9/60, Training Loss: 1.0006, Validation Loss: 0.7862\n",
      "[Trial 133] Epoch 35/60, Training Loss: 0.6502, Validation Loss: 0.5742\n",
      "[Trial 142] Epoch 11/60, Training Loss: 0.9210, Validation Loss: 0.8181\n",
      "[Trial 130] Epoch 51/60, Training Loss: 0.5658, Validation Loss: 0.5152\n",
      "[Trial 139] Epoch 25/60, Training Loss: 0.7062, Validation Loss: 0.5864\n",
      "[Trial 128] Epoch 53/60, Training Loss: 0.5807, Validation Loss: 0.5754\n",
      "[Trial 138] Epoch 26/60, Training Loss: 0.6648, Validation Loss: 0.5593\n",
      "[Trial 141] Epoch 12/60, Training Loss: 0.9292, Validation Loss: 0.7791\n",
      "[Trial 135] Epoch 30/60, Training Loss: 0.6324, Validation Loss: 0.6209\n",
      "[Trial 134] Epoch 32/60, Training Loss: 0.6122, Validation Loss: 0.5451\n",
      "[Trial 140] Epoch 19/60, Training Loss: 0.8474, Validation Loss: 0.6663\n",
      "[Trial 129] Epoch 53/60, Training Loss: 0.5691, Validation Loss: 0.4700\n",
      "[Trial 136] Epoch 30/60, Training Loss: 0.6975, Validation Loss: 0.5854\n",
      "[Trial 132] Epoch 39/60, Training Loss: 0.6038, Validation Loss: 0.5221\n",
      "[Trial 137] Epoch 29/60, Training Loss: 0.6137, Validation Loss: 0.5309\n",
      "[Trial 131] Epoch 48/60, Training Loss: 0.6335, Validation Loss: 0.5922\n",
      "[Trial 143] Epoch 10/60, Training Loss: 0.9341, Validation Loss: 0.9585\n",
      "[Trial 142] Epoch 12/60, Training Loss: 0.8857, Validation Loss: 0.8731\n",
      "[Trial 133] Epoch 36/60, Training Loss: 0.6807, Validation Loss: 0.6680\n",
      "[Trial 130] Epoch 52/60, Training Loss: 0.5592, Validation Loss: 0.4859\n",
      "[Trial 139] Epoch 26/60, Training Loss: 0.6954, Validation Loss: 0.6087\n",
      "[Trial 138] Epoch 27/60, Training Loss: 0.6624, Validation Loss: 0.5796\n",
      "[Trial 128] Epoch 54/60, Training Loss: 0.5791, Validation Loss: 0.5052\n",
      "[Trial 141] Epoch 13/60, Training Loss: 0.8969, Validation Loss: 1.7732\n",
      "[Trial 135] Epoch 31/60, Training Loss: 0.6334, Validation Loss: 0.5476\n",
      "[Trial 134] Epoch 33/60, Training Loss: 0.6113, Validation Loss: 0.6730\n",
      "[Trial 140] Epoch 20/60, Training Loss: 0.7670, Validation Loss: 0.7716\n",
      "[Trial 129] Epoch 54/60, Training Loss: 0.5779, Validation Loss: 0.4876\n",
      "[Trial 136] Epoch 31/60, Training Loss: 0.6544, Validation Loss: 0.5359\n",
      "[Trial 137] Epoch 30/60, Training Loss: 0.6230, Validation Loss: 1.0063\n",
      "[Trial 132] Epoch 40/60, Training Loss: 0.5931, Validation Loss: 0.5496\n",
      "[Trial 131] Epoch 49/60, Training Loss: 0.6023, Validation Loss: 0.6477\n",
      "[Trial 143] Epoch 11/60, Training Loss: 0.9436, Validation Loss: 1.0416\n",
      "[Trial 142] Epoch 13/60, Training Loss: 0.8739, Validation Loss: 0.8620\n",
      "[Trial 139] Epoch 27/60, Training Loss: 0.6880, Validation Loss: 0.5704\n",
      "[Trial 133] Epoch 37/60, Training Loss: 0.7031, Validation Loss: 0.5371\n",
      "[Trial 130] Epoch 53/60, Training Loss: 0.5541, Validation Loss: 0.4945\n",
      "[Trial 138] Epoch 28/60, Training Loss: 0.6466, Validation Loss: 0.5228\n",
      "[Trial 128] Epoch 55/60, Training Loss: 0.5583, Validation Loss: 0.4761\n",
      "[Trial 135] Epoch 32/60, Training Loss: 0.6092, Validation Loss: 0.5261\n",
      "[Trial 141] Epoch 14/60, Training Loss: 0.9716, Validation Loss: 0.8134\n",
      "[Trial 134] Epoch 34/60, Training Loss: 0.6137, Validation Loss: 0.6364\n",
      "[Trial 140] Epoch 21/60, Training Loss: 0.8073, Validation Loss: 0.6384\n",
      "[Trial 136] Epoch 32/60, Training Loss: 0.6605, Validation Loss: 0.6034\n",
      "[Trial 129] Epoch 55/60, Training Loss: 0.5671, Validation Loss: 0.4645\n",
      "[Trial 137] Epoch 31/60, Training Loss: 0.6218, Validation Loss: 0.5628\n",
      "[Trial 132] Epoch 41/60, Training Loss: 0.5988, Validation Loss: 0.5360\n",
      "[Trial 131] Epoch 50/60, Training Loss: 0.5997, Validation Loss: 0.5559\n",
      "[Trial 143] Epoch 12/60, Training Loss: 0.9049, Validation Loss: 0.7714\n",
      "[Trial 139] Epoch 28/60, Training Loss: 0.6584, Validation Loss: 0.5644\n",
      "[Trial 142] Epoch 14/60, Training Loss: 0.8700, Validation Loss: 0.8963\n",
      "[Trial 133] Epoch 38/60, Training Loss: 0.6426, Validation Loss: 0.5466\n",
      "[Trial 130] Epoch 54/60, Training Loss: 0.5524, Validation Loss: 0.5021\n",
      "[Trial 138] Epoch 29/60, Training Loss: 0.6466, Validation Loss: 0.6331\n",
      "[Trial 135] Epoch 33/60, Training Loss: 0.5984, Validation Loss: 0.5405\n",
      "[Trial 128] Epoch 56/60, Training Loss: 0.5502, Validation Loss: 0.4724\n",
      "[Trial 141] Epoch 15/60, Training Loss: 0.8586, Validation Loss: 1.0441\n",
      "[Trial 134] Epoch 35/60, Training Loss: 0.6186, Validation Loss: 0.5014\n",
      "[Trial 140] Epoch 22/60, Training Loss: 0.7490, Validation Loss: 0.7316\n",
      "[Trial 136] Epoch 33/60, Training Loss: 0.6739, Validation Loss: 0.6892\n",
      "[Trial 129] Epoch 56/60, Training Loss: 0.5675, Validation Loss: 0.4693\n",
      "[Trial 137] Epoch 32/60, Training Loss: 0.6038, Validation Loss: 0.5643\n",
      "[Trial 132] Epoch 42/60, Training Loss: 0.5958, Validation Loss: 0.5041\n",
      "[Trial 139] Epoch 29/60, Training Loss: 0.6668, Validation Loss: 0.9011\n",
      "[Trial 143] Epoch 13/60, Training Loss: 0.8801, Validation Loss: 0.7275\n",
      "[Trial 131] Epoch 51/60, Training Loss: 0.5937, Validation Loss: 0.5709\n",
      "[Trial 142] Epoch 15/60, Training Loss: 0.8340, Validation Loss: 0.6991\n",
      "[Trial 133] Epoch 39/60, Training Loss: 0.6456, Validation Loss: 0.5510\n",
      "[Trial 138] Epoch 30/60, Training Loss: 0.6706, Validation Loss: 0.5434\n",
      "[Trial 130] Epoch 55/60, Training Loss: 0.5470, Validation Loss: 0.4808\n",
      "[Trial 135] Epoch 34/60, Training Loss: 0.6025, Validation Loss: 0.5171\n",
      "[Trial 128] Epoch 57/60, Training Loss: 0.5553, Validation Loss: 0.4804\n",
      "[Trial 141] Epoch 16/60, Training Loss: 0.8669, Validation Loss: 0.7915\n",
      "[Trial 134] Epoch 36/60, Training Loss: 0.6082, Validation Loss: 0.5654\n",
      "[Trial 140] Epoch 23/60, Training Loss: 0.7713, Validation Loss: 0.7670\n",
      "[Trial 136] Epoch 34/60, Training Loss: 0.6962, Validation Loss: 0.6354\n",
      "[Trial 137] Epoch 33/60, Training Loss: 0.6068, Validation Loss: 0.5834\n",
      "[Trial 129] Epoch 57/60, Training Loss: 0.5639, Validation Loss: 0.4788\n",
      "[Trial 132] Epoch 43/60, Training Loss: 0.5896, Validation Loss: 0.5542\n",
      "[Trial 139] Epoch 30/60, Training Loss: 0.6796, Validation Loss: 0.5745\n",
      "[Trial 143] Epoch 14/60, Training Loss: 0.8752, Validation Loss: 1.0920\n",
      "[Trial 131] Epoch 52/60, Training Loss: 0.5986, Validation Loss: 0.5477\n",
      "[Trial 142] Epoch 16/60, Training Loss: 0.8059, Validation Loss: 0.7606\n",
      "[Trial 133] Epoch 40/60, Training Loss: 0.6494, Validation Loss: 0.6562\n",
      "[Trial 138] Epoch 31/60, Training Loss: 0.6483, Validation Loss: 0.5722\n",
      "[Trial 130] Epoch 56/60, Training Loss: 0.5469, Validation Loss: 0.5003\n",
      "[Trial 135] Epoch 35/60, Training Loss: 0.6033, Validation Loss: 0.4986\n",
      "[Trial 141] Epoch 17/60, Training Loss: 0.8451, Validation Loss: 0.6723\n",
      "[Trial 128] Epoch 58/60, Training Loss: 0.5553, Validation Loss: 0.4951\n",
      "[Trial 134] Epoch 37/60, Training Loss: 0.6148, Validation Loss: 0.7042\n",
      "[Trial 140] Epoch 24/60, Training Loss: 0.7636, Validation Loss: 0.8327\n",
      "[Trial 136] Epoch 35/60, Training Loss: 0.6569, Validation Loss: 0.5992\n",
      "[Trial 137] Epoch 34/60, Training Loss: 0.6077, Validation Loss: 0.6102\n",
      "[Trial 129] Epoch 58/60, Training Loss: 0.5544, Validation Loss: 0.4713\n",
      "[Trial 139] Epoch 31/60, Training Loss: 0.6663, Validation Loss: 0.5626\n",
      "[Trial 132] Epoch 44/60, Training Loss: 0.6100, Validation Loss: 0.7389\n",
      "[Trial 143] Epoch 15/60, Training Loss: 0.8929, Validation Loss: 1.1946\n",
      "[Trial 131] Epoch 53/60, Training Loss: 0.5914, Validation Loss: 0.6319\n",
      "[Trial 142] Epoch 17/60, Training Loss: 0.8285, Validation Loss: 1.2277\n",
      "[Trial 138] Epoch 32/60, Training Loss: 0.6340, Validation Loss: 0.6141\n",
      "[Trial 133] Epoch 41/60, Training Loss: 0.6138, Validation Loss: 0.5025\n",
      "[Trial 135] Epoch 36/60, Training Loss: 0.5959, Validation Loss: 0.5594\n",
      "[Trial 130] Epoch 57/60, Training Loss: 0.5329, Validation Loss: 0.4751\n",
      "[Trial 141] Epoch 18/60, Training Loss: 0.8055, Validation Loss: 0.9129\n",
      "[Trial 134] Epoch 38/60, Training Loss: 0.6178, Validation Loss: 0.5521\n",
      "[Trial 128] Epoch 59/60, Training Loss: 0.5509, Validation Loss: 0.4863\n",
      "[Trial 136] Epoch 36/60, Training Loss: 0.6429, Validation Loss: 0.5736\n",
      "[Trial 140] Epoch 25/60, Training Loss: 0.7619, Validation Loss: 0.6581\n",
      "[Trial 137] Epoch 35/60, Training Loss: 0.5935, Validation Loss: 0.5515\n",
      "[Trial 129] Epoch 59/60, Training Loss: 0.5682, Validation Loss: 0.4766\n",
      "[Trial 139] Epoch 32/60, Training Loss: 0.6553, Validation Loss: 0.6329\n",
      "[Trial 132] Epoch 45/60, Training Loss: 0.6159, Validation Loss: 0.5304\n",
      "[Trial 143] Epoch 16/60, Training Loss: 0.8326, Validation Loss: 0.6507\n",
      "[Trial 131] Epoch 54/60, Training Loss: 0.5957, Validation Loss: 0.5409\n",
      "[Trial 142] Epoch 18/60, Training Loss: 0.9361, Validation Loss: 0.8074\n",
      "[Trial 138] Epoch 33/60, Training Loss: 0.6392, Validation Loss: 0.5339\n",
      "[Trial 133] Epoch 42/60, Training Loss: 0.6101, Validation Loss: 0.5355\n",
      "[Trial 135] Epoch 37/60, Training Loss: 0.6095, Validation Loss: 0.5358\n",
      "[Trial 130] Epoch 58/60, Training Loss: 0.5487, Validation Loss: 0.4917\n",
      "[Trial 141] Epoch 19/60, Training Loss: 0.8045, Validation Loss: 0.7078\n",
      "[Trial 134] Epoch 39/60, Training Loss: 0.5947, Validation Loss: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:50:36,963] Trial 128 finished with value: 0.47238645354906716 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.004673336927867544, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 128] Epoch 60/60, Training Loss: 0.5533, Validation Loss: 0.4832\n",
      "[Trial 136] Epoch 37/60, Training Loss: 0.6617, Validation Loss: 0.6049\n",
      "[Trial 137] Epoch 36/60, Training Loss: 0.5861, Validation Loss: 0.5132\n",
      "[Trial 140] Epoch 26/60, Training Loss: 0.7549, Validation Loss: 0.5922\n",
      "[Trial 139] Epoch 33/60, Training Loss: 0.6492, Validation Loss: 0.6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:51:00,797] Trial 129 finished with value: 0.46449769188960394 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0026957145419724757, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 129] Epoch 60/60, Training Loss: 0.5675, Validation Loss: 0.4784\n",
      "[Trial 132] Epoch 46/60, Training Loss: 0.5954, Validation Loss: 0.5335\n",
      "[Trial 143] Epoch 17/60, Training Loss: 0.7940, Validation Loss: 0.7137\n",
      "[Trial 131] Epoch 55/60, Training Loss: 0.5794, Validation Loss: 0.6157\n",
      "[Trial 138] Epoch 34/60, Training Loss: 0.6275, Validation Loss: 0.5525\n",
      "[Trial 142] Epoch 19/60, Training Loss: 0.7929, Validation Loss: 0.7416\n",
      "[Trial 133] Epoch 43/60, Training Loss: 0.6122, Validation Loss: 0.5331\n",
      "[Trial 135] Epoch 38/60, Training Loss: 0.6002, Validation Loss: 0.5382\n",
      "[Trial 134] Epoch 40/60, Training Loss: 0.6191, Validation Loss: 0.6951\n",
      "[Trial 130] Epoch 59/60, Training Loss: 0.5398, Validation Loss: 0.4803\n",
      "[Trial 141] Epoch 20/60, Training Loss: 0.8041, Validation Loss: 0.6877\n",
      "[Trial 144] Epoch 1/60, Training Loss: 4.2209, Validation Loss: 1.7433\n",
      "[Trial 136] Epoch 38/60, Training Loss: 0.5942, Validation Loss: 0.5260\n",
      "[Trial 137] Epoch 37/60, Training Loss: 0.5793, Validation Loss: 0.5428\n",
      "[Trial 139] Epoch 34/60, Training Loss: 0.6518, Validation Loss: 0.5422\n",
      "[Trial 140] Epoch 27/60, Training Loss: 0.7188, Validation Loss: 0.5863\n",
      "[Trial 145] Epoch 1/60, Training Loss: 4.8597, Validation Loss: 2.4053\n",
      "[Trial 132] Epoch 47/60, Training Loss: 0.5834, Validation Loss: 0.5341\n",
      "[Trial 143] Epoch 18/60, Training Loss: 0.7858, Validation Loss: 0.7173\n",
      "[Trial 131] Epoch 56/60, Training Loss: 0.5798, Validation Loss: 0.5348\n",
      "[Trial 138] Epoch 35/60, Training Loss: 0.6000, Validation Loss: 0.5082\n",
      "[Trial 142] Epoch 20/60, Training Loss: 0.7551, Validation Loss: 0.7326\n",
      "[Trial 135] Epoch 39/60, Training Loss: 0.6031, Validation Loss: 0.5098\n",
      "[Trial 133] Epoch 44/60, Training Loss: 0.6127, Validation Loss: 0.5631\n",
      "[Trial 134] Epoch 41/60, Training Loss: 0.6229, Validation Loss: 0.4993\n",
      "[Trial 141] Epoch 21/60, Training Loss: 0.7624, Validation Loss: 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:53:32,070] Trial 130 finished with value: 0.47505115369955697 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010172052223450499, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 130] Epoch 60/60, Training Loss: 0.5454, Validation Loss: 0.4920\n",
      "[Trial 144] Epoch 2/60, Training Loss: 1.9197, Validation Loss: 2.4061\n",
      "[Trial 136] Epoch 39/60, Training Loss: 0.5953, Validation Loss: 0.5682\n",
      "[Trial 139] Epoch 35/60, Training Loss: 0.6420, Validation Loss: 0.6022\n",
      "[Trial 137] Epoch 38/60, Training Loss: 0.5806, Validation Loss: 0.5238\n",
      "[Trial 140] Epoch 28/60, Training Loss: 0.7087, Validation Loss: 0.6151\n",
      "[Trial 145] Epoch 2/60, Training Loss: 2.1253, Validation Loss: 1.7958\n",
      "[Trial 132] Epoch 48/60, Training Loss: 0.5903, Validation Loss: 0.5205\n",
      "[Trial 143] Epoch 19/60, Training Loss: 0.7784, Validation Loss: 0.7915\n",
      "[Trial 138] Epoch 36/60, Training Loss: 0.5887, Validation Loss: 0.5219\n",
      "[Trial 131] Epoch 57/60, Training Loss: 0.5768, Validation Loss: 0.5371\n",
      "[Trial 142] Epoch 21/60, Training Loss: 0.7459, Validation Loss: 0.9096\n",
      "[Trial 135] Epoch 40/60, Training Loss: 0.6070, Validation Loss: 0.6465\n",
      "[Trial 133] Epoch 45/60, Training Loss: 0.6069, Validation Loss: 0.5356\n",
      "[Trial 134] Epoch 42/60, Training Loss: 0.5836, Validation Loss: 0.5475\n",
      "[Trial 139] Epoch 36/60, Training Loss: 0.6501, Validation Loss: 0.5549\n",
      "[Trial 141] Epoch 22/60, Training Loss: 0.7732, Validation Loss: 0.7082\n",
      "[Trial 136] Epoch 40/60, Training Loss: 0.6001, Validation Loss: 0.5189\n",
      "[Trial 137] Epoch 39/60, Training Loss: 0.5726, Validation Loss: 0.5501\n",
      "[Trial 144] Epoch 3/60, Training Loss: 1.6049, Validation Loss: 1.3060\n",
      "[Trial 146] Epoch 1/60, Training Loss: 4.5604, Validation Loss: 2.1638\n",
      "[Trial 140] Epoch 29/60, Training Loss: 0.7259, Validation Loss: 0.6989\n",
      "[Trial 145] Epoch 3/60, Training Loss: 1.7208, Validation Loss: 1.5649\n",
      "[Trial 132] Epoch 49/60, Training Loss: 0.5560, Validation Loss: 0.5070\n",
      "[Trial 143] Epoch 20/60, Training Loss: 0.7752, Validation Loss: 0.8528\n",
      "[Trial 138] Epoch 37/60, Training Loss: 0.5901, Validation Loss: 0.5005\n",
      "[Trial 131] Epoch 58/60, Training Loss: 0.5802, Validation Loss: 0.6545\n",
      "[Trial 142] Epoch 22/60, Training Loss: 0.6947, Validation Loss: 0.6027\n",
      "[Trial 135] Epoch 41/60, Training Loss: 0.6195, Validation Loss: 0.5910\n",
      "[Trial 133] Epoch 46/60, Training Loss: 0.6095, Validation Loss: 0.5427\n",
      "[Trial 134] Epoch 43/60, Training Loss: 0.5905, Validation Loss: 0.5283\n",
      "[Trial 139] Epoch 37/60, Training Loss: 0.6419, Validation Loss: 0.5795\n",
      "[Trial 136] Epoch 41/60, Training Loss: 0.5892, Validation Loss: 0.5208\n",
      "[Trial 141] Epoch 23/60, Training Loss: 0.7754, Validation Loss: 0.8872\n",
      "[Trial 137] Epoch 40/60, Training Loss: 0.5728, Validation Loss: 0.5789\n",
      "[Trial 144] Epoch 4/60, Training Loss: 1.4048, Validation Loss: 1.1121\n",
      "[Trial 146] Epoch 2/60, Training Loss: 2.1554, Validation Loss: 1.8570\n",
      "[Trial 140] Epoch 30/60, Training Loss: 0.7175, Validation Loss: 0.6540\n",
      "[Trial 145] Epoch 4/60, Training Loss: 1.5296, Validation Loss: 1.4234\n",
      "[Trial 132] Epoch 50/60, Training Loss: 0.5504, Validation Loss: 0.4989\n",
      "[Trial 143] Epoch 21/60, Training Loss: 0.7982, Validation Loss: 0.6469\n",
      "[Trial 138] Epoch 38/60, Training Loss: 0.5929, Validation Loss: 0.6031\n",
      "[Trial 131] Epoch 59/60, Training Loss: 0.6005, Validation Loss: 0.5753\n",
      "[Trial 142] Epoch 23/60, Training Loss: 0.6753, Validation Loss: 0.6329\n",
      "[Trial 135] Epoch 42/60, Training Loss: 0.5795, Validation Loss: 0.5052\n",
      "[Trial 139] Epoch 38/60, Training Loss: 0.6314, Validation Loss: 0.7368\n",
      "[Trial 133] Epoch 47/60, Training Loss: 0.6004, Validation Loss: 0.5004\n",
      "[Trial 134] Epoch 44/60, Training Loss: 0.5883, Validation Loss: 0.5086\n",
      "[Trial 136] Epoch 42/60, Training Loss: 0.5859, Validation Loss: 0.6070\n",
      "[Trial 137] Epoch 41/60, Training Loss: 0.5769, Validation Loss: 0.5130\n",
      "[Trial 141] Epoch 24/60, Training Loss: 0.7260, Validation Loss: 0.6076\n",
      "[Trial 144] Epoch 5/60, Training Loss: 1.2243, Validation Loss: 0.9224\n",
      "[Trial 140] Epoch 31/60, Training Loss: 0.7366, Validation Loss: 0.6089\n",
      "[Trial 146] Epoch 3/60, Training Loss: 1.8377, Validation Loss: 1.7513\n",
      "[Trial 145] Epoch 5/60, Training Loss: 1.3533, Validation Loss: 1.4054\n",
      "[Trial 138] Epoch 39/60, Training Loss: 0.6115, Validation Loss: 0.9868\n",
      "[Trial 143] Epoch 22/60, Training Loss: 0.7518, Validation Loss: 0.7558\n",
      "[Trial 132] Epoch 51/60, Training Loss: 0.5515, Validation Loss: 0.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 09:59:01,389] Trial 131 finished with value: 0.5348333060741425 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0027607230798789165, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 131] Epoch 60/60, Training Loss: 0.5858, Validation Loss: 0.5696\n",
      "[Trial 135] Epoch 43/60, Training Loss: 0.5644, Validation Loss: 0.4770\n",
      "[Trial 142] Epoch 24/60, Training Loss: 0.6860, Validation Loss: 0.5751\n",
      "[Trial 139] Epoch 39/60, Training Loss: 0.6755, Validation Loss: 0.6829\n",
      "[Trial 134] Epoch 45/60, Training Loss: 0.5792, Validation Loss: 0.4995\n",
      "[Trial 133] Epoch 48/60, Training Loss: 0.6009, Validation Loss: 0.4942\n",
      "[Trial 136] Epoch 43/60, Training Loss: 0.6041, Validation Loss: 0.5696\n",
      "[Trial 137] Epoch 42/60, Training Loss: 0.5717, Validation Loss: 0.5289\n",
      "[Trial 141] Epoch 25/60, Training Loss: 0.6906, Validation Loss: 0.5939\n",
      "[Trial 144] Epoch 6/60, Training Loss: 1.1621, Validation Loss: 1.2596\n",
      "[Trial 140] Epoch 32/60, Training Loss: 0.7225, Validation Loss: 0.8504\n",
      "[Trial 146] Epoch 4/60, Training Loss: 1.5714, Validation Loss: 1.3439\n",
      "[Trial 145] Epoch 6/60, Training Loss: 1.2092, Validation Loss: 0.9714\n",
      "[Trial 138] Epoch 40/60, Training Loss: 0.6247, Validation Loss: 0.5172\n",
      "[Trial 143] Epoch 23/60, Training Loss: 0.7804, Validation Loss: 0.7920\n",
      "[Trial 132] Epoch 52/60, Training Loss: 0.5514, Validation Loss: 0.5082\n",
      "[Trial 139] Epoch 40/60, Training Loss: 0.6365, Validation Loss: 0.6168\n",
      "[Trial 135] Epoch 44/60, Training Loss: 0.5570, Validation Loss: 0.4864\n",
      "[Trial 147] Epoch 1/60, Training Loss: 4.0842, Validation Loss: 2.0175\n",
      "[Trial 142] Epoch 25/60, Training Loss: 0.6803, Validation Loss: 0.5715\n",
      "[Trial 134] Epoch 46/60, Training Loss: 0.5870, Validation Loss: 0.6037\n",
      "[Trial 136] Epoch 44/60, Training Loss: 0.6003, Validation Loss: 0.5036\n",
      "[Trial 133] Epoch 49/60, Training Loss: 0.5935, Validation Loss: 0.4969\n",
      "[Trial 137] Epoch 43/60, Training Loss: 0.5867, Validation Loss: 0.5475\n",
      "[Trial 141] Epoch 26/60, Training Loss: 0.6817, Validation Loss: 0.6187\n",
      "[Trial 144] Epoch 7/60, Training Loss: 1.1008, Validation Loss: 1.0645\n",
      "[Trial 140] Epoch 33/60, Training Loss: 0.7216, Validation Loss: 0.5547\n",
      "[Trial 146] Epoch 5/60, Training Loss: 1.4595, Validation Loss: 1.0854\n",
      "[Trial 138] Epoch 41/60, Training Loss: 0.5820, Validation Loss: 0.5084\n",
      "[Trial 145] Epoch 7/60, Training Loss: 1.1547, Validation Loss: 0.9854\n",
      "[Trial 143] Epoch 24/60, Training Loss: 0.7424, Validation Loss: 0.6634\n",
      "[Trial 132] Epoch 53/60, Training Loss: 0.5498, Validation Loss: 0.4903\n",
      "[Trial 139] Epoch 41/60, Training Loss: 0.5929, Validation Loss: 0.4985\n",
      "[Trial 135] Epoch 45/60, Training Loss: 0.5603, Validation Loss: 0.5179\n",
      "[Trial 147] Epoch 2/60, Training Loss: 1.9771, Validation Loss: 1.3940\n",
      "[Trial 142] Epoch 26/60, Training Loss: 0.6815, Validation Loss: 0.6056\n",
      "[Trial 134] Epoch 47/60, Training Loss: 0.5863, Validation Loss: 0.5404\n",
      "[Trial 136] Epoch 45/60, Training Loss: 0.5853, Validation Loss: 0.5604\n",
      "[Trial 137] Epoch 44/60, Training Loss: 0.5765, Validation Loss: 0.5060\n",
      "[Trial 133] Epoch 50/60, Training Loss: 0.5908, Validation Loss: 0.4950\n",
      "[Trial 141] Epoch 27/60, Training Loss: 0.7207, Validation Loss: 0.5985\n",
      "[Trial 144] Epoch 8/60, Training Loss: 1.0716, Validation Loss: 0.8787\n",
      "[Trial 140] Epoch 34/60, Training Loss: 0.6858, Validation Loss: 0.5388\n",
      "[Trial 146] Epoch 6/60, Training Loss: 1.2612, Validation Loss: 1.5688\n",
      "[Trial 138] Epoch 42/60, Training Loss: 0.5843, Validation Loss: 0.5020\n",
      "[Trial 145] Epoch 8/60, Training Loss: 1.0470, Validation Loss: 0.9356\n",
      "[Trial 139] Epoch 42/60, Training Loss: 0.5767, Validation Loss: 0.5100\n",
      "[Trial 143] Epoch 25/60, Training Loss: 0.7333, Validation Loss: 0.7318\n",
      "[Trial 132] Epoch 54/60, Training Loss: 0.5472, Validation Loss: 0.5044\n",
      "[Trial 135] Epoch 46/60, Training Loss: 0.5701, Validation Loss: 0.5028\n",
      "[Trial 147] Epoch 3/60, Training Loss: 1.5900, Validation Loss: 1.0015\n",
      "[Trial 142] Epoch 27/60, Training Loss: 0.6614, Validation Loss: 0.5665\n",
      "[Trial 134] Epoch 48/60, Training Loss: 0.5556, Validation Loss: 0.4985\n",
      "[Trial 136] Epoch 46/60, Training Loss: 0.5918, Validation Loss: 0.5117\n",
      "[Trial 137] Epoch 45/60, Training Loss: 0.5642, Validation Loss: 0.5026\n",
      "[Trial 133] Epoch 51/60, Training Loss: 0.6061, Validation Loss: 0.5431\n",
      "[Trial 141] Epoch 28/60, Training Loss: 0.6907, Validation Loss: 0.6374\n",
      "[Trial 144] Epoch 9/60, Training Loss: 0.9925, Validation Loss: 1.0772\n",
      "[Trial 140] Epoch 35/60, Training Loss: 0.6808, Validation Loss: 0.7882\n",
      "[Trial 146] Epoch 7/60, Training Loss: 1.2131, Validation Loss: 1.4647\n",
      "[Trial 138] Epoch 43/60, Training Loss: 0.5821, Validation Loss: 0.5385\n",
      "[Trial 139] Epoch 43/60, Training Loss: 0.5740, Validation Loss: 0.5145\n",
      "[Trial 145] Epoch 9/60, Training Loss: 1.0073, Validation Loss: 1.4731\n",
      "[Trial 143] Epoch 26/60, Training Loss: 0.7646, Validation Loss: 0.6103\n",
      "[Trial 132] Epoch 55/60, Training Loss: 0.5614, Validation Loss: 0.5175\n",
      "[Trial 135] Epoch 47/60, Training Loss: 0.5542, Validation Loss: 0.4796\n",
      "[Trial 147] Epoch 4/60, Training Loss: 1.3822, Validation Loss: 1.5048\n",
      "[Trial 142] Epoch 28/60, Training Loss: 0.6628, Validation Loss: 0.6001\n",
      "[Trial 134] Epoch 49/60, Training Loss: 0.5587, Validation Loss: 0.4821\n",
      "[Trial 136] Epoch 47/60, Training Loss: 0.5895, Validation Loss: 0.5129\n",
      "[Trial 137] Epoch 46/60, Training Loss: 0.5622, Validation Loss: 0.5007\n",
      "[Trial 133] Epoch 52/60, Training Loss: 0.6099, Validation Loss: 0.5115\n",
      "[Trial 141] Epoch 29/60, Training Loss: 0.6800, Validation Loss: 0.6056\n",
      "[Trial 144] Epoch 10/60, Training Loss: 0.9917, Validation Loss: 0.7918\n",
      "[Trial 140] Epoch 36/60, Training Loss: 0.7032, Validation Loss: 0.8354\n",
      "[Trial 138] Epoch 44/60, Training Loss: 0.5640, Validation Loss: 0.4916\n",
      "[Trial 139] Epoch 44/60, Training Loss: 0.5792, Validation Loss: 0.5332\n",
      "[Trial 146] Epoch 8/60, Training Loss: 1.1427, Validation Loss: 1.2604\n",
      "[Trial 143] Epoch 27/60, Training Loss: 0.7293, Validation Loss: 0.7521\n",
      "[Trial 145] Epoch 10/60, Training Loss: 0.9882, Validation Loss: 0.9170\n",
      "[Trial 135] Epoch 48/60, Training Loss: 0.5455, Validation Loss: 0.4927\n",
      "[Trial 132] Epoch 56/60, Training Loss: 0.5547, Validation Loss: 0.4867\n",
      "[Trial 147] Epoch 5/60, Training Loss: 1.2569, Validation Loss: 1.0669\n",
      "[Trial 134] Epoch 50/60, Training Loss: 0.5480, Validation Loss: 0.4859\n",
      "[Trial 136] Epoch 48/60, Training Loss: 0.5761, Validation Loss: 0.5076\n",
      "[Trial 142] Epoch 29/60, Training Loss: 0.6685, Validation Loss: 0.5711\n",
      "[Trial 137] Epoch 47/60, Training Loss: 0.5611, Validation Loss: 0.5001\n",
      "[Trial 133] Epoch 53/60, Training Loss: 0.6035, Validation Loss: 0.5058\n",
      "[Trial 141] Epoch 30/60, Training Loss: 0.6693, Validation Loss: 0.5346\n",
      "[Trial 144] Epoch 11/60, Training Loss: 0.9403, Validation Loss: 0.8830\n",
      "[Trial 140] Epoch 37/60, Training Loss: 0.7555, Validation Loss: 0.5841\n",
      "[Trial 139] Epoch 45/60, Training Loss: 0.5789, Validation Loss: 0.5068\n",
      "[Trial 138] Epoch 45/60, Training Loss: 0.5651, Validation Loss: 0.4907\n",
      "[Trial 146] Epoch 9/60, Training Loss: 1.1519, Validation Loss: 0.9756\n",
      "[Trial 143] Epoch 28/60, Training Loss: 0.7119, Validation Loss: 0.6284\n",
      "[Trial 135] Epoch 49/60, Training Loss: 0.5530, Validation Loss: 0.5313\n",
      "[Trial 145] Epoch 11/60, Training Loss: 0.9479, Validation Loss: 1.0480\n",
      "[Trial 132] Epoch 57/60, Training Loss: 0.5467, Validation Loss: 0.4690\n",
      "[Trial 147] Epoch 6/60, Training Loss: 1.1494, Validation Loss: 1.0690\n",
      "[Trial 134] Epoch 51/60, Training Loss: 0.5464, Validation Loss: 0.4700\n",
      "[Trial 136] Epoch 49/60, Training Loss: 0.5800, Validation Loss: 0.6972\n",
      "[Trial 137] Epoch 48/60, Training Loss: 0.5640, Validation Loss: 0.5198\n",
      "[Trial 142] Epoch 30/60, Training Loss: 0.6513, Validation Loss: 0.5435\n",
      "[Trial 133] Epoch 54/60, Training Loss: 0.5931, Validation Loss: 0.5294\n",
      "[Trial 141] Epoch 31/60, Training Loss: 0.6784, Validation Loss: 0.7985\n",
      "[Trial 144] Epoch 12/60, Training Loss: 0.9468, Validation Loss: 0.7881\n",
      "[Trial 140] Epoch 38/60, Training Loss: 0.6783, Validation Loss: 0.6595\n",
      "[Trial 139] Epoch 46/60, Training Loss: 0.5728, Validation Loss: 0.5204\n",
      "[Trial 138] Epoch 46/60, Training Loss: 0.5614, Validation Loss: 0.5027\n",
      "[Trial 146] Epoch 10/60, Training Loss: 1.0082, Validation Loss: 0.9884\n",
      "[Trial 135] Epoch 50/60, Training Loss: 0.5381, Validation Loss: 0.4661\n",
      "[Trial 143] Epoch 29/60, Training Loss: 0.6998, Validation Loss: 0.6162\n",
      "[Trial 145] Epoch 12/60, Training Loss: 0.9547, Validation Loss: 1.1360\n",
      "[Trial 132] Epoch 58/60, Training Loss: 0.5415, Validation Loss: 0.4834\n",
      "[Trial 147] Epoch 7/60, Training Loss: 1.0830, Validation Loss: 0.8123\n",
      "[Trial 134] Epoch 52/60, Training Loss: 0.5417, Validation Loss: 0.4761\n",
      "[Trial 136] Epoch 50/60, Training Loss: 0.5849, Validation Loss: 0.5109\n",
      "[Trial 137] Epoch 49/60, Training Loss: 0.5700, Validation Loss: 0.5137\n",
      "[Trial 142] Epoch 31/60, Training Loss: 0.6558, Validation Loss: 0.7590\n",
      "[Trial 141] Epoch 32/60, Training Loss: 0.6966, Validation Loss: 0.6033\n",
      "[Trial 133] Epoch 55/60, Training Loss: 0.5782, Validation Loss: 0.4756\n",
      "[Trial 144] Epoch 13/60, Training Loss: 0.8761, Validation Loss: 0.9090\n",
      "[Trial 139] Epoch 47/60, Training Loss: 0.5849, Validation Loss: 0.5547\n",
      "[Trial 140] Epoch 39/60, Training Loss: 0.6936, Validation Loss: 0.5208\n",
      "[Trial 138] Epoch 47/60, Training Loss: 0.5666, Validation Loss: 0.4879\n",
      "[Trial 135] Epoch 51/60, Training Loss: 0.5400, Validation Loss: 0.4663\n",
      "[Trial 146] Epoch 11/60, Training Loss: 0.9821, Validation Loss: 0.9336\n",
      "[Trial 143] Epoch 30/60, Training Loss: 0.7029, Validation Loss: 0.7137\n",
      "[Trial 145] Epoch 13/60, Training Loss: 0.9031, Validation Loss: 0.7362\n",
      "[Trial 132] Epoch 59/60, Training Loss: 0.5385, Validation Loss: 0.4940\n",
      "[Trial 147] Epoch 8/60, Training Loss: 1.0522, Validation Loss: 0.8396\n",
      "[Trial 136] Epoch 51/60, Training Loss: 0.5554, Validation Loss: 0.5094\n",
      "[Trial 134] Epoch 53/60, Training Loss: 0.5427, Validation Loss: 0.4691\n",
      "[Trial 137] Epoch 50/60, Training Loss: 0.5551, Validation Loss: 0.4975\n",
      "[Trial 142] Epoch 32/60, Training Loss: 0.6977, Validation Loss: 0.5743\n",
      "[Trial 139] Epoch 48/60, Training Loss: 0.5535, Validation Loss: 0.4841\n",
      "[Trial 141] Epoch 33/60, Training Loss: 0.6546, Validation Loss: 0.5532\n",
      "[Trial 133] Epoch 56/60, Training Loss: 0.5726, Validation Loss: 0.4854\n",
      "[Trial 144] Epoch 14/60, Training Loss: 0.9052, Validation Loss: 0.8453\n",
      "[Trial 140] Epoch 40/60, Training Loss: 0.6603, Validation Loss: 0.5680\n",
      "[Trial 138] Epoch 48/60, Training Loss: 0.5565, Validation Loss: 0.4785\n",
      "[Trial 135] Epoch 52/60, Training Loss: 0.5373, Validation Loss: 0.4762\n",
      "[Trial 143] Epoch 31/60, Training Loss: 0.7032, Validation Loss: 0.6226\n",
      "[Trial 146] Epoch 12/60, Training Loss: 0.9693, Validation Loss: 0.7466\n",
      "[Trial 145] Epoch 14/60, Training Loss: 0.8741, Validation Loss: 0.9183\n",
      "[Trial 136] Epoch 52/60, Training Loss: 0.5563, Validation Loss: 0.4889\n",
      "[Trial 134] Epoch 54/60, Training Loss: 0.5373, Validation Loss: 0.4727\n",
      "[Trial 147] Epoch 9/60, Training Loss: 0.9948, Validation Loss: 0.8258\n",
      "[Trial 137] Epoch 51/60, Training Loss: 0.5472, Validation Loss: 0.4970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:12:28,839] Trial 132 finished with value: 0.4689605941375097 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.0029984796598735886, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 132] Epoch 60/60, Training Loss: 0.5424, Validation Loss: 0.4811\n",
      "[Trial 142] Epoch 33/60, Training Loss: 0.6530, Validation Loss: 0.6521\n",
      "[Trial 139] Epoch 49/60, Training Loss: 0.5486, Validation Loss: 0.4890\n",
      "[Trial 141] Epoch 34/60, Training Loss: 0.6548, Validation Loss: 0.5902\n",
      "[Trial 133] Epoch 57/60, Training Loss: 0.5727, Validation Loss: 0.4992\n",
      "[Trial 144] Epoch 15/60, Training Loss: 0.8886, Validation Loss: 0.9435\n",
      "[Trial 140] Epoch 41/60, Training Loss: 0.6809, Validation Loss: 0.6551\n",
      "[Trial 138] Epoch 49/60, Training Loss: 0.5502, Validation Loss: 0.4820\n",
      "[Trial 135] Epoch 53/60, Training Loss: 0.5368, Validation Loss: 0.4673\n",
      "[Trial 143] Epoch 32/60, Training Loss: 0.7205, Validation Loss: 0.6516\n",
      "[Trial 146] Epoch 13/60, Training Loss: 0.8895, Validation Loss: 0.9294\n",
      "[Trial 136] Epoch 53/60, Training Loss: 0.5543, Validation Loss: 0.4785\n",
      "[Trial 134] Epoch 55/60, Training Loss: 0.5495, Validation Loss: 0.4965\n",
      "[Trial 137] Epoch 52/60, Training Loss: 0.5620, Validation Loss: 0.5119\n",
      "[Trial 145] Epoch 15/60, Training Loss: 0.8439, Validation Loss: 0.6939\n",
      "[Trial 147] Epoch 10/60, Training Loss: 0.9558, Validation Loss: 0.7732\n",
      "[Trial 148] Epoch 1/60, Training Loss: 3.9794, Validation Loss: 1.9265\n",
      "[Trial 142] Epoch 34/60, Training Loss: 0.6449, Validation Loss: 0.5584\n",
      "[Trial 139] Epoch 50/60, Training Loss: 0.5651, Validation Loss: 0.5027\n",
      "[Trial 141] Epoch 35/60, Training Loss: 0.6538, Validation Loss: 0.5387\n",
      "[Trial 144] Epoch 16/60, Training Loss: 0.8590, Validation Loss: 0.6703\n",
      "[Trial 133] Epoch 58/60, Training Loss: 0.5660, Validation Loss: 0.4834\n",
      "[Trial 140] Epoch 42/60, Training Loss: 0.6674, Validation Loss: 0.5647\n",
      "[Trial 138] Epoch 50/60, Training Loss: 0.5483, Validation Loss: 0.4875\n",
      "[Trial 135] Epoch 54/60, Training Loss: 0.5299, Validation Loss: 0.4606\n",
      "[Trial 143] Epoch 33/60, Training Loss: 0.6453, Validation Loss: 0.5543\n",
      "[Trial 136] Epoch 54/60, Training Loss: 0.5442, Validation Loss: 0.4837\n",
      "[Trial 134] Epoch 56/60, Training Loss: 0.5454, Validation Loss: 0.4789\n",
      "[Trial 137] Epoch 53/60, Training Loss: 0.5524, Validation Loss: 0.5213\n",
      "[Trial 146] Epoch 14/60, Training Loss: 0.8950, Validation Loss: 0.9678\n",
      "[Trial 147] Epoch 11/60, Training Loss: 0.9226, Validation Loss: 0.7106\n",
      "[Trial 148] Epoch 2/60, Training Loss: 1.9279, Validation Loss: 3.0202\n",
      "[Trial 145] Epoch 16/60, Training Loss: 0.8145, Validation Loss: 0.6593\n",
      "[Trial 139] Epoch 51/60, Training Loss: 0.5595, Validation Loss: 0.4852\n",
      "[Trial 142] Epoch 35/60, Training Loss: 0.6485, Validation Loss: 0.5279\n",
      "[Trial 141] Epoch 36/60, Training Loss: 0.6447, Validation Loss: 0.5427\n",
      "[Trial 138] Epoch 51/60, Training Loss: 0.5659, Validation Loss: 0.5172\n",
      "[Trial 144] Epoch 17/60, Training Loss: 0.8038, Validation Loss: 0.7412\n",
      "[Trial 133] Epoch 59/60, Training Loss: 0.5634, Validation Loss: 0.4754\n",
      "[Trial 140] Epoch 43/60, Training Loss: 0.6626, Validation Loss: 0.7002\n",
      "[Trial 135] Epoch 55/60, Training Loss: 0.5300, Validation Loss: 0.4620\n",
      "[Trial 143] Epoch 34/60, Training Loss: 0.6289, Validation Loss: 0.6594\n",
      "[Trial 136] Epoch 55/60, Training Loss: 0.5512, Validation Loss: 0.4780\n",
      "[Trial 137] Epoch 54/60, Training Loss: 0.5524, Validation Loss: 0.4869\n",
      "[Trial 134] Epoch 57/60, Training Loss: 0.5420, Validation Loss: 0.5878\n",
      "[Trial 147] Epoch 12/60, Training Loss: 0.9389, Validation Loss: 0.8935\n",
      "[Trial 148] Epoch 3/60, Training Loss: 1.6185, Validation Loss: 1.4832\n",
      "[Trial 146] Epoch 15/60, Training Loss: 0.8762, Validation Loss: 0.9128\n",
      "[Trial 145] Epoch 17/60, Training Loss: 0.8074, Validation Loss: 0.7807\n",
      "[Trial 139] Epoch 52/60, Training Loss: 0.5491, Validation Loss: 0.4748\n",
      "[Trial 142] Epoch 36/60, Training Loss: 0.6248, Validation Loss: 0.5448\n",
      "[Trial 141] Epoch 37/60, Training Loss: 0.6193, Validation Loss: 0.5649\n",
      "[Trial 138] Epoch 52/60, Training Loss: 0.5614, Validation Loss: 0.4864\n",
      "[Trial 144] Epoch 18/60, Training Loss: 0.8290, Validation Loss: 1.6122\n",
      "[Trial 140] Epoch 44/60, Training Loss: 0.6651, Validation Loss: 0.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:17:40,982] Trial 133 finished with value: 0.4754411056637764 and parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.0026198542646832922, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 133] Epoch 60/60, Training Loss: 0.5663, Validation Loss: 0.4984\n",
      "[Trial 135] Epoch 56/60, Training Loss: 0.5387, Validation Loss: 0.4636\n",
      "[Trial 136] Epoch 56/60, Training Loss: 0.5449, Validation Loss: 0.4852\n",
      "[Trial 143] Epoch 35/60, Training Loss: 0.6367, Validation Loss: 0.5595\n",
      "[Trial 137] Epoch 55/60, Training Loss: 0.5511, Validation Loss: 0.6427\n",
      "[Trial 134] Epoch 58/60, Training Loss: 0.5453, Validation Loss: 0.4912\n",
      "[Trial 139] Epoch 53/60, Training Loss: 0.5475, Validation Loss: 0.4764\n",
      "[Trial 148] Epoch 4/60, Training Loss: 1.3912, Validation Loss: 1.3438\n",
      "[Trial 147] Epoch 13/60, Training Loss: 0.9042, Validation Loss: 0.6706\n",
      "[Trial 145] Epoch 18/60, Training Loss: 0.8229, Validation Loss: 0.6726\n",
      "[Trial 146] Epoch 16/60, Training Loss: 0.8711, Validation Loss: 0.9266\n",
      "[Trial 142] Epoch 37/60, Training Loss: 0.6309, Validation Loss: 0.5984\n",
      "[Trial 138] Epoch 53/60, Training Loss: 0.5540, Validation Loss: 0.4740\n",
      "[Trial 141] Epoch 38/60, Training Loss: 0.6209, Validation Loss: 0.6340\n",
      "[Trial 144] Epoch 19/60, Training Loss: 0.8156, Validation Loss: 0.6586\n",
      "[Trial 140] Epoch 45/60, Training Loss: 0.6613, Validation Loss: 0.6845\n",
      "[Trial 149] Epoch 1/60, Training Loss: 4.0959, Validation Loss: 2.1953\n",
      "[Trial 135] Epoch 57/60, Training Loss: 0.5324, Validation Loss: 0.4877\n",
      "[Trial 136] Epoch 57/60, Training Loss: 0.5578, Validation Loss: 0.4958\n",
      "[Trial 137] Epoch 56/60, Training Loss: 0.5590, Validation Loss: 0.4890\n",
      "[Trial 143] Epoch 36/60, Training Loss: 0.6223, Validation Loss: 0.5359\n",
      "[Trial 134] Epoch 59/60, Training Loss: 0.5433, Validation Loss: 0.4782\n",
      "[Trial 139] Epoch 54/60, Training Loss: 0.5440, Validation Loss: 0.4759\n",
      "[Trial 148] Epoch 5/60, Training Loss: 1.2450, Validation Loss: 1.2162\n",
      "[Trial 147] Epoch 14/60, Training Loss: 0.8399, Validation Loss: 0.7160\n",
      "[Trial 145] Epoch 19/60, Training Loss: 0.7807, Validation Loss: 0.9949\n",
      "[Trial 146] Epoch 17/60, Training Loss: 0.8447, Validation Loss: 0.7237\n",
      "[Trial 142] Epoch 38/60, Training Loss: 0.6492, Validation Loss: 0.5283\n",
      "[Trial 138] Epoch 54/60, Training Loss: 0.5493, Validation Loss: 0.4861\n",
      "[Trial 141] Epoch 39/60, Training Loss: 0.6215, Validation Loss: 0.5488\n",
      "[Trial 144] Epoch 20/60, Training Loss: 0.7912, Validation Loss: 0.9544\n",
      "[Trial 149] Epoch 2/60, Training Loss: 1.9979, Validation Loss: 1.6050\n",
      "[Trial 140] Epoch 46/60, Training Loss: 0.6189, Validation Loss: 0.5409\n",
      "[Trial 135] Epoch 58/60, Training Loss: 0.5338, Validation Loss: 0.4654\n",
      "[Trial 136] Epoch 58/60, Training Loss: 0.5503, Validation Loss: 0.4802\n",
      "[Trial 139] Epoch 55/60, Training Loss: 0.5440, Validation Loss: 0.4787\n",
      "[Trial 137] Epoch 57/60, Training Loss: 0.5465, Validation Loss: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:21:14,266] Trial 134 finished with value: 0.4690590883294741 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0029778139331253415, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 134] Epoch 60/60, Training Loss: 0.5271, Validation Loss: 0.4728\n",
      "[Trial 143] Epoch 37/60, Training Loss: 0.6261, Validation Loss: 0.5626\n",
      "[Trial 148] Epoch 6/60, Training Loss: 1.1557, Validation Loss: 1.1772\n",
      "[Trial 147] Epoch 15/60, Training Loss: 0.8333, Validation Loss: 0.9570\n",
      "[Trial 145] Epoch 20/60, Training Loss: 0.8086, Validation Loss: 0.6788\n",
      "[Trial 146] Epoch 18/60, Training Loss: 0.8033, Validation Loss: 0.8146\n",
      "[Trial 142] Epoch 39/60, Training Loss: 0.6198, Validation Loss: 0.5345\n",
      "[Trial 138] Epoch 55/60, Training Loss: 0.5421, Validation Loss: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:22:03,534] Trial 141 finished with value: 0.534571593006452 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0020797080295549874, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 141] Epoch 40/60, Training Loss: 0.6076, Validation Loss: 0.5712\n",
      "[Trial 141] Early stopping after 40 epochs.\n",
      "[Trial 149] Epoch 3/60, Training Loss: 1.6282, Validation Loss: 1.4672\n",
      "[Trial 144] Epoch 21/60, Training Loss: 0.7863, Validation Loss: 0.9172\n",
      "[Trial 140] Epoch 47/60, Training Loss: 0.6068, Validation Loss: 0.5154\n",
      "[Trial 135] Epoch 59/60, Training Loss: 0.5292, Validation Loss: 0.4784\n",
      "[Trial 139] Epoch 56/60, Training Loss: 0.5541, Validation Loss: 0.4934\n",
      "[Trial 136] Epoch 59/60, Training Loss: 0.5522, Validation Loss: 0.5105\n",
      "[Trial 137] Epoch 58/60, Training Loss: 0.5498, Validation Loss: 0.5918\n",
      "[Trial 150] Epoch 1/60, Training Loss: 4.1266, Validation Loss: 1.7071\n",
      "[Trial 143] Epoch 38/60, Training Loss: 0.6280, Validation Loss: 0.6342\n",
      "[Trial 148] Epoch 7/60, Training Loss: 1.0845, Validation Loss: 1.1079\n",
      "[Trial 147] Epoch 16/60, Training Loss: 0.8252, Validation Loss: 0.8748\n",
      "[Trial 145] Epoch 21/60, Training Loss: 0.7592, Validation Loss: 0.7157\n",
      "[Trial 142] Epoch 40/60, Training Loss: 0.6259, Validation Loss: 0.5278\n",
      "[Trial 146] Epoch 19/60, Training Loss: 0.8108, Validation Loss: 1.0501\n",
      "[Trial 138] Epoch 56/60, Training Loss: 0.5432, Validation Loss: 0.4904\n",
      "[Trial 151] Epoch 1/60, Training Loss: 3.2566, Validation Loss: 1.5793\n",
      "[Trial 149] Epoch 4/60, Training Loss: 1.4330, Validation Loss: 2.5539\n",
      "[Trial 144] Epoch 22/60, Training Loss: 0.7892, Validation Loss: 0.6405\n",
      "[Trial 140] Epoch 48/60, Training Loss: 0.6015, Validation Loss: 0.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:23:44,838] Trial 135 finished with value: 0.460621606806914 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.003079662873423006, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 135] Epoch 60/60, Training Loss: 0.5374, Validation Loss: 0.4932\n",
      "[Trial 139] Epoch 57/60, Training Loss: 0.5474, Validation Loss: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:23:57,314] Trial 136 finished with value: 0.47273208300272623 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.002671573792532274, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 136] Epoch 60/60, Training Loss: 0.5438, Validation Loss: 0.4727\n",
      "[Trial 137] Epoch 59/60, Training Loss: 0.5497, Validation Loss: 0.5354\n",
      "[Trial 150] Epoch 2/60, Training Loss: 1.9090, Validation Loss: 1.6980\n",
      "[Trial 143] Epoch 39/60, Training Loss: 0.6350, Validation Loss: 0.5483\n",
      "[Trial 148] Epoch 8/60, Training Loss: 1.0386, Validation Loss: 0.8682\n",
      "[Trial 147] Epoch 17/60, Training Loss: 0.8262, Validation Loss: 1.0625\n",
      "[Trial 145] Epoch 22/60, Training Loss: 0.7496, Validation Loss: 0.7138\n",
      "[Trial 142] Epoch 41/60, Training Loss: 0.6175, Validation Loss: 0.5306\n",
      "[Trial 138] Epoch 57/60, Training Loss: 0.5461, Validation Loss: 0.4857\n",
      "[Trial 146] Epoch 20/60, Training Loss: 0.8307, Validation Loss: 0.6617\n",
      "[Trial 151] Epoch 2/60, Training Loss: 1.7884, Validation Loss: 1.1584\n",
      "[Trial 149] Epoch 5/60, Training Loss: 1.3045, Validation Loss: 1.0475\n",
      "[Trial 144] Epoch 23/60, Training Loss: 0.7435, Validation Loss: 0.8832\n",
      "[Trial 140] Epoch 49/60, Training Loss: 0.6084, Validation Loss: 0.5017\n",
      "[Trial 152] Epoch 1/60, Training Loss: 6.1679, Validation Loss: 2.9380\n",
      "[Trial 139] Epoch 58/60, Training Loss: 0.5396, Validation Loss: 0.4852\n",
      "[Trial 153] Epoch 1/60, Training Loss: 3.6856, Validation Loss: 1.6103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:25:27,378] Trial 137 finished with value: 0.4869031156102816 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.0026902293913627635, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 137] Epoch 60/60, Training Loss: 0.5615, Validation Loss: 0.5004\n",
      "[Trial 150] Epoch 3/60, Training Loss: 1.6765, Validation Loss: 1.0813\n",
      "[Trial 143] Epoch 40/60, Training Loss: 0.6273, Validation Loss: 0.5715\n",
      "[Trial 148] Epoch 9/60, Training Loss: 0.9933, Validation Loss: 0.9945\n",
      "[Trial 147] Epoch 18/60, Training Loss: 0.7927, Validation Loss: 0.7158\n",
      "[Trial 145] Epoch 23/60, Training Loss: 0.6828, Validation Loss: 0.6409\n",
      "[Trial 151] Epoch 3/60, Training Loss: 1.4022, Validation Loss: 1.1052\n",
      "[Trial 142] Epoch 42/60, Training Loss: 0.5874, Validation Loss: 0.5073\n",
      "[Trial 138] Epoch 58/60, Training Loss: 0.5476, Validation Loss: 0.4754\n",
      "[Trial 146] Epoch 21/60, Training Loss: 0.7768, Validation Loss: 0.7143\n",
      "[Trial 149] Epoch 6/60, Training Loss: 1.1893, Validation Loss: 1.3239\n",
      "[Trial 144] Epoch 24/60, Training Loss: 0.7603, Validation Loss: 0.7933\n",
      "[Trial 140] Epoch 50/60, Training Loss: 0.5923, Validation Loss: 0.5048\n",
      "[Trial 139] Epoch 59/60, Training Loss: 0.5445, Validation Loss: 0.4959\n",
      "[Trial 152] Epoch 2/60, Training Loss: 2.3186, Validation Loss: 2.2792\n",
      "[Trial 153] Epoch 2/60, Training Loss: 1.8791, Validation Loss: 1.4964\n",
      "[Trial 154] Epoch 1/60, Training Loss: 6.1689, Validation Loss: 2.6365\n",
      "[Trial 150] Epoch 4/60, Training Loss: 1.3718, Validation Loss: 1.1701\n",
      "[Trial 143] Epoch 41/60, Training Loss: 0.6348, Validation Loss: 0.5722\n",
      "[Trial 148] Epoch 10/60, Training Loss: 0.9861, Validation Loss: 0.7157\n",
      "[Trial 147] Epoch 19/60, Training Loss: 0.7773, Validation Loss: 0.8513\n",
      "[Trial 151] Epoch 4/60, Training Loss: 1.2301, Validation Loss: 1.2056\n",
      "[Trial 145] Epoch 24/60, Training Loss: 0.6917, Validation Loss: 0.5687\n",
      "[Trial 138] Epoch 59/60, Training Loss: 0.5543, Validation Loss: 0.5022\n",
      "[Trial 142] Epoch 43/60, Training Loss: 0.5872, Validation Loss: 0.5191\n",
      "[Trial 146] Epoch 22/60, Training Loss: 0.7746, Validation Loss: 0.7031\n",
      "[Trial 149] Epoch 7/60, Training Loss: 1.1435, Validation Loss: 2.6122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:27:56,067] Trial 139 finished with value: 0.4705505614479383 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0029244726539139156, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 139] Epoch 60/60, Training Loss: 0.5519, Validation Loss: 0.4706\n",
      "[Trial 144] Epoch 25/60, Training Loss: 0.7574, Validation Loss: 0.7798\n",
      "[Trial 140] Epoch 51/60, Training Loss: 0.5990, Validation Loss: 0.5180\n",
      "[Trial 152] Epoch 3/60, Training Loss: 1.7624, Validation Loss: 1.5114\n",
      "[Trial 153] Epoch 3/60, Training Loss: 1.5732, Validation Loss: 1.1999\n",
      "[Trial 154] Epoch 2/60, Training Loss: 2.1387, Validation Loss: 1.6845\n",
      "[Trial 150] Epoch 5/60, Training Loss: 1.2827, Validation Loss: 1.1125\n",
      "[Trial 143] Epoch 42/60, Training Loss: 0.6587, Validation Loss: 0.7028\n",
      "[Trial 148] Epoch 11/60, Training Loss: 0.9289, Validation Loss: 1.0178\n",
      "[Trial 147] Epoch 20/60, Training Loss: 0.6936, Validation Loss: 0.6078\n",
      "[Trial 151] Epoch 5/60, Training Loss: 1.1792, Validation Loss: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:29:04,371] Trial 138 finished with value: 0.47398688793182375 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0029414516098126404, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 138] Epoch 60/60, Training Loss: 0.5367, Validation Loss: 0.4743\n",
      "[Trial 145] Epoch 25/60, Training Loss: 0.6608, Validation Loss: 0.6400\n",
      "[Trial 142] Epoch 44/60, Training Loss: 0.5852, Validation Loss: 0.5026\n",
      "[Trial 146] Epoch 23/60, Training Loss: 0.7725, Validation Loss: 0.6863\n",
      "[Trial 149] Epoch 8/60, Training Loss: 1.1125, Validation Loss: 1.0866\n",
      "[Trial 140] Epoch 52/60, Training Loss: 0.6009, Validation Loss: 0.5225\n",
      "[Trial 144] Epoch 26/60, Training Loss: 0.7453, Validation Loss: 0.6375\n",
      "[Trial 155] Epoch 1/60, Training Loss: 1774962777.9876, Validation Loss: 496.2269\n",
      "[Trial 152] Epoch 4/60, Training Loss: 1.4793, Validation Loss: 1.1054\n",
      "[Trial 153] Epoch 4/60, Training Loss: 1.4465, Validation Loss: 1.2400\n",
      "[Trial 154] Epoch 3/60, Training Loss: 1.5680, Validation Loss: 1.2613\n",
      "[Trial 150] Epoch 6/60, Training Loss: 1.1827, Validation Loss: 1.1088\n",
      "[Trial 143] Epoch 43/60, Training Loss: 0.6111, Validation Loss: 0.5101\n",
      "[Trial 148] Epoch 12/60, Training Loss: 0.8842, Validation Loss: 0.8733\n",
      "[Trial 151] Epoch 6/60, Training Loss: 1.0495, Validation Loss: 0.9456\n",
      "[Trial 147] Epoch 21/60, Training Loss: 0.7005, Validation Loss: 0.6504\n",
      "[Trial 156] Epoch 1/60, Training Loss: 3.4627, Validation Loss: 1.5928\n",
      "[Trial 142] Epoch 45/60, Training Loss: 0.5888, Validation Loss: 0.5185\n",
      "[Trial 145] Epoch 26/60, Training Loss: 0.6652, Validation Loss: 0.5339\n",
      "[Trial 149] Epoch 9/60, Training Loss: 1.0217, Validation Loss: 0.9565\n",
      "[Trial 146] Epoch 24/60, Training Loss: 0.7589, Validation Loss: 0.6288\n",
      "[Trial 140] Epoch 53/60, Training Loss: 0.5986, Validation Loss: 0.5261\n",
      "[Trial 144] Epoch 27/60, Training Loss: 0.7358, Validation Loss: 0.6217\n",
      "[Trial 155] Epoch 2/60, Training Loss: 398.2218, Validation Loss: 341.5614\n",
      "[Trial 152] Epoch 5/60, Training Loss: 1.2911, Validation Loss: 0.8865\n",
      "[Trial 153] Epoch 5/60, Training Loss: 1.2854, Validation Loss: 0.9740\n",
      "[Trial 154] Epoch 4/60, Training Loss: 1.3851, Validation Loss: 1.3301\n",
      "[Trial 150] Epoch 7/60, Training Loss: 1.1195, Validation Loss: 1.3444\n",
      "[Trial 143] Epoch 44/60, Training Loss: 0.5873, Validation Loss: 0.5097\n",
      "[Trial 151] Epoch 7/60, Training Loss: 1.0222, Validation Loss: 0.9430\n",
      "[Trial 148] Epoch 13/60, Training Loss: 0.8757, Validation Loss: 0.9735\n",
      "[Trial 156] Epoch 2/60, Training Loss: 1.6601, Validation Loss: 1.4811\n",
      "[Trial 147] Epoch 22/60, Training Loss: 0.6857, Validation Loss: 0.5741\n",
      "[Trial 142] Epoch 46/60, Training Loss: 0.5892, Validation Loss: 0.5142\n",
      "[Trial 145] Epoch 27/60, Training Loss: 0.6563, Validation Loss: 0.5615\n",
      "[Trial 149] Epoch 10/60, Training Loss: 0.9915, Validation Loss: 0.7258\n",
      "[Trial 146] Epoch 25/60, Training Loss: 0.7382, Validation Loss: 0.7090\n",
      "[Trial 140] Epoch 54/60, Training Loss: 0.6078, Validation Loss: 0.5780\n",
      "[Trial 144] Epoch 28/60, Training Loss: 0.7328, Validation Loss: 0.9974\n",
      "[Trial 152] Epoch 6/60, Training Loss: 1.1893, Validation Loss: 1.2863\n",
      "[Trial 155] Epoch 3/60, Training Loss: 5172.7609, Validation Loss: 325.9610\n",
      "[Trial 153] Epoch 6/60, Training Loss: 1.1834, Validation Loss: 0.9518\n",
      "[Trial 154] Epoch 5/60, Training Loss: 1.2235, Validation Loss: 2.8301\n",
      "[Trial 150] Epoch 8/60, Training Loss: 1.0608, Validation Loss: 0.9174\n",
      "[Trial 151] Epoch 8/60, Training Loss: 1.0079, Validation Loss: 0.7966\n",
      "[Trial 156] Epoch 3/60, Training Loss: 1.3166, Validation Loss: 1.3045\n",
      "[Trial 143] Epoch 45/60, Training Loss: 0.6210, Validation Loss: 0.6048\n",
      "[Trial 148] Epoch 14/60, Training Loss: 0.8561, Validation Loss: 1.0020\n",
      "[Trial 147] Epoch 23/60, Training Loss: 0.6760, Validation Loss: 0.5736\n",
      "[Trial 142] Epoch 47/60, Training Loss: 0.5765, Validation Loss: 0.4925\n",
      "[Trial 145] Epoch 28/60, Training Loss: 0.6553, Validation Loss: 0.6916\n",
      "[Trial 149] Epoch 11/60, Training Loss: 0.9421, Validation Loss: 0.8958\n",
      "[Trial 140] Epoch 55/60, Training Loss: 0.6134, Validation Loss: 0.5108\n",
      "[Trial 144] Epoch 29/60, Training Loss: 0.8237, Validation Loss: 0.9625\n",
      "[Trial 146] Epoch 26/60, Training Loss: 0.7524, Validation Loss: 0.7498\n",
      "[Trial 152] Epoch 7/60, Training Loss: 1.1427, Validation Loss: 0.9937\n",
      "[Trial 153] Epoch 7/60, Training Loss: 1.1131, Validation Loss: 0.8586\n",
      "[Trial 155] Epoch 4/60, Training Loss: 334.0106, Validation Loss: 374.9867\n",
      "[Trial 154] Epoch 6/60, Training Loss: 1.2043, Validation Loss: 1.7395\n",
      "[Trial 150] Epoch 9/60, Training Loss: 1.0402, Validation Loss: 0.9518\n",
      "[Trial 156] Epoch 4/60, Training Loss: 1.1702, Validation Loss: 0.8322\n",
      "[Trial 151] Epoch 9/60, Training Loss: 0.9277, Validation Loss: 0.8101\n",
      "[Trial 148] Epoch 15/60, Training Loss: 0.8589, Validation Loss: 1.2150\n",
      "[Trial 143] Epoch 46/60, Training Loss: 0.6143, Validation Loss: 0.5157\n",
      "[Trial 147] Epoch 24/60, Training Loss: 0.6833, Validation Loss: 0.7099\n",
      "[Trial 142] Epoch 48/60, Training Loss: 0.5770, Validation Loss: 0.5279\n",
      "[Trial 145] Epoch 29/60, Training Loss: 0.6682, Validation Loss: 0.5769\n",
      "[Trial 149] Epoch 12/60, Training Loss: 0.9351, Validation Loss: 0.7758\n",
      "[Trial 140] Epoch 56/60, Training Loss: 0.5781, Validation Loss: 0.4949\n",
      "[Trial 152] Epoch 8/60, Training Loss: 1.0975, Validation Loss: 0.8142\n",
      "[Trial 144] Epoch 30/60, Training Loss: 0.7575, Validation Loss: 0.6368\n",
      "[Trial 153] Epoch 8/60, Training Loss: 1.0675, Validation Loss: 1.2436\n",
      "[Trial 146] Epoch 27/60, Training Loss: 0.7385, Validation Loss: 0.6881\n",
      "[Trial 155] Epoch 5/60, Training Loss: 328.9411, Validation Loss: 277.6997\n",
      "[Trial 154] Epoch 7/60, Training Loss: 1.0743, Validation Loss: 1.3647\n",
      "[Trial 150] Epoch 10/60, Training Loss: 0.9850, Validation Loss: 0.7542\n",
      "[Trial 156] Epoch 5/60, Training Loss: 1.0171, Validation Loss: 1.0184\n",
      "[Trial 151] Epoch 10/60, Training Loss: 0.9027, Validation Loss: 0.8227\n",
      "[Trial 148] Epoch 16/60, Training Loss: 0.8289, Validation Loss: 0.6777\n",
      "[Trial 143] Epoch 47/60, Training Loss: 0.5892, Validation Loss: 0.5143\n",
      "[Trial 147] Epoch 25/60, Training Loss: 0.7186, Validation Loss: 0.6825\n",
      "[Trial 142] Epoch 49/60, Training Loss: 0.5824, Validation Loss: 0.6073\n",
      "[Trial 145] Epoch 30/60, Training Loss: 0.6602, Validation Loss: 0.6786\n",
      "[Trial 149] Epoch 13/60, Training Loss: 0.9048, Validation Loss: 0.7014\n",
      "[Trial 140] Epoch 57/60, Training Loss: 0.5755, Validation Loss: 0.4973\n",
      "[Trial 153] Epoch 9/60, Training Loss: 1.0906, Validation Loss: 1.2005\n",
      "[Trial 152] Epoch 9/60, Training Loss: 0.9749, Validation Loss: 1.5377\n",
      "[Trial 144] Epoch 31/60, Training Loss: 0.7135, Validation Loss: 0.6054\n",
      "[Trial 146] Epoch 28/60, Training Loss: 0.7290, Validation Loss: 0.6945\n",
      "[Trial 156] Epoch 6/60, Training Loss: 1.0462, Validation Loss: 0.8301\n",
      "[Trial 155] Epoch 6/60, Training Loss: 302.6120, Validation Loss: 302.2202\n",
      "[Trial 154] Epoch 8/60, Training Loss: 0.9713, Validation Loss: 2.2595\n",
      "[Trial 150] Epoch 11/60, Training Loss: 0.9341, Validation Loss: 0.7275\n",
      "[Trial 151] Epoch 11/60, Training Loss: 0.8801, Validation Loss: 0.7080\n",
      "[Trial 148] Epoch 17/60, Training Loss: 0.8042, Validation Loss: 1.0765\n",
      "[Trial 143] Epoch 48/60, Training Loss: 0.5859, Validation Loss: 0.5166\n",
      "[Trial 147] Epoch 26/60, Training Loss: 0.6757, Validation Loss: 0.6106\n",
      "[Trial 142] Epoch 50/60, Training Loss: 0.5833, Validation Loss: 0.5048\n",
      "[Trial 149] Epoch 14/60, Training Loss: 0.8665, Validation Loss: 0.8331\n",
      "[Trial 145] Epoch 31/60, Training Loss: 0.6921, Validation Loss: 0.6392\n",
      "[Trial 153] Epoch 10/60, Training Loss: 1.0110, Validation Loss: 0.8072\n",
      "[Trial 152] Epoch 10/60, Training Loss: 0.9644, Validation Loss: 1.2011\n",
      "[Trial 140] Epoch 58/60, Training Loss: 0.5806, Validation Loss: 0.5379\n",
      "[Trial 156] Epoch 7/60, Training Loss: 0.9105, Validation Loss: 0.8858\n",
      "[Trial 144] Epoch 32/60, Training Loss: 0.6898, Validation Loss: 0.5925\n",
      "[Trial 151] Epoch 12/60, Training Loss: 0.8653, Validation Loss: 0.8110\n",
      "[Trial 146] Epoch 29/60, Training Loss: 0.7161, Validation Loss: 0.6434\n",
      "[Trial 154] Epoch 9/60, Training Loss: 0.9603, Validation Loss: 1.2760\n",
      "[Trial 150] Epoch 12/60, Training Loss: 0.9037, Validation Loss: 0.8468\n",
      "[Trial 155] Epoch 7/60, Training Loss: 297.3675, Validation Loss: 284.5091\n",
      "[Trial 148] Epoch 18/60, Training Loss: 0.8123, Validation Loss: 0.6938\n",
      "[Trial 143] Epoch 49/60, Training Loss: 0.5879, Validation Loss: 0.5164\n",
      "[Trial 147] Epoch 27/60, Training Loss: 0.6628, Validation Loss: 0.5773\n",
      "[Trial 142] Epoch 51/60, Training Loss: 0.5784, Validation Loss: 0.5115\n",
      "[Trial 149] Epoch 15/60, Training Loss: 0.8739, Validation Loss: 0.8409\n",
      "[Trial 145] Epoch 32/60, Training Loss: 0.6626, Validation Loss: 0.6718\n",
      "[Trial 156] Epoch 8/60, Training Loss: 0.8993, Validation Loss: 0.7356\n",
      "[Trial 153] Epoch 11/60, Training Loss: 0.9343, Validation Loss: 0.8153\n",
      "[Trial 152] Epoch 11/60, Training Loss: 0.9582, Validation Loss: 0.7279\n",
      "[Trial 140] Epoch 59/60, Training Loss: 0.5856, Validation Loss: 0.4921\n",
      "[Trial 144] Epoch 33/60, Training Loss: 0.7001, Validation Loss: 0.9860\n",
      "[Trial 151] Epoch 13/60, Training Loss: 0.8370, Validation Loss: 0.6608\n",
      "[Trial 154] Epoch 10/60, Training Loss: 0.8172, Validation Loss: 0.6856\n",
      "[Trial 150] Epoch 13/60, Training Loss: 0.8910, Validation Loss: 0.7011\n",
      "[Trial 146] Epoch 30/60, Training Loss: 0.6997, Validation Loss: 0.6429\n",
      "[Trial 155] Epoch 8/60, Training Loss: 287.0252, Validation Loss: 284.3789\n",
      "[Trial 148] Epoch 19/60, Training Loss: 0.7793, Validation Loss: 0.6948\n",
      "[Trial 143] Epoch 50/60, Training Loss: 0.5781, Validation Loss: 0.5128\n",
      "[Trial 147] Epoch 28/60, Training Loss: 0.6704, Validation Loss: 0.5836\n",
      "[Trial 156] Epoch 9/60, Training Loss: 0.8754, Validation Loss: 0.7057\n",
      "[Trial 149] Epoch 16/60, Training Loss: 0.8538, Validation Loss: 0.6997\n",
      "[Trial 142] Epoch 52/60, Training Loss: 0.5748, Validation Loss: 0.5442\n",
      "[Trial 153] Epoch 12/60, Training Loss: 0.9146, Validation Loss: 0.7609\n",
      "[Trial 145] Epoch 33/60, Training Loss: 0.6245, Validation Loss: 0.5446\n",
      "[Trial 152] Epoch 12/60, Training Loss: 0.8460, Validation Loss: 0.6829\n",
      "[Trial 151] Epoch 14/60, Training Loss: 0.8253, Validation Loss: 0.7236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:41:13,483] Trial 140 finished with value: 0.4921326125661532 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.003116406627382173, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 140] Epoch 60/60, Training Loss: 0.5814, Validation Loss: 0.5176\n",
      "[Trial 144] Epoch 34/60, Training Loss: 0.7351, Validation Loss: 0.6993\n",
      "[Trial 154] Epoch 11/60, Training Loss: 0.7876, Validation Loss: 0.6635\n",
      "[Trial 150] Epoch 14/60, Training Loss: 0.8517, Validation Loss: 0.7374\n",
      "[Trial 146] Epoch 31/60, Training Loss: 0.6509, Validation Loss: 0.5753\n",
      "[Trial 155] Epoch 9/60, Training Loss: 276.0019, Validation Loss: 252.8612\n",
      "[Trial 148] Epoch 20/60, Training Loss: 0.7497, Validation Loss: 0.6447\n",
      "[Trial 143] Epoch 51/60, Training Loss: 0.5674, Validation Loss: 0.5070\n",
      "[Trial 147] Epoch 29/60, Training Loss: 0.6642, Validation Loss: 0.6030\n",
      "[Trial 156] Epoch 10/60, Training Loss: 0.8064, Validation Loss: 0.6860\n",
      "[Trial 149] Epoch 17/60, Training Loss: 0.8226, Validation Loss: 0.7004\n",
      "[Trial 142] Epoch 53/60, Training Loss: 0.5766, Validation Loss: 0.4901\n",
      "[Trial 153] Epoch 13/60, Training Loss: 0.8978, Validation Loss: 0.8239\n",
      "[Trial 151] Epoch 15/60, Training Loss: 0.8179, Validation Loss: 0.7314\n",
      "[Trial 157] Epoch 1/60, Training Loss: 3.3585, Validation Loss: 1.3133\n",
      "[Trial 152] Epoch 13/60, Training Loss: 0.8448, Validation Loss: 0.8257\n",
      "[Trial 145] Epoch 34/60, Training Loss: 0.6099, Validation Loss: 0.5374\n",
      "[Trial 144] Epoch 35/60, Training Loss: 0.7118, Validation Loss: 0.5893\n",
      "[Trial 154] Epoch 12/60, Training Loss: 0.8010, Validation Loss: 0.7147\n",
      "[Trial 150] Epoch 15/60, Training Loss: 0.8466, Validation Loss: 0.8800\n",
      "[Trial 146] Epoch 32/60, Training Loss: 0.6431, Validation Loss: 0.6656\n",
      "[Trial 155] Epoch 10/60, Training Loss: 1395.4323, Validation Loss: 262.8193\n",
      "[Trial 148] Epoch 21/60, Training Loss: 0.7627, Validation Loss: 0.7348\n",
      "[Trial 143] Epoch 52/60, Training Loss: 0.5780, Validation Loss: 0.5146\n",
      "[Trial 147] Epoch 30/60, Training Loss: 0.6258, Validation Loss: 0.5671\n",
      "[Trial 156] Epoch 11/60, Training Loss: 0.8213, Validation Loss: 0.6797\n",
      "[Trial 149] Epoch 18/60, Training Loss: 0.8125, Validation Loss: 1.4847\n",
      "[Trial 151] Epoch 16/60, Training Loss: 0.8106, Validation Loss: 0.6817\n",
      "[Trial 142] Epoch 54/60, Training Loss: 0.5741, Validation Loss: 0.5082\n",
      "[Trial 153] Epoch 14/60, Training Loss: 0.9020, Validation Loss: 0.7896\n",
      "[Trial 157] Epoch 2/60, Training Loss: 1.6790, Validation Loss: 1.5297\n",
      "[Trial 152] Epoch 14/60, Training Loss: 0.8562, Validation Loss: 1.0749\n",
      "[Trial 145] Epoch 35/60, Training Loss: 0.6127, Validation Loss: 0.5114\n",
      "[Trial 144] Epoch 36/60, Training Loss: 0.6832, Validation Loss: 0.6969\n",
      "[Trial 154] Epoch 13/60, Training Loss: 0.7855, Validation Loss: 0.6645\n",
      "[Trial 150] Epoch 16/60, Training Loss: 0.8372, Validation Loss: 0.6774\n",
      "[Trial 146] Epoch 33/60, Training Loss: 0.6411, Validation Loss: 0.5151\n",
      "[Trial 155] Epoch 11/60, Training Loss: 922.1779, Validation Loss: 278.8493\n",
      "[Trial 148] Epoch 22/60, Training Loss: 0.7372, Validation Loss: 0.6414\n",
      "[Trial 143] Epoch 53/60, Training Loss: 0.5644, Validation Loss: 0.4926\n",
      "[Trial 147] Epoch 31/60, Training Loss: 0.6312, Validation Loss: 0.5644\n",
      "[Trial 156] Epoch 12/60, Training Loss: 0.8122, Validation Loss: 0.8816\n",
      "[Trial 151] Epoch 17/60, Training Loss: 0.7893, Validation Loss: 0.7323\n",
      "[Trial 157] Epoch 3/60, Training Loss: 1.2509, Validation Loss: 1.1523\n",
      "[Trial 149] Epoch 19/60, Training Loss: 0.8290, Validation Loss: 1.0431\n",
      "[Trial 153] Epoch 15/60, Training Loss: 0.8730, Validation Loss: 0.7831\n",
      "[Trial 142] Epoch 55/60, Training Loss: 0.5677, Validation Loss: 0.4942\n",
      "[Trial 152] Epoch 15/60, Training Loss: 0.8253, Validation Loss: 0.6809\n",
      "[Trial 145] Epoch 36/60, Training Loss: 0.6052, Validation Loss: 0.5149\n",
      "[Trial 144] Epoch 37/60, Training Loss: 0.6764, Validation Loss: 0.5544\n",
      "[Trial 154] Epoch 14/60, Training Loss: 0.7800, Validation Loss: 0.9669\n",
      "[Trial 150] Epoch 17/60, Training Loss: 0.8249, Validation Loss: 0.7339\n",
      "[Trial 148] Epoch 23/60, Training Loss: 0.7389, Validation Loss: 0.7047\n",
      "[Trial 146] Epoch 34/60, Training Loss: 0.6241, Validation Loss: 0.5569\n",
      "[Trial 155] Epoch 12/60, Training Loss: 397.8818, Validation Loss: 280.4052\n",
      "[Trial 156] Epoch 13/60, Training Loss: 0.8071, Validation Loss: 0.7131\n",
      "[Trial 143] Epoch 54/60, Training Loss: 0.5606, Validation Loss: 0.4999\n",
      "[Trial 147] Epoch 32/60, Training Loss: 0.6333, Validation Loss: 0.5502\n",
      "[Trial 151] Epoch 18/60, Training Loss: 0.7824, Validation Loss: 0.6568\n",
      "[Trial 157] Epoch 4/60, Training Loss: 1.1258, Validation Loss: 0.9433\n",
      "[Trial 149] Epoch 20/60, Training Loss: 0.8243, Validation Loss: 0.9498\n",
      "[Trial 153] Epoch 16/60, Training Loss: 0.8441, Validation Loss: 0.7561\n",
      "[Trial 142] Epoch 56/60, Training Loss: 0.5693, Validation Loss: 0.4902\n",
      "[Trial 152] Epoch 16/60, Training Loss: 0.8145, Validation Loss: 0.7010\n",
      "[Trial 145] Epoch 37/60, Training Loss: 0.6010, Validation Loss: 0.5548\n",
      "[Trial 150] Epoch 18/60, Training Loss: 0.8223, Validation Loss: 0.6781\n",
      "[Trial 154] Epoch 15/60, Training Loss: 0.7854, Validation Loss: 0.6944\n",
      "[Trial 144] Epoch 38/60, Training Loss: 0.6818, Validation Loss: 0.6325\n",
      "[Trial 148] Epoch 24/60, Training Loss: 0.7287, Validation Loss: 0.6982\n",
      "[Trial 156] Epoch 14/60, Training Loss: 0.7936, Validation Loss: 0.6078\n",
      "[Trial 155] Epoch 13/60, Training Loss: 283.8545, Validation Loss: 275.9605\n",
      "[Trial 146] Epoch 35/60, Training Loss: 0.6297, Validation Loss: 0.5633\n",
      "[Trial 143] Epoch 55/60, Training Loss: 0.5590, Validation Loss: 0.4923\n",
      "[Trial 147] Epoch 33/60, Training Loss: 0.6201, Validation Loss: 0.5495\n",
      "[Trial 151] Epoch 19/60, Training Loss: 0.7698, Validation Loss: 0.6086\n",
      "[Trial 157] Epoch 5/60, Training Loss: 0.9809, Validation Loss: 0.7917\n",
      "[Trial 153] Epoch 17/60, Training Loss: 0.8329, Validation Loss: 0.8112\n",
      "[Trial 149] Epoch 21/60, Training Loss: 0.7911, Validation Loss: 0.6825\n",
      "[Trial 152] Epoch 17/60, Training Loss: 0.7700, Validation Loss: 0.6631\n",
      "[Trial 142] Epoch 57/60, Training Loss: 0.5682, Validation Loss: 0.5087\n",
      "[Trial 150] Epoch 19/60, Training Loss: 0.8069, Validation Loss: 0.7384\n",
      "[Trial 154] Epoch 16/60, Training Loss: 0.7585, Validation Loss: 0.9184\n",
      "[Trial 145] Epoch 38/60, Training Loss: 0.5983, Validation Loss: 0.5042\n",
      "[Trial 144] Epoch 39/60, Training Loss: 0.6820, Validation Loss: 0.5806\n",
      "[Trial 156] Epoch 15/60, Training Loss: 0.7632, Validation Loss: 0.7930\n",
      "[Trial 148] Epoch 25/60, Training Loss: 0.7053, Validation Loss: 0.5823\n",
      "[Trial 155] Epoch 14/60, Training Loss: 3024067.4706, Validation Loss: 494.6282\n",
      "[Trial 146] Epoch 36/60, Training Loss: 0.6375, Validation Loss: 0.5546\n",
      "[Trial 143] Epoch 56/60, Training Loss: 0.5573, Validation Loss: 0.4950\n",
      "[Trial 147] Epoch 34/60, Training Loss: 0.6477, Validation Loss: 0.6482\n",
      "[Trial 151] Epoch 20/60, Training Loss: 0.7509, Validation Loss: 0.6765\n",
      "[Trial 157] Epoch 6/60, Training Loss: 0.9455, Validation Loss: 0.8633\n",
      "[Trial 153] Epoch 18/60, Training Loss: 0.8758, Validation Loss: 1.0761\n",
      "[Trial 149] Epoch 22/60, Training Loss: 0.7679, Validation Loss: 0.7184\n",
      "[Trial 152] Epoch 18/60, Training Loss: 0.7723, Validation Loss: 0.7636\n",
      "[Trial 142] Epoch 58/60, Training Loss: 0.5682, Validation Loss: 0.4822\n",
      "[Trial 150] Epoch 20/60, Training Loss: 0.7865, Validation Loss: 0.7078\n",
      "[Trial 154] Epoch 17/60, Training Loss: 0.7928, Validation Loss: 0.7916\n",
      "[Trial 144] Epoch 40/60, Training Loss: 0.6676, Validation Loss: 0.6490\n",
      "[Trial 145] Epoch 39/60, Training Loss: 0.5930, Validation Loss: 0.5247\n",
      "[Trial 156] Epoch 16/60, Training Loss: 0.7649, Validation Loss: 0.6674\n",
      "[Trial 148] Epoch 26/60, Training Loss: 0.7137, Validation Loss: 0.7508\n",
      "[Trial 155] Epoch 15/60, Training Loss: 641.5414, Validation Loss: 455.7310\n",
      "[Trial 146] Epoch 37/60, Training Loss: 0.6303, Validation Loss: 0.6383\n",
      "[Trial 143] Epoch 57/60, Training Loss: 0.5585, Validation Loss: 0.4964\n",
      "[Trial 147] Epoch 35/60, Training Loss: 0.6436, Validation Loss: 0.5667\n",
      "[Trial 157] Epoch 7/60, Training Loss: 0.9058, Validation Loss: 0.7937\n",
      "[Trial 151] Epoch 21/60, Training Loss: 0.7539, Validation Loss: 0.7009\n",
      "[Trial 153] Epoch 19/60, Training Loss: 0.8860, Validation Loss: 0.7432\n",
      "[Trial 149] Epoch 23/60, Training Loss: 0.7832, Validation Loss: 0.6043\n",
      "[Trial 152] Epoch 19/60, Training Loss: 0.7661, Validation Loss: 0.6455\n",
      "[Trial 142] Epoch 59/60, Training Loss: 0.5759, Validation Loss: 0.5503\n",
      "[Trial 150] Epoch 21/60, Training Loss: 0.7823, Validation Loss: 0.7197\n",
      "[Trial 154] Epoch 18/60, Training Loss: 0.6938, Validation Loss: 0.6067\n",
      "[Trial 144] Epoch 41/60, Training Loss: 0.6986, Validation Loss: 0.6006\n",
      "[Trial 156] Epoch 17/60, Training Loss: 0.7474, Validation Loss: 0.7088\n",
      "[Trial 145] Epoch 40/60, Training Loss: 0.6089, Validation Loss: 0.5200\n",
      "[Trial 148] Epoch 27/60, Training Loss: 0.7048, Validation Loss: 0.7111\n",
      "[Trial 155] Epoch 16/60, Training Loss: 430.7593, Validation Loss: 443.5181\n",
      "[Trial 157] Epoch 8/60, Training Loss: 0.8957, Validation Loss: 0.7882\n",
      "[Trial 151] Epoch 22/60, Training Loss: 0.7652, Validation Loss: 0.6935\n",
      "[Trial 143] Epoch 58/60, Training Loss: 0.5633, Validation Loss: 0.4974\n",
      "[Trial 146] Epoch 38/60, Training Loss: 0.6361, Validation Loss: 0.5261\n",
      "[Trial 147] Epoch 36/60, Training Loss: 0.6160, Validation Loss: 0.5469\n",
      "[Trial 153] Epoch 20/60, Training Loss: 0.7990, Validation Loss: 0.6862\n",
      "[Trial 149] Epoch 24/60, Training Loss: 0.7534, Validation Loss: 0.6565\n",
      "[Trial 152] Epoch 20/60, Training Loss: 0.7498, Validation Loss: 1.4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:52:29,828] Trial 142 finished with value: 0.4821954647699992 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.002192306231494518, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 142] Epoch 60/60, Training Loss: 0.5726, Validation Loss: 0.5573\n",
      "[Trial 156] Epoch 18/60, Training Loss: 0.7628, Validation Loss: 0.9469\n",
      "[Trial 150] Epoch 22/60, Training Loss: 0.7921, Validation Loss: 0.7666\n",
      "[Trial 154] Epoch 19/60, Training Loss: 0.6957, Validation Loss: 0.6820\n",
      "[Trial 144] Epoch 42/60, Training Loss: 0.6690, Validation Loss: 0.6033\n",
      "[Trial 145] Epoch 41/60, Training Loss: 0.5956, Validation Loss: 0.7023\n",
      "[Trial 148] Epoch 28/60, Training Loss: 0.7219, Validation Loss: 1.2118\n",
      "[Trial 157] Epoch 9/60, Training Loss: 0.8447, Validation Loss: 0.7615\n",
      "[Trial 151] Epoch 23/60, Training Loss: 0.7534, Validation Loss: 1.0972\n",
      "[Trial 143] Epoch 59/60, Training Loss: 0.5637, Validation Loss: 0.5232\n",
      "[Trial 155] Epoch 17/60, Training Loss: 435.4822, Validation Loss: 406.1333\n",
      "[Trial 147] Epoch 37/60, Training Loss: 0.6270, Validation Loss: 0.5368\n",
      "[Trial 146] Epoch 39/60, Training Loss: 0.6200, Validation Loss: 0.5352\n",
      "[Trial 153] Epoch 21/60, Training Loss: 0.7523, Validation Loss: 0.7419\n",
      "[Trial 149] Epoch 25/60, Training Loss: 0.7291, Validation Loss: 0.6723\n",
      "[Trial 152] Epoch 21/60, Training Loss: 0.8796, Validation Loss: 0.6755\n",
      "[Trial 158] Epoch 1/60, Training Loss: 3.5251, Validation Loss: 1.5513\n",
      "[Trial 156] Epoch 19/60, Training Loss: 0.7615, Validation Loss: 0.6993\n",
      "[Trial 150] Epoch 23/60, Training Loss: 0.7073, Validation Loss: 0.6303\n",
      "[Trial 154] Epoch 20/60, Training Loss: 0.7017, Validation Loss: 0.5849\n",
      "[Trial 144] Epoch 43/60, Training Loss: 0.6701, Validation Loss: 0.5616\n",
      "[Trial 145] Epoch 42/60, Training Loss: 0.6102, Validation Loss: 0.5265\n",
      "[Trial 157] Epoch 10/60, Training Loss: 0.8152, Validation Loss: 1.3056\n",
      "[Trial 148] Epoch 29/60, Training Loss: 0.8171, Validation Loss: 0.5816\n",
      "[Trial 151] Epoch 24/60, Training Loss: 0.8096, Validation Loss: 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:54:36,429] Trial 143 finished with value: 0.49229854842027027 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0021304552301711654, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 143] Epoch 60/60, Training Loss: 0.5759, Validation Loss: 0.5171\n",
      "[Trial 155] Epoch 18/60, Training Loss: 397.8829, Validation Loss: 412.8409\n",
      "[Trial 147] Epoch 38/60, Training Loss: 0.6107, Validation Loss: 0.5358\n",
      "[Trial 146] Epoch 40/60, Training Loss: 0.5966, Validation Loss: 0.5091\n",
      "[Trial 153] Epoch 22/60, Training Loss: 0.7912, Validation Loss: 0.6753\n",
      "[Trial 149] Epoch 26/60, Training Loss: 0.7374, Validation Loss: 0.6659\n",
      "[Trial 158] Epoch 2/60, Training Loss: 1.8003, Validation Loss: 1.4312\n",
      "[Trial 156] Epoch 20/60, Training Loss: 0.7570, Validation Loss: 0.6145\n",
      "[Trial 152] Epoch 22/60, Training Loss: 0.7444, Validation Loss: 1.4009\n",
      "[Trial 150] Epoch 24/60, Training Loss: 0.6944, Validation Loss: 0.7040\n",
      "[Trial 154] Epoch 21/60, Training Loss: 0.6798, Validation Loss: 0.5858\n",
      "[Trial 144] Epoch 44/60, Training Loss: 0.6183, Validation Loss: 0.5334\n",
      "[Trial 145] Epoch 43/60, Training Loss: 0.5954, Validation Loss: 0.5446\n",
      "[Trial 157] Epoch 11/60, Training Loss: 0.8294, Validation Loss: 0.6876\n",
      "[Trial 151] Epoch 25/60, Training Loss: 0.7342, Validation Loss: 0.6427\n",
      "[Trial 148] Epoch 30/60, Training Loss: 0.6753, Validation Loss: 0.6408\n",
      "[Trial 159] Epoch 1/60, Training Loss: 3.2836, Validation Loss: 2.0072\n",
      "[Trial 147] Epoch 39/60, Training Loss: 0.6090, Validation Loss: 0.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 10:56:00,870] Trial 155 finished with value: 252.86123046875 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.050457194610678005, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 155] Epoch 19/60, Training Loss: 378.1061, Validation Loss: 377.9184\n",
      "[Trial 155] Early stopping after 19 epochs.\n",
      "[Trial 146] Epoch 41/60, Training Loss: 0.5961, Validation Loss: 0.5057\n",
      "[Trial 153] Epoch 23/60, Training Loss: 0.7507, Validation Loss: 0.6522\n",
      "[Trial 156] Epoch 21/60, Training Loss: 0.6612, Validation Loss: 0.5814\n",
      "[Trial 158] Epoch 3/60, Training Loss: 1.5199, Validation Loss: 1.0614\n",
      "[Trial 149] Epoch 27/60, Training Loss: 0.7500, Validation Loss: 0.7409\n",
      "[Trial 152] Epoch 23/60, Training Loss: 0.7677, Validation Loss: 0.7668\n",
      "[Trial 150] Epoch 25/60, Training Loss: 0.7125, Validation Loss: 0.5725\n",
      "[Trial 154] Epoch 22/60, Training Loss: 0.6767, Validation Loss: 0.6288\n",
      "[Trial 144] Epoch 45/60, Training Loss: 0.6112, Validation Loss: 0.5199\n",
      "[Trial 145] Epoch 44/60, Training Loss: 0.5932, Validation Loss: 0.5011\n",
      "[Trial 157] Epoch 12/60, Training Loss: 0.7616, Validation Loss: 0.6518\n",
      "[Trial 151] Epoch 26/60, Training Loss: 0.6794, Validation Loss: 0.5770\n",
      "[Trial 148] Epoch 31/60, Training Loss: 0.6936, Validation Loss: 0.6959\n",
      "[Trial 159] Epoch 2/60, Training Loss: 1.6028, Validation Loss: 1.5412\n",
      "[Trial 160] Epoch 1/60, Training Loss: 3.2982, Validation Loss: 1.8447\n",
      "[Trial 147] Epoch 40/60, Training Loss: 0.6248, Validation Loss: 0.5704\n",
      "[Trial 146] Epoch 42/60, Training Loss: 0.5880, Validation Loss: 0.5354\n",
      "[Trial 153] Epoch 24/60, Training Loss: 0.7491, Validation Loss: 0.7984\n",
      "[Trial 156] Epoch 22/60, Training Loss: 0.6486, Validation Loss: 0.5523\n",
      "[Trial 158] Epoch 4/60, Training Loss: 1.3143, Validation Loss: 1.0041\n",
      "[Trial 149] Epoch 28/60, Training Loss: 0.7559, Validation Loss: 0.7205\n",
      "[Trial 152] Epoch 24/60, Training Loss: 0.7273, Validation Loss: 0.7091\n",
      "[Trial 150] Epoch 26/60, Training Loss: 0.6837, Validation Loss: 0.5629\n",
      "[Trial 154] Epoch 23/60, Training Loss: 0.6775, Validation Loss: 0.5739\n",
      "[Trial 144] Epoch 46/60, Training Loss: 0.6166, Validation Loss: 0.5215\n",
      "[Trial 157] Epoch 13/60, Training Loss: 0.7468, Validation Loss: 0.8930\n",
      "[Trial 151] Epoch 27/60, Training Loss: 0.6608, Validation Loss: 0.5697\n",
      "[Trial 145] Epoch 45/60, Training Loss: 0.5842, Validation Loss: 0.5115\n",
      "[Trial 159] Epoch 3/60, Training Loss: 1.2489, Validation Loss: 1.1597\n",
      "[Trial 148] Epoch 32/60, Training Loss: 0.6811, Validation Loss: 0.5818\n",
      "[Trial 160] Epoch 2/60, Training Loss: 1.6429, Validation Loss: 1.0714\n",
      "[Trial 147] Epoch 41/60, Training Loss: 0.6312, Validation Loss: 0.5796\n",
      "[Trial 156] Epoch 23/60, Training Loss: 0.6545, Validation Loss: 0.5650\n",
      "[Trial 153] Epoch 25/60, Training Loss: 0.7405, Validation Loss: 0.6292\n",
      "[Trial 158] Epoch 5/60, Training Loss: 1.1576, Validation Loss: 0.8481\n",
      "[Trial 146] Epoch 43/60, Training Loss: 0.5847, Validation Loss: 0.5366\n",
      "[Trial 149] Epoch 29/60, Training Loss: 0.7145, Validation Loss: 0.6481\n",
      "[Trial 152] Epoch 25/60, Training Loss: 0.7214, Validation Loss: 0.9330\n",
      "[Trial 150] Epoch 27/60, Training Loss: 0.6887, Validation Loss: 0.5600\n",
      "[Trial 154] Epoch 24/60, Training Loss: 0.6645, Validation Loss: 0.5953\n",
      "[Trial 157] Epoch 14/60, Training Loss: 0.7557, Validation Loss: 0.7023\n",
      "[Trial 151] Epoch 28/60, Training Loss: 0.6712, Validation Loss: 0.5563\n",
      "[Trial 144] Epoch 47/60, Training Loss: 0.6085, Validation Loss: 0.5290\n",
      "[Trial 145] Epoch 46/60, Training Loss: 0.6020, Validation Loss: 0.5779\n",
      "[Trial 159] Epoch 4/60, Training Loss: 1.0766, Validation Loss: 0.8853\n",
      "[Trial 148] Epoch 33/60, Training Loss: 0.6631, Validation Loss: 0.5612\n",
      "[Trial 160] Epoch 3/60, Training Loss: 1.2673, Validation Loss: 0.9863\n",
      "[Trial 147] Epoch 42/60, Training Loss: 0.6276, Validation Loss: 0.6432\n",
      "[Trial 156] Epoch 24/60, Training Loss: 0.6567, Validation Loss: 0.5792\n",
      "[Trial 158] Epoch 6/60, Training Loss: 1.0915, Validation Loss: 0.9481\n",
      "[Trial 153] Epoch 26/60, Training Loss: 0.7345, Validation Loss: 0.7578\n",
      "[Trial 146] Epoch 44/60, Training Loss: 0.5857, Validation Loss: 0.5008\n",
      "[Trial 149] Epoch 30/60, Training Loss: 0.6465, Validation Loss: 0.5347\n",
      "[Trial 152] Epoch 26/60, Training Loss: 0.6642, Validation Loss: 0.6704\n",
      "[Trial 150] Epoch 28/60, Training Loss: 0.6827, Validation Loss: 0.6035\n",
      "[Trial 154] Epoch 25/60, Training Loss: 0.6765, Validation Loss: 0.6119\n",
      "[Trial 157] Epoch 15/60, Training Loss: 0.7536, Validation Loss: 0.6386\n",
      "[Trial 151] Epoch 29/60, Training Loss: 0.6617, Validation Loss: 0.5735\n",
      "[Trial 144] Epoch 48/60, Training Loss: 0.6147, Validation Loss: 0.7362\n",
      "[Trial 159] Epoch 5/60, Training Loss: 0.9899, Validation Loss: 0.8292\n",
      "[Trial 145] Epoch 47/60, Training Loss: 0.6246, Validation Loss: 0.5586\n",
      "[Trial 160] Epoch 4/60, Training Loss: 1.1337, Validation Loss: 0.8813\n",
      "[Trial 148] Epoch 34/60, Training Loss: 0.6461, Validation Loss: 0.5911\n",
      "[Trial 156] Epoch 25/60, Training Loss: 0.6448, Validation Loss: 0.6354\n",
      "[Trial 147] Epoch 43/60, Training Loss: 0.6415, Validation Loss: 0.5345\n",
      "[Trial 158] Epoch 7/60, Training Loss: 1.0423, Validation Loss: 0.8802\n",
      "[Trial 153] Epoch 27/60, Training Loss: 0.7533, Validation Loss: 0.7262\n",
      "[Trial 149] Epoch 31/60, Training Loss: 0.6381, Validation Loss: 0.5291\n",
      "[Trial 146] Epoch 45/60, Training Loss: 0.5862, Validation Loss: 0.5596\n",
      "[Trial 152] Epoch 27/60, Training Loss: 0.6655, Validation Loss: 0.6304\n",
      "[Trial 157] Epoch 16/60, Training Loss: 0.7296, Validation Loss: 0.8604\n",
      "[Trial 150] Epoch 29/60, Training Loss: 0.6778, Validation Loss: 0.5828\n",
      "[Trial 154] Epoch 26/60, Training Loss: 0.6657, Validation Loss: 0.5851\n",
      "[Trial 151] Epoch 30/60, Training Loss: 0.6563, Validation Loss: 0.5318\n",
      "[Trial 159] Epoch 6/60, Training Loss: 0.9679, Validation Loss: 0.8855\n",
      "[Trial 144] Epoch 49/60, Training Loss: 0.6334, Validation Loss: 0.5223\n",
      "[Trial 145] Epoch 48/60, Training Loss: 0.6007, Validation Loss: 0.5740\n",
      "[Trial 160] Epoch 5/60, Training Loss: 1.0224, Validation Loss: 0.8960\n",
      "[Trial 148] Epoch 35/60, Training Loss: 0.6474, Validation Loss: 0.6021\n",
      "[Trial 156] Epoch 26/60, Training Loss: 0.6526, Validation Loss: 0.6084\n",
      "[Trial 158] Epoch 8/60, Training Loss: 0.9738, Validation Loss: 0.8183\n",
      "[Trial 147] Epoch 44/60, Training Loss: 0.5965, Validation Loss: 0.5177\n",
      "[Trial 153] Epoch 28/60, Training Loss: 0.7488, Validation Loss: 0.6485\n",
      "[Trial 149] Epoch 32/60, Training Loss: 0.6490, Validation Loss: 0.5457\n",
      "[Trial 146] Epoch 46/60, Training Loss: 0.5806, Validation Loss: 0.4923\n",
      "[Trial 152] Epoch 28/60, Training Loss: 0.6810, Validation Loss: 0.6979\n",
      "[Trial 157] Epoch 17/60, Training Loss: 0.7508, Validation Loss: 0.7313\n",
      "[Trial 150] Epoch 30/60, Training Loss: 0.6773, Validation Loss: 0.5518\n",
      "[Trial 154] Epoch 27/60, Training Loss: 0.6567, Validation Loss: 0.5846\n",
      "[Trial 151] Epoch 31/60, Training Loss: 0.6522, Validation Loss: 0.5843\n",
      "[Trial 159] Epoch 7/60, Training Loss: 0.9092, Validation Loss: 0.8370\n",
      "[Trial 144] Epoch 50/60, Training Loss: 0.6018, Validation Loss: 0.5198\n",
      "[Trial 160] Epoch 6/60, Training Loss: 0.9709, Validation Loss: 0.8800\n",
      "[Trial 145] Epoch 49/60, Training Loss: 0.5954, Validation Loss: 0.5087\n",
      "[Trial 148] Epoch 36/60, Training Loss: 0.6582, Validation Loss: 0.6152\n",
      "[Trial 156] Epoch 27/60, Training Loss: 0.6366, Validation Loss: 0.5524\n",
      "[Trial 158] Epoch 9/60, Training Loss: 0.9452, Validation Loss: 0.7053\n",
      "[Trial 147] Epoch 45/60, Training Loss: 0.5961, Validation Loss: 0.5486\n",
      "[Trial 153] Epoch 29/60, Training Loss: 0.7177, Validation Loss: 0.6050\n",
      "[Trial 149] Epoch 33/60, Training Loss: 0.6375, Validation Loss: 0.5404\n",
      "[Trial 157] Epoch 18/60, Training Loss: 0.7149, Validation Loss: 0.6592\n",
      "[Trial 146] Epoch 47/60, Training Loss: 0.5823, Validation Loss: 0.5478\n",
      "[Trial 152] Epoch 29/60, Training Loss: 0.6678, Validation Loss: 0.7375\n",
      "[Trial 151] Epoch 32/60, Training Loss: 0.6626, Validation Loss: 0.6033\n",
      "[Trial 150] Epoch 31/60, Training Loss: 0.6735, Validation Loss: 0.5826\n",
      "[Trial 154] Epoch 28/60, Training Loss: 0.6584, Validation Loss: 0.7238\n",
      "[Trial 159] Epoch 8/60, Training Loss: 0.9017, Validation Loss: 1.1527\n",
      "[Trial 160] Epoch 7/60, Training Loss: 0.9244, Validation Loss: 1.1289\n",
      "[Trial 144] Epoch 51/60, Training Loss: 0.6090, Validation Loss: 0.6244\n",
      "[Trial 156] Epoch 28/60, Training Loss: 0.6437, Validation Loss: 0.5604\n",
      "[Trial 145] Epoch 50/60, Training Loss: 0.5782, Validation Loss: 0.5030\n",
      "[Trial 148] Epoch 37/60, Training Loss: 0.6637, Validation Loss: 1.1964\n",
      "[Trial 158] Epoch 10/60, Training Loss: 0.9205, Validation Loss: 0.7653\n",
      "[Trial 147] Epoch 46/60, Training Loss: 0.5982, Validation Loss: 0.5352\n",
      "[Trial 153] Epoch 30/60, Training Loss: 0.7091, Validation Loss: 0.5946\n",
      "[Trial 149] Epoch 34/60, Training Loss: 0.6478, Validation Loss: 0.5596\n",
      "[Trial 157] Epoch 19/60, Training Loss: 0.7277, Validation Loss: 0.8720\n",
      "[Trial 151] Epoch 33/60, Training Loss: 0.6492, Validation Loss: 0.5474\n",
      "[Trial 152] Epoch 30/60, Training Loss: 0.6724, Validation Loss: 0.5588\n",
      "[Trial 146] Epoch 48/60, Training Loss: 0.5933, Validation Loss: 0.5185\n",
      "[Trial 150] Epoch 32/60, Training Loss: 0.6840, Validation Loss: 0.5657\n",
      "[Trial 154] Epoch 29/60, Training Loss: 0.6827, Validation Loss: 0.6215\n",
      "[Trial 159] Epoch 9/60, Training Loss: 0.9397, Validation Loss: 0.9004\n",
      "[Trial 160] Epoch 8/60, Training Loss: 0.8876, Validation Loss: 0.7490\n",
      "[Trial 144] Epoch 52/60, Training Loss: 0.6317, Validation Loss: 0.5156\n",
      "[Trial 156] Epoch 29/60, Training Loss: 0.5934, Validation Loss: 0.5286\n",
      "[Trial 145] Epoch 51/60, Training Loss: 0.5649, Validation Loss: 0.4871\n",
      "[Trial 148] Epoch 38/60, Training Loss: 0.6712, Validation Loss: 0.5634\n",
      "[Trial 158] Epoch 11/60, Training Loss: 0.8981, Validation Loss: 0.7382\n",
      "[Trial 147] Epoch 47/60, Training Loss: 0.6023, Validation Loss: 0.5733\n",
      "[Trial 153] Epoch 31/60, Training Loss: 0.7160, Validation Loss: 1.0262\n",
      "[Trial 157] Epoch 20/60, Training Loss: 0.7146, Validation Loss: 0.7339\n",
      "[Trial 149] Epoch 35/60, Training Loss: 0.6386, Validation Loss: 0.6213\n",
      "[Trial 151] Epoch 34/60, Training Loss: 0.6523, Validation Loss: 0.5701\n",
      "[Trial 159] Epoch 10/60, Training Loss: 0.8431, Validation Loss: 0.7577\n",
      "[Trial 152] Epoch 31/60, Training Loss: 0.6574, Validation Loss: 0.9275\n",
      "[Trial 154] Epoch 30/60, Training Loss: 0.6196, Validation Loss: 0.5319\n",
      "[Trial 150] Epoch 33/60, Training Loss: 0.6737, Validation Loss: 0.9376\n",
      "[Trial 146] Epoch 49/60, Training Loss: 0.5773, Validation Loss: 0.4849\n",
      "[Trial 160] Epoch 9/60, Training Loss: 0.8362, Validation Loss: 0.6413\n",
      "[Trial 156] Epoch 30/60, Training Loss: 0.5964, Validation Loss: 0.5414\n",
      "[Trial 144] Epoch 53/60, Training Loss: 0.6131, Validation Loss: 0.5558\n",
      "[Trial 145] Epoch 52/60, Training Loss: 0.5618, Validation Loss: 0.5005\n",
      "[Trial 148] Epoch 39/60, Training Loss: 0.6329, Validation Loss: 0.5594\n",
      "[Trial 158] Epoch 12/60, Training Loss: 0.8438, Validation Loss: 0.7218\n",
      "[Trial 147] Epoch 48/60, Training Loss: 0.6073, Validation Loss: 0.5137\n",
      "[Trial 153] Epoch 32/60, Training Loss: 0.7475, Validation Loss: 0.6766\n",
      "[Trial 157] Epoch 21/60, Training Loss: 0.7096, Validation Loss: 0.6855\n",
      "[Trial 149] Epoch 36/60, Training Loss: 0.6412, Validation Loss: 0.5457\n",
      "[Trial 151] Epoch 35/60, Training Loss: 0.6439, Validation Loss: 0.5389\n",
      "[Trial 159] Epoch 11/60, Training Loss: 0.8656, Validation Loss: 0.7448\n",
      "[Trial 152] Epoch 32/60, Training Loss: 0.6622, Validation Loss: 0.7849\n",
      "[Trial 154] Epoch 31/60, Training Loss: 0.6178, Validation Loss: 0.5699\n",
      "[Trial 150] Epoch 34/60, Training Loss: 0.7004, Validation Loss: 0.6375\n",
      "[Trial 160] Epoch 10/60, Training Loss: 0.8355, Validation Loss: 0.6850\n",
      "[Trial 146] Epoch 50/60, Training Loss: 0.5798, Validation Loss: 0.5221\n",
      "[Trial 156] Epoch 31/60, Training Loss: 0.5938, Validation Loss: 0.5190\n",
      "[Trial 144] Epoch 54/60, Training Loss: 0.6102, Validation Loss: 0.5496\n",
      "[Trial 148] Epoch 40/60, Training Loss: 0.6544, Validation Loss: 0.7213\n",
      "[Trial 145] Epoch 53/60, Training Loss: 0.5665, Validation Loss: 0.4854\n",
      "[Trial 158] Epoch 13/60, Training Loss: 0.8304, Validation Loss: 0.7651\n",
      "[Trial 147] Epoch 49/60, Training Loss: 0.5940, Validation Loss: 0.5249\n",
      "[Trial 157] Epoch 22/60, Training Loss: 0.6300, Validation Loss: 0.5690\n",
      "[Trial 153] Epoch 33/60, Training Loss: 0.6968, Validation Loss: 0.6903\n",
      "[Trial 151] Epoch 36/60, Training Loss: 0.6437, Validation Loss: 0.5975\n",
      "[Trial 159] Epoch 12/60, Training Loss: 0.7986, Validation Loss: 0.7880\n",
      "[Trial 149] Epoch 37/60, Training Loss: 0.6258, Validation Loss: 0.5354\n",
      "[Trial 152] Epoch 33/60, Training Loss: 0.6555, Validation Loss: 0.5317\n",
      "[Trial 160] Epoch 11/60, Training Loss: 0.8044, Validation Loss: 0.7371\n",
      "[Trial 150] Epoch 35/60, Training Loss: 0.6761, Validation Loss: 0.7289\n",
      "[Trial 154] Epoch 32/60, Training Loss: 0.6159, Validation Loss: 0.5954\n",
      "[Trial 156] Epoch 32/60, Training Loss: 0.5983, Validation Loss: 0.5960\n",
      "[Trial 146] Epoch 51/60, Training Loss: 0.5917, Validation Loss: 0.4957\n",
      "[Trial 144] Epoch 55/60, Training Loss: 0.6009, Validation Loss: 0.5174\n",
      "[Trial 158] Epoch 14/60, Training Loss: 0.8100, Validation Loss: 0.7138\n",
      "[Trial 148] Epoch 41/60, Training Loss: 0.6541, Validation Loss: 0.5740\n",
      "[Trial 145] Epoch 54/60, Training Loss: 0.5549, Validation Loss: 0.4791\n",
      "[Trial 157] Epoch 23/60, Training Loss: 0.6387, Validation Loss: 0.5792\n",
      "[Trial 147] Epoch 50/60, Training Loss: 0.5946, Validation Loss: 0.5151\n",
      "[Trial 153] Epoch 34/60, Training Loss: 0.7129, Validation Loss: 0.6899\n",
      "[Trial 151] Epoch 37/60, Training Loss: 0.6256, Validation Loss: 0.5174\n",
      "[Trial 159] Epoch 13/60, Training Loss: 0.8032, Validation Loss: 0.6997\n",
      "[Trial 149] Epoch 38/60, Training Loss: 0.5994, Validation Loss: 0.5028\n",
      "[Trial 160] Epoch 12/60, Training Loss: 0.7709, Validation Loss: 0.6464\n",
      "[Trial 152] Epoch 34/60, Training Loss: 0.6506, Validation Loss: 0.6621\n",
      "[Trial 154] Epoch 33/60, Training Loss: 0.6082, Validation Loss: 0.5321\n",
      "[Trial 150] Epoch 36/60, Training Loss: 0.6794, Validation Loss: 0.6293\n",
      "[Trial 156] Epoch 33/60, Training Loss: 0.6002, Validation Loss: 0.5150\n",
      "[Trial 146] Epoch 52/60, Training Loss: 0.5758, Validation Loss: 0.5215\n",
      "[Trial 158] Epoch 15/60, Training Loss: 0.8204, Validation Loss: 0.7666\n",
      "[Trial 144] Epoch 56/60, Training Loss: 0.5958, Validation Loss: 0.7096\n",
      "[Trial 148] Epoch 42/60, Training Loss: 0.6353, Validation Loss: 0.7462\n",
      "[Trial 145] Epoch 55/60, Training Loss: 0.5565, Validation Loss: 0.4899\n",
      "[Trial 157] Epoch 24/60, Training Loss: 0.6294, Validation Loss: 0.6320\n",
      "[Trial 147] Epoch 51/60, Training Loss: 0.5890, Validation Loss: 0.5228\n",
      "[Trial 151] Epoch 38/60, Training Loss: 0.6101, Validation Loss: 0.5167\n",
      "[Trial 153] Epoch 35/60, Training Loss: 0.7132, Validation Loss: 0.5595\n",
      "[Trial 159] Epoch 14/60, Training Loss: 0.7678, Validation Loss: 0.7467\n",
      "[Trial 149] Epoch 39/60, Training Loss: 0.5997, Validation Loss: 0.5102\n",
      "[Trial 160] Epoch 13/60, Training Loss: 0.7695, Validation Loss: 0.6644\n",
      "[Trial 152] Epoch 35/60, Training Loss: 0.6480, Validation Loss: 0.5548\n",
      "[Trial 156] Epoch 34/60, Training Loss: 0.5935, Validation Loss: 0.5768\n",
      "[Trial 150] Epoch 37/60, Training Loss: 0.6417, Validation Loss: 0.5432\n",
      "[Trial 154] Epoch 34/60, Training Loss: 0.6019, Validation Loss: 0.5299\n",
      "[Trial 146] Epoch 53/60, Training Loss: 0.5842, Validation Loss: 0.4890\n",
      "[Trial 158] Epoch 16/60, Training Loss: 0.7509, Validation Loss: 0.6050\n",
      "[Trial 144] Epoch 57/60, Training Loss: 0.6025, Validation Loss: 0.5255\n",
      "[Trial 148] Epoch 43/60, Training Loss: 0.6426, Validation Loss: 0.5376\n",
      "[Trial 145] Epoch 56/60, Training Loss: 0.5612, Validation Loss: 0.5154\n",
      "[Trial 157] Epoch 25/60, Training Loss: 0.6319, Validation Loss: 0.5382\n",
      "[Trial 147] Epoch 52/60, Training Loss: 0.5860, Validation Loss: 0.5708\n",
      "[Trial 151] Epoch 39/60, Training Loss: 0.6139, Validation Loss: 0.5444\n",
      "[Trial 159] Epoch 15/60, Training Loss: 0.7752, Validation Loss: 0.7566\n",
      "[Trial 153] Epoch 36/60, Training Loss: 0.6736, Validation Loss: 0.6672\n",
      "[Trial 160] Epoch 14/60, Training Loss: 0.7663, Validation Loss: 0.6511\n",
      "[Trial 149] Epoch 40/60, Training Loss: 0.6021, Validation Loss: 0.5446\n",
      "[Trial 156] Epoch 35/60, Training Loss: 0.5989, Validation Loss: 0.5214\n",
      "[Trial 152] Epoch 36/60, Training Loss: 0.6455, Validation Loss: 0.6682\n",
      "[Trial 150] Epoch 38/60, Training Loss: 0.6498, Validation Loss: 0.5086\n",
      "[Trial 154] Epoch 35/60, Training Loss: 0.6173, Validation Loss: 0.5736\n",
      "[Trial 146] Epoch 54/60, Training Loss: 0.5783, Validation Loss: 0.5377\n",
      "[Trial 158] Epoch 17/60, Training Loss: 0.7334, Validation Loss: 0.6000\n",
      "[Trial 144] Epoch 58/60, Training Loss: 0.5946, Validation Loss: 0.5288\n",
      "[Trial 148] Epoch 44/60, Training Loss: 0.6233, Validation Loss: 0.5445\n",
      "[Trial 157] Epoch 26/60, Training Loss: 0.6252, Validation Loss: 0.5790\n",
      "[Trial 145] Epoch 57/60, Training Loss: 0.5620, Validation Loss: 0.4845\n",
      "[Trial 151] Epoch 40/60, Training Loss: 0.6206, Validation Loss: 0.5152\n",
      "[Trial 159] Epoch 16/60, Training Loss: 0.7826, Validation Loss: 0.6986\n",
      "[Trial 147] Epoch 53/60, Training Loss: 0.6016, Validation Loss: 0.5300\n",
      "[Trial 153] Epoch 37/60, Training Loss: 0.6956, Validation Loss: 0.9696\n",
      "[Trial 160] Epoch 15/60, Training Loss: 0.7551, Validation Loss: 0.6577\n",
      "[Trial 156] Epoch 36/60, Training Loss: 0.5883, Validation Loss: 0.5723\n",
      "[Trial 149] Epoch 41/60, Training Loss: 0.5928, Validation Loss: 0.5162\n",
      "[Trial 152] Epoch 37/60, Training Loss: 0.6362, Validation Loss: 0.7119\n",
      "[Trial 150] Epoch 39/60, Training Loss: 0.6236, Validation Loss: 0.5386\n",
      "[Trial 154] Epoch 36/60, Training Loss: 0.6065, Validation Loss: 0.5561\n",
      "[Trial 158] Epoch 18/60, Training Loss: 0.7310, Validation Loss: 0.5942\n",
      "[Trial 146] Epoch 55/60, Training Loss: 0.5728, Validation Loss: 0.4792\n",
      "[Trial 144] Epoch 59/60, Training Loss: 0.5713, Validation Loss: 0.4984\n",
      "[Trial 148] Epoch 45/60, Training Loss: 0.6136, Validation Loss: 0.6530\n",
      "[Trial 157] Epoch 27/60, Training Loss: 0.6245, Validation Loss: 0.5991\n",
      "[Trial 145] Epoch 58/60, Training Loss: 0.5572, Validation Loss: 0.4914\n",
      "[Trial 159] Epoch 17/60, Training Loss: 0.7517, Validation Loss: 0.8573\n",
      "[Trial 151] Epoch 41/60, Training Loss: 0.6157, Validation Loss: 0.5227\n",
      "[Trial 147] Epoch 54/60, Training Loss: 0.5914, Validation Loss: 0.5282\n",
      "[Trial 153] Epoch 38/60, Training Loss: 0.7947, Validation Loss: 0.6649\n",
      "[Trial 160] Epoch 16/60, Training Loss: 0.6805, Validation Loss: 0.5683\n",
      "[Trial 156] Epoch 37/60, Training Loss: 0.5869, Validation Loss: 0.5406\n",
      "[Trial 149] Epoch 42/60, Training Loss: 0.5978, Validation Loss: 0.5196\n",
      "[Trial 152] Epoch 38/60, Training Loss: 0.6504, Validation Loss: 0.6378\n",
      "[Trial 150] Epoch 40/60, Training Loss: 0.6223, Validation Loss: 0.5167\n",
      "[Trial 154] Epoch 37/60, Training Loss: 0.6043, Validation Loss: 0.5403\n",
      "[Trial 158] Epoch 19/60, Training Loss: 0.7406, Validation Loss: 0.6011\n",
      "[Trial 146] Epoch 56/60, Training Loss: 0.5665, Validation Loss: 0.4856\n",
      "[Trial 157] Epoch 28/60, Training Loss: 0.6380, Validation Loss: 0.8704\n",
      "[Trial 148] Epoch 46/60, Training Loss: 0.6192, Validation Loss: 0.5808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:16:15,185] Trial 144 finished with value: 0.49802909046411514 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0021348592777000385, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 144] Epoch 60/60, Training Loss: 0.5664, Validation Loss: 0.4980\n",
      "[Trial 159] Epoch 18/60, Training Loss: 0.7865, Validation Loss: 0.7392\n",
      "[Trial 151] Epoch 42/60, Training Loss: 0.6217, Validation Loss: 0.5857\n",
      "[Trial 145] Epoch 59/60, Training Loss: 0.5597, Validation Loss: 0.4848\n",
      "[Trial 160] Epoch 17/60, Training Loss: 0.6718, Validation Loss: 0.5620\n",
      "[Trial 147] Epoch 55/60, Training Loss: 0.5749, Validation Loss: 0.5118\n",
      "[Trial 153] Epoch 39/60, Training Loss: 0.7032, Validation Loss: 0.6985\n",
      "[Trial 156] Epoch 38/60, Training Loss: 0.5797, Validation Loss: 0.5146\n",
      "[Trial 149] Epoch 43/60, Training Loss: 0.5923, Validation Loss: 0.5137\n",
      "[Trial 152] Epoch 39/60, Training Loss: 0.6457, Validation Loss: 0.6212\n",
      "[Trial 150] Epoch 41/60, Training Loss: 0.6137, Validation Loss: 0.5489\n",
      "[Trial 154] Epoch 38/60, Training Loss: 0.6168, Validation Loss: 0.5415\n",
      "[Trial 158] Epoch 20/60, Training Loss: 0.7324, Validation Loss: 0.6677\n",
      "[Trial 157] Epoch 29/60, Training Loss: 0.6757, Validation Loss: 0.5586\n",
      "[Trial 146] Epoch 57/60, Training Loss: 0.5711, Validation Loss: 0.5126\n",
      "[Trial 161] Epoch 1/60, Training Loss: 3.3903, Validation Loss: 1.9376\n",
      "[Trial 148] Epoch 47/60, Training Loss: 0.6171, Validation Loss: 0.6863\n",
      "[Trial 159] Epoch 19/60, Training Loss: 0.7440, Validation Loss: 0.9197\n",
      "[Trial 151] Epoch 43/60, Training Loss: 0.6289, Validation Loss: 0.5309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:17:42,948] Trial 145 finished with value: 0.47908272544542946 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.0021635540837610045, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 145] Epoch 60/60, Training Loss: 0.5534, Validation Loss: 0.5036\n",
      "[Trial 160] Epoch 18/60, Training Loss: 0.6749, Validation Loss: 0.6463\n",
      "[Trial 156] Epoch 39/60, Training Loss: 0.5789, Validation Loss: 0.4964\n",
      "[Trial 153] Epoch 40/60, Training Loss: 0.6688, Validation Loss: 0.5879\n",
      "[Trial 147] Epoch 56/60, Training Loss: 0.5750, Validation Loss: 0.5021\n",
      "[Trial 149] Epoch 44/60, Training Loss: 0.5915, Validation Loss: 0.5414\n",
      "[Trial 152] Epoch 40/60, Training Loss: 0.5986, Validation Loss: 0.5107\n",
      "[Trial 150] Epoch 42/60, Training Loss: 0.6137, Validation Loss: 0.5591\n",
      "[Trial 154] Epoch 39/60, Training Loss: 0.6060, Validation Loss: 0.5250\n",
      "[Trial 158] Epoch 21/60, Training Loss: 0.7144, Validation Loss: 0.6482\n",
      "[Trial 157] Epoch 30/60, Training Loss: 0.6315, Validation Loss: 0.7233\n",
      "[Trial 161] Epoch 2/60, Training Loss: 1.7092, Validation Loss: 1.4380\n",
      "[Trial 146] Epoch 58/60, Training Loss: 0.5698, Validation Loss: 0.4881\n",
      "[Trial 159] Epoch 20/60, Training Loss: 0.8442, Validation Loss: 0.9026\n",
      "[Trial 151] Epoch 44/60, Training Loss: 0.6051, Validation Loss: 0.5491\n",
      "[Trial 148] Epoch 48/60, Training Loss: 0.6675, Validation Loss: 0.6098\n",
      "[Trial 162] Epoch 1/60, Training Loss: 3.3224, Validation Loss: 1.9574\n",
      "[Trial 160] Epoch 19/60, Training Loss: 0.6658, Validation Loss: 0.5744\n",
      "[Trial 156] Epoch 40/60, Training Loss: 0.5740, Validation Loss: 0.5232\n",
      "[Trial 153] Epoch 41/60, Training Loss: 0.6612, Validation Loss: 0.5620\n",
      "[Trial 147] Epoch 57/60, Training Loss: 0.5691, Validation Loss: 0.5010\n",
      "[Trial 149] Epoch 45/60, Training Loss: 0.5829, Validation Loss: 0.4936\n",
      "[Trial 152] Epoch 41/60, Training Loss: 0.5793, Validation Loss: 0.5107\n",
      "[Trial 150] Epoch 43/60, Training Loss: 0.6125, Validation Loss: 0.5428\n",
      "[Trial 154] Epoch 40/60, Training Loss: 0.5958, Validation Loss: 0.5443\n",
      "[Trial 158] Epoch 22/60, Training Loss: 0.7071, Validation Loss: 0.5601\n",
      "[Trial 157] Epoch 31/60, Training Loss: 0.6288, Validation Loss: 0.6568\n",
      "[Trial 161] Epoch 3/60, Training Loss: 1.3211, Validation Loss: 1.0022\n",
      "[Trial 159] Epoch 21/60, Training Loss: 0.7388, Validation Loss: 0.8259\n",
      "[Trial 151] Epoch 45/60, Training Loss: 0.6098, Validation Loss: 0.5192\n",
      "[Trial 148] Epoch 49/60, Training Loss: 0.6331, Validation Loss: 0.6314\n",
      "[Trial 146] Epoch 59/60, Training Loss: 0.5678, Validation Loss: 0.4947\n",
      "[Trial 162] Epoch 2/60, Training Loss: 1.6856, Validation Loss: 1.0618\n",
      "[Trial 160] Epoch 20/60, Training Loss: 0.6595, Validation Loss: 0.5521\n",
      "[Trial 156] Epoch 41/60, Training Loss: 0.5746, Validation Loss: 0.5149\n",
      "[Trial 153] Epoch 42/60, Training Loss: 0.6139, Validation Loss: 0.5416\n",
      "[Trial 147] Epoch 58/60, Training Loss: 0.5687, Validation Loss: 0.5028\n",
      "[Trial 149] Epoch 46/60, Training Loss: 0.5806, Validation Loss: 0.4926\n",
      "[Trial 152] Epoch 42/60, Training Loss: 0.5816, Validation Loss: 0.4985\n",
      "[Trial 150] Epoch 44/60, Training Loss: 0.6263, Validation Loss: 0.5584\n",
      "[Trial 154] Epoch 41/60, Training Loss: 0.6055, Validation Loss: 0.5268\n",
      "[Trial 158] Epoch 23/60, Training Loss: 0.7083, Validation Loss: 0.6823\n",
      "[Trial 157] Epoch 32/60, Training Loss: 0.5964, Validation Loss: 0.5459\n",
      "[Trial 161] Epoch 4/60, Training Loss: 1.1137, Validation Loss: 0.8594\n",
      "[Trial 159] Epoch 22/60, Training Loss: 0.7477, Validation Loss: 0.7396\n",
      "[Trial 151] Epoch 46/60, Training Loss: 0.6060, Validation Loss: 0.5324\n",
      "[Trial 162] Epoch 3/60, Training Loss: 1.2853, Validation Loss: 0.9696\n",
      "[Trial 148] Epoch 50/60, Training Loss: 0.5827, Validation Loss: 0.4958\n",
      "[Trial 160] Epoch 21/60, Training Loss: 0.6473, Validation Loss: 0.5513\n",
      "[Trial 156] Epoch 42/60, Training Loss: 0.5735, Validation Loss: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:21:13,026] Trial 146 finished with value: 0.4791948437690735 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.0020670400779497144, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 146] Epoch 60/60, Training Loss: 0.5672, Validation Loss: 0.4923\n",
      "[Trial 153] Epoch 43/60, Training Loss: 0.6122, Validation Loss: 0.5426\n",
      "[Trial 147] Epoch 59/60, Training Loss: 0.5715, Validation Loss: 0.5104\n",
      "[Trial 149] Epoch 47/60, Training Loss: 0.5704, Validation Loss: 0.4940\n",
      "[Trial 158] Epoch 24/60, Training Loss: 0.7073, Validation Loss: 0.6066\n",
      "[Trial 152] Epoch 43/60, Training Loss: 0.5837, Validation Loss: 0.5478\n",
      "[Trial 154] Epoch 42/60, Training Loss: 0.6024, Validation Loss: 0.5497\n",
      "[Trial 150] Epoch 45/60, Training Loss: 0.6087, Validation Loss: 0.5032\n",
      "[Trial 157] Epoch 33/60, Training Loss: 0.6073, Validation Loss: 0.5116\n",
      "[Trial 161] Epoch 5/60, Training Loss: 1.0028, Validation Loss: 0.9188\n",
      "[Trial 159] Epoch 23/60, Training Loss: 0.6759, Validation Loss: 0.6244\n",
      "[Trial 151] Epoch 47/60, Training Loss: 0.5968, Validation Loss: 0.5030\n",
      "[Trial 162] Epoch 4/60, Training Loss: 1.1052, Validation Loss: 0.8773\n",
      "[Trial 160] Epoch 22/60, Training Loss: 0.6577, Validation Loss: 0.6843\n",
      "[Trial 156] Epoch 43/60, Training Loss: 0.5723, Validation Loss: 0.5261\n",
      "[Trial 148] Epoch 51/60, Training Loss: 0.5760, Validation Loss: 0.5583\n",
      "[Trial 163] Epoch 1/60, Training Loss: 3.5864, Validation Loss: 1.4735\n",
      "[Trial 153] Epoch 44/60, Training Loss: 0.6099, Validation Loss: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:22:39,088] Trial 147 finished with value: 0.4929797699054082 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.002242834030671853, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 147] Epoch 60/60, Training Loss: 0.5675, Validation Loss: 0.4930\n",
      "[Trial 149] Epoch 48/60, Training Loss: 0.5653, Validation Loss: 0.4909\n",
      "[Trial 158] Epoch 25/60, Training Loss: 0.6978, Validation Loss: 0.6347\n",
      "[Trial 150] Epoch 46/60, Training Loss: 0.6065, Validation Loss: 0.5057\n",
      "[Trial 154] Epoch 43/60, Training Loss: 0.5929, Validation Loss: 0.5142\n",
      "[Trial 152] Epoch 44/60, Training Loss: 0.5962, Validation Loss: 0.4951\n",
      "[Trial 157] Epoch 34/60, Training Loss: 0.5784, Validation Loss: 0.5136\n",
      "[Trial 161] Epoch 6/60, Training Loss: 0.9657, Validation Loss: 0.8930\n",
      "[Trial 159] Epoch 24/60, Training Loss: 0.6494, Validation Loss: 0.6533\n",
      "[Trial 151] Epoch 48/60, Training Loss: 0.5880, Validation Loss: 0.5131\n",
      "[Trial 162] Epoch 5/60, Training Loss: 0.9712, Validation Loss: 0.7702\n",
      "[Trial 160] Epoch 23/60, Training Loss: 0.6787, Validation Loss: 0.5762\n",
      "[Trial 156] Epoch 44/60, Training Loss: 0.5749, Validation Loss: 0.4999\n",
      "[Trial 163] Epoch 2/60, Training Loss: 1.8598, Validation Loss: 1.3138\n",
      "[Trial 148] Epoch 52/60, Training Loss: 0.5675, Validation Loss: 0.5050\n",
      "[Trial 164] Epoch 1/60, Training Loss: 3.4332, Validation Loss: 1.7335\n",
      "[Trial 153] Epoch 45/60, Training Loss: 0.6086, Validation Loss: 0.5092\n",
      "[Trial 158] Epoch 26/60, Training Loss: 0.7163, Validation Loss: 0.5832\n",
      "[Trial 149] Epoch 49/60, Training Loss: 0.5728, Validation Loss: 0.4979\n",
      "[Trial 157] Epoch 35/60, Training Loss: 0.5775, Validation Loss: 0.5372\n",
      "[Trial 150] Epoch 47/60, Training Loss: 0.6007, Validation Loss: 0.5001\n",
      "[Trial 152] Epoch 45/60, Training Loss: 0.5885, Validation Loss: 0.5132\n",
      "[Trial 154] Epoch 44/60, Training Loss: 0.6033, Validation Loss: 0.5754\n",
      "[Trial 161] Epoch 7/60, Training Loss: 0.9082, Validation Loss: 0.8642\n",
      "[Trial 159] Epoch 25/60, Training Loss: 0.6508, Validation Loss: 0.5428\n",
      "[Trial 151] Epoch 49/60, Training Loss: 0.5933, Validation Loss: 0.4992\n",
      "[Trial 162] Epoch 6/60, Training Loss: 0.9429, Validation Loss: 1.3851\n",
      "[Trial 156] Epoch 45/60, Training Loss: 0.5794, Validation Loss: 0.5293\n",
      "[Trial 160] Epoch 24/60, Training Loss: 0.6486, Validation Loss: 0.7159\n",
      "[Trial 163] Epoch 3/60, Training Loss: 1.5340, Validation Loss: 1.1221\n",
      "[Trial 148] Epoch 53/60, Training Loss: 0.5632, Validation Loss: 0.7439\n",
      "[Trial 164] Epoch 2/60, Training Loss: 1.6665, Validation Loss: 1.4170\n",
      "[Trial 153] Epoch 46/60, Training Loss: 0.6072, Validation Loss: 0.5715\n",
      "[Trial 158] Epoch 27/60, Training Loss: 0.6809, Validation Loss: 0.5795\n",
      "[Trial 149] Epoch 50/60, Training Loss: 0.5672, Validation Loss: 0.4853\n",
      "[Trial 157] Epoch 36/60, Training Loss: 0.5829, Validation Loss: 0.5289\n",
      "[Trial 150] Epoch 48/60, Training Loss: 0.5930, Validation Loss: 0.5072\n",
      "[Trial 152] Epoch 46/60, Training Loss: 0.5893, Validation Loss: 0.5166\n",
      "[Trial 154] Epoch 45/60, Training Loss: 0.6104, Validation Loss: 0.5530\n",
      "[Trial 161] Epoch 8/60, Training Loss: 0.8961, Validation Loss: 0.7915\n",
      "[Trial 159] Epoch 26/60, Training Loss: 0.6423, Validation Loss: 0.5814\n",
      "[Trial 151] Epoch 50/60, Training Loss: 0.5871, Validation Loss: 0.5136\n",
      "[Trial 162] Epoch 7/60, Training Loss: 0.9524, Validation Loss: 0.8742\n",
      "[Trial 160] Epoch 25/60, Training Loss: 0.6615, Validation Loss: 0.5979\n",
      "[Trial 156] Epoch 46/60, Training Loss: 0.5633, Validation Loss: 0.4995\n",
      "[Trial 163] Epoch 4/60, Training Loss: 1.3311, Validation Loss: 1.0056\n",
      "[Trial 148] Epoch 54/60, Training Loss: 0.5879, Validation Loss: 0.5308\n",
      "[Trial 164] Epoch 3/60, Training Loss: 1.3524, Validation Loss: 1.1291\n",
      "[Trial 153] Epoch 47/60, Training Loss: 0.6141, Validation Loss: 0.5202\n",
      "[Trial 158] Epoch 28/60, Training Loss: 0.6780, Validation Loss: 0.5669\n",
      "[Trial 157] Epoch 37/60, Training Loss: 0.5725, Validation Loss: 0.5053\n",
      "[Trial 149] Epoch 51/60, Training Loss: 0.5615, Validation Loss: 0.4961\n",
      "[Trial 150] Epoch 49/60, Training Loss: 0.5886, Validation Loss: 0.4865\n",
      "[Trial 152] Epoch 47/60, Training Loss: 0.5809, Validation Loss: 0.5215\n",
      "[Trial 154] Epoch 46/60, Training Loss: 0.5956, Validation Loss: 0.5844\n",
      "[Trial 161] Epoch 9/60, Training Loss: 0.8636, Validation Loss: 0.7644\n",
      "[Trial 159] Epoch 27/60, Training Loss: 0.6323, Validation Loss: 0.5556\n",
      "[Trial 151] Epoch 51/60, Training Loss: 0.5859, Validation Loss: 0.4974\n",
      "[Trial 162] Epoch 8/60, Training Loss: 0.9043, Validation Loss: 0.7982\n",
      "[Trial 160] Epoch 26/60, Training Loss: 0.6326, Validation Loss: 0.5564\n",
      "[Trial 156] Epoch 47/60, Training Loss: 0.5583, Validation Loss: 0.4870\n",
      "[Trial 163] Epoch 5/60, Training Loss: 1.1812, Validation Loss: 0.9289\n",
      "[Trial 148] Epoch 55/60, Training Loss: 0.5621, Validation Loss: 0.4959\n",
      "[Trial 164] Epoch 4/60, Training Loss: 1.1542, Validation Loss: 0.8740\n",
      "[Trial 153] Epoch 48/60, Training Loss: 0.6201, Validation Loss: 0.5850\n",
      "[Trial 158] Epoch 29/60, Training Loss: 0.6525, Validation Loss: 0.5309\n",
      "[Trial 157] Epoch 38/60, Training Loss: 0.5810, Validation Loss: 0.5181\n",
      "[Trial 149] Epoch 52/60, Training Loss: 0.5786, Validation Loss: 0.5152\n",
      "[Trial 161] Epoch 10/60, Training Loss: 0.8227, Validation Loss: 1.4286\n",
      "[Trial 150] Epoch 50/60, Training Loss: 0.5938, Validation Loss: 0.5200\n",
      "[Trial 159] Epoch 28/60, Training Loss: 0.6393, Validation Loss: 0.6352\n",
      "[Trial 154] Epoch 47/60, Training Loss: 0.5927, Validation Loss: 0.5553\n",
      "[Trial 152] Epoch 48/60, Training Loss: 0.5857, Validation Loss: 0.5136\n",
      "[Trial 151] Epoch 52/60, Training Loss: 0.5859, Validation Loss: 0.4970\n",
      "[Trial 162] Epoch 9/60, Training Loss: 0.8295, Validation Loss: 0.6602\n",
      "[Trial 156] Epoch 48/60, Training Loss: 0.5458, Validation Loss: 0.4894\n",
      "[Trial 160] Epoch 27/60, Training Loss: 0.6412, Validation Loss: 0.5849\n",
      "[Trial 163] Epoch 6/60, Training Loss: 1.1208, Validation Loss: 0.9863\n",
      "[Trial 164] Epoch 5/60, Training Loss: 1.0453, Validation Loss: 0.8535\n",
      "[Trial 148] Epoch 56/60, Training Loss: 0.5591, Validation Loss: 0.4956\n",
      "[Trial 153] Epoch 49/60, Training Loss: 0.6119, Validation Loss: 0.5053\n",
      "[Trial 158] Epoch 30/60, Training Loss: 0.6424, Validation Loss: 0.5310\n",
      "[Trial 157] Epoch 39/60, Training Loss: 0.5743, Validation Loss: 0.5026\n",
      "[Trial 149] Epoch 53/60, Training Loss: 0.5717, Validation Loss: 0.4916\n",
      "[Trial 161] Epoch 11/60, Training Loss: 0.8333, Validation Loss: 0.7381\n",
      "[Trial 159] Epoch 29/60, Training Loss: 0.6420, Validation Loss: 0.6196\n",
      "[Trial 150] Epoch 51/60, Training Loss: 0.5965, Validation Loss: 0.4905\n",
      "[Trial 151] Epoch 53/60, Training Loss: 0.5857, Validation Loss: 0.4972\n",
      "[Trial 154] Epoch 48/60, Training Loss: 0.5957, Validation Loss: 0.5959\n",
      "[Trial 152] Epoch 49/60, Training Loss: 0.5870, Validation Loss: 0.5425\n",
      "[Trial 162] Epoch 10/60, Training Loss: 0.8142, Validation Loss: 0.6998\n",
      "[Trial 156] Epoch 49/60, Training Loss: 0.5503, Validation Loss: 0.4924\n",
      "[Trial 160] Epoch 28/60, Training Loss: 0.5977, Validation Loss: 0.5102\n",
      "[Trial 163] Epoch 7/60, Training Loss: 1.0393, Validation Loss: 0.9090\n",
      "[Trial 164] Epoch 6/60, Training Loss: 0.9742, Validation Loss: 0.7827\n",
      "[Trial 148] Epoch 57/60, Training Loss: 0.5659, Validation Loss: 0.4940\n",
      "[Trial 158] Epoch 31/60, Training Loss: 0.6487, Validation Loss: 0.5631\n",
      "[Trial 153] Epoch 50/60, Training Loss: 0.5982, Validation Loss: 0.5230\n",
      "[Trial 157] Epoch 40/60, Training Loss: 0.5647, Validation Loss: 0.5310\n",
      "[Trial 161] Epoch 12/60, Training Loss: 0.7765, Validation Loss: 0.7072\n",
      "[Trial 159] Epoch 30/60, Training Loss: 0.6462, Validation Loss: 0.5901\n",
      "[Trial 149] Epoch 54/60, Training Loss: 0.5666, Validation Loss: 0.4980\n",
      "[Trial 151] Epoch 54/60, Training Loss: 0.5816, Validation Loss: 0.4983\n",
      "[Trial 162] Epoch 11/60, Training Loss: 0.7975, Validation Loss: 0.6742\n",
      "[Trial 150] Epoch 52/60, Training Loss: 0.5916, Validation Loss: 0.5167\n",
      "[Trial 154] Epoch 49/60, Training Loss: 0.6006, Validation Loss: 0.7063\n",
      "[Trial 152] Epoch 50/60, Training Loss: 0.5910, Validation Loss: 0.5839\n",
      "[Trial 160] Epoch 29/60, Training Loss: 0.5969, Validation Loss: 0.5236\n",
      "[Trial 156] Epoch 50/60, Training Loss: 0.5482, Validation Loss: 0.4903\n",
      "[Trial 163] Epoch 8/60, Training Loss: 0.9874, Validation Loss: 0.7869\n",
      "[Trial 164] Epoch 7/60, Training Loss: 0.9236, Validation Loss: 0.7534\n",
      "[Trial 148] Epoch 58/60, Training Loss: 0.5678, Validation Loss: 0.5504\n",
      "[Trial 158] Epoch 32/60, Training Loss: 0.6468, Validation Loss: 0.5379\n",
      "[Trial 157] Epoch 41/60, Training Loss: 0.5761, Validation Loss: 0.5250\n",
      "[Trial 153] Epoch 51/60, Training Loss: 0.6054, Validation Loss: 0.5760\n",
      "[Trial 159] Epoch 31/60, Training Loss: 0.6415, Validation Loss: 0.5984\n",
      "[Trial 161] Epoch 13/60, Training Loss: 0.8010, Validation Loss: 0.8012\n",
      "[Trial 151] Epoch 55/60, Training Loss: 0.5788, Validation Loss: 0.5026\n",
      "[Trial 162] Epoch 12/60, Training Loss: 0.8019, Validation Loss: 0.7782\n",
      "[Trial 149] Epoch 55/60, Training Loss: 0.5669, Validation Loss: 0.4895\n",
      "[Trial 160] Epoch 30/60, Training Loss: 0.6084, Validation Loss: 0.6061\n",
      "[Trial 156] Epoch 51/60, Training Loss: 0.5615, Validation Loss: 0.5211\n",
      "[Trial 150] Epoch 53/60, Training Loss: 0.5876, Validation Loss: 0.4880\n",
      "[Trial 154] Epoch 50/60, Training Loss: 0.5744, Validation Loss: 0.5410\n",
      "[Trial 152] Epoch 51/60, Training Loss: 0.5676, Validation Loss: 0.5065\n",
      "[Trial 163] Epoch 9/60, Training Loss: 0.9363, Validation Loss: 0.7388\n",
      "[Trial 164] Epoch 8/60, Training Loss: 0.8927, Validation Loss: 0.7172\n",
      "[Trial 148] Epoch 59/60, Training Loss: 0.5643, Validation Loss: 0.5759\n",
      "[Trial 158] Epoch 33/60, Training Loss: 0.6436, Validation Loss: 0.5548\n",
      "[Trial 157] Epoch 42/60, Training Loss: 0.5743, Validation Loss: 0.5493\n",
      "[Trial 153] Epoch 52/60, Training Loss: 0.6154, Validation Loss: 0.5753\n",
      "[Trial 159] Epoch 32/60, Training Loss: 0.6008, Validation Loss: 0.5282\n",
      "[Trial 161] Epoch 14/60, Training Loss: 0.7913, Validation Loss: 0.6829\n",
      "[Trial 162] Epoch 13/60, Training Loss: 0.7910, Validation Loss: 0.9452\n",
      "[Trial 151] Epoch 56/60, Training Loss: 0.5840, Validation Loss: 0.5065\n",
      "[Trial 160] Epoch 31/60, Training Loss: 0.6056, Validation Loss: 0.5049\n",
      "[Trial 149] Epoch 56/60, Training Loss: 0.5602, Validation Loss: 0.4998\n",
      "[Trial 156] Epoch 52/60, Training Loss: 0.5466, Validation Loss: 0.4887\n",
      "[Trial 150] Epoch 54/60, Training Loss: 0.5879, Validation Loss: 0.4894\n",
      "[Trial 154] Epoch 51/60, Training Loss: 0.5690, Validation Loss: 0.5172\n",
      "[Trial 152] Epoch 52/60, Training Loss: 0.5749, Validation Loss: 0.5267\n",
      "[Trial 163] Epoch 10/60, Training Loss: 0.9108, Validation Loss: 0.8121\n",
      "[Trial 164] Epoch 9/60, Training Loss: 0.9007, Validation Loss: 0.9559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:32:36,171] Trial 148 finished with value: 0.4939771190285683 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.002056073226549424, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 148] Epoch 60/60, Training Loss: 0.5743, Validation Loss: 0.5454\n",
      "[Trial 158] Epoch 34/60, Training Loss: 0.6407, Validation Loss: 0.5531\n",
      "[Trial 157] Epoch 43/60, Training Loss: 0.5691, Validation Loss: 0.5221\n",
      "[Trial 153] Epoch 53/60, Training Loss: 0.6006, Validation Loss: 0.5463\n",
      "[Trial 159] Epoch 33/60, Training Loss: 0.5994, Validation Loss: 0.5425\n",
      "[Trial 161] Epoch 15/60, Training Loss: 0.7584, Validation Loss: 0.6535\n",
      "[Trial 162] Epoch 14/60, Training Loss: 0.7891, Validation Loss: 0.7296\n",
      "[Trial 151] Epoch 57/60, Training Loss: 0.5819, Validation Loss: 0.4902\n",
      "[Trial 156] Epoch 53/60, Training Loss: 0.5462, Validation Loss: 0.4899\n",
      "[Trial 160] Epoch 32/60, Training Loss: 0.5995, Validation Loss: 0.5998\n",
      "[Trial 149] Epoch 57/60, Training Loss: 0.5527, Validation Loss: 0.4838\n",
      "[Trial 150] Epoch 55/60, Training Loss: 0.5876, Validation Loss: 0.4923\n",
      "[Trial 154] Epoch 52/60, Training Loss: 0.5663, Validation Loss: 0.4988\n",
      "[Trial 152] Epoch 53/60, Training Loss: 0.5583, Validation Loss: 0.4643\n",
      "[Trial 163] Epoch 11/60, Training Loss: 0.8953, Validation Loss: 0.7192\n",
      "[Trial 164] Epoch 10/60, Training Loss: 0.8612, Validation Loss: 0.7091\n",
      "[Trial 165] Epoch 1/60, Training Loss: 3.4292, Validation Loss: 1.7188\n",
      "[Trial 158] Epoch 35/60, Training Loss: 0.6328, Validation Loss: 0.5443\n",
      "[Trial 157] Epoch 44/60, Training Loss: 0.5731, Validation Loss: 0.5267\n",
      "[Trial 159] Epoch 34/60, Training Loss: 0.5978, Validation Loss: 0.5237\n",
      "[Trial 153] Epoch 54/60, Training Loss: 0.5941, Validation Loss: 0.5529\n",
      "[Trial 161] Epoch 16/60, Training Loss: 0.7433, Validation Loss: 0.7107\n",
      "[Trial 162] Epoch 15/60, Training Loss: 0.7565, Validation Loss: 0.7664\n",
      "[Trial 151] Epoch 58/60, Training Loss: 0.5812, Validation Loss: 0.5011\n",
      "[Trial 156] Epoch 54/60, Training Loss: 0.5334, Validation Loss: 0.4798\n",
      "[Trial 160] Epoch 33/60, Training Loss: 0.6054, Validation Loss: 0.5333\n",
      "[Trial 149] Epoch 58/60, Training Loss: 0.5502, Validation Loss: 0.4773\n",
      "[Trial 150] Epoch 56/60, Training Loss: 0.5804, Validation Loss: 0.4931\n",
      "[Trial 154] Epoch 53/60, Training Loss: 0.5623, Validation Loss: 0.4995\n",
      "[Trial 152] Epoch 54/60, Training Loss: 0.5586, Validation Loss: 0.4989\n",
      "[Trial 163] Epoch 12/60, Training Loss: 0.8654, Validation Loss: 0.8218\n",
      "[Trial 164] Epoch 11/60, Training Loss: 0.8183, Validation Loss: 0.6744\n",
      "[Trial 165] Epoch 2/60, Training Loss: 1.8500, Validation Loss: 1.3271\n",
      "[Trial 158] Epoch 36/60, Training Loss: 0.6222, Validation Loss: 0.5235\n",
      "[Trial 157] Epoch 45/60, Training Loss: 0.5598, Validation Loss: 0.5395\n",
      "[Trial 159] Epoch 35/60, Training Loss: 0.5904, Validation Loss: 0.5131\n",
      "[Trial 161] Epoch 17/60, Training Loss: 0.7442, Validation Loss: 0.7126\n",
      "[Trial 162] Epoch 16/60, Training Loss: 0.6883, Validation Loss: 0.5641\n",
      "[Trial 153] Epoch 55/60, Training Loss: 0.6086, Validation Loss: 0.5077\n",
      "[Trial 151] Epoch 59/60, Training Loss: 0.5783, Validation Loss: 0.4974\n",
      "[Trial 156] Epoch 55/60, Training Loss: 0.5317, Validation Loss: 0.4867\n",
      "[Trial 160] Epoch 34/60, Training Loss: 0.5839, Validation Loss: 0.5298\n",
      "[Trial 149] Epoch 59/60, Training Loss: 0.5494, Validation Loss: 0.4791\n",
      "[Trial 150] Epoch 57/60, Training Loss: 0.5722, Validation Loss: 0.4880\n",
      "[Trial 154] Epoch 54/60, Training Loss: 0.5915, Validation Loss: 0.5204\n",
      "[Trial 163] Epoch 13/60, Training Loss: 0.9163, Validation Loss: 0.7343\n",
      "[Trial 152] Epoch 55/60, Training Loss: 0.5622, Validation Loss: 0.4887\n",
      "[Trial 164] Epoch 12/60, Training Loss: 0.8225, Validation Loss: 0.6393\n",
      "[Trial 165] Epoch 3/60, Training Loss: 1.5610, Validation Loss: 1.0473\n",
      "[Trial 158] Epoch 37/60, Training Loss: 0.6177, Validation Loss: 0.5262\n",
      "[Trial 157] Epoch 46/60, Training Loss: 0.5490, Validation Loss: 0.4745\n",
      "[Trial 159] Epoch 36/60, Training Loss: 0.5900, Validation Loss: 0.5402\n",
      "[Trial 161] Epoch 18/60, Training Loss: 0.7534, Validation Loss: 0.6210\n",
      "[Trial 162] Epoch 17/60, Training Loss: 0.6703, Validation Loss: 0.7868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:36:05,500] Trial 151 finished with value: 0.49024677524964017 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.002141401488605839, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 151] Epoch 60/60, Training Loss: 0.5827, Validation Loss: 0.4964\n",
      "[Trial 156] Epoch 56/60, Training Loss: 0.5350, Validation Loss: 0.4875\n",
      "[Trial 153] Epoch 56/60, Training Loss: 0.5651, Validation Loss: 0.4967\n",
      "[Trial 160] Epoch 35/60, Training Loss: 0.5848, Validation Loss: 0.5214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:36:21,859] Trial 149 finished with value: 0.4773096079627673 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.002025893095272421, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 149] Epoch 60/60, Training Loss: 0.5501, Validation Loss: 0.4840\n",
      "[Trial 150] Epoch 58/60, Training Loss: 0.5709, Validation Loss: 0.4974\n",
      "[Trial 163] Epoch 14/60, Training Loss: 0.8410, Validation Loss: 0.7451\n",
      "[Trial 154] Epoch 55/60, Training Loss: 0.5804, Validation Loss: 0.5200\n",
      "[Trial 164] Epoch 13/60, Training Loss: 0.7970, Validation Loss: 0.6506\n",
      "[Trial 152] Epoch 56/60, Training Loss: 0.5528, Validation Loss: 0.4823\n",
      "[Trial 165] Epoch 4/60, Training Loss: 1.3274, Validation Loss: 1.1363\n",
      "[Trial 158] Epoch 38/60, Training Loss: 0.6116, Validation Loss: 0.5225\n",
      "[Trial 157] Epoch 47/60, Training Loss: 0.5448, Validation Loss: 0.5025\n",
      "[Trial 159] Epoch 37/60, Training Loss: 0.6115, Validation Loss: 0.6366\n",
      "[Trial 162] Epoch 18/60, Training Loss: 0.6786, Validation Loss: 0.6110\n",
      "[Trial 161] Epoch 19/60, Training Loss: 0.7026, Validation Loss: 0.8465\n",
      "[Trial 156] Epoch 57/60, Training Loss: 0.5487, Validation Loss: 0.4821\n",
      "[Trial 166] Epoch 1/60, Training Loss: 3.6142, Validation Loss: 2.2468\n",
      "[Trial 160] Epoch 36/60, Training Loss: 0.5726, Validation Loss: 0.4777\n",
      "[Trial 153] Epoch 57/60, Training Loss: 0.5687, Validation Loss: 0.5083\n",
      "[Trial 167] Epoch 1/60, Training Loss: 3.7150, Validation Loss: 1.7671\n",
      "[Trial 163] Epoch 15/60, Training Loss: 0.8343, Validation Loss: 0.6397\n",
      "[Trial 150] Epoch 59/60, Training Loss: 0.5757, Validation Loss: 0.4828\n",
      "[Trial 164] Epoch 14/60, Training Loss: 0.8166, Validation Loss: 1.2492\n",
      "[Trial 154] Epoch 56/60, Training Loss: 0.5749, Validation Loss: 0.4984\n",
      "[Trial 152] Epoch 57/60, Training Loss: 0.5534, Validation Loss: 0.4963\n",
      "[Trial 165] Epoch 5/60, Training Loss: 1.2239, Validation Loss: 0.9456\n",
      "[Trial 157] Epoch 48/60, Training Loss: 0.5481, Validation Loss: 0.5013\n",
      "[Trial 158] Epoch 39/60, Training Loss: 0.6158, Validation Loss: 0.5288\n",
      "[Trial 159] Epoch 38/60, Training Loss: 0.6002, Validation Loss: 0.5311\n",
      "[Trial 162] Epoch 19/60, Training Loss: 0.6793, Validation Loss: 0.5974\n",
      "[Trial 161] Epoch 20/60, Training Loss: 0.7368, Validation Loss: 0.7754\n",
      "[Trial 156] Epoch 58/60, Training Loss: 0.5474, Validation Loss: 0.4901\n",
      "[Trial 166] Epoch 2/60, Training Loss: 1.9063, Validation Loss: 1.5748\n",
      "[Trial 160] Epoch 37/60, Training Loss: 0.5822, Validation Loss: 0.5823\n",
      "[Trial 153] Epoch 58/60, Training Loss: 0.5644, Validation Loss: 0.4913\n",
      "[Trial 167] Epoch 2/60, Training Loss: 1.9725, Validation Loss: 1.3559\n",
      "[Trial 163] Epoch 16/60, Training Loss: 0.7939, Validation Loss: 0.7348\n",
      "[Trial 164] Epoch 15/60, Training Loss: 0.8868, Validation Loss: 1.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:38:33,240] Trial 150 finished with value: 0.48170359383026756 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0020463313780613194, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 150] Epoch 60/60, Training Loss: 0.5760, Validation Loss: 0.4817\n",
      "[Trial 152] Epoch 58/60, Training Loss: 0.5508, Validation Loss: 0.4589\n",
      "[Trial 154] Epoch 57/60, Training Loss: 0.5641, Validation Loss: 0.5235\n",
      "[Trial 165] Epoch 6/60, Training Loss: 1.1335, Validation Loss: 0.9170\n",
      "[Trial 157] Epoch 49/60, Training Loss: 0.5377, Validation Loss: 0.4839\n",
      "[Trial 158] Epoch 40/60, Training Loss: 0.6161, Validation Loss: 0.5213\n",
      "[Trial 159] Epoch 39/60, Training Loss: 0.5953, Validation Loss: 0.5561\n",
      "[Trial 162] Epoch 20/60, Training Loss: 0.6944, Validation Loss: 0.6553\n",
      "[Trial 156] Epoch 59/60, Training Loss: 0.5306, Validation Loss: 0.4795\n",
      "[Trial 161] Epoch 21/60, Training Loss: 0.7105, Validation Loss: 0.6447\n",
      "[Trial 160] Epoch 38/60, Training Loss: 0.5867, Validation Loss: 0.5274\n",
      "[Trial 166] Epoch 3/60, Training Loss: 1.4555, Validation Loss: 1.0077\n",
      "[Trial 153] Epoch 59/60, Training Loss: 0.5686, Validation Loss: 0.4951\n",
      "[Trial 167] Epoch 3/60, Training Loss: 1.5277, Validation Loss: 1.0053\n",
      "[Trial 164] Epoch 16/60, Training Loss: 0.8332, Validation Loss: 0.7702\n",
      "[Trial 163] Epoch 17/60, Training Loss: 0.8009, Validation Loss: 0.6233\n",
      "[Trial 168] Epoch 1/60, Training Loss: 3.8129, Validation Loss: 1.7250\n",
      "[Trial 152] Epoch 59/60, Training Loss: 0.5523, Validation Loss: 0.4659\n",
      "[Trial 154] Epoch 58/60, Training Loss: 0.5628, Validation Loss: 0.5180\n",
      "[Trial 165] Epoch 7/60, Training Loss: 1.0838, Validation Loss: 0.9177\n",
      "[Trial 157] Epoch 50/60, Training Loss: 0.5416, Validation Loss: 0.4904\n",
      "[Trial 158] Epoch 41/60, Training Loss: 0.6123, Validation Loss: 0.5254\n",
      "[Trial 159] Epoch 40/60, Training Loss: 0.6027, Validation Loss: 0.5979\n",
      "[Trial 162] Epoch 21/60, Training Loss: 0.6734, Validation Loss: 0.6188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:40:06,509] Trial 156 finished with value: 0.47950647125641505 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0061659824028770195, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 156] Epoch 60/60, Training Loss: 0.5309, Validation Loss: 0.4819\n",
      "[Trial 161] Epoch 22/60, Training Loss: 0.6974, Validation Loss: 0.7328\n",
      "[Trial 160] Epoch 39/60, Training Loss: 0.5842, Validation Loss: 0.5225\n",
      "[Trial 166] Epoch 4/60, Training Loss: 1.1260, Validation Loss: 0.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:40:21,939] Trial 153 finished with value: 0.4912560080488523 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.0013679326004975756, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 153] Epoch 60/60, Training Loss: 0.5807, Validation Loss: 0.6091\n",
      "[Trial 167] Epoch 4/60, Training Loss: 1.2499, Validation Loss: 1.4917\n",
      "[Trial 164] Epoch 17/60, Training Loss: 0.7900, Validation Loss: 0.7280\n",
      "[Trial 163] Epoch 18/60, Training Loss: 0.7660, Validation Loss: 0.6063\n",
      "[Trial 168] Epoch 2/60, Training Loss: 2.0113, Validation Loss: 1.4034\n",
      "[Trial 165] Epoch 8/60, Training Loss: 1.0102, Validation Loss: 0.8173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:40:43,884] Trial 152 finished with value: 0.45890136857827507 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.005741556335824061, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 152] Epoch 60/60, Training Loss: 0.5530, Validation Loss: 0.4796\n",
      "[Trial 154] Epoch 59/60, Training Loss: 0.5674, Validation Loss: 0.5237\n",
      "[Trial 157] Epoch 51/60, Training Loss: 0.5370, Validation Loss: 0.4942\n",
      "[Trial 158] Epoch 42/60, Training Loss: 0.6143, Validation Loss: 0.5094\n",
      "[Trial 170] Epoch 1/60, Training Loss: 5.0559, Validation Loss: 2.2747\n",
      "[Trial 159] Epoch 41/60, Training Loss: 0.6111, Validation Loss: 0.5263\n",
      "[Trial 162] Epoch 22/60, Training Loss: 0.6593, Validation Loss: 0.5456\n",
      "[Trial 169] Epoch 1/60, Training Loss: 3.8548, Validation Loss: 2.2506\n",
      "[Trial 160] Epoch 40/60, Training Loss: 0.5812, Validation Loss: 0.5589\n",
      "[Trial 161] Epoch 23/60, Training Loss: 0.6834, Validation Loss: 0.5728\n",
      "[Trial 166] Epoch 5/60, Training Loss: 1.0216, Validation Loss: 0.8942\n",
      "[Trial 171] Epoch 1/60, Training Loss: 4.4788, Validation Loss: 1.6964\n",
      "[Trial 167] Epoch 5/60, Training Loss: 1.1767, Validation Loss: 0.8838\n",
      "[Trial 164] Epoch 18/60, Training Loss: 0.7672, Validation Loss: 0.7523\n",
      "[Trial 163] Epoch 19/60, Training Loss: 0.7528, Validation Loss: 0.6624\n",
      "[Trial 168] Epoch 3/60, Training Loss: 1.7532, Validation Loss: 1.2388\n",
      "[Trial 170] Epoch 2/60, Training Loss: 2.1198, Validation Loss: 1.4923\n",
      "[Trial 165] Epoch 9/60, Training Loss: 0.9576, Validation Loss: 0.7509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:41:47,938] Trial 154 finished with value: 0.49839180360237756 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.006380749296695525, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 154] Epoch 60/60, Training Loss: 0.5645, Validation Loss: 0.5081\n",
      "[Trial 171] Epoch 2/60, Training Loss: 1.9019, Validation Loss: 1.2860\n",
      "[Trial 157] Epoch 52/60, Training Loss: 0.5356, Validation Loss: 0.4741\n",
      "[Trial 158] Epoch 43/60, Training Loss: 0.6129, Validation Loss: 0.5171\n",
      "[Trial 159] Epoch 42/60, Training Loss: 0.5699, Validation Loss: 0.5169\n",
      "[Trial 162] Epoch 23/60, Training Loss: 0.6563, Validation Loss: 0.7134\n",
      "[Trial 169] Epoch 2/60, Training Loss: 2.0383, Validation Loss: 1.6288\n",
      "[Trial 170] Epoch 3/60, Training Loss: 1.8583, Validation Loss: 1.5283\n",
      "[Trial 160] Epoch 41/60, Training Loss: 0.5929, Validation Loss: 0.5482\n",
      "[Trial 161] Epoch 24/60, Training Loss: 0.6808, Validation Loss: 0.6524\n",
      "[Trial 166] Epoch 6/60, Training Loss: 0.9841, Validation Loss: 1.8249\n",
      "[Trial 167] Epoch 6/60, Training Loss: 1.0014, Validation Loss: 0.8240\n",
      "[Trial 172] Epoch 1/60, Training Loss: 4.5734, Validation Loss: 1.9331\n",
      "[Trial 164] Epoch 19/60, Training Loss: 0.6961, Validation Loss: 0.5642\n",
      "[Trial 171] Epoch 3/60, Training Loss: 1.5795, Validation Loss: 1.0889\n",
      "[Trial 168] Epoch 4/60, Training Loss: 1.5907, Validation Loss: 1.1569\n",
      "[Trial 163] Epoch 20/60, Training Loss: 0.7730, Validation Loss: 0.6269\n",
      "[Trial 165] Epoch 10/60, Training Loss: 0.9194, Validation Loss: 0.7188\n",
      "[Trial 170] Epoch 4/60, Training Loss: 1.7089, Validation Loss: 1.2222\n",
      "[Trial 157] Epoch 53/60, Training Loss: 0.5405, Validation Loss: 0.4959\n",
      "[Trial 158] Epoch 44/60, Training Loss: 0.6079, Validation Loss: 0.5141\n",
      "[Trial 172] Epoch 2/60, Training Loss: 2.0062, Validation Loss: 1.3667\n",
      "[Trial 171] Epoch 4/60, Training Loss: 1.4667, Validation Loss: 1.0474\n",
      "[Trial 159] Epoch 43/60, Training Loss: 0.5654, Validation Loss: 0.5130\n",
      "[Trial 162] Epoch 24/60, Training Loss: 0.6881, Validation Loss: 0.5982\n",
      "[Trial 160] Epoch 42/60, Training Loss: 0.5996, Validation Loss: 0.4975\n",
      "[Trial 169] Epoch 3/60, Training Loss: 1.5882, Validation Loss: 1.2604\n",
      "[Trial 161] Epoch 25/60, Training Loss: 0.7196, Validation Loss: 0.7708\n",
      "[Trial 166] Epoch 7/60, Training Loss: 0.9473, Validation Loss: 0.7178\n",
      "[Trial 170] Epoch 5/60, Training Loss: 1.4970, Validation Loss: 1.1254\n",
      "[Trial 167] Epoch 7/60, Training Loss: 0.9667, Validation Loss: 1.1241\n",
      "[Trial 164] Epoch 20/60, Training Loss: 0.6797, Validation Loss: 0.6148\n",
      "[Trial 168] Epoch 5/60, Training Loss: 1.4136, Validation Loss: 1.1057\n",
      "[Trial 163] Epoch 21/60, Training Loss: 0.7536, Validation Loss: 0.6831\n",
      "[Trial 172] Epoch 3/60, Training Loss: 1.6297, Validation Loss: 1.2866\n",
      "[Trial 171] Epoch 5/60, Training Loss: 1.2341, Validation Loss: 0.8978\n",
      "[Trial 165] Epoch 11/60, Training Loss: 0.9008, Validation Loss: 0.7245\n",
      "[Trial 170] Epoch 6/60, Training Loss: 1.3278, Validation Loss: 1.0491\n",
      "[Trial 157] Epoch 54/60, Training Loss: 0.5362, Validation Loss: 0.4853\n",
      "[Trial 158] Epoch 45/60, Training Loss: 0.6069, Validation Loss: 0.5088\n",
      "[Trial 159] Epoch 44/60, Training Loss: 0.5628, Validation Loss: 0.5044\n",
      "[Trial 162] Epoch 25/60, Training Loss: 0.6502, Validation Loss: 0.5835\n",
      "[Trial 160] Epoch 43/60, Training Loss: 0.5537, Validation Loss: 0.4705\n",
      "[Trial 169] Epoch 4/60, Training Loss: 1.2629, Validation Loss: 1.1653\n",
      "[Trial 172] Epoch 4/60, Training Loss: 1.4101, Validation Loss: 1.0134\n",
      "[Trial 161] Epoch 26/60, Training Loss: 0.6863, Validation Loss: 0.5904\n",
      "[Trial 171] Epoch 6/60, Training Loss: 1.1215, Validation Loss: 0.8440\n",
      "[Trial 166] Epoch 8/60, Training Loss: 0.8434, Validation Loss: 0.7782\n",
      "[Trial 167] Epoch 8/60, Training Loss: 0.9714, Validation Loss: 0.9066\n",
      "[Trial 164] Epoch 21/60, Training Loss: 0.6712, Validation Loss: 0.5648\n",
      "[Trial 168] Epoch 6/60, Training Loss: 1.2590, Validation Loss: 0.9034\n",
      "[Trial 170] Epoch 7/60, Training Loss: 1.2200, Validation Loss: 0.9048\n",
      "[Trial 163] Epoch 22/60, Training Loss: 0.7591, Validation Loss: 0.7909\n",
      "[Trial 165] Epoch 12/60, Training Loss: 0.8878, Validation Loss: 0.6730\n",
      "[Trial 172] Epoch 5/60, Training Loss: 1.2734, Validation Loss: 0.9642\n",
      "[Trial 171] Epoch 7/60, Training Loss: 1.0512, Validation Loss: 0.8096\n",
      "[Trial 157] Epoch 55/60, Training Loss: 0.5331, Validation Loss: 0.4876\n",
      "[Trial 158] Epoch 46/60, Training Loss: 0.6091, Validation Loss: 0.5258\n",
      "[Trial 159] Epoch 45/60, Training Loss: 0.5691, Validation Loss: 0.5058\n",
      "[Trial 160] Epoch 44/60, Training Loss: 0.5589, Validation Loss: 0.4876\n",
      "[Trial 162] Epoch 26/60, Training Loss: 0.6557, Validation Loss: 0.5540\n",
      "[Trial 170] Epoch 8/60, Training Loss: 1.1206, Validation Loss: 0.9134\n",
      "[Trial 169] Epoch 5/60, Training Loss: 1.1391, Validation Loss: 1.1125\n",
      "[Trial 161] Epoch 27/60, Training Loss: 0.6923, Validation Loss: 0.9242\n",
      "[Trial 166] Epoch 9/60, Training Loss: 0.8389, Validation Loss: 0.7677\n",
      "[Trial 167] Epoch 9/60, Training Loss: 0.8814, Validation Loss: 0.6554\n",
      "[Trial 172] Epoch 6/60, Training Loss: 1.1506, Validation Loss: 1.0667\n",
      "[Trial 171] Epoch 8/60, Training Loss: 0.9832, Validation Loss: 0.7654\n",
      "[Trial 164] Epoch 22/60, Training Loss: 0.6771, Validation Loss: 0.6298\n",
      "[Trial 168] Epoch 7/60, Training Loss: 1.1328, Validation Loss: 0.9514\n",
      "[Trial 163] Epoch 23/60, Training Loss: 0.7615, Validation Loss: 0.6220\n",
      "[Trial 165] Epoch 13/60, Training Loss: 0.8521, Validation Loss: 0.7040\n",
      "[Trial 170] Epoch 9/60, Training Loss: 1.0334, Validation Loss: 0.8656\n",
      "[Trial 157] Epoch 56/60, Training Loss: 0.5336, Validation Loss: 0.4818\n",
      "[Trial 172] Epoch 7/60, Training Loss: 1.1026, Validation Loss: 0.8820\n",
      "[Trial 171] Epoch 9/60, Training Loss: 0.9418, Validation Loss: 0.8053\n",
      "[Trial 158] Epoch 47/60, Training Loss: 0.6140, Validation Loss: 0.5141\n",
      "[Trial 159] Epoch 46/60, Training Loss: 0.5814, Validation Loss: 0.5320\n",
      "[Trial 160] Epoch 45/60, Training Loss: 0.5571, Validation Loss: 0.4769\n",
      "[Trial 162] Epoch 27/60, Training Loss: 0.6342, Validation Loss: 0.5525\n",
      "[Trial 169] Epoch 6/60, Training Loss: 1.0981, Validation Loss: 0.8621\n",
      "[Trial 161] Epoch 28/60, Training Loss: 0.7002, Validation Loss: 0.5837\n",
      "[Trial 170] Epoch 10/60, Training Loss: 0.9777, Validation Loss: 0.7045\n",
      "[Trial 166] Epoch 10/60, Training Loss: 0.8956, Validation Loss: 0.6773\n",
      "[Trial 167] Epoch 10/60, Training Loss: 0.8665, Validation Loss: 0.7337\n",
      "[Trial 164] Epoch 23/60, Training Loss: 0.6858, Validation Loss: 0.5653\n",
      "[Trial 168] Epoch 8/60, Training Loss: 1.0394, Validation Loss: 0.8338\n",
      "[Trial 172] Epoch 8/60, Training Loss: 1.0034, Validation Loss: 0.8995\n",
      "[Trial 171] Epoch 10/60, Training Loss: 0.9393, Validation Loss: 0.7105\n",
      "[Trial 163] Epoch 24/60, Training Loss: 0.7405, Validation Loss: 0.8510\n",
      "[Trial 165] Epoch 14/60, Training Loss: 0.8427, Validation Loss: 0.6746\n",
      "[Trial 170] Epoch 11/60, Training Loss: 0.9274, Validation Loss: 0.8278\n",
      "[Trial 157] Epoch 57/60, Training Loss: 0.5648, Validation Loss: 0.5063\n",
      "[Trial 158] Epoch 48/60, Training Loss: 0.6166, Validation Loss: 0.5364\n",
      "[Trial 160] Epoch 46/60, Training Loss: 0.5512, Validation Loss: 0.4853\n",
      "[Trial 159] Epoch 47/60, Training Loss: 0.5739, Validation Loss: 0.5158\n",
      "[Trial 162] Epoch 28/60, Training Loss: 0.6427, Validation Loss: 0.6237\n",
      "[Trial 172] Epoch 9/60, Training Loss: 0.9887, Validation Loss: 0.8716\n",
      "[Trial 171] Epoch 11/60, Training Loss: 0.8839, Validation Loss: 0.7547\n",
      "[Trial 169] Epoch 7/60, Training Loss: 0.9902, Validation Loss: 0.8986\n",
      "[Trial 161] Epoch 29/60, Training Loss: 0.6763, Validation Loss: 0.6598\n",
      "[Trial 166] Epoch 11/60, Training Loss: 0.8173, Validation Loss: 0.8378\n",
      "[Trial 167] Epoch 11/60, Training Loss: 0.8378, Validation Loss: 0.8881\n",
      "[Trial 164] Epoch 24/60, Training Loss: 0.6756, Validation Loss: 0.6109\n",
      "[Trial 168] Epoch 9/60, Training Loss: 0.9889, Validation Loss: 0.7614\n",
      "[Trial 170] Epoch 12/60, Training Loss: 0.9055, Validation Loss: 0.7925\n",
      "[Trial 163] Epoch 25/60, Training Loss: 0.6930, Validation Loss: 0.5698\n",
      "[Trial 165] Epoch 15/60, Training Loss: 0.8242, Validation Loss: 0.6737\n",
      "[Trial 172] Epoch 10/60, Training Loss: 0.9386, Validation Loss: 0.7183\n",
      "[Trial 171] Epoch 12/60, Training Loss: 0.8802, Validation Loss: 0.7043\n",
      "[Trial 157] Epoch 58/60, Training Loss: 0.5606, Validation Loss: 0.5388\n",
      "[Trial 158] Epoch 49/60, Training Loss: 0.6151, Validation Loss: 0.5122\n",
      "[Trial 160] Epoch 47/60, Training Loss: 0.5515, Validation Loss: 0.4800\n",
      "[Trial 159] Epoch 48/60, Training Loss: 0.5582, Validation Loss: 0.5014\n",
      "[Trial 170] Epoch 13/60, Training Loss: 0.8767, Validation Loss: 0.7029\n",
      "[Trial 162] Epoch 29/60, Training Loss: 0.6078, Validation Loss: 0.5408\n",
      "[Trial 169] Epoch 8/60, Training Loss: 0.9292, Validation Loss: 0.8158\n",
      "[Trial 161] Epoch 30/60, Training Loss: 0.6180, Validation Loss: 0.5839\n",
      "[Trial 167] Epoch 12/60, Training Loss: 0.8641, Validation Loss: 0.7353\n",
      "[Trial 172] Epoch 11/60, Training Loss: 0.8880, Validation Loss: 0.7491\n",
      "[Trial 171] Epoch 13/60, Training Loss: 0.8520, Validation Loss: 0.6211\n",
      "[Trial 166] Epoch 12/60, Training Loss: 0.8159, Validation Loss: 0.6950\n",
      "[Trial 164] Epoch 25/60, Training Loss: 0.6657, Validation Loss: 0.6270\n",
      "[Trial 168] Epoch 10/60, Training Loss: 0.9649, Validation Loss: 0.7651\n",
      "[Trial 165] Epoch 16/60, Training Loss: 0.8102, Validation Loss: 0.6967\n",
      "[Trial 163] Epoch 26/60, Training Loss: 0.6725, Validation Loss: 0.5661\n",
      "[Trial 170] Epoch 14/60, Training Loss: 0.8584, Validation Loss: 0.7220\n",
      "[Trial 157] Epoch 59/60, Training Loss: 0.5258, Validation Loss: 0.4812\n",
      "[Trial 172] Epoch 12/60, Training Loss: 0.8996, Validation Loss: 0.7208\n",
      "[Trial 171] Epoch 14/60, Training Loss: 0.8187, Validation Loss: 0.6496\n",
      "[Trial 158] Epoch 50/60, Training Loss: 0.6140, Validation Loss: 0.5260\n",
      "[Trial 160] Epoch 48/60, Training Loss: 0.5453, Validation Loss: 0.4731\n",
      "[Trial 159] Epoch 49/60, Training Loss: 0.5615, Validation Loss: 0.5070\n",
      "[Trial 162] Epoch 30/60, Training Loss: 0.5964, Validation Loss: 0.5361\n",
      "[Trial 169] Epoch 9/60, Training Loss: 0.8880, Validation Loss: 0.7396\n",
      "[Trial 170] Epoch 15/60, Training Loss: 0.8652, Validation Loss: 0.6841\n",
      "[Trial 161] Epoch 31/60, Training Loss: 0.6271, Validation Loss: 0.5518\n",
      "[Trial 167] Epoch 13/60, Training Loss: 0.8270, Validation Loss: 0.9334\n",
      "[Trial 166] Epoch 13/60, Training Loss: 0.7872, Validation Loss: 0.6762\n",
      "[Trial 164] Epoch 26/60, Training Loss: 0.6375, Validation Loss: 0.5480\n",
      "[Trial 168] Epoch 11/60, Training Loss: 0.9248, Validation Loss: 0.7215\n",
      "[Trial 172] Epoch 13/60, Training Loss: 0.8403, Validation Loss: 0.7342\n",
      "[Trial 171] Epoch 15/60, Training Loss: 0.8055, Validation Loss: 0.6200\n",
      "[Trial 165] Epoch 17/60, Training Loss: 0.8004, Validation Loss: 0.6580\n",
      "[Trial 163] Epoch 27/60, Training Loss: 0.6828, Validation Loss: 0.5605\n",
      "[Trial 170] Epoch 16/60, Training Loss: 0.8121, Validation Loss: 0.7253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:49:30,830] Trial 157 finished with value: 0.4741221492489179 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006417598416605169, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 157] Epoch 60/60, Training Loss: 0.5242, Validation Loss: 0.4883\n",
      "[Trial 160] Epoch 49/60, Training Loss: 0.5426, Validation Loss: 0.4961\n",
      "[Trial 159] Epoch 50/60, Training Loss: 0.5558, Validation Loss: 0.5275\n",
      "[Trial 158] Epoch 51/60, Training Loss: 0.6042, Validation Loss: 0.5164\n",
      "[Trial 162] Epoch 31/60, Training Loss: 0.5945, Validation Loss: 0.5268\n",
      "[Trial 172] Epoch 14/60, Training Loss: 0.8415, Validation Loss: 0.6913\n",
      "[Trial 171] Epoch 16/60, Training Loss: 0.7803, Validation Loss: 0.5925\n",
      "[Trial 169] Epoch 10/60, Training Loss: 0.8534, Validation Loss: 0.8519\n",
      "[Trial 161] Epoch 32/60, Training Loss: 0.6113, Validation Loss: 0.5332\n",
      "[Trial 167] Epoch 14/60, Training Loss: 0.9320, Validation Loss: 0.6661\n",
      "[Trial 164] Epoch 27/60, Training Loss: 0.6354, Validation Loss: 0.5671\n",
      "[Trial 166] Epoch 14/60, Training Loss: 0.7707, Validation Loss: 0.6830\n",
      "[Trial 168] Epoch 12/60, Training Loss: 0.9024, Validation Loss: 0.6908\n",
      "[Trial 170] Epoch 17/60, Training Loss: 0.8281, Validation Loss: 0.7336\n",
      "[Trial 165] Epoch 18/60, Training Loss: 0.7863, Validation Loss: 0.6566\n",
      "[Trial 163] Epoch 28/60, Training Loss: 0.6599, Validation Loss: 0.5666\n",
      "[Trial 172] Epoch 15/60, Training Loss: 0.8169, Validation Loss: 0.6605\n",
      "[Trial 171] Epoch 17/60, Training Loss: 0.7574, Validation Loss: 0.6228\n",
      "[Trial 173] Epoch 1/60, Training Loss: 3.4746, Validation Loss: 1.8785\n",
      "[Trial 170] Epoch 18/60, Training Loss: 0.7856, Validation Loss: 0.6277\n",
      "[Trial 160] Epoch 50/60, Training Loss: 0.5436, Validation Loss: 0.4651\n",
      "[Trial 159] Epoch 51/60, Training Loss: 0.5647, Validation Loss: 0.5020\n",
      "[Trial 162] Epoch 32/60, Training Loss: 0.5904, Validation Loss: 0.5162\n",
      "[Trial 158] Epoch 52/60, Training Loss: 0.5970, Validation Loss: 0.5171\n",
      "[Trial 169] Epoch 11/60, Training Loss: 0.8435, Validation Loss: 0.6588\n",
      "[Trial 171] Epoch 18/60, Training Loss: 0.7557, Validation Loss: 0.5845\n",
      "[Trial 172] Epoch 16/60, Training Loss: 0.7935, Validation Loss: 0.6242\n",
      "[Trial 161] Epoch 33/60, Training Loss: 0.6076, Validation Loss: 0.5722\n",
      "[Trial 167] Epoch 15/60, Training Loss: 0.7910, Validation Loss: 0.9425\n",
      "[Trial 164] Epoch 28/60, Training Loss: 0.6393, Validation Loss: 0.5435\n",
      "[Trial 166] Epoch 15/60, Training Loss: 0.7696, Validation Loss: 0.6890\n",
      "[Trial 168] Epoch 13/60, Training Loss: 0.8761, Validation Loss: 0.6686\n",
      "[Trial 165] Epoch 19/60, Training Loss: 0.7820, Validation Loss: 0.6813\n",
      "[Trial 170] Epoch 19/60, Training Loss: 0.7734, Validation Loss: 0.5998\n",
      "[Trial 163] Epoch 29/60, Training Loss: 0.6527, Validation Loss: 0.5632\n",
      "[Trial 171] Epoch 19/60, Training Loss: 0.7471, Validation Loss: 0.6500\n",
      "[Trial 172] Epoch 17/60, Training Loss: 0.7642, Validation Loss: 0.6036\n",
      "[Trial 173] Epoch 2/60, Training Loss: 1.7369, Validation Loss: 1.3385\n",
      "[Trial 160] Epoch 51/60, Training Loss: 0.5337, Validation Loss: 0.4633\n",
      "[Trial 159] Epoch 52/60, Training Loss: 0.5592, Validation Loss: 0.5079\n",
      "[Trial 162] Epoch 33/60, Training Loss: 0.5942, Validation Loss: 0.5551\n",
      "[Trial 158] Epoch 53/60, Training Loss: 0.5920, Validation Loss: 0.5138\n",
      "[Trial 170] Epoch 20/60, Training Loss: 0.7546, Validation Loss: 0.6652\n",
      "[Trial 169] Epoch 12/60, Training Loss: 0.8062, Validation Loss: 0.6970\n",
      "[Trial 167] Epoch 16/60, Training Loss: 0.7653, Validation Loss: 0.5842\n",
      "[Trial 161] Epoch 34/60, Training Loss: 0.6118, Validation Loss: 0.5333\n",
      "[Trial 164] Epoch 29/60, Training Loss: 0.6125, Validation Loss: 0.5038\n",
      "[Trial 168] Epoch 14/60, Training Loss: 0.8634, Validation Loss: 0.7044\n",
      "[Trial 166] Epoch 16/60, Training Loss: 0.7460, Validation Loss: 0.6288\n",
      "[Trial 171] Epoch 20/60, Training Loss: 0.7303, Validation Loss: 0.6469\n",
      "[Trial 172] Epoch 18/60, Training Loss: 0.7889, Validation Loss: 0.6664\n",
      "[Trial 165] Epoch 20/60, Training Loss: 0.7832, Validation Loss: 0.6812\n",
      "[Trial 163] Epoch 30/60, Training Loss: 0.6569, Validation Loss: 0.6270\n",
      "[Trial 170] Epoch 21/60, Training Loss: 0.7481, Validation Loss: 0.6249\n",
      "[Trial 173] Epoch 3/60, Training Loss: 1.3727, Validation Loss: 1.2790\n",
      "[Trial 160] Epoch 52/60, Training Loss: 0.5372, Validation Loss: 0.4663\n",
      "[Trial 171] Epoch 21/60, Training Loss: 0.7280, Validation Loss: 0.5531\n",
      "[Trial 159] Epoch 53/60, Training Loss: 0.5614, Validation Loss: 0.5138\n",
      "[Trial 172] Epoch 19/60, Training Loss: 0.7723, Validation Loss: 0.6439\n",
      "[Trial 162] Epoch 34/60, Training Loss: 0.5973, Validation Loss: 0.5268\n",
      "[Trial 158] Epoch 54/60, Training Loss: 0.6003, Validation Loss: 0.4980\n",
      "[Trial 169] Epoch 13/60, Training Loss: 0.8039, Validation Loss: 0.8520\n",
      "[Trial 167] Epoch 17/60, Training Loss: 0.7011, Validation Loss: 0.5680\n",
      "[Trial 161] Epoch 35/60, Training Loss: 0.6184, Validation Loss: 0.5507\n",
      "[Trial 164] Epoch 30/60, Training Loss: 0.6175, Validation Loss: 0.5631\n",
      "[Trial 168] Epoch 15/60, Training Loss: 0.8376, Validation Loss: 0.6308\n",
      "[Trial 170] Epoch 22/60, Training Loss: 0.7435, Validation Loss: 0.6404\n",
      "[Trial 166] Epoch 17/60, Training Loss: 0.7572, Validation Loss: 0.6946\n",
      "[Trial 165] Epoch 21/60, Training Loss: 0.7551, Validation Loss: 0.7285\n",
      "[Trial 171] Epoch 22/60, Training Loss: 0.7094, Validation Loss: 0.5705\n",
      "[Trial 172] Epoch 20/60, Training Loss: 0.7534, Validation Loss: 0.5879\n",
      "[Trial 163] Epoch 31/60, Training Loss: 0.6793, Validation Loss: 0.6681\n",
      "[Trial 160] Epoch 53/60, Training Loss: 0.5336, Validation Loss: 0.4592\n",
      "[Trial 173] Epoch 4/60, Training Loss: 1.1810, Validation Loss: 1.1447\n",
      "[Trial 170] Epoch 23/60, Training Loss: 0.7461, Validation Loss: 0.5911\n",
      "[Trial 159] Epoch 54/60, Training Loss: 0.5545, Validation Loss: 0.4943\n",
      "[Trial 162] Epoch 35/60, Training Loss: 0.5887, Validation Loss: 0.5038\n",
      "[Trial 158] Epoch 55/60, Training Loss: 0.5920, Validation Loss: 0.5068\n",
      "[Trial 171] Epoch 23/60, Training Loss: 0.7095, Validation Loss: 0.5872\n",
      "[Trial 172] Epoch 21/60, Training Loss: 0.7480, Validation Loss: 0.6174\n",
      "[Trial 169] Epoch 14/60, Training Loss: 0.8240, Validation Loss: 0.6537\n",
      "[Trial 167] Epoch 18/60, Training Loss: 0.7162, Validation Loss: 0.7292\n",
      "[Trial 164] Epoch 31/60, Training Loss: 0.6200, Validation Loss: 0.5090\n",
      "[Trial 161] Epoch 36/60, Training Loss: 0.6151, Validation Loss: 0.5555\n",
      "[Trial 168] Epoch 16/60, Training Loss: 0.8276, Validation Loss: 0.6531\n",
      "[Trial 166] Epoch 18/60, Training Loss: 0.7503, Validation Loss: 0.8301\n",
      "[Trial 165] Epoch 22/60, Training Loss: 0.7633, Validation Loss: 0.6383\n",
      "[Trial 170] Epoch 24/60, Training Loss: 0.7253, Validation Loss: 0.6401\n",
      "[Trial 163] Epoch 32/60, Training Loss: 0.6858, Validation Loss: 0.5629\n",
      "[Trial 171] Epoch 24/60, Training Loss: 0.6952, Validation Loss: 0.5442\n",
      "[Trial 172] Epoch 22/60, Training Loss: 0.7356, Validation Loss: 0.5955\n",
      "[Trial 160] Epoch 54/60, Training Loss: 0.5356, Validation Loss: 0.4676\n",
      "[Trial 173] Epoch 5/60, Training Loss: 1.0941, Validation Loss: 0.9151\n",
      "[Trial 159] Epoch 55/60, Training Loss: 0.5632, Validation Loss: 0.5417\n",
      "[Trial 162] Epoch 36/60, Training Loss: 0.5845, Validation Loss: 0.5262\n",
      "[Trial 158] Epoch 56/60, Training Loss: 0.5849, Validation Loss: 0.4954\n",
      "[Trial 170] Epoch 25/60, Training Loss: 0.7248, Validation Loss: 0.6212\n",
      "[Trial 167] Epoch 19/60, Training Loss: 0.7508, Validation Loss: 0.6280\n",
      "[Trial 169] Epoch 15/60, Training Loss: 0.7697, Validation Loss: 0.6694\n",
      "[Trial 164] Epoch 32/60, Training Loss: 0.6027, Validation Loss: 0.5287\n",
      "[Trial 171] Epoch 25/60, Training Loss: 0.6748, Validation Loss: 0.5899\n",
      "[Trial 168] Epoch 17/60, Training Loss: 0.8241, Validation Loss: 0.6457\n",
      "[Trial 161] Epoch 37/60, Training Loss: 0.6152, Validation Loss: 0.6219\n",
      "[Trial 172] Epoch 23/60, Training Loss: 0.7142, Validation Loss: 0.5874\n",
      "[Trial 166] Epoch 19/60, Training Loss: 0.7554, Validation Loss: 0.7208\n",
      "[Trial 165] Epoch 23/60, Training Loss: 0.7683, Validation Loss: 0.6541\n",
      "[Trial 163] Epoch 33/60, Training Loss: 0.6579, Validation Loss: 0.6012\n",
      "[Trial 170] Epoch 26/60, Training Loss: 0.7105, Validation Loss: 0.6797\n",
      "[Trial 171] Epoch 26/60, Training Loss: 0.6817, Validation Loss: 0.5382\n",
      "[Trial 160] Epoch 55/60, Training Loss: 0.5261, Validation Loss: 0.4596\n",
      "[Trial 172] Epoch 24/60, Training Loss: 0.7315, Validation Loss: 0.5819\n",
      "[Trial 159] Epoch 56/60, Training Loss: 0.5585, Validation Loss: 0.4972\n",
      "[Trial 173] Epoch 6/60, Training Loss: 1.0241, Validation Loss: 1.4306\n",
      "[Trial 162] Epoch 37/60, Training Loss: 0.5917, Validation Loss: 0.5611\n",
      "[Trial 158] Epoch 57/60, Training Loss: 0.5922, Validation Loss: 0.5020\n",
      "[Trial 167] Epoch 20/60, Training Loss: 0.7056, Validation Loss: 0.5988\n",
      "[Trial 164] Epoch 33/60, Training Loss: 0.6095, Validation Loss: 0.5379\n",
      "[Trial 169] Epoch 16/60, Training Loss: 0.7564, Validation Loss: 0.7187\n",
      "[Trial 168] Epoch 18/60, Training Loss: 0.8018, Validation Loss: 0.6091\n",
      "[Trial 170] Epoch 27/60, Training Loss: 0.7081, Validation Loss: 0.6115\n",
      "[Trial 161] Epoch 38/60, Training Loss: 0.6074, Validation Loss: 0.5572\n",
      "[Trial 165] Epoch 24/60, Training Loss: 0.7939, Validation Loss: 0.6489\n",
      "[Trial 166] Epoch 20/60, Training Loss: 0.7414, Validation Loss: 0.5693\n",
      "[Trial 171] Epoch 27/60, Training Loss: 0.6778, Validation Loss: 0.5958\n",
      "[Trial 172] Epoch 25/60, Training Loss: 0.6979, Validation Loss: 0.5574\n",
      "[Trial 163] Epoch 34/60, Training Loss: 0.6369, Validation Loss: 0.5468\n",
      "[Trial 160] Epoch 56/60, Training Loss: 0.5419, Validation Loss: 0.4928\n",
      "[Trial 170] Epoch 28/60, Training Loss: 0.6922, Validation Loss: 0.6487\n",
      "[Trial 159] Epoch 57/60, Training Loss: 0.5601, Validation Loss: 0.4875\n",
      "[Trial 173] Epoch 7/60, Training Loss: 0.9825, Validation Loss: 1.0273\n",
      "[Trial 162] Epoch 38/60, Training Loss: 0.5914, Validation Loss: 0.5128\n",
      "[Trial 171] Epoch 28/60, Training Loss: 0.6860, Validation Loss: 0.6134\n",
      "[Trial 172] Epoch 26/60, Training Loss: 0.7074, Validation Loss: 0.5607\n",
      "[Trial 158] Epoch 58/60, Training Loss: 0.5945, Validation Loss: 0.4989\n",
      "[Trial 167] Epoch 21/60, Training Loss: 0.6986, Validation Loss: 0.6625\n",
      "[Trial 164] Epoch 34/60, Training Loss: 0.6161, Validation Loss: 0.5301\n",
      "[Trial 169] Epoch 17/60, Training Loss: 0.7439, Validation Loss: 0.7235\n",
      "[Trial 168] Epoch 19/60, Training Loss: 0.7854, Validation Loss: 0.6099\n",
      "[Trial 161] Epoch 39/60, Training Loss: 0.5805, Validation Loss: 0.5015\n",
      "[Trial 165] Epoch 25/60, Training Loss: 0.7513, Validation Loss: 0.5909\n",
      "[Trial 166] Epoch 21/60, Training Loss: 0.7040, Validation Loss: 0.6721\n",
      "[Trial 170] Epoch 29/60, Training Loss: 0.7089, Validation Loss: 0.6748\n",
      "[Trial 171] Epoch 29/60, Training Loss: 0.6806, Validation Loss: 0.5991\n",
      "[Trial 172] Epoch 27/60, Training Loss: 0.6976, Validation Loss: 0.5615\n",
      "[Trial 163] Epoch 35/60, Training Loss: 0.6332, Validation Loss: 0.5574\n",
      "[Trial 160] Epoch 57/60, Training Loss: 0.5401, Validation Loss: 0.4659\n",
      "[Trial 159] Epoch 58/60, Training Loss: 0.5639, Validation Loss: 0.5388\n",
      "[Trial 162] Epoch 39/60, Training Loss: 0.5849, Validation Loss: 0.5081\n",
      "[Trial 173] Epoch 8/60, Training Loss: 0.9258, Validation Loss: 0.7929\n",
      "[Trial 170] Epoch 30/60, Training Loss: 0.6471, Validation Loss: 0.5260\n",
      "[Trial 158] Epoch 59/60, Training Loss: 0.5928, Validation Loss: 0.4899\n",
      "[Trial 167] Epoch 22/60, Training Loss: 0.7102, Validation Loss: 0.5619\n",
      "[Trial 164] Epoch 35/60, Training Loss: 0.6070, Validation Loss: 0.5507\n",
      "[Trial 171] Epoch 30/60, Training Loss: 0.6613, Validation Loss: 0.5675\n",
      "[Trial 169] Epoch 18/60, Training Loss: 0.7323, Validation Loss: 0.8120\n",
      "[Trial 168] Epoch 20/60, Training Loss: 0.7803, Validation Loss: 0.6132\n",
      "[Trial 172] Epoch 28/60, Training Loss: 0.6802, Validation Loss: 0.5760\n",
      "[Trial 161] Epoch 40/60, Training Loss: 0.5716, Validation Loss: 0.5164\n",
      "[Trial 165] Epoch 26/60, Training Loss: 0.7229, Validation Loss: 0.6232\n",
      "[Trial 166] Epoch 22/60, Training Loss: 0.7070, Validation Loss: 0.7113\n",
      "[Trial 170] Epoch 31/60, Training Loss: 0.6301, Validation Loss: 0.5150\n",
      "[Trial 163] Epoch 36/60, Training Loss: 0.6365, Validation Loss: 0.5266\n",
      "[Trial 171] Epoch 31/60, Training Loss: 0.6490, Validation Loss: 0.5478\n",
      "[Trial 160] Epoch 58/60, Training Loss: 0.5292, Validation Loss: 0.4776\n",
      "[Trial 172] Epoch 29/60, Training Loss: 0.6746, Validation Loss: 0.5748\n",
      "[Trial 159] Epoch 59/60, Training Loss: 0.5536, Validation Loss: 0.4973\n",
      "[Trial 162] Epoch 40/60, Training Loss: 0.5889, Validation Loss: 0.5525\n",
      "[Trial 173] Epoch 9/60, Training Loss: 0.8889, Validation Loss: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:58:27,149] Trial 158 finished with value: 0.4898915226260821 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0012914993324991736, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 158] Epoch 60/60, Training Loss: 0.5834, Validation Loss: 0.4905\n",
      "[Trial 167] Epoch 23/60, Training Loss: 0.6874, Validation Loss: 0.5560\n",
      "[Trial 164] Epoch 36/60, Training Loss: 0.5835, Validation Loss: 0.4906\n",
      "[Trial 168] Epoch 21/60, Training Loss: 0.7707, Validation Loss: 0.6486\n",
      "[Trial 169] Epoch 19/60, Training Loss: 0.7629, Validation Loss: 0.6537\n",
      "[Trial 170] Epoch 32/60, Training Loss: 0.6349, Validation Loss: 0.5570\n",
      "[Trial 165] Epoch 27/60, Training Loss: 0.7187, Validation Loss: 0.5740\n",
      "[Trial 161] Epoch 41/60, Training Loss: 0.5699, Validation Loss: 0.5120\n",
      "[Trial 171] Epoch 32/60, Training Loss: 0.6057, Validation Loss: 0.4826\n",
      "[Trial 172] Epoch 30/60, Training Loss: 0.6894, Validation Loss: 0.5849\n",
      "[Trial 166] Epoch 23/60, Training Loss: 0.7371, Validation Loss: 1.0880\n",
      "[Trial 163] Epoch 37/60, Training Loss: 0.6179, Validation Loss: 0.5214\n",
      "[Trial 174] Epoch 1/60, Training Loss: 4.6071, Validation Loss: 1.9409\n",
      "[Trial 160] Epoch 59/60, Training Loss: 0.5356, Validation Loss: 0.4667\n",
      "[Trial 170] Epoch 33/60, Training Loss: 0.6426, Validation Loss: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 11:59:11,731] Trial 159 finished with value: 0.48750137637058893 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006462305813922278, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 159] Epoch 60/60, Training Loss: 0.5567, Validation Loss: 0.5080\n",
      "[Trial 162] Epoch 41/60, Training Loss: 0.5804, Validation Loss: 0.5863\n",
      "[Trial 171] Epoch 33/60, Training Loss: 0.5839, Validation Loss: 0.4973\n",
      "[Trial 173] Epoch 10/60, Training Loss: 0.8487, Validation Loss: 0.8934\n",
      "[Trial 172] Epoch 31/60, Training Loss: 0.6331, Validation Loss: 0.5095\n",
      "[Trial 167] Epoch 24/60, Training Loss: 0.6919, Validation Loss: 0.7077\n",
      "[Trial 164] Epoch 37/60, Training Loss: 0.5693, Validation Loss: 0.4994\n",
      "[Trial 168] Epoch 22/60, Training Loss: 0.7513, Validation Loss: 0.6337\n",
      "[Trial 169] Epoch 20/60, Training Loss: 0.7310, Validation Loss: 0.6535\n",
      "[Trial 165] Epoch 28/60, Training Loss: 0.7207, Validation Loss: 0.6259\n",
      "[Trial 174] Epoch 2/60, Training Loss: 1.9499, Validation Loss: 1.4661\n",
      "[Trial 161] Epoch 42/60, Training Loss: 0.5704, Validation Loss: 0.5249\n",
      "[Trial 170] Epoch 34/60, Training Loss: 0.6352, Validation Loss: 0.5321\n",
      "[Trial 175] Epoch 1/60, Training Loss: 4.4017, Validation Loss: 1.9561\n",
      "[Trial 166] Epoch 24/60, Training Loss: 0.7252, Validation Loss: 0.8192\n",
      "[Trial 171] Epoch 34/60, Training Loss: 0.5990, Validation Loss: 0.4979\n",
      "[Trial 172] Epoch 32/60, Training Loss: 0.6188, Validation Loss: 0.5090\n",
      "[Trial 163] Epoch 38/60, Training Loss: 0.6137, Validation Loss: 0.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:00:04,999] Trial 160 finished with value: 0.45642521381378176 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006322225629408339, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 160] Epoch 60/60, Training Loss: 0.5278, Validation Loss: 0.4564\n",
      "[Trial 174] Epoch 3/60, Training Loss: 1.5527, Validation Loss: 1.1326\n",
      "[Trial 162] Epoch 42/60, Training Loss: 0.5704, Validation Loss: 0.5160\n",
      "[Trial 173] Epoch 11/60, Training Loss: 0.8572, Validation Loss: 0.8645\n",
      "[Trial 170] Epoch 35/60, Training Loss: 0.6263, Validation Loss: 0.5478\n",
      "[Trial 175] Epoch 2/60, Training Loss: 1.8745, Validation Loss: 1.3647\n",
      "[Trial 171] Epoch 35/60, Training Loss: 0.5885, Validation Loss: 0.4691\n",
      "[Trial 167] Epoch 25/60, Training Loss: 0.7152, Validation Loss: 0.5804\n",
      "[Trial 164] Epoch 38/60, Training Loss: 0.5742, Validation Loss: 0.4869\n",
      "[Trial 168] Epoch 23/60, Training Loss: 0.7482, Validation Loss: 0.5863\n",
      "[Trial 172] Epoch 33/60, Training Loss: 0.6107, Validation Loss: 0.5033\n",
      "[Trial 169] Epoch 21/60, Training Loss: 0.7060, Validation Loss: 0.6206\n",
      "[Trial 165] Epoch 29/60, Training Loss: 0.7117, Validation Loss: 0.6829\n",
      "[Trial 161] Epoch 43/60, Training Loss: 0.5737, Validation Loss: 0.5170\n",
      "[Trial 176] Epoch 1/60, Training Loss: 4.8816, Validation Loss: 1.9214\n",
      "[Trial 166] Epoch 25/60, Training Loss: 0.7249, Validation Loss: 0.5991\n",
      "[Trial 174] Epoch 4/60, Training Loss: 1.3489, Validation Loss: 0.9984\n",
      "[Trial 170] Epoch 36/60, Training Loss: 0.6266, Validation Loss: 0.5324\n",
      "[Trial 175] Epoch 3/60, Training Loss: 1.5678, Validation Loss: 1.1628\n",
      "[Trial 171] Epoch 36/60, Training Loss: 0.5916, Validation Loss: 0.4867\n",
      "[Trial 163] Epoch 39/60, Training Loss: 0.6138, Validation Loss: 0.5367\n",
      "[Trial 172] Epoch 34/60, Training Loss: 0.6152, Validation Loss: 0.5432\n",
      "[Trial 162] Epoch 43/60, Training Loss: 0.5692, Validation Loss: 0.4827\n",
      "[Trial 176] Epoch 2/60, Training Loss: 1.8630, Validation Loss: 1.2447\n",
      "[Trial 173] Epoch 12/60, Training Loss: 0.8371, Validation Loss: 0.7566\n",
      "[Trial 167] Epoch 26/60, Training Loss: 0.6795, Validation Loss: 0.5819\n",
      "[Trial 164] Epoch 39/60, Training Loss: 0.5932, Validation Loss: 0.5429\n",
      "[Trial 174] Epoch 5/60, Training Loss: 1.2532, Validation Loss: 1.0253\n",
      "[Trial 168] Epoch 24/60, Training Loss: 0.7559, Validation Loss: 0.7219\n",
      "[Trial 170] Epoch 37/60, Training Loss: 0.6333, Validation Loss: 0.5289\n",
      "[Trial 169] Epoch 22/60, Training Loss: 0.7211, Validation Loss: 0.6614\n",
      "[Trial 165] Epoch 30/60, Training Loss: 0.7257, Validation Loss: 0.5965\n",
      "[Trial 175] Epoch 4/60, Training Loss: 1.3072, Validation Loss: 1.0572\n",
      "[Trial 171] Epoch 37/60, Training Loss: 0.5839, Validation Loss: 0.5562\n",
      "[Trial 161] Epoch 44/60, Training Loss: 0.5654, Validation Loss: 0.4920\n",
      "[Trial 172] Epoch 35/60, Training Loss: 0.6137, Validation Loss: 0.5573\n",
      "[Trial 166] Epoch 26/60, Training Loss: 0.7009, Validation Loss: 0.6453\n",
      "[Trial 176] Epoch 3/60, Training Loss: 1.5783, Validation Loss: 1.1740\n",
      "[Trial 174] Epoch 6/60, Training Loss: 1.1076, Validation Loss: 1.0087\n",
      "[Trial 163] Epoch 40/60, Training Loss: 0.6137, Validation Loss: 0.5228\n",
      "[Trial 170] Epoch 38/60, Training Loss: 0.5998, Validation Loss: 0.4926\n",
      "[Trial 175] Epoch 5/60, Training Loss: 1.1704, Validation Loss: 1.0998\n",
      "[Trial 171] Epoch 38/60, Training Loss: 0.5968, Validation Loss: 0.4833\n",
      "[Trial 162] Epoch 44/60, Training Loss: 0.5578, Validation Loss: 0.5140\n",
      "[Trial 172] Epoch 36/60, Training Loss: 0.6105, Validation Loss: 0.5027\n",
      "[Trial 173] Epoch 13/60, Training Loss: 0.7950, Validation Loss: 0.7592\n",
      "[Trial 167] Epoch 27/60, Training Loss: 0.6800, Validation Loss: 0.6226\n",
      "[Trial 164] Epoch 40/60, Training Loss: 0.5885, Validation Loss: 0.5016\n",
      "[Trial 176] Epoch 4/60, Training Loss: 1.3478, Validation Loss: 1.2237\n",
      "[Trial 168] Epoch 25/60, Training Loss: 0.8056, Validation Loss: 0.7092\n",
      "[Trial 165] Epoch 31/60, Training Loss: 0.7075, Validation Loss: 0.5811\n",
      "[Trial 169] Epoch 23/60, Training Loss: 0.6980, Validation Loss: 0.7539\n",
      "[Trial 174] Epoch 7/60, Training Loss: 1.0242, Validation Loss: 0.8533\n",
      "[Trial 170] Epoch 39/60, Training Loss: 0.5870, Validation Loss: 0.5086\n",
      "[Trial 161] Epoch 45/60, Training Loss: 0.5646, Validation Loss: 0.5225\n",
      "[Trial 171] Epoch 39/60, Training Loss: 0.5885, Validation Loss: 0.4746\n",
      "[Trial 175] Epoch 6/60, Training Loss: 1.0898, Validation Loss: 0.9135\n",
      "[Trial 166] Epoch 27/60, Training Loss: 0.6422, Validation Loss: 0.5336\n",
      "[Trial 172] Epoch 37/60, Training Loss: 0.6123, Validation Loss: 0.5043\n",
      "[Trial 176] Epoch 5/60, Training Loss: 1.2452, Validation Loss: 1.1515\n",
      "[Trial 163] Epoch 41/60, Training Loss: 0.6077, Validation Loss: 0.5208\n",
      "[Trial 174] Epoch 8/60, Training Loss: 1.0040, Validation Loss: 0.7853\n",
      "[Trial 162] Epoch 45/60, Training Loss: 0.5599, Validation Loss: 0.5519\n",
      "[Trial 170] Epoch 40/60, Training Loss: 0.5941, Validation Loss: 0.4926\n",
      "[Trial 171] Epoch 40/60, Training Loss: 0.5808, Validation Loss: 0.4987\n",
      "[Trial 175] Epoch 7/60, Training Loss: 1.0068, Validation Loss: 0.8151\n",
      "[Trial 173] Epoch 14/60, Training Loss: 0.7907, Validation Loss: 0.7364\n",
      "[Trial 167] Epoch 28/60, Training Loss: 0.6994, Validation Loss: 0.5857\n",
      "[Trial 164] Epoch 41/60, Training Loss: 0.5796, Validation Loss: 0.5034\n",
      "[Trial 168] Epoch 26/60, Training Loss: 0.7514, Validation Loss: 0.6073\n",
      "[Trial 172] Epoch 38/60, Training Loss: 0.6054, Validation Loss: 0.5148\n",
      "[Trial 165] Epoch 32/60, Training Loss: 0.7144, Validation Loss: 0.5997\n",
      "[Trial 169] Epoch 24/60, Training Loss: 0.7160, Validation Loss: 0.6249\n",
      "[Trial 176] Epoch 6/60, Training Loss: 1.1585, Validation Loss: 1.1807\n",
      "[Trial 161] Epoch 46/60, Training Loss: 0.5659, Validation Loss: 0.4913\n",
      "[Trial 174] Epoch 9/60, Training Loss: 0.9398, Validation Loss: 0.8205\n",
      "[Trial 170] Epoch 41/60, Training Loss: 0.5911, Validation Loss: 0.4882\n",
      "[Trial 166] Epoch 28/60, Training Loss: 0.6324, Validation Loss: 0.5414\n",
      "[Trial 171] Epoch 41/60, Training Loss: 0.5595, Validation Loss: 0.4492\n",
      "[Trial 175] Epoch 8/60, Training Loss: 0.9427, Validation Loss: 0.8658\n",
      "[Trial 163] Epoch 42/60, Training Loss: 0.6085, Validation Loss: 0.5187\n",
      "[Trial 172] Epoch 39/60, Training Loss: 0.6078, Validation Loss: 0.5062\n",
      "[Trial 162] Epoch 46/60, Training Loss: 0.5680, Validation Loss: 0.4838\n",
      "[Trial 176] Epoch 7/60, Training Loss: 1.0779, Validation Loss: 0.8714\n",
      "[Trial 167] Epoch 29/60, Training Loss: 0.6860, Validation Loss: 0.6294\n",
      "[Trial 164] Epoch 42/60, Training Loss: 0.5766, Validation Loss: 0.5204\n",
      "[Trial 173] Epoch 15/60, Training Loss: 0.7714, Validation Loss: 0.8078\n",
      "[Trial 168] Epoch 27/60, Training Loss: 0.7427, Validation Loss: 0.6045\n",
      "[Trial 174] Epoch 10/60, Training Loss: 0.9529, Validation Loss: 0.7762\n",
      "[Trial 170] Epoch 42/60, Training Loss: 0.5877, Validation Loss: 0.4923\n",
      "[Trial 171] Epoch 42/60, Training Loss: 0.5490, Validation Loss: 0.4598\n",
      "[Trial 165] Epoch 33/60, Training Loss: 0.7218, Validation Loss: 0.5615\n",
      "[Trial 175] Epoch 9/60, Training Loss: 0.9289, Validation Loss: 0.7904\n",
      "[Trial 169] Epoch 25/60, Training Loss: 0.6938, Validation Loss: 0.6392\n",
      "[Trial 172] Epoch 40/60, Training Loss: 0.6283, Validation Loss: 0.5182\n",
      "[Trial 161] Epoch 47/60, Training Loss: 0.5717, Validation Loss: 0.5198\n",
      "[Trial 176] Epoch 8/60, Training Loss: 1.0175, Validation Loss: 0.7633\n",
      "[Trial 166] Epoch 29/60, Training Loss: 0.6201, Validation Loss: 0.5144\n",
      "[Trial 170] Epoch 43/60, Training Loss: 0.5859, Validation Loss: 0.4919\n",
      "[Trial 174] Epoch 11/60, Training Loss: 0.8882, Validation Loss: 0.7962\n",
      "[Trial 171] Epoch 43/60, Training Loss: 0.5516, Validation Loss: 0.4747\n",
      "[Trial 163] Epoch 43/60, Training Loss: 0.6124, Validation Loss: 0.5368\n",
      "[Trial 175] Epoch 10/60, Training Loss: 0.8732, Validation Loss: 0.7119\n",
      "[Trial 162] Epoch 47/60, Training Loss: 0.5549, Validation Loss: 0.5034\n",
      "[Trial 172] Epoch 41/60, Training Loss: 0.6027, Validation Loss: 0.5180\n",
      "[Trial 167] Epoch 30/60, Training Loss: 0.6415, Validation Loss: 0.5487\n",
      "[Trial 164] Epoch 43/60, Training Loss: 0.5698, Validation Loss: 0.4742\n",
      "[Trial 176] Epoch 9/60, Training Loss: 0.9413, Validation Loss: 0.7723\n",
      "[Trial 173] Epoch 16/60, Training Loss: 0.7730, Validation Loss: 0.7236\n",
      "[Trial 168] Epoch 28/60, Training Loss: 0.7185, Validation Loss: 0.6715\n",
      "[Trial 165] Epoch 34/60, Training Loss: 0.6851, Validation Loss: 0.5869\n",
      "[Trial 169] Epoch 26/60, Training Loss: 0.6865, Validation Loss: 0.6468\n",
      "[Trial 170] Epoch 44/60, Training Loss: 0.5881, Validation Loss: 0.5018\n",
      "[Trial 174] Epoch 12/60, Training Loss: 0.8665, Validation Loss: 0.8320\n",
      "[Trial 171] Epoch 44/60, Training Loss: 0.5470, Validation Loss: 0.4710\n",
      "[Trial 175] Epoch 11/60, Training Loss: 0.8555, Validation Loss: 0.7494\n",
      "[Trial 161] Epoch 48/60, Training Loss: 0.5776, Validation Loss: 0.5065\n",
      "[Trial 172] Epoch 42/60, Training Loss: 0.5802, Validation Loss: 0.4880\n",
      "[Trial 166] Epoch 30/60, Training Loss: 0.6196, Validation Loss: 0.5925\n",
      "[Trial 176] Epoch 10/60, Training Loss: 0.9406, Validation Loss: 0.7907\n",
      "[Trial 163] Epoch 44/60, Training Loss: 0.6109, Validation Loss: 0.5266\n",
      "[Trial 162] Epoch 48/60, Training Loss: 0.5599, Validation Loss: 0.4918\n",
      "[Trial 170] Epoch 45/60, Training Loss: 0.5854, Validation Loss: 0.4916\n",
      "[Trial 174] Epoch 13/60, Training Loss: 0.8532, Validation Loss: 0.7255\n",
      "[Trial 171] Epoch 45/60, Training Loss: 0.5503, Validation Loss: 0.4736\n",
      "[Trial 175] Epoch 12/60, Training Loss: 0.8244, Validation Loss: 0.7052\n",
      "[Trial 167] Epoch 31/60, Training Loss: 0.6391, Validation Loss: 0.5475\n",
      "[Trial 164] Epoch 44/60, Training Loss: 0.5769, Validation Loss: 0.5021\n",
      "[Trial 168] Epoch 29/60, Training Loss: 0.7685, Validation Loss: 0.6417\n",
      "[Trial 173] Epoch 17/60, Training Loss: 0.7530, Validation Loss: 0.5947\n",
      "[Trial 172] Epoch 43/60, Training Loss: 0.5754, Validation Loss: 0.4819\n",
      "[Trial 165] Epoch 35/60, Training Loss: 0.6928, Validation Loss: 0.5727\n",
      "[Trial 176] Epoch 11/60, Training Loss: 0.9213, Validation Loss: 0.7210\n",
      "[Trial 169] Epoch 27/60, Training Loss: 0.6827, Validation Loss: 0.7902\n",
      "[Trial 161] Epoch 49/60, Training Loss: 0.5664, Validation Loss: 0.4971\n",
      "[Trial 170] Epoch 46/60, Training Loss: 0.5855, Validation Loss: 0.4919\n",
      "[Trial 171] Epoch 46/60, Training Loss: 0.5483, Validation Loss: 0.4735\n",
      "[Trial 174] Epoch 14/60, Training Loss: 0.8124, Validation Loss: 0.6692\n",
      "[Trial 175] Epoch 13/60, Training Loss: 0.8237, Validation Loss: 0.7504\n",
      "[Trial 166] Epoch 31/60, Training Loss: 0.6144, Validation Loss: 0.5270\n",
      "[Trial 172] Epoch 44/60, Training Loss: 0.5708, Validation Loss: 0.4836\n",
      "[Trial 163] Epoch 45/60, Training Loss: 0.6164, Validation Loss: 0.5214\n",
      "[Trial 176] Epoch 12/60, Training Loss: 0.8864, Validation Loss: 0.7338\n",
      "[Trial 162] Epoch 49/60, Training Loss: 0.5630, Validation Loss: 0.5085\n",
      "[Trial 167] Epoch 32/60, Training Loss: 0.6320, Validation Loss: 0.5706\n",
      "[Trial 164] Epoch 45/60, Training Loss: 0.5666, Validation Loss: 0.5063\n",
      "[Trial 168] Epoch 30/60, Training Loss: 0.6873, Validation Loss: 0.5574\n",
      "[Trial 170] Epoch 47/60, Training Loss: 0.5884, Validation Loss: 0.4969\n",
      "[Trial 171] Epoch 47/60, Training Loss: 0.5380, Validation Loss: 0.4526\n",
      "[Trial 173] Epoch 18/60, Training Loss: 0.7302, Validation Loss: 0.6693\n",
      "[Trial 165] Epoch 36/60, Training Loss: 0.6904, Validation Loss: 0.7521\n",
      "[Trial 174] Epoch 15/60, Training Loss: 0.8050, Validation Loss: 0.7230\n",
      "[Trial 175] Epoch 14/60, Training Loss: 0.7807, Validation Loss: 0.6697\n",
      "[Trial 169] Epoch 28/60, Training Loss: 0.6194, Validation Loss: 0.5510\n",
      "[Trial 172] Epoch 45/60, Training Loss: 0.5655, Validation Loss: 0.4877\n",
      "[Trial 176] Epoch 13/60, Training Loss: 0.8648, Validation Loss: 0.7521\n",
      "[Trial 161] Epoch 50/60, Training Loss: 0.5572, Validation Loss: 0.4889\n",
      "[Trial 166] Epoch 32/60, Training Loss: 0.6081, Validation Loss: 0.5345\n",
      "[Trial 170] Epoch 48/60, Training Loss: 0.5730, Validation Loss: 0.4853\n",
      "[Trial 171] Epoch 48/60, Training Loss: 0.5320, Validation Loss: 0.4467\n",
      "[Trial 174] Epoch 16/60, Training Loss: 0.7972, Validation Loss: 0.7038\n",
      "[Trial 175] Epoch 15/60, Training Loss: 0.7744, Validation Loss: 0.6406\n",
      "[Trial 163] Epoch 46/60, Training Loss: 0.6115, Validation Loss: 0.5215\n",
      "[Trial 162] Epoch 50/60, Training Loss: 0.5485, Validation Loss: 0.4937\n",
      "[Trial 172] Epoch 46/60, Training Loss: 0.5710, Validation Loss: 0.4710\n",
      "[Trial 176] Epoch 14/60, Training Loss: 0.8549, Validation Loss: 0.6850\n",
      "[Trial 167] Epoch 33/60, Training Loss: 0.6253, Validation Loss: 0.5461\n",
      "[Trial 164] Epoch 46/60, Training Loss: 0.5758, Validation Loss: 0.4949\n",
      "[Trial 168] Epoch 31/60, Training Loss: 0.6681, Validation Loss: 0.5620\n",
      "[Trial 165] Epoch 37/60, Training Loss: 0.6977, Validation Loss: 0.5803\n",
      "[Trial 173] Epoch 19/60, Training Loss: 0.7309, Validation Loss: 0.9669\n",
      "[Trial 170] Epoch 49/60, Training Loss: 0.5662, Validation Loss: 0.4854\n",
      "[Trial 171] Epoch 49/60, Training Loss: 0.5355, Validation Loss: 0.4475\n",
      "[Trial 169] Epoch 29/60, Training Loss: 0.6238, Validation Loss: 0.5525\n",
      "[Trial 174] Epoch 17/60, Training Loss: 0.7771, Validation Loss: 0.6929\n",
      "[Trial 175] Epoch 16/60, Training Loss: 0.7602, Validation Loss: 0.6460\n",
      "[Trial 172] Epoch 47/60, Training Loss: 0.5628, Validation Loss: 0.4711\n",
      "[Trial 161] Epoch 51/60, Training Loss: 0.5601, Validation Loss: 0.4937\n",
      "[Trial 176] Epoch 15/60, Training Loss: 0.8335, Validation Loss: 0.6774\n",
      "[Trial 166] Epoch 33/60, Training Loss: 0.6118, Validation Loss: 0.5296\n",
      "[Trial 163] Epoch 47/60, Training Loss: 0.6189, Validation Loss: 0.5442\n",
      "[Trial 170] Epoch 50/60, Training Loss: 0.5662, Validation Loss: 0.4803\n",
      "[Trial 171] Epoch 50/60, Training Loss: 0.5353, Validation Loss: 0.4536\n",
      "[Trial 162] Epoch 51/60, Training Loss: 0.5439, Validation Loss: 0.4862\n",
      "[Trial 174] Epoch 18/60, Training Loss: 0.7682, Validation Loss: 0.6456\n",
      "[Trial 175] Epoch 17/60, Training Loss: 0.7487, Validation Loss: 0.6180\n",
      "[Trial 164] Epoch 47/60, Training Loss: 0.5826, Validation Loss: 0.5123\n",
      "[Trial 167] Epoch 34/60, Training Loss: 0.6254, Validation Loss: 0.5228\n",
      "[Trial 168] Epoch 32/60, Training Loss: 0.6562, Validation Loss: 0.5470\n",
      "[Trial 172] Epoch 48/60, Training Loss: 0.5682, Validation Loss: 0.4833\n",
      "[Trial 165] Epoch 38/60, Training Loss: 0.6787, Validation Loss: 0.6200\n",
      "[Trial 173] Epoch 20/60, Training Loss: 0.7465, Validation Loss: 0.6086\n",
      "[Trial 176] Epoch 16/60, Training Loss: 0.8366, Validation Loss: 0.6741\n",
      "[Trial 169] Epoch 30/60, Training Loss: 0.6174, Validation Loss: 0.5594\n",
      "[Trial 171] Epoch 51/60, Training Loss: 0.5326, Validation Loss: 0.4557\n",
      "[Trial 170] Epoch 51/60, Training Loss: 0.5754, Validation Loss: 0.5104\n",
      "[Trial 161] Epoch 52/60, Training Loss: 0.5637, Validation Loss: 0.4851\n",
      "[Trial 174] Epoch 19/60, Training Loss: 0.7722, Validation Loss: 0.6760\n",
      "[Trial 175] Epoch 18/60, Training Loss: 0.7439, Validation Loss: 0.6304\n",
      "[Trial 166] Epoch 34/60, Training Loss: 0.6228, Validation Loss: 0.6052\n",
      "[Trial 172] Epoch 49/60, Training Loss: 0.5714, Validation Loss: 0.4763\n",
      "[Trial 176] Epoch 17/60, Training Loss: 0.7923, Validation Loss: 0.6930\n",
      "[Trial 163] Epoch 48/60, Training Loss: 0.6025, Validation Loss: 0.5198\n",
      "[Trial 162] Epoch 52/60, Training Loss: 0.5426, Validation Loss: 0.4851\n",
      "[Trial 164] Epoch 48/60, Training Loss: 0.5705, Validation Loss: 0.4962\n",
      "[Trial 167] Epoch 35/60, Training Loss: 0.6336, Validation Loss: 0.5711\n",
      "[Trial 171] Epoch 52/60, Training Loss: 0.5328, Validation Loss: 0.4529\n",
      "[Trial 168] Epoch 33/60, Training Loss: 0.6515, Validation Loss: 0.5435\n",
      "[Trial 170] Epoch 52/60, Training Loss: 0.5683, Validation Loss: 0.4887\n",
      "[Trial 165] Epoch 39/60, Training Loss: 0.6851, Validation Loss: 0.6019\n",
      "[Trial 175] Epoch 19/60, Training Loss: 0.7288, Validation Loss: 0.6275\n",
      "[Trial 174] Epoch 20/60, Training Loss: 0.7472, Validation Loss: 0.7003\n",
      "[Trial 173] Epoch 21/60, Training Loss: 0.7208, Validation Loss: 0.7915\n",
      "[Trial 172] Epoch 50/60, Training Loss: 0.5647, Validation Loss: 0.4759\n",
      "[Trial 169] Epoch 31/60, Training Loss: 0.6157, Validation Loss: 0.5681\n",
      "[Trial 176] Epoch 18/60, Training Loss: 0.8029, Validation Loss: 0.6678\n",
      "[Trial 161] Epoch 53/60, Training Loss: 0.5616, Validation Loss: 0.4823\n",
      "[Trial 171] Epoch 53/60, Training Loss: 0.5272, Validation Loss: 0.4508\n",
      "[Trial 170] Epoch 53/60, Training Loss: 0.5645, Validation Loss: 0.4770\n",
      "[Trial 166] Epoch 35/60, Training Loss: 0.6424, Validation Loss: 0.5924\n",
      "[Trial 175] Epoch 20/60, Training Loss: 0.7157, Validation Loss: 0.5751\n",
      "[Trial 174] Epoch 21/60, Training Loss: 0.7330, Validation Loss: 0.6179\n",
      "[Trial 163] Epoch 49/60, Training Loss: 0.6027, Validation Loss: 0.5436\n",
      "[Trial 172] Epoch 51/60, Training Loss: 0.5609, Validation Loss: 0.4731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:11:02,753] Trial 162 finished with value: 0.48268120040496193 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006171787988097564, 'batch_size': 16, 'patience': 10}. Best is trial 28 with value: 0.4444171443581581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 162] Epoch 53/60, Training Loss: 0.5380, Validation Loss: 0.4834\n",
      "[Trial 162] Early stopping after 53 epochs.\n",
      "[Trial 176] Epoch 19/60, Training Loss: 0.7931, Validation Loss: 0.6318\n",
      "[Trial 164] Epoch 49/60, Training Loss: 0.5735, Validation Loss: 0.5115\n",
      "[Trial 167] Epoch 36/60, Training Loss: 0.6326, Validation Loss: 0.5572\n",
      "[Trial 168] Epoch 34/60, Training Loss: 0.6517, Validation Loss: 0.5336\n",
      "[Trial 165] Epoch 40/60, Training Loss: 0.6384, Validation Loss: 0.5395\n",
      "[Trial 171] Epoch 54/60, Training Loss: 0.5258, Validation Loss: 0.4408\n",
      "[Trial 173] Epoch 22/60, Training Loss: 0.7640, Validation Loss: 0.6819\n",
      "[Trial 170] Epoch 54/60, Training Loss: 0.5642, Validation Loss: 0.4828\n",
      "[Trial 175] Epoch 21/60, Training Loss: 0.7244, Validation Loss: 0.6156\n",
      "[Trial 169] Epoch 32/60, Training Loss: 0.6181, Validation Loss: 0.6581\n",
      "[Trial 174] Epoch 22/60, Training Loss: 0.7409, Validation Loss: 0.6586\n",
      "[Trial 172] Epoch 52/60, Training Loss: 0.5534, Validation Loss: 0.4573\n",
      "[Trial 177] Epoch 1/60, Training Loss: 4.1935, Validation Loss: 1.9364\n",
      "[Trial 161] Epoch 54/60, Training Loss: 0.5635, Validation Loss: 0.5133\n",
      "[Trial 176] Epoch 20/60, Training Loss: 0.7639, Validation Loss: 0.6087\n",
      "[Trial 166] Epoch 36/60, Training Loss: 0.5821, Validation Loss: 0.4745\n",
      "[Trial 171] Epoch 55/60, Training Loss: 0.5207, Validation Loss: 0.4420\n",
      "[Trial 170] Epoch 55/60, Training Loss: 0.5611, Validation Loss: 0.4856\n",
      "[Trial 163] Epoch 50/60, Training Loss: 0.5955, Validation Loss: 0.4985\n",
      "[Trial 175] Epoch 22/60, Training Loss: 0.6912, Validation Loss: 0.6949\n",
      "[Trial 174] Epoch 23/60, Training Loss: 0.7116, Validation Loss: 0.6330\n",
      "[Trial 164] Epoch 50/60, Training Loss: 0.5664, Validation Loss: 0.4794\n",
      "[Trial 167] Epoch 37/60, Training Loss: 0.6213, Validation Loss: 0.5268\n",
      "[Trial 168] Epoch 35/60, Training Loss: 0.6592, Validation Loss: 0.5472\n",
      "[Trial 172] Epoch 53/60, Training Loss: 0.5448, Validation Loss: 0.4653\n",
      "[Trial 177] Epoch 2/60, Training Loss: 1.9518, Validation Loss: 1.4014\n",
      "[Trial 165] Epoch 41/60, Training Loss: 0.6256, Validation Loss: 0.5340\n",
      "[Trial 176] Epoch 21/60, Training Loss: 0.7489, Validation Loss: 0.6315\n",
      "[Trial 173] Epoch 23/60, Training Loss: 0.6509, Validation Loss: 0.5504\n",
      "[Trial 169] Epoch 33/60, Training Loss: 0.6289, Validation Loss: 0.5458\n",
      "[Trial 171] Epoch 56/60, Training Loss: 0.5174, Validation Loss: 0.4527\n",
      "[Trial 170] Epoch 56/60, Training Loss: 0.5626, Validation Loss: 0.4822\n",
      "[Trial 175] Epoch 23/60, Training Loss: 0.7016, Validation Loss: 0.5585\n",
      "[Trial 161] Epoch 55/60, Training Loss: 0.5550, Validation Loss: 0.4737\n",
      "[Trial 174] Epoch 24/60, Training Loss: 0.7155, Validation Loss: 0.6579\n",
      "[Trial 177] Epoch 3/60, Training Loss: 1.4965, Validation Loss: 1.1678\n",
      "[Trial 172] Epoch 54/60, Training Loss: 0.5474, Validation Loss: 0.4599\n",
      "[Trial 176] Epoch 22/60, Training Loss: 0.7496, Validation Loss: 0.6679\n",
      "[Trial 166] Epoch 37/60, Training Loss: 0.5853, Validation Loss: 0.5037\n",
      "[Trial 163] Epoch 51/60, Training Loss: 0.5854, Validation Loss: 0.4999\n",
      "[Trial 171] Epoch 57/60, Training Loss: 0.5243, Validation Loss: 0.4382\n",
      "[Trial 164] Epoch 51/60, Training Loss: 0.5614, Validation Loss: 0.4705\n",
      "[Trial 167] Epoch 38/60, Training Loss: 0.6286, Validation Loss: 0.5249\n",
      "[Trial 170] Epoch 57/60, Training Loss: 0.5597, Validation Loss: 0.4818\n",
      "[Trial 168] Epoch 36/60, Training Loss: 0.6649, Validation Loss: 0.6474\n",
      "[Trial 165] Epoch 42/60, Training Loss: 0.6355, Validation Loss: 0.5620\n",
      "[Trial 175] Epoch 24/60, Training Loss: 0.6914, Validation Loss: 0.6560\n",
      "[Trial 174] Epoch 25/60, Training Loss: 0.7215, Validation Loss: 0.6662\n",
      "[Trial 177] Epoch 4/60, Training Loss: 1.2731, Validation Loss: 0.9329\n",
      "[Trial 172] Epoch 55/60, Training Loss: 0.5436, Validation Loss: 0.4535\n",
      "[Trial 173] Epoch 24/60, Training Loss: 0.6607, Validation Loss: 0.5694\n",
      "[Trial 176] Epoch 23/60, Training Loss: 0.7466, Validation Loss: 0.5936\n",
      "[Trial 169] Epoch 34/60, Training Loss: 0.6049, Validation Loss: 0.6268\n",
      "[Trial 171] Epoch 58/60, Training Loss: 0.5217, Validation Loss: 0.4430\n",
      "[Trial 161] Epoch 56/60, Training Loss: 0.5545, Validation Loss: 0.5041\n",
      "[Trial 170] Epoch 58/60, Training Loss: 0.5627, Validation Loss: 0.4838\n",
      "[Trial 175] Epoch 25/60, Training Loss: 0.6927, Validation Loss: 0.5894\n",
      "[Trial 174] Epoch 26/60, Training Loss: 0.7068, Validation Loss: 0.6327\n",
      "[Trial 166] Epoch 38/60, Training Loss: 0.5800, Validation Loss: 0.5101\n",
      "[Trial 177] Epoch 5/60, Training Loss: 1.1460, Validation Loss: 0.9984\n",
      "[Trial 172] Epoch 56/60, Training Loss: 0.5484, Validation Loss: 0.4654\n",
      "[Trial 176] Epoch 24/60, Training Loss: 0.7516, Validation Loss: 0.6729\n",
      "[Trial 163] Epoch 52/60, Training Loss: 0.5863, Validation Loss: 0.5005\n",
      "[Trial 164] Epoch 52/60, Training Loss: 0.5598, Validation Loss: 0.4858\n",
      "[Trial 167] Epoch 39/60, Training Loss: 0.6240, Validation Loss: 0.5280\n",
      "[Trial 168] Epoch 37/60, Training Loss: 0.6690, Validation Loss: 0.5223\n",
      "[Trial 165] Epoch 43/60, Training Loss: 0.6349, Validation Loss: 0.5361\n",
      "[Trial 171] Epoch 59/60, Training Loss: 0.5207, Validation Loss: 0.4432\n",
      "[Trial 170] Epoch 59/60, Training Loss: 0.5615, Validation Loss: 0.4898\n",
      "[Trial 175] Epoch 26/60, Training Loss: 0.6912, Validation Loss: 0.6177\n",
      "[Trial 173] Epoch 25/60, Training Loss: 0.6516, Validation Loss: 0.5484\n",
      "[Trial 174] Epoch 27/60, Training Loss: 0.6455, Validation Loss: 0.5591\n",
      "[Trial 169] Epoch 35/60, Training Loss: 0.6208, Validation Loss: 0.5785\n",
      "[Trial 177] Epoch 6/60, Training Loss: 1.0726, Validation Loss: 0.9084\n",
      "[Trial 172] Epoch 57/60, Training Loss: 0.5455, Validation Loss: 0.4643\n",
      "[Trial 176] Epoch 25/60, Training Loss: 0.7212, Validation Loss: 0.6144\n",
      "[Trial 161] Epoch 57/60, Training Loss: 0.5600, Validation Loss: 0.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:14:51,136] Trial 171 finished with value: 0.4382066955169042 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004250162901723459, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 171] Epoch 60/60, Training Loss: 0.5221, Validation Loss: 0.4456\n",
      "[Trial 166] Epoch 39/60, Training Loss: 0.5843, Validation Loss: 0.5015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:14:56,320] Trial 170 finished with value: 0.4738396604855855 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 0.0041977272531972904, 'batch_size': 32, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 170] Epoch 60/60, Training Loss: 0.5504, Validation Loss: 0.4738\n",
      "[Trial 175] Epoch 27/60, Training Loss: 0.6720, Validation Loss: 0.6020\n",
      "[Trial 163] Epoch 53/60, Training Loss: 0.5883, Validation Loss: 0.5070\n",
      "[Trial 174] Epoch 28/60, Training Loss: 0.6292, Validation Loss: 0.5612\n",
      "[Trial 164] Epoch 53/60, Training Loss: 0.5576, Validation Loss: 0.4775\n",
      "[Trial 167] Epoch 40/60, Training Loss: 0.6232, Validation Loss: 0.5397\n",
      "[Trial 177] Epoch 7/60, Training Loss: 0.9805, Validation Loss: 0.8372\n",
      "[Trial 168] Epoch 38/60, Training Loss: 0.6555, Validation Loss: 0.5429\n",
      "[Trial 165] Epoch 44/60, Training Loss: 0.6290, Validation Loss: 0.5536\n",
      "[Trial 172] Epoch 58/60, Training Loss: 0.5467, Validation Loss: 0.4560\n",
      "[Trial 176] Epoch 26/60, Training Loss: 0.7231, Validation Loss: 0.5752\n",
      "[Trial 178] Epoch 1/60, Training Loss: 4.0403, Validation Loss: 2.0896\n",
      "[Trial 173] Epoch 26/60, Training Loss: 0.6355, Validation Loss: 0.5936\n",
      "[Trial 169] Epoch 36/60, Training Loss: 0.6004, Validation Loss: 0.5245\n",
      "[Trial 179] Epoch 1/60, Training Loss: 6.7826, Validation Loss: 2.6488\n",
      "[Trial 175] Epoch 28/60, Training Loss: 0.6659, Validation Loss: 0.5844\n",
      "[Trial 174] Epoch 29/60, Training Loss: 0.6368, Validation Loss: 0.5838\n",
      "[Trial 177] Epoch 8/60, Training Loss: 0.9564, Validation Loss: 0.8565\n",
      "[Trial 161] Epoch 58/60, Training Loss: 0.5539, Validation Loss: 0.5041\n",
      "[Trial 172] Epoch 59/60, Training Loss: 0.5427, Validation Loss: 0.4550\n",
      "[Trial 176] Epoch 27/60, Training Loss: 0.7232, Validation Loss: 0.6530\n",
      "[Trial 166] Epoch 40/60, Training Loss: 0.5747, Validation Loss: 0.5279\n",
      "[Trial 178] Epoch 2/60, Training Loss: 1.8980, Validation Loss: 1.3671\n",
      "[Trial 164] Epoch 54/60, Training Loss: 0.5552, Validation Loss: 0.4776\n",
      "[Trial 163] Epoch 54/60, Training Loss: 0.5873, Validation Loss: 0.4987\n",
      "[Trial 167] Epoch 41/60, Training Loss: 0.6013, Validation Loss: 0.5171\n",
      "[Trial 165] Epoch 45/60, Training Loss: 0.6469, Validation Loss: 0.6306\n",
      "[Trial 168] Epoch 39/60, Training Loss: 0.6585, Validation Loss: 0.6015\n",
      "[Trial 179] Epoch 2/60, Training Loss: 2.1630, Validation Loss: 1.9004\n",
      "[Trial 175] Epoch 29/60, Training Loss: 0.6145, Validation Loss: 0.5510\n",
      "[Trial 174] Epoch 30/60, Training Loss: 0.6361, Validation Loss: 0.5504\n",
      "[Trial 177] Epoch 9/60, Training Loss: 0.9424, Validation Loss: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:16:23,285] Trial 172 finished with value: 0.45351214905579884 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.00435029347796764, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 172] Epoch 60/60, Training Loss: 0.5472, Validation Loss: 0.4613\n",
      "[Trial 176] Epoch 28/60, Training Loss: 0.6971, Validation Loss: 0.5606\n",
      "[Trial 173] Epoch 27/60, Training Loss: 0.6394, Validation Loss: 0.5677\n",
      "[Trial 169] Epoch 37/60, Training Loss: 0.6135, Validation Loss: 0.6886\n",
      "[Trial 178] Epoch 3/60, Training Loss: 1.5947, Validation Loss: 1.1254\n",
      "[Trial 161] Epoch 59/60, Training Loss: 0.5576, Validation Loss: 0.5278\n",
      "[Trial 179] Epoch 3/60, Training Loss: 1.8985, Validation Loss: 1.5395\n",
      "[Trial 175] Epoch 30/60, Training Loss: 0.6052, Validation Loss: 0.5321\n",
      "[Trial 177] Epoch 10/60, Training Loss: 0.9177, Validation Loss: 0.7220\n",
      "[Trial 174] Epoch 31/60, Training Loss: 0.6261, Validation Loss: 0.5637\n",
      "[Trial 166] Epoch 41/60, Training Loss: 0.5865, Validation Loss: 0.4906\n",
      "[Trial 180] Epoch 1/60, Training Loss: 4.5443, Validation Loss: 1.8461\n",
      "[Trial 176] Epoch 29/60, Training Loss: 0.7051, Validation Loss: 0.5707\n",
      "[Trial 164] Epoch 55/60, Training Loss: 0.5465, Validation Loss: 0.4863\n",
      "[Trial 167] Epoch 42/60, Training Loss: 0.5953, Validation Loss: 0.4957\n",
      "[Trial 163] Epoch 55/60, Training Loss: 0.5853, Validation Loss: 0.5147\n",
      "[Trial 165] Epoch 46/60, Training Loss: 0.6569, Validation Loss: 0.5637\n",
      "[Trial 168] Epoch 40/60, Training Loss: 0.6558, Validation Loss: 0.5397\n",
      "[Trial 178] Epoch 4/60, Training Loss: 1.3502, Validation Loss: 0.9447\n",
      "[Trial 179] Epoch 4/60, Training Loss: 1.7037, Validation Loss: 1.3779\n",
      "[Trial 175] Epoch 31/60, Training Loss: 0.6062, Validation Loss: 0.5282\n",
      "[Trial 177] Epoch 11/60, Training Loss: 0.8878, Validation Loss: 0.8195\n",
      "[Trial 174] Epoch 32/60, Training Loss: 0.6336, Validation Loss: 0.5585\n",
      "[Trial 173] Epoch 28/60, Training Loss: 0.6405, Validation Loss: 0.6113\n",
      "[Trial 169] Epoch 38/60, Training Loss: 0.6476, Validation Loss: 0.5748\n",
      "[Trial 180] Epoch 2/60, Training Loss: 1.9237, Validation Loss: 1.4728\n",
      "[Trial 176] Epoch 30/60, Training Loss: 0.6933, Validation Loss: 0.5721\n",
      "[Trial 178] Epoch 5/60, Training Loss: 1.2111, Validation Loss: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:17:49,089] Trial 161 finished with value: 0.4736725091934204 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.005987994974031222, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 161] Epoch 60/60, Training Loss: 0.5632, Validation Loss: 0.4930\n",
      "[Trial 166] Epoch 42/60, Training Loss: 0.5693, Validation Loss: 0.4880\n",
      "[Trial 175] Epoch 32/60, Training Loss: 0.6055, Validation Loss: 0.5173\n",
      "[Trial 179] Epoch 5/60, Training Loss: 1.4481, Validation Loss: 1.1752\n",
      "[Trial 164] Epoch 56/60, Training Loss: 0.5538, Validation Loss: 0.4705\n",
      "[Trial 177] Epoch 12/60, Training Loss: 0.8789, Validation Loss: 0.7337\n",
      "[Trial 167] Epoch 43/60, Training Loss: 0.5928, Validation Loss: 0.5076\n",
      "[Trial 165] Epoch 47/60, Training Loss: 0.6240, Validation Loss: 0.5197\n",
      "[Trial 168] Epoch 41/60, Training Loss: 0.6493, Validation Loss: 0.6036\n",
      "[Trial 174] Epoch 33/60, Training Loss: 0.6220, Validation Loss: 0.5744\n",
      "[Trial 163] Epoch 56/60, Training Loss: 0.5864, Validation Loss: 0.5093\n",
      "[Trial 180] Epoch 3/60, Training Loss: 1.5642, Validation Loss: 1.2146\n",
      "[Trial 176] Epoch 31/60, Training Loss: 0.6863, Validation Loss: 0.5912\n",
      "[Trial 178] Epoch 6/60, Training Loss: 1.0806, Validation Loss: 0.8284\n",
      "[Trial 181] Epoch 1/60, Training Loss: 4.4432, Validation Loss: 1.7547\n",
      "[Trial 173] Epoch 29/60, Training Loss: 0.6581, Validation Loss: 0.5979\n",
      "[Trial 169] Epoch 39/60, Training Loss: 0.6118, Validation Loss: 0.5685\n",
      "[Trial 175] Epoch 33/60, Training Loss: 0.6070, Validation Loss: 0.5077\n",
      "[Trial 179] Epoch 6/60, Training Loss: 1.3188, Validation Loss: 1.4224\n",
      "[Trial 177] Epoch 13/60, Training Loss: 0.8411, Validation Loss: 0.6547\n",
      "[Trial 174] Epoch 34/60, Training Loss: 0.6175, Validation Loss: 0.5542\n",
      "[Trial 176] Epoch 32/60, Training Loss: 0.6820, Validation Loss: 0.5913\n",
      "[Trial 180] Epoch 4/60, Training Loss: 1.3828, Validation Loss: 1.2064\n",
      "[Trial 178] Epoch 7/60, Training Loss: 1.0317, Validation Loss: 0.8743\n",
      "[Trial 166] Epoch 43/60, Training Loss: 0.5579, Validation Loss: 0.4740\n",
      "[Trial 181] Epoch 2/60, Training Loss: 1.9635, Validation Loss: 1.3774\n",
      "[Trial 164] Epoch 57/60, Training Loss: 0.5568, Validation Loss: 0.4705\n",
      "[Trial 167] Epoch 44/60, Training Loss: 0.5928, Validation Loss: 0.5168\n",
      "[Trial 165] Epoch 48/60, Training Loss: 0.6300, Validation Loss: 0.5738\n",
      "[Trial 168] Epoch 42/60, Training Loss: 0.6595, Validation Loss: 0.5254\n",
      "[Trial 163] Epoch 57/60, Training Loss: 0.5802, Validation Loss: 0.5001\n",
      "[Trial 175] Epoch 34/60, Training Loss: 0.5930, Validation Loss: 0.5168\n",
      "[Trial 177] Epoch 14/60, Training Loss: 0.8429, Validation Loss: 0.7882\n",
      "[Trial 179] Epoch 7/60, Training Loss: 1.2133, Validation Loss: 0.9880\n",
      "[Trial 174] Epoch 35/60, Training Loss: 0.6289, Validation Loss: 0.5863\n",
      "[Trial 176] Epoch 33/60, Training Loss: 0.6821, Validation Loss: 0.5545\n",
      "[Trial 180] Epoch 5/60, Training Loss: 1.2489, Validation Loss: 0.9691\n",
      "[Trial 178] Epoch 8/60, Training Loss: 0.9705, Validation Loss: 0.8668\n",
      "[Trial 173] Epoch 30/60, Training Loss: 0.6545, Validation Loss: 0.5448\n",
      "[Trial 169] Epoch 40/60, Training Loss: 0.6087, Validation Loss: 0.5611\n",
      "[Trial 181] Epoch 3/60, Training Loss: 1.5981, Validation Loss: 1.0778\n",
      "[Trial 175] Epoch 35/60, Training Loss: 0.5984, Validation Loss: 0.5532\n",
      "[Trial 177] Epoch 15/60, Training Loss: 0.8028, Validation Loss: 0.7390\n",
      "[Trial 179] Epoch 8/60, Training Loss: 1.1523, Validation Loss: 0.9599\n",
      "[Trial 176] Epoch 34/60, Training Loss: 0.6830, Validation Loss: 0.5895\n",
      "[Trial 174] Epoch 36/60, Training Loss: 0.5913, Validation Loss: 0.5280\n",
      "[Trial 180] Epoch 6/60, Training Loss: 1.1124, Validation Loss: 0.9045\n",
      "[Trial 164] Epoch 58/60, Training Loss: 0.5464, Validation Loss: 0.4696\n",
      "[Trial 166] Epoch 44/60, Training Loss: 0.5485, Validation Loss: 0.4836\n",
      "[Trial 178] Epoch 9/60, Training Loss: 0.9467, Validation Loss: 0.7186\n",
      "[Trial 167] Epoch 45/60, Training Loss: 0.5852, Validation Loss: 0.5178\n",
      "[Trial 165] Epoch 49/60, Training Loss: 0.6296, Validation Loss: 0.5360\n",
      "[Trial 168] Epoch 43/60, Training Loss: 0.6380, Validation Loss: 0.5268\n",
      "[Trial 163] Epoch 58/60, Training Loss: 0.5796, Validation Loss: 0.5050\n",
      "[Trial 181] Epoch 4/60, Training Loss: 1.3659, Validation Loss: 1.0686\n",
      "[Trial 177] Epoch 16/60, Training Loss: 0.8159, Validation Loss: 0.6477\n",
      "[Trial 175] Epoch 36/60, Training Loss: 0.5938, Validation Loss: 0.5275\n",
      "[Trial 179] Epoch 9/60, Training Loss: 1.0549, Validation Loss: 0.8981\n",
      "[Trial 176] Epoch 35/60, Training Loss: 0.6875, Validation Loss: 0.5476\n",
      "[Trial 174] Epoch 37/60, Training Loss: 0.5882, Validation Loss: 0.5309\n",
      "[Trial 180] Epoch 7/60, Training Loss: 1.0739, Validation Loss: 0.8544\n",
      "[Trial 173] Epoch 31/60, Training Loss: 0.6341, Validation Loss: 0.5453\n",
      "[Trial 178] Epoch 10/60, Training Loss: 0.9300, Validation Loss: 0.8222\n",
      "[Trial 169] Epoch 41/60, Training Loss: 0.5937, Validation Loss: 0.6101\n",
      "[Trial 181] Epoch 5/60, Training Loss: 1.2269, Validation Loss: 1.0861\n",
      "[Trial 177] Epoch 17/60, Training Loss: 0.7814, Validation Loss: 0.6421\n",
      "[Trial 164] Epoch 59/60, Training Loss: 0.5422, Validation Loss: 0.4667\n",
      "[Trial 175] Epoch 37/60, Training Loss: 0.6036, Validation Loss: 0.5359\n",
      "[Trial 166] Epoch 45/60, Training Loss: 0.5623, Validation Loss: 0.4785\n",
      "[Trial 167] Epoch 46/60, Training Loss: 0.5928, Validation Loss: 0.5114\n",
      "[Trial 165] Epoch 50/60, Training Loss: 0.6191, Validation Loss: 0.5315\n",
      "[Trial 179] Epoch 10/60, Training Loss: 1.0528, Validation Loss: 0.8484\n",
      "[Trial 168] Epoch 44/60, Training Loss: 0.6152, Validation Loss: 0.5184\n",
      "[Trial 176] Epoch 36/60, Training Loss: 0.6704, Validation Loss: 0.5280\n",
      "[Trial 180] Epoch 8/60, Training Loss: 1.0365, Validation Loss: 0.7825\n",
      "[Trial 174] Epoch 38/60, Training Loss: 0.5875, Validation Loss: 0.5328\n",
      "[Trial 163] Epoch 59/60, Training Loss: 0.5782, Validation Loss: 0.4962\n",
      "[Trial 178] Epoch 11/60, Training Loss: 0.8879, Validation Loss: 0.6967\n",
      "[Trial 181] Epoch 6/60, Training Loss: 1.1622, Validation Loss: 0.8457\n",
      "[Trial 177] Epoch 18/60, Training Loss: 0.7597, Validation Loss: 0.6523\n",
      "[Trial 175] Epoch 38/60, Training Loss: 0.5976, Validation Loss: 0.5280\n",
      "[Trial 173] Epoch 32/60, Training Loss: 0.6191, Validation Loss: 0.5576\n",
      "[Trial 169] Epoch 42/60, Training Loss: 0.6195, Validation Loss: 0.7313\n",
      "[Trial 179] Epoch 11/60, Training Loss: 0.9741, Validation Loss: 0.9175\n",
      "[Trial 176] Epoch 37/60, Training Loss: 0.6796, Validation Loss: 0.5510\n",
      "[Trial 180] Epoch 9/60, Training Loss: 0.9703, Validation Loss: 0.8814\n",
      "[Trial 174] Epoch 39/60, Training Loss: 0.5853, Validation Loss: 0.5208\n",
      "[Trial 178] Epoch 12/60, Training Loss: 0.8680, Validation Loss: 0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:22:05,752] Trial 164 finished with value: 0.4667132650812467 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.006186704907169433, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 164] Epoch 60/60, Training Loss: 0.5421, Validation Loss: 0.4672\n",
      "[Trial 167] Epoch 47/60, Training Loss: 0.6009, Validation Loss: 0.5253\n",
      "[Trial 181] Epoch 7/60, Training Loss: 1.0515, Validation Loss: 0.8568\n",
      "[Trial 165] Epoch 51/60, Training Loss: 0.6256, Validation Loss: 0.5200\n",
      "[Trial 166] Epoch 46/60, Training Loss: 0.5533, Validation Loss: 0.4714\n",
      "[Trial 168] Epoch 45/60, Training Loss: 0.6156, Validation Loss: 0.5381\n",
      "[Trial 177] Epoch 19/60, Training Loss: 0.7708, Validation Loss: 0.6174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:22:19,185] Trial 163 finished with value: 0.4962438464164734 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0012740191240534994, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 163] Epoch 60/60, Training Loss: 0.5881, Validation Loss: 0.5130\n",
      "[Trial 175] Epoch 39/60, Training Loss: 0.5758, Validation Loss: 0.5154\n",
      "[Trial 179] Epoch 12/60, Training Loss: 0.9314, Validation Loss: 0.7732\n",
      "[Trial 176] Epoch 38/60, Training Loss: 0.6671, Validation Loss: 0.5335\n",
      "[Trial 178] Epoch 13/60, Training Loss: 0.8627, Validation Loss: 0.6597\n",
      "[Trial 180] Epoch 10/60, Training Loss: 0.9217, Validation Loss: 0.7640\n",
      "[Trial 174] Epoch 40/60, Training Loss: 0.5877, Validation Loss: 0.5111\n",
      "[Trial 182] Epoch 1/60, Training Loss: 4.7539, Validation Loss: 2.0715\n",
      "[Trial 181] Epoch 8/60, Training Loss: 0.9771, Validation Loss: 0.9370\n",
      "[Trial 173] Epoch 33/60, Training Loss: 0.6428, Validation Loss: 0.5688\n",
      "[Trial 169] Epoch 43/60, Training Loss: 0.5981, Validation Loss: 0.5038\n",
      "[Trial 177] Epoch 20/60, Training Loss: 0.7482, Validation Loss: 0.7001\n",
      "[Trial 175] Epoch 40/60, Training Loss: 0.5691, Validation Loss: 0.4938\n",
      "[Trial 183] Epoch 1/60, Training Loss: 5.8521, Validation Loss: 1.9211\n",
      "[Trial 176] Epoch 39/60, Training Loss: 0.6559, Validation Loss: 0.5314\n",
      "[Trial 179] Epoch 13/60, Training Loss: 0.9470, Validation Loss: 0.7446\n",
      "[Trial 178] Epoch 14/60, Training Loss: 0.8227, Validation Loss: 0.6743\n",
      "[Trial 180] Epoch 11/60, Training Loss: 0.9304, Validation Loss: 0.8961\n",
      "[Trial 174] Epoch 41/60, Training Loss: 0.5835, Validation Loss: 0.5194\n",
      "[Trial 167] Epoch 48/60, Training Loss: 0.5956, Validation Loss: 0.5072\n",
      "[Trial 165] Epoch 52/60, Training Loss: 0.6164, Validation Loss: 0.5242\n",
      "[Trial 168] Epoch 46/60, Training Loss: 0.6116, Validation Loss: 0.5253\n",
      "[Trial 166] Epoch 47/60, Training Loss: 0.5637, Validation Loss: 0.5088\n",
      "[Trial 182] Epoch 2/60, Training Loss: 1.9579, Validation Loss: 1.6284\n",
      "[Trial 181] Epoch 9/60, Training Loss: 0.9649, Validation Loss: 0.7764\n",
      "[Trial 177] Epoch 21/60, Training Loss: 0.7615, Validation Loss: 0.6795\n",
      "[Trial 175] Epoch 41/60, Training Loss: 0.5654, Validation Loss: 0.4890\n",
      "[Trial 183] Epoch 2/60, Training Loss: 2.1189, Validation Loss: 1.4959\n",
      "[Trial 176] Epoch 40/60, Training Loss: 0.6775, Validation Loss: 0.5482\n",
      "[Trial 178] Epoch 15/60, Training Loss: 0.7925, Validation Loss: 0.6454\n",
      "[Trial 179] Epoch 14/60, Training Loss: 0.8925, Validation Loss: 0.6826\n",
      "[Trial 180] Epoch 12/60, Training Loss: 0.8798, Validation Loss: 0.8728\n",
      "[Trial 174] Epoch 42/60, Training Loss: 0.5825, Validation Loss: 0.5386\n",
      "[Trial 169] Epoch 44/60, Training Loss: 0.5624, Validation Loss: 0.5153\n",
      "[Trial 173] Epoch 34/60, Training Loss: 0.6257, Validation Loss: 0.5315\n",
      "[Trial 182] Epoch 3/60, Training Loss: 1.6393, Validation Loss: 1.2530\n",
      "[Trial 181] Epoch 10/60, Training Loss: 0.9245, Validation Loss: 0.8465\n",
      "[Trial 177] Epoch 22/60, Training Loss: 0.7225, Validation Loss: 0.6430\n",
      "[Trial 175] Epoch 42/60, Training Loss: 0.5654, Validation Loss: 0.5068\n",
      "[Trial 183] Epoch 3/60, Training Loss: 1.6957, Validation Loss: 1.1805\n",
      "[Trial 165] Epoch 53/60, Training Loss: 0.6217, Validation Loss: 0.5827\n",
      "[Trial 167] Epoch 49/60, Training Loss: 0.5770, Validation Loss: 0.5006\n",
      "[Trial 176] Epoch 41/60, Training Loss: 0.6560, Validation Loss: 0.5600\n",
      "[Trial 178] Epoch 16/60, Training Loss: 0.8040, Validation Loss: 0.6364\n",
      "[Trial 168] Epoch 47/60, Training Loss: 0.6138, Validation Loss: 0.4993\n",
      "[Trial 179] Epoch 15/60, Training Loss: 0.8979, Validation Loss: 0.7439\n",
      "[Trial 166] Epoch 48/60, Training Loss: 0.5597, Validation Loss: 0.4878\n",
      "[Trial 180] Epoch 13/60, Training Loss: 0.8699, Validation Loss: 0.6738\n",
      "[Trial 174] Epoch 43/60, Training Loss: 0.5797, Validation Loss: 0.5251\n",
      "[Trial 182] Epoch 4/60, Training Loss: 1.4250, Validation Loss: 1.0164\n",
      "[Trial 181] Epoch 11/60, Training Loss: 0.8872, Validation Loss: 0.8483\n",
      "[Trial 177] Epoch 23/60, Training Loss: 0.7242, Validation Loss: 0.6497\n",
      "[Trial 175] Epoch 43/60, Training Loss: 0.5582, Validation Loss: 0.4860\n",
      "[Trial 183] Epoch 4/60, Training Loss: 1.4303, Validation Loss: 1.0343\n",
      "[Trial 176] Epoch 42/60, Training Loss: 0.6596, Validation Loss: 0.5925\n",
      "[Trial 178] Epoch 17/60, Training Loss: 0.7783, Validation Loss: 0.6388\n",
      "[Trial 169] Epoch 45/60, Training Loss: 0.5579, Validation Loss: 0.5037\n",
      "[Trial 173] Epoch 35/60, Training Loss: 0.6104, Validation Loss: 0.6371\n",
      "[Trial 179] Epoch 16/60, Training Loss: 0.8972, Validation Loss: 0.7284\n",
      "[Trial 180] Epoch 14/60, Training Loss: 0.8377, Validation Loss: 0.7477\n",
      "[Trial 174] Epoch 44/60, Training Loss: 0.5856, Validation Loss: 0.5244\n",
      "[Trial 182] Epoch 5/60, Training Loss: 1.2731, Validation Loss: 0.9277\n",
      "[Trial 165] Epoch 54/60, Training Loss: 0.6057, Validation Loss: 0.5156\n",
      "[Trial 167] Epoch 50/60, Training Loss: 0.5838, Validation Loss: 0.5025\n",
      "[Trial 181] Epoch 12/60, Training Loss: 0.8619, Validation Loss: 0.6864\n",
      "[Trial 177] Epoch 24/60, Training Loss: 0.7212, Validation Loss: 0.6379\n",
      "[Trial 168] Epoch 48/60, Training Loss: 0.6017, Validation Loss: 0.4942\n",
      "[Trial 166] Epoch 49/60, Training Loss: 0.5500, Validation Loss: 0.4628\n",
      "[Trial 175] Epoch 44/60, Training Loss: 0.5858, Validation Loss: 0.4986\n",
      "[Trial 183] Epoch 5/60, Training Loss: 1.2359, Validation Loss: 0.9590\n",
      "[Trial 178] Epoch 18/60, Training Loss: 0.7778, Validation Loss: 0.6641\n",
      "[Trial 176] Epoch 43/60, Training Loss: 0.6156, Validation Loss: 0.5065\n",
      "[Trial 180] Epoch 15/60, Training Loss: 0.8281, Validation Loss: 0.7055\n",
      "[Trial 179] Epoch 17/60, Training Loss: 0.8727, Validation Loss: 0.7221\n",
      "[Trial 174] Epoch 45/60, Training Loss: 0.5819, Validation Loss: 0.5295\n",
      "[Trial 182] Epoch 6/60, Training Loss: 1.1439, Validation Loss: 0.8979\n",
      "[Trial 177] Epoch 25/60, Training Loss: 0.6802, Validation Loss: 0.5873\n",
      "[Trial 181] Epoch 13/60, Training Loss: 0.8229, Validation Loss: 0.6214\n",
      "[Trial 169] Epoch 46/60, Training Loss: 0.5619, Validation Loss: 0.5168\n",
      "[Trial 173] Epoch 36/60, Training Loss: 0.6335, Validation Loss: 0.6110\n",
      "[Trial 175] Epoch 45/60, Training Loss: 0.5610, Validation Loss: 0.4922\n",
      "[Trial 178] Epoch 19/60, Training Loss: 0.7800, Validation Loss: 0.5763\n",
      "[Trial 183] Epoch 6/60, Training Loss: 1.1021, Validation Loss: 0.8477\n",
      "[Trial 176] Epoch 44/60, Training Loss: 0.6057, Validation Loss: 0.5149\n",
      "[Trial 180] Epoch 16/60, Training Loss: 0.8121, Validation Loss: 0.6584\n",
      "[Trial 179] Epoch 18/60, Training Loss: 0.8176, Validation Loss: 0.6714\n",
      "[Trial 174] Epoch 46/60, Training Loss: 0.5608, Validation Loss: 0.5061\n",
      "[Trial 165] Epoch 55/60, Training Loss: 0.5969, Validation Loss: 0.5138\n",
      "[Trial 167] Epoch 51/60, Training Loss: 0.5758, Validation Loss: 0.4950\n",
      "[Trial 168] Epoch 49/60, Training Loss: 0.6098, Validation Loss: 0.5030\n",
      "[Trial 182] Epoch 7/60, Training Loss: 1.1087, Validation Loss: 0.8369\n",
      "[Trial 166] Epoch 50/60, Training Loss: 0.5614, Validation Loss: 0.5068\n",
      "[Trial 177] Epoch 26/60, Training Loss: 0.6604, Validation Loss: 0.5714\n",
      "[Trial 181] Epoch 14/60, Training Loss: 0.8288, Validation Loss: 0.6735\n",
      "[Trial 175] Epoch 46/60, Training Loss: 0.5581, Validation Loss: 0.5004\n",
      "[Trial 178] Epoch 20/60, Training Loss: 0.7372, Validation Loss: 0.6072\n",
      "[Trial 176] Epoch 45/60, Training Loss: 0.6041, Validation Loss: 0.4999\n",
      "[Trial 183] Epoch 7/60, Training Loss: 1.0216, Validation Loss: 0.8182\n",
      "[Trial 180] Epoch 17/60, Training Loss: 0.8104, Validation Loss: 0.6745\n",
      "[Trial 179] Epoch 19/60, Training Loss: 0.7969, Validation Loss: 0.6325\n",
      "[Trial 174] Epoch 47/60, Training Loss: 0.5711, Validation Loss: 0.5169\n",
      "[Trial 182] Epoch 8/60, Training Loss: 1.0183, Validation Loss: 0.7721\n",
      "[Trial 169] Epoch 47/60, Training Loss: 0.5613, Validation Loss: 0.4955\n",
      "[Trial 173] Epoch 37/60, Training Loss: 0.6238, Validation Loss: 0.6439\n",
      "[Trial 177] Epoch 27/60, Training Loss: 0.6578, Validation Loss: 0.5909\n",
      "[Trial 181] Epoch 15/60, Training Loss: 0.7895, Validation Loss: 0.6925\n",
      "[Trial 178] Epoch 21/60, Training Loss: 0.7387, Validation Loss: 0.5968\n",
      "[Trial 175] Epoch 47/60, Training Loss: 0.5643, Validation Loss: 0.4828\n",
      "[Trial 165] Epoch 56/60, Training Loss: 0.5974, Validation Loss: 0.5079\n",
      "[Trial 176] Epoch 46/60, Training Loss: 0.5983, Validation Loss: 0.4977\n",
      "[Trial 167] Epoch 52/60, Training Loss: 0.5758, Validation Loss: 0.4887\n",
      "[Trial 183] Epoch 8/60, Training Loss: 0.9608, Validation Loss: 0.7631\n",
      "[Trial 168] Epoch 50/60, Training Loss: 0.6005, Validation Loss: 0.4965\n",
      "[Trial 180] Epoch 18/60, Training Loss: 0.7762, Validation Loss: 0.6532\n",
      "[Trial 179] Epoch 20/60, Training Loss: 0.8073, Validation Loss: 0.6371\n",
      "[Trial 166] Epoch 51/60, Training Loss: 0.5565, Validation Loss: 0.4562\n",
      "[Trial 174] Epoch 48/60, Training Loss: 0.5622, Validation Loss: 0.5089\n",
      "[Trial 182] Epoch 9/60, Training Loss: 0.9566, Validation Loss: 0.8264\n",
      "[Trial 177] Epoch 28/60, Training Loss: 0.6567, Validation Loss: 0.5864\n",
      "[Trial 181] Epoch 16/60, Training Loss: 0.7738, Validation Loss: 0.6139\n",
      "[Trial 178] Epoch 22/60, Training Loss: 0.7296, Validation Loss: 0.6088\n",
      "[Trial 175] Epoch 48/60, Training Loss: 0.5571, Validation Loss: 0.5067\n",
      "[Trial 176] Epoch 47/60, Training Loss: 0.6077, Validation Loss: 0.5020\n",
      "[Trial 183] Epoch 9/60, Training Loss: 0.9449, Validation Loss: 0.7236\n",
      "[Trial 180] Epoch 19/60, Training Loss: 0.7678, Validation Loss: 0.6537\n",
      "[Trial 169] Epoch 48/60, Training Loss: 0.5555, Validation Loss: 0.5033\n",
      "[Trial 179] Epoch 21/60, Training Loss: 0.7886, Validation Loss: 0.6376\n",
      "[Trial 173] Epoch 38/60, Training Loss: 0.6213, Validation Loss: 0.4989\n",
      "[Trial 174] Epoch 49/60, Training Loss: 0.5626, Validation Loss: 0.5048\n",
      "[Trial 182] Epoch 10/60, Training Loss: 0.9101, Validation Loss: 0.7295\n",
      "[Trial 165] Epoch 57/60, Training Loss: 0.5869, Validation Loss: 0.5083\n",
      "[Trial 177] Epoch 29/60, Training Loss: 0.6511, Validation Loss: 0.5804\n",
      "[Trial 167] Epoch 53/60, Training Loss: 0.5816, Validation Loss: 0.5038\n",
      "[Trial 168] Epoch 51/60, Training Loss: 0.6089, Validation Loss: 0.5052\n",
      "[Trial 181] Epoch 17/60, Training Loss: 0.7760, Validation Loss: 0.6493\n",
      "[Trial 178] Epoch 23/60, Training Loss: 0.7386, Validation Loss: 0.6489\n",
      "[Trial 175] Epoch 49/60, Training Loss: 0.5568, Validation Loss: 0.4934\n",
      "[Trial 176] Epoch 48/60, Training Loss: 0.6051, Validation Loss: 0.4939\n",
      "[Trial 166] Epoch 52/60, Training Loss: 0.5439, Validation Loss: 0.4726\n",
      "[Trial 183] Epoch 10/60, Training Loss: 0.8748, Validation Loss: 0.6817\n",
      "[Trial 180] Epoch 20/60, Training Loss: 0.7598, Validation Loss: 0.6407\n",
      "[Trial 179] Epoch 22/60, Training Loss: 0.7730, Validation Loss: 0.7514\n",
      "[Trial 174] Epoch 50/60, Training Loss: 0.5624, Validation Loss: 0.5011\n",
      "[Trial 182] Epoch 11/60, Training Loss: 0.9007, Validation Loss: 0.6978\n",
      "[Trial 177] Epoch 30/60, Training Loss: 0.6507, Validation Loss: 0.5651\n",
      "[Trial 178] Epoch 24/60, Training Loss: 0.7243, Validation Loss: 0.5724\n",
      "[Trial 181] Epoch 18/60, Training Loss: 0.7524, Validation Loss: 0.6269\n",
      "[Trial 175] Epoch 50/60, Training Loss: 0.5571, Validation Loss: 0.4918\n",
      "[Trial 176] Epoch 49/60, Training Loss: 0.6147, Validation Loss: 0.5654\n",
      "[Trial 169] Epoch 49/60, Training Loss: 0.5533, Validation Loss: 0.5202\n",
      "[Trial 173] Epoch 39/60, Training Loss: 0.6116, Validation Loss: 0.5006\n",
      "[Trial 183] Epoch 11/60, Training Loss: 0.8764, Validation Loss: 0.6670\n",
      "[Trial 180] Epoch 21/60, Training Loss: 0.7492, Validation Loss: 0.6328\n",
      "[Trial 165] Epoch 58/60, Training Loss: 0.5853, Validation Loss: 0.4994\n",
      "[Trial 179] Epoch 23/60, Training Loss: 0.7707, Validation Loss: 0.6552\n",
      "[Trial 174] Epoch 51/60, Training Loss: 0.5559, Validation Loss: 0.4985\n",
      "[Trial 167] Epoch 54/60, Training Loss: 0.5898, Validation Loss: 0.5067\n",
      "[Trial 182] Epoch 12/60, Training Loss: 0.8628, Validation Loss: 0.6680\n",
      "[Trial 168] Epoch 52/60, Training Loss: 0.6109, Validation Loss: 0.5096\n",
      "[Trial 177] Epoch 31/60, Training Loss: 0.6501, Validation Loss: 0.5530\n",
      "[Trial 166] Epoch 53/60, Training Loss: 0.5560, Validation Loss: 0.4753\n",
      "[Trial 178] Epoch 25/60, Training Loss: 0.7227, Validation Loss: 0.5834\n",
      "[Trial 181] Epoch 19/60, Training Loss: 0.7350, Validation Loss: 0.6295\n",
      "[Trial 175] Epoch 51/60, Training Loss: 0.5560, Validation Loss: 0.5053\n",
      "[Trial 176] Epoch 50/60, Training Loss: 0.6067, Validation Loss: 0.5063\n",
      "[Trial 183] Epoch 12/60, Training Loss: 0.8509, Validation Loss: 0.6434\n",
      "[Trial 180] Epoch 22/60, Training Loss: 0.7328, Validation Loss: 0.6116\n",
      "[Trial 179] Epoch 24/60, Training Loss: 0.7734, Validation Loss: 0.6162\n",
      "[Trial 174] Epoch 52/60, Training Loss: 0.5597, Validation Loss: 0.5074\n",
      "[Trial 182] Epoch 13/60, Training Loss: 0.8292, Validation Loss: 0.6511\n",
      "[Trial 177] Epoch 32/60, Training Loss: 0.6578, Validation Loss: 0.5569\n",
      "[Trial 169] Epoch 50/60, Training Loss: 0.5524, Validation Loss: 0.4876\n",
      "[Trial 178] Epoch 26/60, Training Loss: 0.7274, Validation Loss: 0.5625\n",
      "[Trial 173] Epoch 40/60, Training Loss: 0.6105, Validation Loss: 0.6135\n",
      "[Trial 181] Epoch 20/60, Training Loss: 0.7440, Validation Loss: 0.6167\n",
      "[Trial 175] Epoch 52/60, Training Loss: 0.5517, Validation Loss: 0.5001\n",
      "[Trial 165] Epoch 59/60, Training Loss: 0.5854, Validation Loss: 0.5049\n",
      "[Trial 176] Epoch 51/60, Training Loss: 0.5997, Validation Loss: 0.4935\n",
      "[Trial 167] Epoch 55/60, Training Loss: 0.5804, Validation Loss: 0.5028\n",
      "[Trial 168] Epoch 53/60, Training Loss: 0.5976, Validation Loss: 0.4925\n",
      "[Trial 183] Epoch 13/60, Training Loss: 0.8117, Validation Loss: 0.6745\n",
      "[Trial 180] Epoch 23/60, Training Loss: 0.7390, Validation Loss: 0.7191\n",
      "[Trial 179] Epoch 25/60, Training Loss: 0.7501, Validation Loss: 0.6231\n",
      "[Trial 174] Epoch 53/60, Training Loss: 0.5517, Validation Loss: 0.5006\n",
      "[Trial 182] Epoch 14/60, Training Loss: 0.7921, Validation Loss: 0.6904\n",
      "[Trial 166] Epoch 54/60, Training Loss: 0.5439, Validation Loss: 0.4560\n",
      "[Trial 177] Epoch 33/60, Training Loss: 0.6490, Validation Loss: 0.5368\n",
      "[Trial 178] Epoch 27/60, Training Loss: 0.6961, Validation Loss: 0.5761\n",
      "[Trial 175] Epoch 53/60, Training Loss: 0.5409, Validation Loss: 0.4770\n",
      "[Trial 181] Epoch 21/60, Training Loss: 0.7141, Validation Loss: 0.5738\n",
      "[Trial 176] Epoch 52/60, Training Loss: 0.5968, Validation Loss: 0.5188\n",
      "[Trial 180] Epoch 24/60, Training Loss: 0.7431, Validation Loss: 0.6617\n",
      "[Trial 183] Epoch 14/60, Training Loss: 0.8141, Validation Loss: 0.6950\n",
      "[Trial 182] Epoch 15/60, Training Loss: 0.7801, Validation Loss: 0.6371\n",
      "[Trial 179] Epoch 26/60, Training Loss: 0.7309, Validation Loss: 0.6551\n",
      "[Trial 174] Epoch 54/60, Training Loss: 0.5533, Validation Loss: 0.5031\n",
      "[Trial 169] Epoch 51/60, Training Loss: 0.5743, Validation Loss: 0.5916\n",
      "[Trial 173] Epoch 41/60, Training Loss: 0.6310, Validation Loss: 0.7544\n",
      "[Trial 177] Epoch 34/60, Training Loss: 0.6355, Validation Loss: 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:31:25,929] Trial 165 finished with value: 0.49939741094907125 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.0013530642235097372, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 165] Epoch 60/60, Training Loss: 0.5837, Validation Loss: 0.5088\n",
      "[Trial 178] Epoch 28/60, Training Loss: 0.7028, Validation Loss: 0.5758\n",
      "[Trial 167] Epoch 56/60, Training Loss: 0.5803, Validation Loss: 0.4951\n",
      "[Trial 168] Epoch 54/60, Training Loss: 0.5961, Validation Loss: 0.4890\n",
      "[Trial 175] Epoch 54/60, Training Loss: 0.5347, Validation Loss: 0.4730\n",
      "[Trial 181] Epoch 22/60, Training Loss: 0.7062, Validation Loss: 0.5887\n",
      "[Trial 176] Epoch 53/60, Training Loss: 0.6050, Validation Loss: 0.5059\n",
      "[Trial 166] Epoch 55/60, Training Loss: 0.5521, Validation Loss: 0.4870\n",
      "[Trial 180] Epoch 25/60, Training Loss: 0.7331, Validation Loss: 0.6034\n",
      "[Trial 183] Epoch 15/60, Training Loss: 0.7934, Validation Loss: 0.6603\n",
      "[Trial 182] Epoch 16/60, Training Loss: 0.7840, Validation Loss: 0.6211\n",
      "[Trial 174] Epoch 55/60, Training Loss: 0.5638, Validation Loss: 0.5111\n",
      "[Trial 179] Epoch 27/60, Training Loss: 0.7542, Validation Loss: 0.6270\n",
      "[Trial 177] Epoch 35/60, Training Loss: 0.6338, Validation Loss: 0.5700\n",
      "[Trial 184] Epoch 1/60, Training Loss: 4.4299, Validation Loss: 1.8259\n",
      "[Trial 178] Epoch 29/60, Training Loss: 0.7096, Validation Loss: 0.6577\n",
      "[Trial 175] Epoch 55/60, Training Loss: 0.5350, Validation Loss: 0.4949\n",
      "[Trial 181] Epoch 23/60, Training Loss: 0.7000, Validation Loss: 0.6039\n",
      "[Trial 176] Epoch 54/60, Training Loss: 0.5998, Validation Loss: 0.4955\n",
      "[Trial 169] Epoch 52/60, Training Loss: 0.5748, Validation Loss: 0.5132\n",
      "[Trial 180] Epoch 26/60, Training Loss: 0.7057, Validation Loss: 0.6712\n",
      "[Trial 183] Epoch 16/60, Training Loss: 0.7735, Validation Loss: 0.6292\n",
      "[Trial 173] Epoch 42/60, Training Loss: 0.6644, Validation Loss: 0.5874\n",
      "[Trial 167] Epoch 57/60, Training Loss: 0.5729, Validation Loss: 0.4958\n",
      "[Trial 182] Epoch 17/60, Training Loss: 0.7546, Validation Loss: 0.6580\n",
      "[Trial 174] Epoch 56/60, Training Loss: 0.5578, Validation Loss: 0.5135\n",
      "[Trial 179] Epoch 28/60, Training Loss: 0.7210, Validation Loss: 0.6509\n",
      "[Trial 177] Epoch 36/60, Training Loss: 0.6336, Validation Loss: 0.5304\n",
      "[Trial 168] Epoch 55/60, Training Loss: 0.5958, Validation Loss: 0.5210\n",
      "[Trial 178] Epoch 30/60, Training Loss: 0.6923, Validation Loss: 0.5901\n",
      "[Trial 184] Epoch 2/60, Training Loss: 1.9850, Validation Loss: 1.4552\n",
      "[Trial 166] Epoch 56/60, Training Loss: 0.5432, Validation Loss: 0.4612\n",
      "[Trial 175] Epoch 56/60, Training Loss: 0.5324, Validation Loss: 0.4753\n",
      "[Trial 176] Epoch 55/60, Training Loss: 0.5936, Validation Loss: 0.4957\n",
      "[Trial 181] Epoch 24/60, Training Loss: 0.6875, Validation Loss: 0.5885\n",
      "[Trial 180] Epoch 27/60, Training Loss: 0.7067, Validation Loss: 0.6559\n",
      "[Trial 183] Epoch 17/60, Training Loss: 0.7481, Validation Loss: 0.6222\n",
      "[Trial 182] Epoch 18/60, Training Loss: 0.7516, Validation Loss: 0.6516\n",
      "[Trial 174] Epoch 57/60, Training Loss: 0.5468, Validation Loss: 0.5021\n",
      "[Trial 177] Epoch 37/60, Training Loss: 0.6292, Validation Loss: 0.5787\n",
      "[Trial 179] Epoch 29/60, Training Loss: 0.7085, Validation Loss: 0.5878\n",
      "[Trial 178] Epoch 31/60, Training Loss: 0.6879, Validation Loss: 0.5806\n",
      "[Trial 184] Epoch 3/60, Training Loss: 1.6962, Validation Loss: 1.2690\n",
      "[Trial 169] Epoch 53/60, Training Loss: 0.5547, Validation Loss: 0.5533\n",
      "[Trial 175] Epoch 57/60, Training Loss: 0.5289, Validation Loss: 0.4632\n",
      "[Trial 176] Epoch 56/60, Training Loss: 0.5934, Validation Loss: 0.5207\n",
      "[Trial 173] Epoch 43/60, Training Loss: 0.6145, Validation Loss: 0.6110\n",
      "[Trial 181] Epoch 25/60, Training Loss: 0.6911, Validation Loss: 0.5461\n",
      "[Trial 167] Epoch 58/60, Training Loss: 0.5820, Validation Loss: 0.5039\n",
      "[Trial 180] Epoch 28/60, Training Loss: 0.7133, Validation Loss: 0.5980\n",
      "[Trial 168] Epoch 56/60, Training Loss: 0.5995, Validation Loss: 0.4900\n",
      "[Trial 183] Epoch 18/60, Training Loss: 0.7313, Validation Loss: 0.6309\n",
      "[Trial 182] Epoch 19/60, Training Loss: 0.7476, Validation Loss: 0.6116\n",
      "[Trial 177] Epoch 38/60, Training Loss: 0.6252, Validation Loss: 0.5377\n",
      "[Trial 174] Epoch 58/60, Training Loss: 0.5451, Validation Loss: 0.4957\n",
      "[Trial 179] Epoch 30/60, Training Loss: 0.7236, Validation Loss: 0.6031\n",
      "[Trial 178] Epoch 32/60, Training Loss: 0.6327, Validation Loss: 0.5320\n",
      "[Trial 166] Epoch 57/60, Training Loss: 0.5421, Validation Loss: 0.4801\n",
      "[Trial 184] Epoch 4/60, Training Loss: 1.4418, Validation Loss: 1.0133\n",
      "[Trial 175] Epoch 58/60, Training Loss: 0.5331, Validation Loss: 0.4746\n",
      "[Trial 176] Epoch 57/60, Training Loss: 0.5957, Validation Loss: 0.5385\n",
      "[Trial 181] Epoch 26/60, Training Loss: 0.6802, Validation Loss: 0.5570\n",
      "[Trial 180] Epoch 29/60, Training Loss: 0.6963, Validation Loss: 0.6159\n",
      "[Trial 183] Epoch 19/60, Training Loss: 0.7414, Validation Loss: 0.6814\n",
      "[Trial 182] Epoch 20/60, Training Loss: 0.7209, Validation Loss: 0.5902\n",
      "[Trial 177] Epoch 39/60, Training Loss: 0.6232, Validation Loss: 0.5504\n",
      "[Trial 174] Epoch 59/60, Training Loss: 0.5386, Validation Loss: 0.4870\n",
      "[Trial 178] Epoch 33/60, Training Loss: 0.6303, Validation Loss: 0.5268\n",
      "[Trial 179] Epoch 31/60, Training Loss: 0.7133, Validation Loss: 0.5625\n",
      "[Trial 184] Epoch 5/60, Training Loss: 1.2517, Validation Loss: 0.9609\n",
      "[Trial 169] Epoch 54/60, Training Loss: 0.5565, Validation Loss: 0.5276\n",
      "[Trial 173] Epoch 44/60, Training Loss: 0.5782, Validation Loss: 0.5160\n",
      "[Trial 167] Epoch 59/60, Training Loss: 0.5631, Validation Loss: 0.4887\n",
      "[Trial 168] Epoch 57/60, Training Loss: 0.5930, Validation Loss: 0.4928\n",
      "[Trial 175] Epoch 59/60, Training Loss: 0.5307, Validation Loss: 0.4757\n",
      "[Trial 176] Epoch 58/60, Training Loss: 0.5721, Validation Loss: 0.4939\n",
      "[Trial 181] Epoch 27/60, Training Loss: 0.7045, Validation Loss: 0.6383\n",
      "[Trial 180] Epoch 30/60, Training Loss: 0.6947, Validation Loss: 0.6259\n",
      "[Trial 183] Epoch 20/60, Training Loss: 0.7518, Validation Loss: 0.6086\n",
      "[Trial 166] Epoch 58/60, Training Loss: 0.5482, Validation Loss: 0.4720\n",
      "[Trial 182] Epoch 21/60, Training Loss: 0.7195, Validation Loss: 0.5803\n",
      "[Trial 177] Epoch 40/60, Training Loss: 0.6353, Validation Loss: 0.5806\n",
      "[Trial 178] Epoch 34/60, Training Loss: 0.6280, Validation Loss: 0.5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:35:06,252] Trial 174 finished with value: 0.4869901438554128 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004321511441551789, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 174] Epoch 60/60, Training Loss: 0.5419, Validation Loss: 0.4888\n",
      "[Trial 179] Epoch 32/60, Training Loss: 0.6988, Validation Loss: 0.5809\n",
      "[Trial 184] Epoch 6/60, Training Loss: 1.1981, Validation Loss: 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:35:20,658] Trial 175 finished with value: 0.4631953944762548 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004394509638854261, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 175] Epoch 60/60, Training Loss: 0.5320, Validation Loss: 0.4795\n",
      "[Trial 176] Epoch 59/60, Training Loss: 0.5638, Validation Loss: 0.4749\n",
      "[Trial 181] Epoch 28/60, Training Loss: 0.6748, Validation Loss: 0.5655\n",
      "[Trial 180] Epoch 31/60, Training Loss: 0.6918, Validation Loss: 0.5750\n",
      "[Trial 183] Epoch 21/60, Training Loss: 0.7109, Validation Loss: 0.6401\n",
      "[Trial 169] Epoch 55/60, Training Loss: 0.5576, Validation Loss: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:35:39,817] Trial 167 finished with value: 0.4886615589261055 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.006175215268380958, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 167] Epoch 60/60, Training Loss: 0.5707, Validation Loss: 0.4909\n",
      "[Trial 182] Epoch 22/60, Training Loss: 0.7139, Validation Loss: 0.5852\n",
      "[Trial 177] Epoch 41/60, Training Loss: 0.6322, Validation Loss: 0.5428\n",
      "[Trial 173] Epoch 45/60, Training Loss: 0.5785, Validation Loss: 0.5033\n",
      "[Trial 178] Epoch 35/60, Training Loss: 0.6258, Validation Loss: 0.5185\n",
      "[Trial 185] Epoch 1/60, Training Loss: 5.4571, Validation Loss: 1.9521\n",
      "[Trial 168] Epoch 58/60, Training Loss: 0.5912, Validation Loss: 0.4951\n",
      "[Trial 184] Epoch 7/60, Training Loss: 1.0678, Validation Loss: 0.8550\n",
      "[Trial 179] Epoch 33/60, Training Loss: 0.6904, Validation Loss: 0.6014\n",
      "[Trial 186] Epoch 1/60, Training Loss: 5.4510, Validation Loss: 2.1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:36:00,343] Trial 176 finished with value: 0.47487799227237704 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.00451075757426427, 'batch_size': 32, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 176] Epoch 60/60, Training Loss: 0.5653, Validation Loss: 0.4791\n",
      "[Trial 166] Epoch 59/60, Training Loss: 0.5473, Validation Loss: 0.5105\n",
      "[Trial 181] Epoch 29/60, Training Loss: 0.6690, Validation Loss: 0.5640\n",
      "[Trial 180] Epoch 32/60, Training Loss: 0.6872, Validation Loss: 0.5926\n",
      "[Trial 183] Epoch 22/60, Training Loss: 0.7094, Validation Loss: 0.5927\n",
      "[Trial 187] Epoch 1/60, Training Loss: 5.8922, Validation Loss: 2.0127\n",
      "[Trial 182] Epoch 23/60, Training Loss: 0.6906, Validation Loss: 0.6021\n",
      "[Trial 177] Epoch 42/60, Training Loss: 0.5951, Validation Loss: 0.5356\n",
      "[Trial 178] Epoch 36/60, Training Loss: 0.6300, Validation Loss: 0.5223\n",
      "[Trial 185] Epoch 2/60, Training Loss: 1.9957, Validation Loss: 1.7353\n",
      "[Trial 184] Epoch 8/60, Training Loss: 1.0218, Validation Loss: 0.7966\n",
      "[Trial 179] Epoch 34/60, Training Loss: 0.6910, Validation Loss: 0.5921\n",
      "[Trial 186] Epoch 2/60, Training Loss: 1.9011, Validation Loss: 1.4017\n",
      "[Trial 188] Epoch 1/60, Training Loss: 5.7597, Validation Loss: 2.3760\n",
      "[Trial 169] Epoch 56/60, Training Loss: 0.5580, Validation Loss: 0.4897\n",
      "[Trial 181] Epoch 30/60, Training Loss: 0.6768, Validation Loss: 0.5832\n",
      "[Trial 180] Epoch 33/60, Training Loss: 0.6779, Validation Loss: 0.5770\n",
      "[Trial 173] Epoch 46/60, Training Loss: 0.5629, Validation Loss: 0.5087\n",
      "[Trial 168] Epoch 59/60, Training Loss: 0.5973, Validation Loss: 0.4849\n",
      "[Trial 183] Epoch 23/60, Training Loss: 0.6919, Validation Loss: 0.5617\n",
      "[Trial 187] Epoch 2/60, Training Loss: 2.0509, Validation Loss: 1.4071\n",
      "[Trial 177] Epoch 43/60, Training Loss: 0.5877, Validation Loss: 0.5115\n",
      "[Trial 178] Epoch 37/60, Training Loss: 0.6232, Validation Loss: 0.5189\n",
      "[Trial 182] Epoch 24/60, Training Loss: 0.7058, Validation Loss: 0.6103\n",
      "[Trial 184] Epoch 9/60, Training Loss: 0.9563, Validation Loss: 0.8213\n",
      "[Trial 185] Epoch 3/60, Training Loss: 1.5953, Validation Loss: 1.2540\n",
      "[Trial 179] Epoch 35/60, Training Loss: 0.6900, Validation Loss: 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:37:08,398] Trial 166 finished with value: 0.4539472828308741 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.006133525361514774, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 166] Epoch 60/60, Training Loss: 0.5396, Validation Loss: 0.4539\n",
      "[Trial 186] Epoch 3/60, Training Loss: 1.5096, Validation Loss: 1.1926\n",
      "[Trial 188] Epoch 2/60, Training Loss: 2.1370, Validation Loss: 1.8093\n",
      "[Trial 181] Epoch 31/60, Training Loss: 0.6119, Validation Loss: 0.4963\n",
      "[Trial 180] Epoch 34/60, Training Loss: 0.6849, Validation Loss: 0.6013\n",
      "[Trial 183] Epoch 24/60, Training Loss: 0.7045, Validation Loss: 0.5466\n",
      "[Trial 177] Epoch 44/60, Training Loss: 0.5956, Validation Loss: 0.5241\n",
      "[Trial 187] Epoch 3/60, Training Loss: 1.6624, Validation Loss: 1.3610\n",
      "[Trial 178] Epoch 38/60, Training Loss: 0.6257, Validation Loss: 0.5268\n",
      "[Trial 182] Epoch 25/60, Training Loss: 0.7046, Validation Loss: 0.6681\n",
      "[Trial 184] Epoch 10/60, Training Loss: 0.9278, Validation Loss: 0.7426\n",
      "[Trial 185] Epoch 4/60, Training Loss: 1.3474, Validation Loss: 0.9970\n",
      "[Trial 179] Epoch 36/60, Training Loss: 0.6798, Validation Loss: 0.5358\n",
      "[Trial 169] Epoch 57/60, Training Loss: 0.5337, Validation Loss: 0.4888\n",
      "[Trial 189] Epoch 1/60, Training Loss: 5.2351, Validation Loss: 1.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:37:52,730] Trial 168 finished with value: 0.48490597208340963 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.0012255047441706633, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 168] Epoch 60/60, Training Loss: 0.5847, Validation Loss: 0.4898\n",
      "[Trial 173] Epoch 47/60, Training Loss: 0.5672, Validation Loss: 0.4884\n",
      "[Trial 186] Epoch 4/60, Training Loss: 1.3158, Validation Loss: 1.0885\n",
      "[Trial 188] Epoch 3/60, Training Loss: 1.6959, Validation Loss: 1.3122\n",
      "[Trial 181] Epoch 32/60, Training Loss: 0.6068, Validation Loss: 0.5322\n",
      "[Trial 180] Epoch 35/60, Training Loss: 0.6833, Validation Loss: 0.5658\n",
      "[Trial 177] Epoch 45/60, Training Loss: 0.5916, Validation Loss: 0.5269\n",
      "[Trial 178] Epoch 39/60, Training Loss: 0.6383, Validation Loss: 0.5238\n",
      "[Trial 187] Epoch 4/60, Training Loss: 1.3787, Validation Loss: 1.0876\n",
      "[Trial 183] Epoch 25/60, Training Loss: 0.6858, Validation Loss: 0.5953\n",
      "[Trial 182] Epoch 26/60, Training Loss: 0.7002, Validation Loss: 0.5614\n",
      "[Trial 184] Epoch 11/60, Training Loss: 0.8764, Validation Loss: 0.7743\n",
      "[Trial 190] Epoch 1/60, Training Loss: 7.9202, Validation Loss: 2.6214\n",
      "[Trial 185] Epoch 5/60, Training Loss: 1.1881, Validation Loss: 0.9499\n",
      "[Trial 179] Epoch 37/60, Training Loss: 0.6661, Validation Loss: 0.5656\n",
      "[Trial 189] Epoch 2/60, Training Loss: 1.9733, Validation Loss: 1.3484\n",
      "[Trial 186] Epoch 5/60, Training Loss: 1.1538, Validation Loss: 1.1589\n",
      "[Trial 188] Epoch 4/60, Training Loss: 1.4153, Validation Loss: 1.2552\n",
      "[Trial 181] Epoch 33/60, Training Loss: 0.6018, Validation Loss: 0.4921\n",
      "[Trial 180] Epoch 36/60, Training Loss: 0.6691, Validation Loss: 0.6041\n",
      "[Trial 190] Epoch 2/60, Training Loss: 2.4863, Validation Loss: 2.1561\n",
      "[Trial 178] Epoch 40/60, Training Loss: 0.6320, Validation Loss: 0.5364\n",
      "[Trial 177] Epoch 46/60, Training Loss: 0.5830, Validation Loss: 0.5126\n",
      "[Trial 187] Epoch 5/60, Training Loss: 1.1988, Validation Loss: 0.9894\n",
      "[Trial 183] Epoch 26/60, Training Loss: 0.7117, Validation Loss: 0.5652\n",
      "[Trial 182] Epoch 27/60, Training Loss: 0.6805, Validation Loss: 0.5623\n",
      "[Trial 169] Epoch 58/60, Training Loss: 0.5289, Validation Loss: 0.4777\n",
      "[Trial 184] Epoch 12/60, Training Loss: 0.8863, Validation Loss: 0.7497\n",
      "[Trial 185] Epoch 6/60, Training Loss: 1.0693, Validation Loss: 0.9302\n",
      "[Trial 173] Epoch 48/60, Training Loss: 0.5685, Validation Loss: 0.4676\n",
      "[Trial 179] Epoch 38/60, Training Loss: 0.6682, Validation Loss: 0.5393\n",
      "[Trial 189] Epoch 3/60, Training Loss: 1.6191, Validation Loss: 1.1849\n",
      "[Trial 190] Epoch 3/60, Training Loss: 2.0560, Validation Loss: 1.4046\n",
      "[Trial 186] Epoch 6/60, Training Loss: 1.0750, Validation Loss: 0.9400\n",
      "[Trial 188] Epoch 5/60, Training Loss: 1.2141, Validation Loss: 0.9794\n",
      "[Trial 181] Epoch 34/60, Training Loss: 0.5984, Validation Loss: 0.4933\n",
      "[Trial 180] Epoch 37/60, Training Loss: 0.6644, Validation Loss: 0.6018\n",
      "[Trial 178] Epoch 41/60, Training Loss: 0.5952, Validation Loss: 0.5157\n",
      "[Trial 177] Epoch 47/60, Training Loss: 0.5865, Validation Loss: 0.5318\n",
      "[Trial 187] Epoch 6/60, Training Loss: 1.1044, Validation Loss: 0.8768\n",
      "[Trial 182] Epoch 28/60, Training Loss: 0.6764, Validation Loss: 0.5875\n",
      "[Trial 183] Epoch 27/60, Training Loss: 0.7058, Validation Loss: 0.6791\n",
      "[Trial 190] Epoch 4/60, Training Loss: 1.7255, Validation Loss: 1.4025\n",
      "[Trial 184] Epoch 13/60, Training Loss: 0.8516, Validation Loss: 0.7925\n",
      "[Trial 185] Epoch 7/60, Training Loss: 1.0077, Validation Loss: 0.9547\n",
      "[Trial 179] Epoch 39/60, Training Loss: 0.6709, Validation Loss: 0.5615\n",
      "[Trial 189] Epoch 4/60, Training Loss: 1.3366, Validation Loss: 1.1045\n",
      "[Trial 186] Epoch 7/60, Training Loss: 0.9836, Validation Loss: 0.8138\n",
      "[Trial 188] Epoch 6/60, Training Loss: 1.1148, Validation Loss: 0.7945\n",
      "[Trial 190] Epoch 5/60, Training Loss: 1.5309, Validation Loss: 1.2453\n",
      "[Trial 181] Epoch 35/60, Training Loss: 0.5934, Validation Loss: 0.5107\n",
      "[Trial 180] Epoch 38/60, Training Loss: 0.6647, Validation Loss: 0.6141\n",
      "[Trial 169] Epoch 59/60, Training Loss: 0.5305, Validation Loss: 0.5091\n",
      "[Trial 178] Epoch 42/60, Training Loss: 0.5947, Validation Loss: 0.5075\n",
      "[Trial 177] Epoch 48/60, Training Loss: 0.5904, Validation Loss: 0.5289\n",
      "[Trial 187] Epoch 7/60, Training Loss: 1.0171, Validation Loss: 0.8412\n",
      "[Trial 173] Epoch 49/60, Training Loss: 0.5594, Validation Loss: 0.4823\n",
      "[Trial 182] Epoch 29/60, Training Loss: 0.6838, Validation Loss: 0.5535\n",
      "[Trial 183] Epoch 28/60, Training Loss: 0.6835, Validation Loss: 0.5929\n",
      "[Trial 184] Epoch 14/60, Training Loss: 0.8430, Validation Loss: 0.6787\n",
      "[Trial 185] Epoch 8/60, Training Loss: 0.9653, Validation Loss: 0.8550\n",
      "[Trial 190] Epoch 6/60, Training Loss: 1.4185, Validation Loss: 1.1181\n",
      "[Trial 179] Epoch 40/60, Training Loss: 0.6970, Validation Loss: 0.6029\n",
      "[Trial 189] Epoch 5/60, Training Loss: 1.2169, Validation Loss: 0.9969\n",
      "[Trial 188] Epoch 7/60, Training Loss: 1.0100, Validation Loss: 0.8343\n",
      "[Trial 186] Epoch 8/60, Training Loss: 0.9263, Validation Loss: 0.7394\n",
      "[Trial 181] Epoch 36/60, Training Loss: 0.5955, Validation Loss: 0.5111\n",
      "[Trial 180] Epoch 39/60, Training Loss: 0.6632, Validation Loss: 0.5841\n",
      "[Trial 178] Epoch 43/60, Training Loss: 0.5938, Validation Loss: 0.5146\n",
      "[Trial 177] Epoch 49/60, Training Loss: 0.5686, Validation Loss: 0.5002\n",
      "[Trial 187] Epoch 8/60, Training Loss: 0.9841, Validation Loss: 0.7486\n",
      "[Trial 182] Epoch 30/60, Training Loss: 0.6604, Validation Loss: 0.5663\n",
      "[Trial 190] Epoch 7/60, Training Loss: 1.2745, Validation Loss: 1.0956\n",
      "[Trial 183] Epoch 29/60, Training Loss: 0.6827, Validation Loss: 0.6028\n",
      "[Trial 184] Epoch 15/60, Training Loss: 0.8259, Validation Loss: 0.6464\n",
      "[Trial 185] Epoch 9/60, Training Loss: 0.9237, Validation Loss: 0.8262\n",
      "[Trial 179] Epoch 41/60, Training Loss: 0.6625, Validation Loss: 0.5680\n",
      "[Trial 189] Epoch 6/60, Training Loss: 1.0922, Validation Loss: 0.8585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:41:10,400] Trial 169 finished with value: 0.4777284642060598 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 0.004301039095356645, 'batch_size': 16, 'patience': 10}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 188] Epoch 8/60, Training Loss: 0.9829, Validation Loss: 0.8263\n",
      "[Trial 169] Epoch 60/60, Training Loss: 0.5377, Validation Loss: 0.4858\n",
      "[Trial 186] Epoch 9/60, Training Loss: 0.9025, Validation Loss: 0.7466\n",
      "[Trial 190] Epoch 8/60, Training Loss: 1.1569, Validation Loss: 1.0327\n",
      "[Trial 173] Epoch 50/60, Training Loss: 0.5698, Validation Loss: 0.5542\n",
      "[Trial 180] Epoch 40/60, Training Loss: 0.6518, Validation Loss: 0.5500\n",
      "[Trial 181] Epoch 37/60, Training Loss: 0.5939, Validation Loss: 0.4981\n",
      "[Trial 178] Epoch 44/60, Training Loss: 0.5928, Validation Loss: 0.5123\n",
      "[Trial 177] Epoch 50/60, Training Loss: 0.5715, Validation Loss: 0.5094\n",
      "[Trial 187] Epoch 9/60, Training Loss: 0.9491, Validation Loss: 0.8373\n",
      "[Trial 182] Epoch 31/60, Training Loss: 0.6576, Validation Loss: 0.5260\n",
      "[Trial 183] Epoch 30/60, Training Loss: 0.6215, Validation Loss: 0.5426\n",
      "[Trial 184] Epoch 16/60, Training Loss: 0.8001, Validation Loss: 0.7283\n",
      "[Trial 185] Epoch 10/60, Training Loss: 0.8948, Validation Loss: 0.7523\n",
      "[Trial 190] Epoch 9/60, Training Loss: 1.1128, Validation Loss: 1.0458\n",
      "[Trial 189] Epoch 7/60, Training Loss: 1.0028, Validation Loss: 0.9834\n",
      "[Trial 179] Epoch 42/60, Training Loss: 0.6060, Validation Loss: 0.5183\n",
      "[Trial 188] Epoch 9/60, Training Loss: 0.9129, Validation Loss: 0.8023\n",
      "[Trial 191] Epoch 1/60, Training Loss: 5.6405, Validation Loss: 1.8428\n",
      "[Trial 186] Epoch 10/60, Training Loss: 0.8486, Validation Loss: 0.6970\n",
      "[Trial 180] Epoch 41/60, Training Loss: 0.6559, Validation Loss: 0.5552\n",
      "[Trial 181] Epoch 38/60, Training Loss: 0.5979, Validation Loss: 0.5164\n",
      "[Trial 178] Epoch 45/60, Training Loss: 0.5930, Validation Loss: 0.4948\n",
      "[Trial 177] Epoch 51/60, Training Loss: 0.5697, Validation Loss: 0.5103\n",
      "[Trial 190] Epoch 10/60, Training Loss: 1.0774, Validation Loss: 0.8143\n",
      "[Trial 187] Epoch 10/60, Training Loss: 0.9084, Validation Loss: 0.7052\n",
      "[Trial 182] Epoch 32/60, Training Loss: 0.6634, Validation Loss: 0.5531\n",
      "[Trial 183] Epoch 31/60, Training Loss: 0.6113, Validation Loss: 0.5151\n",
      "[Trial 184] Epoch 17/60, Training Loss: 0.7915, Validation Loss: 0.6493\n",
      "[Trial 185] Epoch 11/60, Training Loss: 0.8869, Validation Loss: 0.6780\n",
      "[Trial 173] Epoch 51/60, Training Loss: 0.5700, Validation Loss: 0.5035\n",
      "[Trial 189] Epoch 8/60, Training Loss: 0.9367, Validation Loss: 0.7803\n",
      "[Trial 179] Epoch 43/60, Training Loss: 0.6015, Validation Loss: 0.5049\n",
      "[Trial 190] Epoch 11/60, Training Loss: 1.0172, Validation Loss: 0.8943\n",
      "[Trial 188] Epoch 10/60, Training Loss: 0.9219, Validation Loss: 0.7385\n",
      "[Trial 191] Epoch 2/60, Training Loss: 2.0802, Validation Loss: 1.7230\n",
      "[Trial 186] Epoch 11/60, Training Loss: 0.8751, Validation Loss: 0.7092\n",
      "[Trial 178] Epoch 46/60, Training Loss: 0.5944, Validation Loss: 0.5066\n",
      "[Trial 180] Epoch 42/60, Training Loss: 0.6651, Validation Loss: 0.6142\n",
      "[Trial 181] Epoch 39/60, Training Loss: 0.5678, Validation Loss: 0.4686\n",
      "[Trial 177] Epoch 52/60, Training Loss: 0.5644, Validation Loss: 0.4961\n",
      "[Trial 187] Epoch 11/60, Training Loss: 0.8728, Validation Loss: 0.7255\n",
      "[Trial 182] Epoch 33/60, Training Loss: 0.6636, Validation Loss: 0.5954\n",
      "[Trial 184] Epoch 18/60, Training Loss: 0.8032, Validation Loss: 0.6737\n",
      "[Trial 183] Epoch 32/60, Training Loss: 0.6081, Validation Loss: 0.5041\n",
      "[Trial 190] Epoch 12/60, Training Loss: 0.9818, Validation Loss: 0.8113\n",
      "[Trial 185] Epoch 12/60, Training Loss: 0.8875, Validation Loss: 0.7253\n",
      "[Trial 189] Epoch 9/60, Training Loss: 0.9141, Validation Loss: 0.7881\n",
      "[Trial 179] Epoch 44/60, Training Loss: 0.5973, Validation Loss: 0.5114\n",
      "[Trial 188] Epoch 11/60, Training Loss: 0.8602, Validation Loss: 0.6787\n",
      "[Trial 191] Epoch 3/60, Training Loss: 1.6491, Validation Loss: 1.2045\n",
      "[Trial 186] Epoch 12/60, Training Loss: 0.7906, Validation Loss: 0.7368\n",
      "[Trial 178] Epoch 47/60, Training Loss: 0.5919, Validation Loss: 0.5062\n",
      "[Trial 180] Epoch 43/60, Training Loss: 0.6554, Validation Loss: 0.5634\n",
      "[Trial 177] Epoch 53/60, Training Loss: 0.5628, Validation Loss: 0.4976\n",
      "[Trial 181] Epoch 40/60, Training Loss: 0.5636, Validation Loss: 0.4712\n",
      "[Trial 190] Epoch 13/60, Training Loss: 0.9951, Validation Loss: 0.7758\n",
      "[Trial 187] Epoch 12/60, Training Loss: 0.8272, Validation Loss: 0.6837\n",
      "[Trial 182] Epoch 34/60, Training Loss: 0.6513, Validation Loss: 0.5460\n",
      "[Trial 184] Epoch 19/60, Training Loss: 0.7716, Validation Loss: 0.6230\n",
      "[Trial 183] Epoch 33/60, Training Loss: 0.6124, Validation Loss: 0.4996\n",
      "[Trial 173] Epoch 52/60, Training Loss: 0.5608, Validation Loss: 0.4853\n",
      "[Trial 185] Epoch 13/60, Training Loss: 0.8307, Validation Loss: 0.7235\n",
      "[Trial 190] Epoch 14/60, Training Loss: 0.9272, Validation Loss: 0.7834\n",
      "[Trial 189] Epoch 10/60, Training Loss: 0.8928, Validation Loss: 0.7951\n",
      "[Trial 179] Epoch 45/60, Training Loss: 0.5931, Validation Loss: 0.5210\n",
      "[Trial 188] Epoch 12/60, Training Loss: 0.8372, Validation Loss: 0.6628\n",
      "[Trial 191] Epoch 4/60, Training Loss: 1.4019, Validation Loss: 0.9382\n",
      "[Trial 186] Epoch 13/60, Training Loss: 0.8000, Validation Loss: 0.6417\n",
      "[Trial 178] Epoch 48/60, Training Loss: 0.5899, Validation Loss: 0.5194\n",
      "[Trial 180] Epoch 44/60, Training Loss: 0.6418, Validation Loss: 0.5902\n",
      "[Trial 177] Epoch 54/60, Training Loss: 0.5649, Validation Loss: 0.5115\n",
      "[Trial 181] Epoch 41/60, Training Loss: 0.5682, Validation Loss: 0.4918\n",
      "[Trial 187] Epoch 13/60, Training Loss: 0.7990, Validation Loss: 0.7040\n",
      "[Trial 182] Epoch 35/60, Training Loss: 0.6520, Validation Loss: 0.5536\n",
      "[Trial 190] Epoch 15/60, Training Loss: 0.9156, Validation Loss: 0.7040\n",
      "[Trial 184] Epoch 20/60, Training Loss: 0.7434, Validation Loss: 0.6532\n",
      "[Trial 183] Epoch 34/60, Training Loss: 0.6101, Validation Loss: 0.5717\n",
      "[Trial 185] Epoch 14/60, Training Loss: 0.8212, Validation Loss: 0.6556\n",
      "[Trial 189] Epoch 11/60, Training Loss: 0.8508, Validation Loss: 0.6805\n",
      "[Trial 188] Epoch 13/60, Training Loss: 0.8132, Validation Loss: 0.6830\n",
      "[Trial 191] Epoch 5/60, Training Loss: 1.1924, Validation Loss: 0.8776\n",
      "[Trial 179] Epoch 46/60, Training Loss: 0.6085, Validation Loss: 0.5194\n",
      "[Trial 186] Epoch 14/60, Training Loss: 0.7929, Validation Loss: 0.7074\n",
      "[Trial 178] Epoch 49/60, Training Loss: 0.5902, Validation Loss: 0.4947\n",
      "[Trial 190] Epoch 16/60, Training Loss: 0.8795, Validation Loss: 0.7198\n",
      "[Trial 180] Epoch 45/60, Training Loss: 0.6413, Validation Loss: 0.5631\n",
      "[Trial 177] Epoch 55/60, Training Loss: 0.5624, Validation Loss: 0.5004\n",
      "[Trial 181] Epoch 42/60, Training Loss: 0.5690, Validation Loss: 0.4928\n",
      "[Trial 182] Epoch 36/60, Training Loss: 0.6536, Validation Loss: 0.5222\n",
      "[Trial 187] Epoch 14/60, Training Loss: 0.8125, Validation Loss: 0.6370\n",
      "[Trial 173] Epoch 53/60, Training Loss: 0.5733, Validation Loss: 0.5216\n",
      "[Trial 184] Epoch 21/60, Training Loss: 0.7500, Validation Loss: 0.6641\n",
      "[Trial 183] Epoch 35/60, Training Loss: 0.6176, Validation Loss: 0.5285\n",
      "[Trial 185] Epoch 15/60, Training Loss: 0.8099, Validation Loss: 0.7141\n",
      "[Trial 190] Epoch 17/60, Training Loss: 0.8592, Validation Loss: 0.6711\n",
      "[Trial 189] Epoch 12/60, Training Loss: 0.8383, Validation Loss: 0.7002\n",
      "[Trial 188] Epoch 14/60, Training Loss: 0.8108, Validation Loss: 0.6414\n",
      "[Trial 191] Epoch 6/60, Training Loss: 1.0908, Validation Loss: 0.9575\n",
      "[Trial 186] Epoch 15/60, Training Loss: 0.7559, Validation Loss: 0.6195\n",
      "[Trial 178] Epoch 50/60, Training Loss: 0.5907, Validation Loss: 0.5150\n",
      "[Trial 179] Epoch 47/60, Training Loss: 0.5994, Validation Loss: 0.5096\n",
      "[Trial 177] Epoch 56/60, Training Loss: 0.5652, Validation Loss: 0.4984\n",
      "[Trial 180] Epoch 46/60, Training Loss: 0.5994, Validation Loss: 0.5158\n",
      "[Trial 181] Epoch 43/60, Training Loss: 0.5699, Validation Loss: 0.4818\n",
      "[Trial 182] Epoch 37/60, Training Loss: 0.6548, Validation Loss: 0.5552\n",
      "[Trial 187] Epoch 15/60, Training Loss: 0.7951, Validation Loss: 0.7033\n",
      "[Trial 190] Epoch 18/60, Training Loss: 0.8540, Validation Loss: 0.6775\n",
      "[Trial 184] Epoch 22/60, Training Loss: 0.7506, Validation Loss: 0.8436\n",
      "[Trial 183] Epoch 36/60, Training Loss: 0.6087, Validation Loss: 0.4978\n",
      "[Trial 185] Epoch 16/60, Training Loss: 0.7721, Validation Loss: 0.6546\n",
      "[Trial 189] Epoch 13/60, Training Loss: 0.8345, Validation Loss: 0.7247\n",
      "[Trial 188] Epoch 15/60, Training Loss: 0.7574, Validation Loss: 0.5904\n",
      "[Trial 191] Epoch 7/60, Training Loss: 1.0195, Validation Loss: 0.7777\n",
      "[Trial 178] Epoch 51/60, Training Loss: 0.5941, Validation Loss: 0.5156\n",
      "[Trial 186] Epoch 16/60, Training Loss: 0.7529, Validation Loss: 0.7132\n",
      "[Trial 179] Epoch 48/60, Training Loss: 0.6023, Validation Loss: 0.4886\n",
      "[Trial 173] Epoch 54/60, Training Loss: 0.5536, Validation Loss: 0.4648\n",
      "[Trial 190] Epoch 19/60, Training Loss: 0.8209, Validation Loss: 0.6640\n",
      "[Trial 177] Epoch 57/60, Training Loss: 0.5645, Validation Loss: 0.4976\n",
      "[Trial 180] Epoch 47/60, Training Loss: 0.5969, Validation Loss: 0.5142\n",
      "[Trial 182] Epoch 38/60, Training Loss: 0.6329, Validation Loss: 0.5458\n",
      "[Trial 181] Epoch 44/60, Training Loss: 0.5638, Validation Loss: 0.4927\n",
      "[Trial 187] Epoch 16/60, Training Loss: 0.7789, Validation Loss: 0.6290\n",
      "[Trial 184] Epoch 23/60, Training Loss: 0.7336, Validation Loss: 0.5982\n",
      "[Trial 183] Epoch 37/60, Training Loss: 0.6056, Validation Loss: 0.5082\n",
      "[Trial 190] Epoch 20/60, Training Loss: 0.8097, Validation Loss: 0.7120\n",
      "[Trial 185] Epoch 17/60, Training Loss: 0.7574, Validation Loss: 0.6341\n",
      "[Trial 188] Epoch 16/60, Training Loss: 0.7437, Validation Loss: 0.6542\n",
      "[Trial 178] Epoch 52/60, Training Loss: 0.5922, Validation Loss: 0.5049\n",
      "[Trial 189] Epoch 14/60, Training Loss: 0.8044, Validation Loss: 0.6738\n",
      "[Trial 191] Epoch 8/60, Training Loss: 0.9764, Validation Loss: 0.8917\n",
      "[Trial 186] Epoch 17/60, Training Loss: 0.7351, Validation Loss: 0.6516\n",
      "[Trial 179] Epoch 49/60, Training Loss: 0.5979, Validation Loss: 0.5408\n",
      "[Trial 177] Epoch 58/60, Training Loss: 0.5555, Validation Loss: 0.4947\n",
      "[Trial 180] Epoch 48/60, Training Loss: 0.5906, Validation Loss: 0.5242\n",
      "[Trial 182] Epoch 39/60, Training Loss: 0.6399, Validation Loss: 0.5765\n",
      "[Trial 187] Epoch 17/60, Training Loss: 0.7645, Validation Loss: 0.6907\n",
      "[Trial 181] Epoch 45/60, Training Loss: 0.5500, Validation Loss: 0.4703\n",
      "[Trial 190] Epoch 21/60, Training Loss: 0.8281, Validation Loss: 0.6720\n",
      "[Trial 184] Epoch 24/60, Training Loss: 0.7283, Validation Loss: 0.6276\n",
      "[Trial 183] Epoch 38/60, Training Loss: 0.6036, Validation Loss: 0.5146\n",
      "[Trial 185] Epoch 18/60, Training Loss: 0.7731, Validation Loss: 0.6262\n",
      "[Trial 173] Epoch 55/60, Training Loss: 0.5367, Validation Loss: 0.4792\n",
      "[Trial 178] Epoch 53/60, Training Loss: 0.5861, Validation Loss: 0.5121\n",
      "[Trial 188] Epoch 17/60, Training Loss: 0.7692, Validation Loss: 0.6548\n",
      "[Trial 191] Epoch 9/60, Training Loss: 0.9372, Validation Loss: 0.7505\n",
      "[Trial 189] Epoch 15/60, Training Loss: 0.7623, Validation Loss: 0.6995\n",
      "[Trial 190] Epoch 22/60, Training Loss: 0.8115, Validation Loss: 0.6622\n",
      "[Trial 186] Epoch 18/60, Training Loss: 0.7399, Validation Loss: 0.5950\n",
      "[Trial 177] Epoch 59/60, Training Loss: 0.5547, Validation Loss: 0.5013\n",
      "[Trial 179] Epoch 50/60, Training Loss: 0.5952, Validation Loss: 0.5164\n",
      "[Trial 180] Epoch 49/60, Training Loss: 0.5829, Validation Loss: 0.5196\n",
      "[Trial 182] Epoch 40/60, Training Loss: 0.6321, Validation Loss: 0.5315\n",
      "[Trial 187] Epoch 18/60, Training Loss: 0.7520, Validation Loss: 0.6274\n",
      "[Trial 181] Epoch 46/60, Training Loss: 0.5452, Validation Loss: 0.4696\n",
      "[Trial 184] Epoch 25/60, Training Loss: 0.7216, Validation Loss: 0.6115\n",
      "[Trial 190] Epoch 23/60, Training Loss: 0.7769, Validation Loss: 0.6260\n",
      "[Trial 183] Epoch 39/60, Training Loss: 0.6046, Validation Loss: 0.5294\n",
      "[Trial 185] Epoch 19/60, Training Loss: 0.7456, Validation Loss: 0.6148\n",
      "[Trial 178] Epoch 54/60, Training Loss: 0.5937, Validation Loss: 0.5008\n",
      "[Trial 188] Epoch 18/60, Training Loss: 0.7400, Validation Loss: 0.6117\n",
      "[Trial 191] Epoch 10/60, Training Loss: 0.8673, Validation Loss: 0.7307\n",
      "[Trial 189] Epoch 16/60, Training Loss: 0.7667, Validation Loss: 0.6502\n",
      "[Trial 186] Epoch 19/60, Training Loss: 0.6992, Validation Loss: 0.6227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:47:47,069] Trial 177 finished with value: 0.4946580082178116 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.004238999023915013, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 177] Epoch 60/60, Training Loss: 0.5508, Validation Loss: 0.4951\n",
      "[Trial 179] Epoch 51/60, Training Loss: 0.5971, Validation Loss: 0.5258\n",
      "[Trial 180] Epoch 50/60, Training Loss: 0.5869, Validation Loss: 0.5051\n",
      "[Trial 182] Epoch 41/60, Training Loss: 0.6364, Validation Loss: 0.5280\n",
      "[Trial 190] Epoch 24/60, Training Loss: 0.7911, Validation Loss: 0.6382\n",
      "[Trial 187] Epoch 19/60, Training Loss: 0.7395, Validation Loss: 0.6336\n",
      "[Trial 181] Epoch 47/60, Training Loss: 0.5401, Validation Loss: 0.4696\n",
      "[Trial 184] Epoch 26/60, Training Loss: 0.7264, Validation Loss: 0.7527\n",
      "[Trial 173] Epoch 56/60, Training Loss: 0.5433, Validation Loss: 0.4853\n",
      "[Trial 183] Epoch 40/60, Training Loss: 0.6086, Validation Loss: 0.5087\n",
      "[Trial 185] Epoch 20/60, Training Loss: 0.7390, Validation Loss: 0.5968\n",
      "[Trial 178] Epoch 55/60, Training Loss: 0.5747, Validation Loss: 0.4925\n",
      "[Trial 190] Epoch 25/60, Training Loss: 0.7767, Validation Loss: 0.7015\n",
      "[Trial 188] Epoch 19/60, Training Loss: 0.7179, Validation Loss: 0.5789\n",
      "[Trial 191] Epoch 11/60, Training Loss: 0.8689, Validation Loss: 0.7239\n",
      "[Trial 189] Epoch 17/60, Training Loss: 0.7747, Validation Loss: 0.6738\n",
      "[Trial 186] Epoch 20/60, Training Loss: 0.7074, Validation Loss: 0.6158\n",
      "[Trial 192] Epoch 1/60, Training Loss: 5.3603, Validation Loss: 2.0256\n",
      "[Trial 180] Epoch 51/60, Training Loss: 0.5873, Validation Loss: 0.5083\n",
      "[Trial 179] Epoch 52/60, Training Loss: 0.5950, Validation Loss: 0.5130\n",
      "[Trial 182] Epoch 42/60, Training Loss: 0.5942, Validation Loss: 0.4942\n",
      "[Trial 187] Epoch 20/60, Training Loss: 0.7371, Validation Loss: 0.6176\n",
      "[Trial 181] Epoch 48/60, Training Loss: 0.5417, Validation Loss: 0.4563\n",
      "[Trial 184] Epoch 27/60, Training Loss: 0.7144, Validation Loss: 0.5846\n",
      "[Trial 190] Epoch 26/60, Training Loss: 0.7751, Validation Loss: 0.6312\n",
      "[Trial 183] Epoch 41/60, Training Loss: 0.5999, Validation Loss: 0.5247\n",
      "[Trial 185] Epoch 21/60, Training Loss: 0.7301, Validation Loss: 0.6606\n",
      "[Trial 178] Epoch 56/60, Training Loss: 0.5740, Validation Loss: 0.4832\n",
      "[Trial 188] Epoch 20/60, Training Loss: 0.7265, Validation Loss: 0.6238\n",
      "[Trial 191] Epoch 12/60, Training Loss: 0.8299, Validation Loss: 0.6445\n",
      "[Trial 189] Epoch 18/60, Training Loss: 0.7231, Validation Loss: 0.6652\n",
      "[Trial 186] Epoch 21/60, Training Loss: 0.7071, Validation Loss: 0.5834\n",
      "[Trial 192] Epoch 2/60, Training Loss: 2.1688, Validation Loss: 1.5508\n",
      "[Trial 180] Epoch 52/60, Training Loss: 0.5777, Validation Loss: 0.4972\n",
      "[Trial 190] Epoch 27/60, Training Loss: 0.7505, Validation Loss: 0.6605\n",
      "[Trial 179] Epoch 53/60, Training Loss: 0.5890, Validation Loss: 0.5099\n",
      "[Trial 182] Epoch 43/60, Training Loss: 0.5840, Validation Loss: 0.4858\n",
      "[Trial 187] Epoch 21/60, Training Loss: 0.7323, Validation Loss: 0.6225\n",
      "[Trial 173] Epoch 57/60, Training Loss: 0.5410, Validation Loss: 0.4770\n",
      "[Trial 181] Epoch 49/60, Training Loss: 0.5432, Validation Loss: 0.4628\n",
      "[Trial 184] Epoch 28/60, Training Loss: 0.7091, Validation Loss: 0.6360\n",
      "[Trial 183] Epoch 42/60, Training Loss: 0.5681, Validation Loss: 0.4782\n",
      "[Trial 178] Epoch 57/60, Training Loss: 0.5718, Validation Loss: 0.4860\n",
      "[Trial 185] Epoch 22/60, Training Loss: 0.7387, Validation Loss: 0.5610\n",
      "[Trial 190] Epoch 28/60, Training Loss: 0.7426, Validation Loss: 0.6294\n",
      "[Trial 188] Epoch 21/60, Training Loss: 0.7053, Validation Loss: 0.5755\n",
      "[Trial 191] Epoch 13/60, Training Loss: 0.8025, Validation Loss: 0.6887\n",
      "[Trial 189] Epoch 19/60, Training Loss: 0.7371, Validation Loss: 0.6195\n",
      "[Trial 186] Epoch 22/60, Training Loss: 0.6969, Validation Loss: 0.5889\n",
      "[Trial 192] Epoch 3/60, Training Loss: 1.6415, Validation Loss: 1.2736\n",
      "[Trial 180] Epoch 53/60, Training Loss: 0.5879, Validation Loss: 0.5067\n",
      "[Trial 179] Epoch 54/60, Training Loss: 0.5651, Validation Loss: 0.4763\n",
      "[Trial 187] Epoch 22/60, Training Loss: 0.7357, Validation Loss: 0.6786\n",
      "[Trial 182] Epoch 44/60, Training Loss: 0.5792, Validation Loss: 0.4954\n",
      "[Trial 181] Epoch 50/60, Training Loss: 0.5393, Validation Loss: 0.4634\n",
      "[Trial 190] Epoch 29/60, Training Loss: 0.6760, Validation Loss: 0.5783\n",
      "[Trial 184] Epoch 29/60, Training Loss: 0.6973, Validation Loss: 0.6161\n",
      "[Trial 183] Epoch 43/60, Training Loss: 0.5685, Validation Loss: 0.4968\n",
      "[Trial 178] Epoch 58/60, Training Loss: 0.5700, Validation Loss: 0.4900\n",
      "[Trial 185] Epoch 23/60, Training Loss: 0.7058, Validation Loss: 0.6420\n",
      "[Trial 188] Epoch 22/60, Training Loss: 0.7299, Validation Loss: 0.6623\n",
      "[Trial 191] Epoch 14/60, Training Loss: 0.8236, Validation Loss: 0.6884\n",
      "[Trial 189] Epoch 20/60, Training Loss: 0.6989, Validation Loss: 0.5992\n",
      "[Trial 186] Epoch 23/60, Training Loss: 0.7100, Validation Loss: 0.6110\n",
      "[Trial 173] Epoch 58/60, Training Loss: 0.5411, Validation Loss: 0.4770\n",
      "[Trial 192] Epoch 4/60, Training Loss: 1.3630, Validation Loss: 1.0228\n",
      "[Trial 190] Epoch 30/60, Training Loss: 0.6607, Validation Loss: 0.5712\n",
      "[Trial 180] Epoch 54/60, Training Loss: 0.5867, Validation Loss: 0.4906\n",
      "[Trial 179] Epoch 55/60, Training Loss: 0.5607, Validation Loss: 0.4730\n",
      "[Trial 182] Epoch 45/60, Training Loss: 0.5795, Validation Loss: 0.5281\n",
      "[Trial 187] Epoch 23/60, Training Loss: 0.7135, Validation Loss: 0.5978\n",
      "[Trial 181] Epoch 51/60, Training Loss: 0.5425, Validation Loss: 0.4702\n",
      "[Trial 184] Epoch 30/60, Training Loss: 0.6932, Validation Loss: 0.6015\n",
      "[Trial 190] Epoch 31/60, Training Loss: 0.6488, Validation Loss: 0.5410\n",
      "[Trial 178] Epoch 59/60, Training Loss: 0.5661, Validation Loss: 0.4895\n",
      "[Trial 183] Epoch 44/60, Training Loss: 0.5725, Validation Loss: 0.5067\n",
      "[Trial 185] Epoch 24/60, Training Loss: 0.7048, Validation Loss: 0.6139\n",
      "[Trial 191] Epoch 15/60, Training Loss: 0.7665, Validation Loss: 0.6386\n",
      "[Trial 188] Epoch 23/60, Training Loss: 0.7121, Validation Loss: 0.5560\n",
      "[Trial 189] Epoch 21/60, Training Loss: 0.7191, Validation Loss: 0.6149\n",
      "[Trial 186] Epoch 24/60, Training Loss: 0.6913, Validation Loss: 0.5648\n",
      "[Trial 192] Epoch 5/60, Training Loss: 1.1727, Validation Loss: 0.9547\n",
      "[Trial 180] Epoch 55/60, Training Loss: 0.5822, Validation Loss: 0.5021\n",
      "[Trial 187] Epoch 24/60, Training Loss: 0.7149, Validation Loss: 0.5957\n",
      "[Trial 182] Epoch 46/60, Training Loss: 0.5774, Validation Loss: 0.5094\n",
      "[Trial 179] Epoch 56/60, Training Loss: 0.5591, Validation Loss: 0.4819\n",
      "[Trial 190] Epoch 32/60, Training Loss: 0.6617, Validation Loss: 0.5497\n",
      "[Trial 181] Epoch 52/60, Training Loss: 0.5404, Validation Loss: 0.4663\n",
      "[Trial 184] Epoch 31/60, Training Loss: 0.7038, Validation Loss: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:51:30,560] Trial 178 finished with value: 0.4831719090541204 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.004138770262166165, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 178] Epoch 60/60, Training Loss: 0.5666, Validation Loss: 0.4943\n",
      "[Trial 173] Epoch 59/60, Training Loss: 0.5368, Validation Loss: 0.4724\n",
      "[Trial 183] Epoch 45/60, Training Loss: 0.5624, Validation Loss: 0.5028\n",
      "[Trial 185] Epoch 25/60, Training Loss: 0.7149, Validation Loss: 0.5984\n",
      "[Trial 191] Epoch 16/60, Training Loss: 0.7699, Validation Loss: 0.6444\n",
      "[Trial 188] Epoch 24/60, Training Loss: 0.6860, Validation Loss: 0.6174\n",
      "[Trial 190] Epoch 33/60, Training Loss: 0.6506, Validation Loss: 0.5507\n",
      "[Trial 189] Epoch 22/60, Training Loss: 0.7110, Validation Loss: 0.6403\n",
      "[Trial 186] Epoch 25/60, Training Loss: 0.6818, Validation Loss: 0.5965\n",
      "[Trial 192] Epoch 6/60, Training Loss: 1.0246, Validation Loss: 0.8490\n",
      "[Trial 180] Epoch 56/60, Training Loss: 0.5879, Validation Loss: 0.5344\n",
      "[Trial 187] Epoch 25/60, Training Loss: 0.7109, Validation Loss: 0.5694\n",
      "[Trial 182] Epoch 47/60, Training Loss: 0.5841, Validation Loss: 0.4915\n",
      "[Trial 179] Epoch 57/60, Training Loss: 0.5519, Validation Loss: 0.4825\n",
      "[Trial 184] Epoch 32/60, Training Loss: 0.6847, Validation Loss: 0.5923\n",
      "[Trial 181] Epoch 53/60, Training Loss: 0.5350, Validation Loss: 0.4683\n",
      "[Trial 190] Epoch 34/60, Training Loss: 0.6611, Validation Loss: 0.5749\n",
      "[Trial 193] Epoch 1/60, Training Loss: 5.5805, Validation Loss: 1.9236\n",
      "[Trial 183] Epoch 46/60, Training Loss: 0.5653, Validation Loss: 0.4843\n",
      "[Trial 185] Epoch 26/60, Training Loss: 0.7014, Validation Loss: 0.5567\n",
      "[Trial 191] Epoch 17/60, Training Loss: 0.7528, Validation Loss: 0.6147\n",
      "[Trial 188] Epoch 25/60, Training Loss: 0.6841, Validation Loss: 0.5795\n",
      "[Trial 189] Epoch 23/60, Training Loss: 0.6962, Validation Loss: 0.6382\n",
      "[Trial 186] Epoch 26/60, Training Loss: 0.6783, Validation Loss: 0.5514\n",
      "[Trial 192] Epoch 7/60, Training Loss: 0.9614, Validation Loss: 0.8281\n",
      "[Trial 180] Epoch 57/60, Training Loss: 0.5797, Validation Loss: 0.4879\n",
      "[Trial 190] Epoch 35/60, Training Loss: 0.6515, Validation Loss: 0.5634\n",
      "[Trial 187] Epoch 26/60, Training Loss: 0.7032, Validation Loss: 0.5501\n",
      "[Trial 182] Epoch 48/60, Training Loss: 0.5764, Validation Loss: 0.4839\n",
      "[Trial 179] Epoch 58/60, Training Loss: 0.5482, Validation Loss: 0.4637\n",
      "[Trial 184] Epoch 33/60, Training Loss: 0.6353, Validation Loss: 0.5567\n",
      "[Trial 181] Epoch 54/60, Training Loss: 0.5338, Validation Loss: 0.4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:52:42,656] Trial 173 finished with value: 0.464781986673673 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004381874158027646, 'batch_size': 16, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 173] Epoch 60/60, Training Loss: 0.5424, Validation Loss: 0.4702\n",
      "[Trial 193] Epoch 2/60, Training Loss: 2.1313, Validation Loss: 1.6107\n",
      "[Trial 190] Epoch 36/60, Training Loss: 0.6541, Validation Loss: 0.5366\n",
      "[Trial 183] Epoch 47/60, Training Loss: 0.5602, Validation Loss: 0.4618\n",
      "[Trial 185] Epoch 27/60, Training Loss: 0.6915, Validation Loss: 0.6196\n",
      "[Trial 191] Epoch 18/60, Training Loss: 0.7480, Validation Loss: 0.6702\n",
      "[Trial 188] Epoch 26/60, Training Loss: 0.6927, Validation Loss: 0.5695\n",
      "[Trial 189] Epoch 24/60, Training Loss: 0.6783, Validation Loss: 0.5646\n",
      "[Trial 186] Epoch 27/60, Training Loss: 0.6717, Validation Loss: 0.5658\n",
      "[Trial 192] Epoch 8/60, Training Loss: 0.9233, Validation Loss: 0.8424\n",
      "[Trial 180] Epoch 58/60, Training Loss: 0.5841, Validation Loss: 0.5530\n",
      "[Trial 187] Epoch 27/60, Training Loss: 0.6889, Validation Loss: 0.5684\n",
      "[Trial 182] Epoch 49/60, Training Loss: 0.5781, Validation Loss: 0.4935\n",
      "[Trial 179] Epoch 59/60, Training Loss: 0.5576, Validation Loss: 0.4807\n",
      "[Trial 184] Epoch 34/60, Training Loss: 0.6291, Validation Loss: 0.5388\n",
      "[Trial 181] Epoch 55/60, Training Loss: 0.5298, Validation Loss: 0.4528\n",
      "[Trial 190] Epoch 37/60, Training Loss: 0.6516, Validation Loss: 0.5445\n",
      "[Trial 194] Epoch 1/60, Training Loss: 5.2801, Validation Loss: 2.2827\n",
      "[Trial 193] Epoch 3/60, Training Loss: 1.7473, Validation Loss: 1.3074\n",
      "[Trial 183] Epoch 48/60, Training Loss: 0.5584, Validation Loss: 0.4613\n",
      "[Trial 191] Epoch 19/60, Training Loss: 0.7328, Validation Loss: 0.5896\n",
      "[Trial 185] Epoch 28/60, Training Loss: 0.6818, Validation Loss: 0.5826\n",
      "[Trial 188] Epoch 27/60, Training Loss: 0.6641, Validation Loss: 0.7550\n",
      "[Trial 189] Epoch 25/60, Training Loss: 0.6789, Validation Loss: 0.5927\n",
      "[Trial 186] Epoch 28/60, Training Loss: 0.6613, Validation Loss: 0.6254\n",
      "[Trial 192] Epoch 9/60, Training Loss: 0.8977, Validation Loss: 1.0114\n",
      "[Trial 190] Epoch 38/60, Training Loss: 0.6366, Validation Loss: 0.5330\n",
      "[Trial 180] Epoch 59/60, Training Loss: 0.5777, Validation Loss: 0.5116\n",
      "[Trial 187] Epoch 28/60, Training Loss: 0.6850, Validation Loss: 0.5807\n",
      "[Trial 182] Epoch 50/60, Training Loss: 0.5773, Validation Loss: 0.4943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:53:56,212] Trial 179 finished with value: 0.46370363334814707 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.004353372713226948, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 179] Epoch 60/60, Training Loss: 0.5546, Validation Loss: 0.4849\n",
      "[Trial 184] Epoch 35/60, Training Loss: 0.6251, Validation Loss: 0.5902\n",
      "[Trial 181] Epoch 56/60, Training Loss: 0.5326, Validation Loss: 0.4601\n",
      "[Trial 194] Epoch 2/60, Training Loss: 2.0191, Validation Loss: 1.5310\n",
      "[Trial 193] Epoch 4/60, Training Loss: 1.5496, Validation Loss: 1.1907\n",
      "[Trial 190] Epoch 39/60, Training Loss: 0.6404, Validation Loss: 0.5459\n",
      "[Trial 191] Epoch 20/60, Training Loss: 0.7425, Validation Loss: 0.6525\n",
      "[Trial 183] Epoch 49/60, Training Loss: 0.5652, Validation Loss: 0.5023\n",
      "[Trial 185] Epoch 29/60, Training Loss: 0.6927, Validation Loss: 0.5974\n",
      "[Trial 188] Epoch 28/60, Training Loss: 0.7005, Validation Loss: 0.6095\n",
      "[Trial 189] Epoch 26/60, Training Loss: 0.6946, Validation Loss: 0.5713\n",
      "[Trial 186] Epoch 29/60, Training Loss: 0.6665, Validation Loss: 0.5970\n",
      "[Trial 192] Epoch 10/60, Training Loss: 0.8946, Validation Loss: 0.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:54:29,491] Trial 180 finished with value: 0.4879194935162862 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004305886983353465, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 180] Epoch 60/60, Training Loss: 0.5779, Validation Loss: 0.5529\n",
      "[Trial 187] Epoch 29/60, Training Loss: 0.6844, Validation Loss: 0.5928\n",
      "[Trial 182] Epoch 51/60, Training Loss: 0.5753, Validation Loss: 0.4830\n",
      "[Trial 195] Epoch 1/60, Training Loss: 5.5950, Validation Loss: 2.1392\n",
      "[Trial 190] Epoch 40/60, Training Loss: 0.6376, Validation Loss: 0.5373\n",
      "[Trial 184] Epoch 36/60, Training Loss: 0.6295, Validation Loss: 0.5472\n",
      "[Trial 181] Epoch 57/60, Training Loss: 0.5342, Validation Loss: 0.4593\n",
      "[Trial 194] Epoch 3/60, Training Loss: 1.6228, Validation Loss: 1.3008\n",
      "[Trial 193] Epoch 5/60, Training Loss: 1.2648, Validation Loss: 0.9500\n",
      "[Trial 191] Epoch 21/60, Training Loss: 0.7154, Validation Loss: 0.6435\n",
      "[Trial 185] Epoch 30/60, Training Loss: 0.6772, Validation Loss: 0.5941\n",
      "[Trial 183] Epoch 50/60, Training Loss: 0.5636, Validation Loss: 0.4844\n",
      "[Trial 188] Epoch 29/60, Training Loss: 0.6149, Validation Loss: 0.5027\n",
      "[Trial 190] Epoch 41/60, Training Loss: 0.6418, Validation Loss: 0.5465\n",
      "[Trial 189] Epoch 27/60, Training Loss: 0.6840, Validation Loss: 0.6112\n",
      "[Trial 186] Epoch 30/60, Training Loss: 0.6589, Validation Loss: 0.5284\n",
      "[Trial 192] Epoch 11/60, Training Loss: 0.8236, Validation Loss: 0.7712\n",
      "[Trial 187] Epoch 30/60, Training Loss: 0.6973, Validation Loss: 0.5971\n",
      "[Trial 196] Epoch 1/60, Training Loss: 6.2279, Validation Loss: 2.7812\n",
      "[Trial 182] Epoch 52/60, Training Loss: 0.5756, Validation Loss: 0.5059\n",
      "[Trial 195] Epoch 2/60, Training Loss: 2.1049, Validation Loss: 1.7253\n",
      "[Trial 184] Epoch 37/60, Training Loss: 0.6267, Validation Loss: 0.5452\n",
      "[Trial 181] Epoch 58/60, Training Loss: 0.5343, Validation Loss: 0.4571\n",
      "[Trial 194] Epoch 4/60, Training Loss: 1.4144, Validation Loss: 1.0354\n",
      "[Trial 190] Epoch 42/60, Training Loss: 0.6346, Validation Loss: 0.5571\n",
      "[Trial 193] Epoch 6/60, Training Loss: 1.1411, Validation Loss: 0.9201\n",
      "[Trial 191] Epoch 22/60, Training Loss: 0.6993, Validation Loss: 0.5700\n",
      "[Trial 185] Epoch 31/60, Training Loss: 0.6880, Validation Loss: 0.5695\n",
      "[Trial 188] Epoch 30/60, Training Loss: 0.6019, Validation Loss: 0.5146\n",
      "[Trial 183] Epoch 51/60, Training Loss: 0.5602, Validation Loss: 0.4995\n",
      "[Trial 186] Epoch 31/60, Training Loss: 0.6678, Validation Loss: 0.5720\n",
      "[Trial 189] Epoch 28/60, Training Loss: 0.6649, Validation Loss: 0.5699\n",
      "[Trial 192] Epoch 12/60, Training Loss: 0.8014, Validation Loss: 0.7202\n",
      "[Trial 187] Epoch 31/60, Training Loss: 0.6836, Validation Loss: 0.5980\n",
      "[Trial 182] Epoch 53/60, Training Loss: 0.5830, Validation Loss: 0.4912\n",
      "[Trial 196] Epoch 2/60, Training Loss: 2.1828, Validation Loss: 1.6810\n",
      "[Trial 190] Epoch 43/60, Training Loss: 0.6378, Validation Loss: 0.5399\n",
      "[Trial 195] Epoch 3/60, Training Loss: 1.6866, Validation Loss: 1.1532\n",
      "[Trial 184] Epoch 38/60, Training Loss: 0.6263, Validation Loss: 0.5392\n",
      "[Trial 181] Epoch 59/60, Training Loss: 0.5293, Validation Loss: 0.4507\n",
      "[Trial 194] Epoch 5/60, Training Loss: 1.2806, Validation Loss: 1.0818\n",
      "[Trial 193] Epoch 7/60, Training Loss: 1.0612, Validation Loss: 0.8182\n",
      "[Trial 191] Epoch 23/60, Training Loss: 0.7059, Validation Loss: 0.6025\n",
      "[Trial 190] Epoch 44/60, Training Loss: 0.6154, Validation Loss: 0.5080\n",
      "[Trial 188] Epoch 31/60, Training Loss: 0.6164, Validation Loss: 0.5036\n",
      "[Trial 185] Epoch 32/60, Training Loss: 0.6216, Validation Loss: 0.5102\n",
      "[Trial 183] Epoch 52/60, Training Loss: 0.5643, Validation Loss: 0.5131\n",
      "[Trial 186] Epoch 32/60, Training Loss: 0.6662, Validation Loss: 0.6378\n",
      "[Trial 192] Epoch 13/60, Training Loss: 0.7969, Validation Loss: 0.6394\n",
      "[Trial 189] Epoch 29/60, Training Loss: 0.6537, Validation Loss: 0.5658\n",
      "[Trial 187] Epoch 32/60, Training Loss: 0.6176, Validation Loss: 0.5155\n",
      "[Trial 182] Epoch 54/60, Training Loss: 0.5693, Validation Loss: 0.4956\n",
      "[Trial 196] Epoch 3/60, Training Loss: 1.6524, Validation Loss: 1.6291\n",
      "[Trial 195] Epoch 4/60, Training Loss: 1.5076, Validation Loss: 0.9911\n",
      "[Trial 184] Epoch 39/60, Training Loss: 0.6187, Validation Loss: 0.5229\n",
      "[Trial 190] Epoch 45/60, Training Loss: 0.6032, Validation Loss: 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:56:40,137] Trial 181 finished with value: 0.450721400976181 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004283043985987272, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 194] Epoch 6/60, Training Loss: 1.1384, Validation Loss: 1.0335\n",
      "[Trial 181] Epoch 60/60, Training Loss: 0.5291, Validation Loss: 0.4520\n",
      "[Trial 193] Epoch 8/60, Training Loss: 0.9646, Validation Loss: 0.8460\n",
      "[Trial 191] Epoch 24/60, Training Loss: 0.7042, Validation Loss: 0.5928\n",
      "[Trial 188] Epoch 32/60, Training Loss: 0.6026, Validation Loss: 0.4975\n",
      "[Trial 185] Epoch 33/60, Training Loss: 0.6147, Validation Loss: 0.5184\n",
      "[Trial 183] Epoch 53/60, Training Loss: 0.5555, Validation Loss: 0.4729\n",
      "[Trial 186] Epoch 33/60, Training Loss: 0.6460, Validation Loss: 0.6129\n",
      "[Trial 192] Epoch 14/60, Training Loss: 0.7869, Validation Loss: 0.6324\n",
      "[Trial 189] Epoch 30/60, Training Loss: 0.6001, Validation Loss: 0.5196\n",
      "[Trial 182] Epoch 55/60, Training Loss: 0.5758, Validation Loss: 0.4862\n",
      "[Trial 187] Epoch 33/60, Training Loss: 0.6194, Validation Loss: 0.5625\n",
      "[Trial 190] Epoch 46/60, Training Loss: 0.6035, Validation Loss: 0.5060\n",
      "[Trial 196] Epoch 4/60, Training Loss: 1.3747, Validation Loss: 1.3175\n",
      "[Trial 195] Epoch 5/60, Training Loss: 1.2832, Validation Loss: 0.9985\n",
      "[Trial 184] Epoch 40/60, Training Loss: 0.6247, Validation Loss: 0.5594\n",
      "[Trial 194] Epoch 7/60, Training Loss: 1.0436, Validation Loss: 0.7983\n",
      "[Trial 197] Epoch 1/60, Training Loss: 5.5728, Validation Loss: 2.0658\n",
      "[Trial 193] Epoch 9/60, Training Loss: 0.9441, Validation Loss: 0.7849\n",
      "[Trial 191] Epoch 25/60, Training Loss: 0.6924, Validation Loss: 0.6918\n",
      "[Trial 190] Epoch 47/60, Training Loss: 0.5894, Validation Loss: 0.5142\n",
      "[Trial 188] Epoch 33/60, Training Loss: 0.6023, Validation Loss: 0.5124\n",
      "[Trial 185] Epoch 34/60, Training Loss: 0.6174, Validation Loss: 0.5544\n",
      "[Trial 183] Epoch 54/60, Training Loss: 0.5423, Validation Loss: 0.4703\n",
      "[Trial 186] Epoch 34/60, Training Loss: 0.6425, Validation Loss: 0.6770\n",
      "[Trial 192] Epoch 15/60, Training Loss: 0.7580, Validation Loss: 0.6502\n",
      "[Trial 189] Epoch 31/60, Training Loss: 0.5946, Validation Loss: 0.5144\n",
      "[Trial 182] Epoch 56/60, Training Loss: 0.5741, Validation Loss: 0.4985\n",
      "[Trial 187] Epoch 34/60, Training Loss: 0.6234, Validation Loss: 0.5197\n",
      "[Trial 196] Epoch 5/60, Training Loss: 1.1924, Validation Loss: 1.0951\n",
      "[Trial 195] Epoch 6/60, Training Loss: 1.1144, Validation Loss: 0.8908\n",
      "[Trial 184] Epoch 41/60, Training Loss: 0.6206, Validation Loss: 0.5406\n",
      "[Trial 190] Epoch 48/60, Training Loss: 0.5924, Validation Loss: 0.5072\n",
      "[Trial 194] Epoch 8/60, Training Loss: 0.9805, Validation Loss: 0.8589\n",
      "[Trial 197] Epoch 2/60, Training Loss: 2.0633, Validation Loss: 1.3673\n",
      "[Trial 193] Epoch 10/60, Training Loss: 0.9051, Validation Loss: 0.7428\n",
      "[Trial 191] Epoch 26/60, Training Loss: 0.6889, Validation Loss: 0.5943\n",
      "[Trial 188] Epoch 34/60, Training Loss: 0.6083, Validation Loss: 0.5008\n",
      "[Trial 185] Epoch 35/60, Training Loss: 0.6123, Validation Loss: 0.5374\n",
      "[Trial 183] Epoch 55/60, Training Loss: 0.5377, Validation Loss: 0.4571\n",
      "[Trial 186] Epoch 35/60, Training Loss: 0.6400, Validation Loss: 0.5812\n",
      "[Trial 190] Epoch 49/60, Training Loss: 0.5881, Validation Loss: 0.4899\n",
      "[Trial 192] Epoch 16/60, Training Loss: 0.7520, Validation Loss: 0.5906\n",
      "[Trial 189] Epoch 32/60, Training Loss: 0.5949, Validation Loss: 0.5179\n",
      "[Trial 187] Epoch 35/60, Training Loss: 0.6146, Validation Loss: 0.5273\n",
      "[Trial 182] Epoch 57/60, Training Loss: 0.5460, Validation Loss: 0.4921\n",
      "[Trial 196] Epoch 6/60, Training Loss: 1.1025, Validation Loss: 0.8765\n",
      "[Trial 195] Epoch 7/60, Training Loss: 1.0451, Validation Loss: 0.8171\n",
      "[Trial 184] Epoch 42/60, Training Loss: 0.6234, Validation Loss: 0.5639\n",
      "[Trial 194] Epoch 9/60, Training Loss: 0.9122, Validation Loss: 0.7901\n",
      "[Trial 193] Epoch 11/60, Training Loss: 0.8831, Validation Loss: 0.7281\n",
      "[Trial 197] Epoch 3/60, Training Loss: 1.5999, Validation Loss: 1.5438\n",
      "[Trial 190] Epoch 50/60, Training Loss: 0.5902, Validation Loss: 0.5027\n",
      "[Trial 191] Epoch 27/60, Training Loss: 0.6724, Validation Loss: 0.5943\n",
      "[Trial 188] Epoch 35/60, Training Loss: 0.5977, Validation Loss: 0.5060\n",
      "[Trial 185] Epoch 36/60, Training Loss: 0.6183, Validation Loss: 0.5405\n",
      "[Trial 183] Epoch 56/60, Training Loss: 0.5379, Validation Loss: 0.4754\n",
      "[Trial 186] Epoch 36/60, Training Loss: 0.5917, Validation Loss: 0.5226\n",
      "[Trial 192] Epoch 17/60, Training Loss: 0.7413, Validation Loss: 0.6357\n",
      "[Trial 189] Epoch 33/60, Training Loss: 0.5923, Validation Loss: 0.5181\n",
      "[Trial 187] Epoch 36/60, Training Loss: 0.6150, Validation Loss: 0.5267\n",
      "[Trial 182] Epoch 58/60, Training Loss: 0.5444, Validation Loss: 0.4749\n",
      "[Trial 196] Epoch 7/60, Training Loss: 1.0333, Validation Loss: 0.8994\n",
      "[Trial 195] Epoch 8/60, Training Loss: 1.0018, Validation Loss: 0.8620\n",
      "[Trial 184] Epoch 43/60, Training Loss: 0.6182, Validation Loss: 0.5315\n",
      "[Trial 190] Epoch 51/60, Training Loss: 0.5990, Validation Loss: 0.5034\n",
      "[Trial 194] Epoch 10/60, Training Loss: 0.8848, Validation Loss: 0.7378\n",
      "[Trial 193] Epoch 12/60, Training Loss: 0.8700, Validation Loss: 0.6961\n",
      "[Trial 197] Epoch 4/60, Training Loss: 1.3781, Validation Loss: 1.0323\n",
      "[Trial 191] Epoch 28/60, Training Loss: 0.6276, Validation Loss: 0.5392\n",
      "[Trial 188] Epoch 36/60, Training Loss: 0.6026, Validation Loss: 0.5090\n",
      "[Trial 190] Epoch 52/60, Training Loss: 0.5970, Validation Loss: 0.5196\n",
      "[Trial 185] Epoch 37/60, Training Loss: 0.6153, Validation Loss: 0.5167\n",
      "[Trial 183] Epoch 57/60, Training Loss: 0.5367, Validation Loss: 0.4710\n",
      "[Trial 186] Epoch 37/60, Training Loss: 0.5842, Validation Loss: 0.4820\n",
      "[Trial 192] Epoch 18/60, Training Loss: 0.7239, Validation Loss: 0.6697\n",
      "[Trial 189] Epoch 34/60, Training Loss: 0.5880, Validation Loss: 0.5216\n",
      "[Trial 187] Epoch 37/60, Training Loss: 0.6175, Validation Loss: 0.5433\n",
      "[Trial 182] Epoch 59/60, Training Loss: 0.5392, Validation Loss: 0.4759\n",
      "[Trial 196] Epoch 8/60, Training Loss: 0.9486, Validation Loss: 0.8424\n",
      "[Trial 195] Epoch 9/60, Training Loss: 0.9630, Validation Loss: 0.7454\n",
      "[Trial 184] Epoch 44/60, Training Loss: 0.6093, Validation Loss: 0.5450\n",
      "[Trial 193] Epoch 13/60, Training Loss: 0.8319, Validation Loss: 0.6029\n",
      "[Trial 194] Epoch 11/60, Training Loss: 0.8868, Validation Loss: 0.6953\n",
      "[Trial 190] Epoch 53/60, Training Loss: 0.5967, Validation Loss: 0.5167\n",
      "[Trial 197] Epoch 5/60, Training Loss: 1.2232, Validation Loss: 0.9996\n",
      "[Trial 191] Epoch 29/60, Training Loss: 0.6098, Validation Loss: 0.5114\n",
      "[Trial 188] Epoch 37/60, Training Loss: 0.5975, Validation Loss: 0.5214\n",
      "[Trial 185] Epoch 38/60, Training Loss: 0.5805, Validation Loss: 0.4925\n",
      "[Trial 186] Epoch 38/60, Training Loss: 0.5805, Validation Loss: 0.5302\n",
      "[Trial 183] Epoch 58/60, Training Loss: 0.5342, Validation Loss: 0.4531\n",
      "[Trial 192] Epoch 19/60, Training Loss: 0.7084, Validation Loss: 0.6331\n",
      "[Trial 187] Epoch 38/60, Training Loss: 0.5852, Validation Loss: 0.4918\n",
      "[Trial 189] Epoch 35/60, Training Loss: 0.5856, Validation Loss: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:00:16,985] Trial 182 finished with value: 0.4648661772410075 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.0044468764011847016, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 182] Epoch 60/60, Training Loss: 0.5442, Validation Loss: 0.4649\n",
      "[Trial 196] Epoch 9/60, Training Loss: 0.9278, Validation Loss: 0.7256\n",
      "[Trial 195] Epoch 10/60, Training Loss: 0.9278, Validation Loss: 0.7548\n",
      "[Trial 184] Epoch 45/60, Training Loss: 0.5882, Validation Loss: 0.5068\n",
      "[Trial 190] Epoch 54/60, Training Loss: 0.5899, Validation Loss: 0.5136\n",
      "[Trial 193] Epoch 14/60, Training Loss: 0.8448, Validation Loss: 0.8554\n",
      "[Trial 194] Epoch 12/60, Training Loss: 0.8024, Validation Loss: 0.7344\n",
      "[Trial 191] Epoch 30/60, Training Loss: 0.6125, Validation Loss: 0.5579\n",
      "[Trial 197] Epoch 6/60, Training Loss: 1.1033, Validation Loss: 0.9202\n",
      "[Trial 190] Epoch 55/60, Training Loss: 0.5728, Validation Loss: 0.4980\n",
      "[Trial 188] Epoch 38/60, Training Loss: 0.5619, Validation Loss: 0.4716\n",
      "[Trial 186] Epoch 39/60, Training Loss: 0.5899, Validation Loss: 0.5223\n",
      "[Trial 192] Epoch 20/60, Training Loss: 0.7300, Validation Loss: 0.6045\n",
      "[Trial 185] Epoch 39/60, Training Loss: 0.5781, Validation Loss: 0.5054\n",
      "[Trial 183] Epoch 59/60, Training Loss: 0.5361, Validation Loss: 0.4637\n",
      "[Trial 187] Epoch 39/60, Training Loss: 0.5788, Validation Loss: 0.4918\n",
      "[Trial 198] Epoch 1/60, Training Loss: 4.1171, Validation Loss: 1.8351\n",
      "[Trial 196] Epoch 10/60, Training Loss: 0.8845, Validation Loss: 0.7634\n",
      "[Trial 189] Epoch 36/60, Training Loss: 0.5894, Validation Loss: 0.4799\n",
      "[Trial 195] Epoch 11/60, Training Loss: 0.8884, Validation Loss: 0.7178\n",
      "[Trial 184] Epoch 46/60, Training Loss: 0.5848, Validation Loss: 0.5303\n",
      "[Trial 190] Epoch 56/60, Training Loss: 0.5678, Validation Loss: 0.4851\n",
      "[Trial 193] Epoch 15/60, Training Loss: 0.8204, Validation Loss: 0.7014\n",
      "[Trial 194] Epoch 13/60, Training Loss: 0.7908, Validation Loss: 0.6620\n",
      "[Trial 191] Epoch 31/60, Training Loss: 0.6103, Validation Loss: 0.5159\n",
      "[Trial 197] Epoch 7/60, Training Loss: 1.0223, Validation Loss: 0.7928\n",
      "[Trial 188] Epoch 39/60, Training Loss: 0.5626, Validation Loss: 0.4978\n",
      "[Trial 186] Epoch 40/60, Training Loss: 0.5834, Validation Loss: 0.5253\n",
      "[Trial 192] Epoch 21/60, Training Loss: 0.7024, Validation Loss: 0.5930\n",
      "[Trial 185] Epoch 40/60, Training Loss: 0.5834, Validation Loss: 0.4849\n",
      "[Trial 187] Epoch 40/60, Training Loss: 0.5820, Validation Loss: 0.4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:01:33,677] Trial 183 finished with value: 0.4531402538220088 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008323661528774085, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 183] Epoch 60/60, Training Loss: 0.5367, Validation Loss: 0.4610\n",
      "[Trial 198] Epoch 2/60, Training Loss: 1.9554, Validation Loss: 1.4294\n",
      "[Trial 190] Epoch 57/60, Training Loss: 0.5685, Validation Loss: 0.4933\n",
      "[Trial 196] Epoch 11/60, Training Loss: 0.8783, Validation Loss: 0.8273\n",
      "[Trial 195] Epoch 12/60, Training Loss: 0.8830, Validation Loss: 0.8547\n",
      "[Trial 189] Epoch 37/60, Training Loss: 0.5921, Validation Loss: 0.5192\n",
      "[Trial 184] Epoch 47/60, Training Loss: 0.5880, Validation Loss: 0.5022\n",
      "[Trial 193] Epoch 16/60, Training Loss: 0.7988, Validation Loss: 0.7313\n",
      "[Trial 194] Epoch 14/60, Training Loss: 0.7761, Validation Loss: 0.6543\n",
      "[Trial 191] Epoch 32/60, Training Loss: 0.6050, Validation Loss: 0.5434\n",
      "[Trial 197] Epoch 8/60, Training Loss: 0.9506, Validation Loss: 0.7912\n",
      "[Trial 190] Epoch 58/60, Training Loss: 0.5687, Validation Loss: 0.4928\n",
      "[Trial 188] Epoch 40/60, Training Loss: 0.5601, Validation Loss: 0.4793\n",
      "[Trial 186] Epoch 41/60, Training Loss: 0.5864, Validation Loss: 0.4962\n",
      "[Trial 192] Epoch 22/60, Training Loss: 0.6419, Validation Loss: 0.5300\n",
      "[Trial 187] Epoch 41/60, Training Loss: 0.5813, Validation Loss: 0.5015\n",
      "[Trial 185] Epoch 41/60, Training Loss: 0.5811, Validation Loss: 0.4907\n",
      "[Trial 198] Epoch 3/60, Training Loss: 1.6185, Validation Loss: 1.1893\n",
      "[Trial 196] Epoch 12/60, Training Loss: 0.8720, Validation Loss: 0.7333\n",
      "[Trial 195] Epoch 13/60, Training Loss: 0.8510, Validation Loss: 0.6718\n",
      "[Trial 199] Epoch 1/60, Training Loss: 5.5374, Validation Loss: 1.8433\n",
      "[Trial 184] Epoch 48/60, Training Loss: 0.5842, Validation Loss: 0.5193\n",
      "[Trial 189] Epoch 38/60, Training Loss: 0.5885, Validation Loss: 0.5243\n",
      "[Trial 190] Epoch 59/60, Training Loss: 0.5778, Validation Loss: 0.4999\n",
      "[Trial 193] Epoch 17/60, Training Loss: 0.7914, Validation Loss: 0.9342\n",
      "[Trial 194] Epoch 15/60, Training Loss: 0.7709, Validation Loss: 0.6151\n",
      "[Trial 191] Epoch 33/60, Training Loss: 0.6138, Validation Loss: 0.5336\n",
      "[Trial 197] Epoch 9/60, Training Loss: 0.9196, Validation Loss: 0.7200\n",
      "[Trial 188] Epoch 41/60, Training Loss: 0.5594, Validation Loss: 0.4663\n",
      "[Trial 186] Epoch 42/60, Training Loss: 0.5799, Validation Loss: 0.5140\n",
      "[Trial 192] Epoch 23/60, Training Loss: 0.6320, Validation Loss: 0.5447\n",
      "[Trial 187] Epoch 42/60, Training Loss: 0.5862, Validation Loss: 0.5074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:02:50,290] Trial 190 finished with value: 0.4850668489933014 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007959924740953759, 'batch_size': 64, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 190] Epoch 60/60, Training Loss: 0.5706, Validation Loss: 0.4891\n",
      "[Trial 198] Epoch 4/60, Training Loss: 1.3663, Validation Loss: 1.1244\n",
      "[Trial 195] Epoch 14/60, Training Loss: 0.8193, Validation Loss: 0.6483\n",
      "[Trial 196] Epoch 13/60, Training Loss: 0.8008, Validation Loss: 0.6715\n",
      "[Trial 185] Epoch 42/60, Training Loss: 0.5770, Validation Loss: 0.5016\n",
      "[Trial 199] Epoch 2/60, Training Loss: 1.9971, Validation Loss: 1.3695\n",
      "[Trial 184] Epoch 49/60, Training Loss: 0.5815, Validation Loss: 0.5118\n",
      "[Trial 189] Epoch 39/60, Training Loss: 0.5885, Validation Loss: 0.5033\n",
      "[Trial 193] Epoch 18/60, Training Loss: 0.7765, Validation Loss: 0.6284\n",
      "[Trial 194] Epoch 16/60, Training Loss: 0.7345, Validation Loss: 0.6498\n",
      "[Trial 191] Epoch 34/60, Training Loss: 0.6077, Validation Loss: 0.5130\n",
      "[Trial 197] Epoch 10/60, Training Loss: 0.8843, Validation Loss: 0.7918\n",
      "[Trial 188] Epoch 42/60, Training Loss: 0.5637, Validation Loss: 0.4930\n",
      "[Trial 186] Epoch 43/60, Training Loss: 0.5552, Validation Loss: 0.4871\n",
      "[Trial 192] Epoch 24/60, Training Loss: 0.6255, Validation Loss: 0.5919\n",
      "[Trial 187] Epoch 43/60, Training Loss: 0.5796, Validation Loss: 0.4954\n",
      "[Trial 195] Epoch 15/60, Training Loss: 0.7918, Validation Loss: 0.6950\n",
      "[Trial 198] Epoch 5/60, Training Loss: 1.2445, Validation Loss: 0.9382\n",
      "[Trial 196] Epoch 14/60, Training Loss: 0.7988, Validation Loss: 0.6868\n",
      "[Trial 185] Epoch 43/60, Training Loss: 0.5750, Validation Loss: 0.4960\n",
      "[Trial 184] Epoch 50/60, Training Loss: 0.5864, Validation Loss: 0.5082\n",
      "[Trial 199] Epoch 3/60, Training Loss: 1.6435, Validation Loss: 1.1626\n",
      "[Trial 189] Epoch 40/60, Training Loss: 0.5857, Validation Loss: 0.5275\n",
      "[Trial 193] Epoch 19/60, Training Loss: 0.6998, Validation Loss: 0.5541\n",
      "[Trial 191] Epoch 35/60, Training Loss: 0.5821, Validation Loss: 0.4988\n",
      "[Trial 194] Epoch 17/60, Training Loss: 0.7352, Validation Loss: 0.7331\n",
      "[Trial 197] Epoch 11/60, Training Loss: 0.8929, Validation Loss: 0.7212\n",
      "[Trial 188] Epoch 43/60, Training Loss: 0.5567, Validation Loss: 0.4865\n",
      "[Trial 186] Epoch 44/60, Training Loss: 0.5466, Validation Loss: 0.4861\n",
      "[Trial 187] Epoch 44/60, Training Loss: 0.5867, Validation Loss: 0.4950\n",
      "[Trial 192] Epoch 25/60, Training Loss: 0.6301, Validation Loss: 0.5539\n",
      "[Trial 195] Epoch 16/60, Training Loss: 0.7835, Validation Loss: 0.6542\n",
      "[Trial 198] Epoch 6/60, Training Loss: 1.1364, Validation Loss: 0.9255\n",
      "[Trial 184] Epoch 51/60, Training Loss: 0.5822, Validation Loss: 0.5015\n",
      "[Trial 196] Epoch 15/60, Training Loss: 0.7808, Validation Loss: 0.7965\n",
      "[Trial 185] Epoch 44/60, Training Loss: 0.5802, Validation Loss: 0.4816\n",
      "[Trial 199] Epoch 4/60, Training Loss: 1.3794, Validation Loss: 1.1167\n",
      "[Trial 189] Epoch 41/60, Training Loss: 0.5756, Validation Loss: 0.5031\n",
      "[Trial 193] Epoch 20/60, Training Loss: 0.6965, Validation Loss: 0.5699\n",
      "[Trial 191] Epoch 36/60, Training Loss: 0.5750, Validation Loss: 0.4809\n",
      "[Trial 194] Epoch 18/60, Training Loss: 0.7418, Validation Loss: 0.6863\n",
      "[Trial 197] Epoch 12/60, Training Loss: 0.8286, Validation Loss: 0.7073\n",
      "[Trial 188] Epoch 44/60, Training Loss: 0.5567, Validation Loss: 0.4818\n",
      "[Trial 186] Epoch 45/60, Training Loss: 0.5525, Validation Loss: 0.4809\n",
      "[Trial 187] Epoch 45/60, Training Loss: 0.5626, Validation Loss: 0.4845\n",
      "[Trial 195] Epoch 17/60, Training Loss: 0.7657, Validation Loss: 0.6550\n",
      "[Trial 192] Epoch 26/60, Training Loss: 0.6214, Validation Loss: 0.5186\n",
      "[Trial 198] Epoch 7/60, Training Loss: 1.0880, Validation Loss: 0.7895\n",
      "[Trial 184] Epoch 52/60, Training Loss: 0.5823, Validation Loss: 0.5084\n",
      "[Trial 196] Epoch 16/60, Training Loss: 0.7701, Validation Loss: 0.6596\n",
      "[Trial 185] Epoch 45/60, Training Loss: 0.5728, Validation Loss: 0.4952\n",
      "[Trial 199] Epoch 5/60, Training Loss: 1.1976, Validation Loss: 1.0347\n",
      "[Trial 189] Epoch 42/60, Training Loss: 0.5517, Validation Loss: 0.4873\n",
      "[Trial 193] Epoch 21/60, Training Loss: 0.6976, Validation Loss: 0.5730\n",
      "[Trial 191] Epoch 37/60, Training Loss: 0.5673, Validation Loss: 0.4965\n",
      "[Trial 194] Epoch 19/60, Training Loss: 0.7334, Validation Loss: 0.5938\n",
      "[Trial 197] Epoch 13/60, Training Loss: 0.8188, Validation Loss: 0.6636\n",
      "[Trial 188] Epoch 45/60, Training Loss: 0.5592, Validation Loss: 0.4855\n",
      "[Trial 195] Epoch 18/60, Training Loss: 0.7519, Validation Loss: 0.5808\n",
      "[Trial 186] Epoch 46/60, Training Loss: 0.5564, Validation Loss: 0.4966\n",
      "[Trial 187] Epoch 46/60, Training Loss: 0.5596, Validation Loss: 0.4777\n",
      "[Trial 192] Epoch 27/60, Training Loss: 0.6244, Validation Loss: 0.5605\n",
      "[Trial 184] Epoch 53/60, Training Loss: 0.5770, Validation Loss: 0.5102\n",
      "[Trial 198] Epoch 8/60, Training Loss: 1.0291, Validation Loss: 0.8297\n",
      "[Trial 196] Epoch 17/60, Training Loss: 0.7315, Validation Loss: 0.6592\n",
      "[Trial 185] Epoch 46/60, Training Loss: 0.5720, Validation Loss: 0.4862\n",
      "[Trial 199] Epoch 6/60, Training Loss: 1.1091, Validation Loss: 0.8487\n",
      "[Trial 189] Epoch 43/60, Training Loss: 0.5500, Validation Loss: 0.4798\n",
      "[Trial 193] Epoch 22/60, Training Loss: 0.6787, Validation Loss: 0.5735\n",
      "[Trial 191] Epoch 38/60, Training Loss: 0.5664, Validation Loss: 0.5074\n",
      "[Trial 194] Epoch 20/60, Training Loss: 0.7031, Validation Loss: 0.6253\n",
      "[Trial 197] Epoch 14/60, Training Loss: 0.8018, Validation Loss: 0.6695\n",
      "[Trial 188] Epoch 46/60, Training Loss: 0.5709, Validation Loss: 0.4719\n",
      "[Trial 195] Epoch 19/60, Training Loss: 0.7396, Validation Loss: 0.6288\n",
      "[Trial 187] Epoch 47/60, Training Loss: 0.5632, Validation Loss: 0.5064\n",
      "[Trial 186] Epoch 47/60, Training Loss: 0.5552, Validation Loss: 0.5019\n",
      "[Trial 192] Epoch 28/60, Training Loss: 0.6309, Validation Loss: 0.5403\n",
      "[Trial 184] Epoch 54/60, Training Loss: 0.5779, Validation Loss: 0.5116\n",
      "[Trial 198] Epoch 9/60, Training Loss: 0.9758, Validation Loss: 0.7333\n",
      "[Trial 196] Epoch 18/60, Training Loss: 0.7372, Validation Loss: 0.8462\n",
      "[Trial 185] Epoch 47/60, Training Loss: 0.5729, Validation Loss: 0.4993\n",
      "[Trial 199] Epoch 7/60, Training Loss: 1.0372, Validation Loss: 1.2068\n",
      "[Trial 189] Epoch 44/60, Training Loss: 0.5527, Validation Loss: 0.4665\n",
      "[Trial 193] Epoch 23/60, Training Loss: 0.6803, Validation Loss: 0.5680\n",
      "[Trial 191] Epoch 39/60, Training Loss: 0.5741, Validation Loss: 0.5016\n",
      "[Trial 194] Epoch 21/60, Training Loss: 0.6926, Validation Loss: 0.6166\n",
      "[Trial 197] Epoch 15/60, Training Loss: 0.8287, Validation Loss: 0.7707\n",
      "[Trial 188] Epoch 47/60, Training Loss: 0.5446, Validation Loss: 0.4610\n",
      "[Trial 195] Epoch 20/60, Training Loss: 0.7510, Validation Loss: 0.6994\n",
      "[Trial 187] Epoch 48/60, Training Loss: 0.5664, Validation Loss: 0.4827\n",
      "[Trial 186] Epoch 48/60, Training Loss: 0.5498, Validation Loss: 0.4812\n",
      "[Trial 184] Epoch 55/60, Training Loss: 0.5759, Validation Loss: 0.4998\n",
      "[Trial 192] Epoch 29/60, Training Loss: 0.6348, Validation Loss: 0.5844\n",
      "[Trial 198] Epoch 10/60, Training Loss: 0.9445, Validation Loss: 0.7608\n",
      "[Trial 196] Epoch 19/60, Training Loss: 0.7702, Validation Loss: 0.6217\n",
      "[Trial 185] Epoch 48/60, Training Loss: 0.5681, Validation Loss: 0.4993\n",
      "[Trial 199] Epoch 8/60, Training Loss: 1.0147, Validation Loss: 0.7403\n",
      "[Trial 189] Epoch 45/60, Training Loss: 0.5451, Validation Loss: 0.4932\n",
      "[Trial 191] Epoch 40/60, Training Loss: 0.5674, Validation Loss: 0.5095\n",
      "[Trial 193] Epoch 24/60, Training Loss: 0.6811, Validation Loss: 0.5992\n",
      "[Trial 194] Epoch 22/60, Training Loss: 0.7496, Validation Loss: 0.5780\n",
      "[Trial 197] Epoch 16/60, Training Loss: 0.7861, Validation Loss: 0.6197\n",
      "[Trial 188] Epoch 48/60, Training Loss: 0.5419, Validation Loss: 0.4658\n",
      "[Trial 195] Epoch 21/60, Training Loss: 0.7327, Validation Loss: 0.6699\n",
      "[Trial 187] Epoch 49/60, Training Loss: 0.5597, Validation Loss: 0.4739\n",
      "[Trial 186] Epoch 49/60, Training Loss: 0.5452, Validation Loss: 0.4755\n",
      "[Trial 184] Epoch 56/60, Training Loss: 0.5797, Validation Loss: 0.5321\n",
      "[Trial 192] Epoch 30/60, Training Loss: 0.6209, Validation Loss: 0.5259\n",
      "[Trial 198] Epoch 11/60, Training Loss: 0.9339, Validation Loss: 0.7460\n",
      "[Trial 196] Epoch 20/60, Training Loss: 0.7209, Validation Loss: 0.6542\n",
      "[Trial 185] Epoch 49/60, Training Loss: 0.5621, Validation Loss: 0.4811\n",
      "[Trial 189] Epoch 46/60, Training Loss: 0.5465, Validation Loss: 0.4727\n",
      "[Trial 199] Epoch 9/60, Training Loss: 0.9288, Validation Loss: 0.7101\n",
      "[Trial 191] Epoch 41/60, Training Loss: 0.5759, Validation Loss: 0.4983\n",
      "[Trial 193] Epoch 25/60, Training Loss: 0.6342, Validation Loss: 0.5235\n",
      "[Trial 194] Epoch 23/60, Training Loss: 0.6953, Validation Loss: 0.5970\n",
      "[Trial 197] Epoch 17/60, Training Loss: 0.7590, Validation Loss: 0.6376\n",
      "[Trial 188] Epoch 49/60, Training Loss: 0.5341, Validation Loss: 0.4595\n",
      "[Trial 195] Epoch 22/60, Training Loss: 0.7276, Validation Loss: 0.6257\n",
      "[Trial 187] Epoch 50/60, Training Loss: 0.5636, Validation Loss: 0.4833\n",
      "[Trial 184] Epoch 57/60, Training Loss: 0.5776, Validation Loss: 0.5211\n",
      "[Trial 186] Epoch 50/60, Training Loss: 0.5495, Validation Loss: 0.4906\n",
      "[Trial 198] Epoch 12/60, Training Loss: 0.9170, Validation Loss: 0.7826\n",
      "[Trial 192] Epoch 31/60, Training Loss: 0.6084, Validation Loss: 0.5578\n",
      "[Trial 196] Epoch 21/60, Training Loss: 0.6914, Validation Loss: 0.6115\n",
      "[Trial 185] Epoch 50/60, Training Loss: 0.5580, Validation Loss: 0.4701\n",
      "[Trial 189] Epoch 47/60, Training Loss: 0.5502, Validation Loss: 0.4801\n",
      "[Trial 199] Epoch 10/60, Training Loss: 0.8863, Validation Loss: 1.1233\n",
      "[Trial 191] Epoch 42/60, Training Loss: 0.5572, Validation Loss: 0.4809\n",
      "[Trial 193] Epoch 26/60, Training Loss: 0.6397, Validation Loss: 0.5197\n",
      "[Trial 194] Epoch 24/60, Training Loss: 0.6502, Validation Loss: 0.5898\n",
      "[Trial 197] Epoch 18/60, Training Loss: 0.7414, Validation Loss: 0.6291\n",
      "[Trial 195] Epoch 23/60, Training Loss: 0.7254, Validation Loss: 0.6632\n",
      "[Trial 188] Epoch 50/60, Training Loss: 0.5381, Validation Loss: 0.4598\n",
      "[Trial 187] Epoch 51/60, Training Loss: 0.5622, Validation Loss: 0.5010\n",
      "[Trial 184] Epoch 58/60, Training Loss: 0.5736, Validation Loss: 0.5148\n",
      "[Trial 198] Epoch 13/60, Training Loss: 0.8959, Validation Loss: 0.7902\n",
      "[Trial 186] Epoch 51/60, Training Loss: 0.5483, Validation Loss: 0.5071\n",
      "[Trial 192] Epoch 32/60, Training Loss: 0.5858, Validation Loss: 0.5064\n",
      "[Trial 196] Epoch 22/60, Training Loss: 0.6921, Validation Loss: 0.6553\n",
      "[Trial 185] Epoch 51/60, Training Loss: 0.5623, Validation Loss: 0.4799\n",
      "[Trial 189] Epoch 48/60, Training Loss: 0.5486, Validation Loss: 0.4883\n",
      "[Trial 199] Epoch 11/60, Training Loss: 0.8839, Validation Loss: 0.7183\n",
      "[Trial 191] Epoch 43/60, Training Loss: 0.5488, Validation Loss: 0.4869\n",
      "[Trial 193] Epoch 27/60, Training Loss: 0.6331, Validation Loss: 0.5212\n",
      "[Trial 194] Epoch 25/60, Training Loss: 0.6642, Validation Loss: 0.5911\n",
      "[Trial 197] Epoch 19/60, Training Loss: 0.7262, Validation Loss: 0.6183\n",
      "[Trial 195] Epoch 24/60, Training Loss: 0.6468, Validation Loss: 0.5564\n",
      "[Trial 188] Epoch 51/60, Training Loss: 0.5321, Validation Loss: 0.4590\n",
      "[Trial 187] Epoch 52/60, Training Loss: 0.5625, Validation Loss: 0.4923\n",
      "[Trial 184] Epoch 59/60, Training Loss: 0.5749, Validation Loss: 0.5198\n",
      "[Trial 198] Epoch 14/60, Training Loss: 0.8858, Validation Loss: 0.6842\n",
      "[Trial 186] Epoch 52/60, Training Loss: 0.5471, Validation Loss: 0.5002\n",
      "[Trial 192] Epoch 33/60, Training Loss: 0.5868, Validation Loss: 0.5302\n",
      "[Trial 196] Epoch 23/60, Training Loss: 0.7196, Validation Loss: 0.6378\n",
      "[Trial 185] Epoch 52/60, Training Loss: 0.5608, Validation Loss: 0.4964\n",
      "[Trial 189] Epoch 49/60, Training Loss: 0.5420, Validation Loss: 0.4814\n",
      "[Trial 199] Epoch 12/60, Training Loss: 0.8509, Validation Loss: 0.7341\n",
      "[Trial 191] Epoch 44/60, Training Loss: 0.5492, Validation Loss: 0.4682\n",
      "[Trial 193] Epoch 28/60, Training Loss: 0.6302, Validation Loss: 0.5197\n",
      "[Trial 194] Epoch 26/60, Training Loss: 0.6655, Validation Loss: 0.5823\n",
      "[Trial 195] Epoch 25/60, Training Loss: 0.6316, Validation Loss: 0.5673\n",
      "[Trial 197] Epoch 20/60, Training Loss: 0.7221, Validation Loss: 0.6480\n",
      "[Trial 188] Epoch 52/60, Training Loss: 0.5408, Validation Loss: 0.4679\n",
      "[Trial 187] Epoch 53/60, Training Loss: 0.5591, Validation Loss: 0.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:09:15,688] Trial 184 finished with value: 0.49977145592371625 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004318492256978591, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 184] Epoch 60/60, Training Loss: 0.5778, Validation Loss: 0.5075\n",
      "[Trial 198] Epoch 15/60, Training Loss: 0.8311, Validation Loss: 1.0185\n",
      "[Trial 186] Epoch 53/60, Training Loss: 0.5492, Validation Loss: 0.4785\n",
      "[Trial 192] Epoch 34/60, Training Loss: 0.5790, Validation Loss: 0.4904\n",
      "[Trial 196] Epoch 24/60, Training Loss: 0.6948, Validation Loss: 0.6343\n",
      "[Trial 185] Epoch 53/60, Training Loss: 0.5593, Validation Loss: 0.5081\n",
      "[Trial 191] Epoch 45/60, Training Loss: 0.5495, Validation Loss: 0.4705\n",
      "[Trial 189] Epoch 50/60, Training Loss: 0.5300, Validation Loss: 0.4635\n",
      "[Trial 199] Epoch 13/60, Training Loss: 0.8270, Validation Loss: 0.7088\n",
      "[Trial 193] Epoch 29/60, Training Loss: 0.6197, Validation Loss: 0.5355\n",
      "[Trial 194] Epoch 27/60, Training Loss: 0.6698, Validation Loss: 0.6016\n",
      "[Trial 195] Epoch 26/60, Training Loss: 0.6306, Validation Loss: 0.5310\n",
      "[Trial 197] Epoch 21/60, Training Loss: 0.7216, Validation Loss: 0.6041\n",
      "[Trial 187] Epoch 54/60, Training Loss: 0.5610, Validation Loss: 0.4823\n",
      "[Trial 188] Epoch 53/60, Training Loss: 0.5370, Validation Loss: 0.4685\n",
      "[Trial 198] Epoch 16/60, Training Loss: 0.8288, Validation Loss: 0.6513\n",
      "[Trial 186] Epoch 54/60, Training Loss: 0.5435, Validation Loss: 0.4882\n",
      "[Trial 192] Epoch 35/60, Training Loss: 0.5807, Validation Loss: 0.5318\n",
      "[Trial 196] Epoch 25/60, Training Loss: 0.6869, Validation Loss: 0.6396\n",
      "[Trial 191] Epoch 46/60, Training Loss: 0.5505, Validation Loss: 0.4913\n",
      "[Trial 185] Epoch 54/60, Training Loss: 0.5619, Validation Loss: 0.4933\n",
      "[Trial 189] Epoch 51/60, Training Loss: 0.5238, Validation Loss: 0.4601\n",
      "[Trial 199] Epoch 14/60, Training Loss: 0.8211, Validation Loss: 0.6797\n",
      "[Trial 193] Epoch 30/60, Training Loss: 0.6252, Validation Loss: 0.5346\n",
      "[Trial 194] Epoch 28/60, Training Loss: 0.6073, Validation Loss: 0.5166\n",
      "[Trial 195] Epoch 27/60, Training Loss: 0.6269, Validation Loss: 0.5511\n",
      "[Trial 187] Epoch 55/60, Training Loss: 0.5466, Validation Loss: 0.4651\n",
      "[Trial 197] Epoch 22/60, Training Loss: 0.7133, Validation Loss: 0.6189\n",
      "[Trial 188] Epoch 54/60, Training Loss: 0.5381, Validation Loss: 0.4560\n",
      "[Trial 198] Epoch 17/60, Training Loss: 0.8123, Validation Loss: 0.6501\n",
      "[Trial 186] Epoch 55/60, Training Loss: 0.5302, Validation Loss: 0.4704\n",
      "[Trial 192] Epoch 36/60, Training Loss: 0.5834, Validation Loss: 0.5100\n",
      "[Trial 196] Epoch 26/60, Training Loss: 0.6901, Validation Loss: 0.5615\n",
      "[Trial 191] Epoch 47/60, Training Loss: 0.5468, Validation Loss: 0.4737\n",
      "[Trial 185] Epoch 55/60, Training Loss: 0.5628, Validation Loss: 0.4932\n",
      "[Trial 189] Epoch 52/60, Training Loss: 0.5238, Validation Loss: 0.4566\n",
      "[Trial 193] Epoch 31/60, Training Loss: 0.6244, Validation Loss: 0.5260\n",
      "[Trial 199] Epoch 15/60, Training Loss: 0.7883, Validation Loss: 0.6628\n",
      "[Trial 194] Epoch 29/60, Training Loss: 0.6072, Validation Loss: 0.5151\n",
      "[Trial 195] Epoch 28/60, Training Loss: 0.6276, Validation Loss: 0.5481\n",
      "[Trial 187] Epoch 56/60, Training Loss: 0.5448, Validation Loss: 0.4716\n",
      "[Trial 197] Epoch 23/60, Training Loss: 0.7053, Validation Loss: 0.6592\n",
      "[Trial 188] Epoch 55/60, Training Loss: 0.5315, Validation Loss: 0.4680\n",
      "[Trial 198] Epoch 18/60, Training Loss: 0.7807, Validation Loss: 0.6411\n",
      "[Trial 186] Epoch 56/60, Training Loss: 0.5236, Validation Loss: 0.4717\n",
      "[Trial 192] Epoch 37/60, Training Loss: 0.5791, Validation Loss: 0.5027\n",
      "[Trial 196] Epoch 27/60, Training Loss: 0.6962, Validation Loss: 0.5571\n",
      "[Trial 191] Epoch 48/60, Training Loss: 0.5576, Validation Loss: 0.4893\n",
      "[Trial 193] Epoch 32/60, Training Loss: 0.6013, Validation Loss: 0.5065\n",
      "[Trial 185] Epoch 56/60, Training Loss: 0.5384, Validation Loss: 0.4700\n",
      "[Trial 189] Epoch 53/60, Training Loss: 0.5255, Validation Loss: 0.4727\n",
      "[Trial 199] Epoch 16/60, Training Loss: 0.7916, Validation Loss: 0.6866\n",
      "[Trial 194] Epoch 30/60, Training Loss: 0.6051, Validation Loss: 0.5121\n",
      "[Trial 195] Epoch 29/60, Training Loss: 0.6299, Validation Loss: 0.5496\n",
      "[Trial 187] Epoch 57/60, Training Loss: 0.5409, Validation Loss: 0.4762\n",
      "[Trial 197] Epoch 24/60, Training Loss: 0.6939, Validation Loss: 0.5954\n",
      "[Trial 188] Epoch 56/60, Training Loss: 0.5362, Validation Loss: 0.4651\n",
      "[Trial 198] Epoch 19/60, Training Loss: 0.7740, Validation Loss: 0.7003\n",
      "[Trial 186] Epoch 57/60, Training Loss: 0.5259, Validation Loss: 0.4740\n",
      "[Trial 192] Epoch 38/60, Training Loss: 0.5752, Validation Loss: 0.4939\n",
      "[Trial 196] Epoch 28/60, Training Loss: 0.6759, Validation Loss: 0.5967\n",
      "[Trial 191] Epoch 49/60, Training Loss: 0.5493, Validation Loss: 0.4723\n",
      "[Trial 193] Epoch 33/60, Training Loss: 0.5963, Validation Loss: 0.5050\n",
      "[Trial 185] Epoch 57/60, Training Loss: 0.5423, Validation Loss: 0.4730\n",
      "[Trial 189] Epoch 54/60, Training Loss: 0.5231, Validation Loss: 0.4549\n",
      "[Trial 199] Epoch 17/60, Training Loss: 0.7655, Validation Loss: 0.6123\n",
      "[Trial 194] Epoch 31/60, Training Loss: 0.5927, Validation Loss: 0.5357\n",
      "[Trial 195] Epoch 30/60, Training Loss: 0.6240, Validation Loss: 0.5249\n",
      "[Trial 187] Epoch 58/60, Training Loss: 0.5440, Validation Loss: 0.4699\n",
      "[Trial 197] Epoch 25/60, Training Loss: 0.7083, Validation Loss: 0.5985\n",
      "[Trial 198] Epoch 20/60, Training Loss: 0.7607, Validation Loss: 0.6193\n",
      "[Trial 188] Epoch 57/60, Training Loss: 0.5320, Validation Loss: 0.4705\n",
      "[Trial 186] Epoch 58/60, Training Loss: 0.5250, Validation Loss: 0.4604\n",
      "[Trial 196] Epoch 29/60, Training Loss: 0.6561, Validation Loss: 0.6131\n",
      "[Trial 192] Epoch 39/60, Training Loss: 0.5732, Validation Loss: 0.4903\n",
      "[Trial 191] Epoch 50/60, Training Loss: 0.5363, Validation Loss: 0.4678\n",
      "[Trial 193] Epoch 34/60, Training Loss: 0.6001, Validation Loss: 0.5030\n",
      "[Trial 185] Epoch 58/60, Training Loss: 0.5362, Validation Loss: 0.4642\n",
      "[Trial 189] Epoch 55/60, Training Loss: 0.5206, Validation Loss: 0.4537\n",
      "[Trial 199] Epoch 18/60, Training Loss: 0.7603, Validation Loss: 0.7047\n",
      "[Trial 194] Epoch 32/60, Training Loss: 0.5953, Validation Loss: 0.5215\n",
      "[Trial 195] Epoch 31/60, Training Loss: 0.6248, Validation Loss: 0.5544\n",
      "[Trial 187] Epoch 59/60, Training Loss: 0.5434, Validation Loss: 0.4774\n",
      "[Trial 197] Epoch 26/60, Training Loss: 0.6898, Validation Loss: 0.6046\n",
      "[Trial 198] Epoch 21/60, Training Loss: 0.7396, Validation Loss: 0.6417\n",
      "[Trial 188] Epoch 58/60, Training Loss: 0.5338, Validation Loss: 0.4708\n",
      "[Trial 186] Epoch 59/60, Training Loss: 0.5262, Validation Loss: 0.4850\n",
      "[Trial 196] Epoch 30/60, Training Loss: 0.6671, Validation Loss: 0.5663\n",
      "[Trial 192] Epoch 40/60, Training Loss: 0.5734, Validation Loss: 0.4942\n",
      "[Trial 191] Epoch 51/60, Training Loss: 0.5337, Validation Loss: 0.4560\n",
      "[Trial 193] Epoch 35/60, Training Loss: 0.5989, Validation Loss: 0.4910\n",
      "[Trial 189] Epoch 56/60, Training Loss: 0.5233, Validation Loss: 0.4792\n",
      "[Trial 185] Epoch 59/60, Training Loss: 0.5360, Validation Loss: 0.4801\n",
      "[Trial 199] Epoch 19/60, Training Loss: 0.7458, Validation Loss: 0.6693\n",
      "[Trial 195] Epoch 32/60, Training Loss: 0.6172, Validation Loss: 0.5640\n",
      "[Trial 194] Epoch 33/60, Training Loss: 0.6002, Validation Loss: 0.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:13:00,958] Trial 187 finished with value: 0.4650843799114227 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008126740634002535, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 187] Epoch 60/60, Training Loss: 0.5422, Validation Loss: 0.4712\n",
      "[Trial 198] Epoch 22/60, Training Loss: 0.7573, Validation Loss: 0.6842\n",
      "[Trial 197] Epoch 27/60, Training Loss: 0.6791, Validation Loss: 0.5863\n",
      "[Trial 188] Epoch 59/60, Training Loss: 0.5316, Validation Loss: 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:13:07,827] Trial 186 finished with value: 0.46035088996092477 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007800042495431243, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 186] Epoch 60/60, Training Loss: 0.5254, Validation Loss: 0.4690\n",
      "[Trial 196] Epoch 31/60, Training Loss: 0.6449, Validation Loss: 0.5892\n",
      "[Trial 192] Epoch 41/60, Training Loss: 0.5716, Validation Loss: 0.4954\n",
      "[Trial 191] Epoch 52/60, Training Loss: 0.5357, Validation Loss: 0.4659\n",
      "[Trial 193] Epoch 36/60, Training Loss: 0.5929, Validation Loss: 0.4998\n",
      "[Trial 189] Epoch 57/60, Training Loss: 0.5194, Validation Loss: 0.4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:13:17,570] Trial 185 finished with value: 0.4584368308385213 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007582946524519896, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 185] Epoch 60/60, Training Loss: 0.5330, Validation Loss: 0.4584\n",
      "[Trial 199] Epoch 20/60, Training Loss: 0.7386, Validation Loss: 0.6073\n",
      "[Trial 195] Epoch 33/60, Training Loss: 0.6123, Validation Loss: 0.5565\n",
      "[Trial 194] Epoch 34/60, Training Loss: 0.5949, Validation Loss: 0.5119\n",
      "[Trial 198] Epoch 23/60, Training Loss: 0.7477, Validation Loss: 0.6082\n",
      "[Trial 197] Epoch 28/60, Training Loss: 0.6882, Validation Loss: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:13:32,363] Trial 188 finished with value: 0.45479461749394734 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008099524239142373, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 188] Epoch 60/60, Training Loss: 0.5266, Validation Loss: 0.4548\n",
      "[Trial 196] Epoch 32/60, Training Loss: 0.6702, Validation Loss: 0.5728\n",
      "[Trial 191] Epoch 53/60, Training Loss: 0.5334, Validation Loss: 0.4674\n",
      "[Trial 192] Epoch 42/60, Training Loss: 0.5688, Validation Loss: 0.5179\n",
      "[Trial 193] Epoch 37/60, Training Loss: 0.5946, Validation Loss: 0.4961\n",
      "[Trial 189] Epoch 58/60, Training Loss: 0.5242, Validation Loss: 0.4829\n",
      "[Trial 199] Epoch 21/60, Training Loss: 0.7089, Validation Loss: 0.6147\n",
      "[Trial 195] Epoch 34/60, Training Loss: 0.6205, Validation Loss: 0.5685\n",
      "[Trial 194] Epoch 35/60, Training Loss: 0.6001, Validation Loss: 0.5280\n",
      "[Trial 198] Epoch 24/60, Training Loss: 0.7432, Validation Loss: 0.6401\n",
      "[Trial 197] Epoch 29/60, Training Loss: 0.6632, Validation Loss: 0.5962\n",
      "[Trial 191] Epoch 54/60, Training Loss: 0.5335, Validation Loss: 0.4624\n",
      "[Trial 192] Epoch 43/60, Training Loss: 0.5691, Validation Loss: 0.4840\n",
      "[Trial 196] Epoch 33/60, Training Loss: 0.6010, Validation Loss: 0.5266\n",
      "[Trial 193] Epoch 38/60, Training Loss: 0.5980, Validation Loss: 0.5085\n",
      "[Trial 189] Epoch 59/60, Training Loss: 0.5279, Validation Loss: 0.4650\n",
      "[Trial 199] Epoch 22/60, Training Loss: 0.7244, Validation Loss: 0.6198\n",
      "[Trial 195] Epoch 35/60, Training Loss: 0.6194, Validation Loss: 0.5756\n",
      "[Trial 194] Epoch 36/60, Training Loss: 0.5949, Validation Loss: 0.5215\n",
      "[Trial 198] Epoch 25/60, Training Loss: 0.7180, Validation Loss: 0.6278\n",
      "[Trial 197] Epoch 30/60, Training Loss: 0.6870, Validation Loss: 0.5849\n",
      "[Trial 191] Epoch 55/60, Training Loss: 0.5312, Validation Loss: 0.4640\n",
      "[Trial 196] Epoch 34/60, Training Loss: 0.5973, Validation Loss: 0.5055\n",
      "[Trial 192] Epoch 44/60, Training Loss: 0.5705, Validation Loss: 0.5115\n",
      "[Trial 193] Epoch 39/60, Training Loss: 0.6018, Validation Loss: 0.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:14:26,776] Trial 189 finished with value: 0.45362643003463743 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007908147315585834, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 189] Epoch 60/60, Training Loss: 0.5192, Validation Loss: 0.4536\n",
      "[Trial 199] Epoch 23/60, Training Loss: 0.7194, Validation Loss: 0.5653\n",
      "[Trial 195] Epoch 36/60, Training Loss: 0.5807, Validation Loss: 0.5037\n",
      "[Trial 194] Epoch 37/60, Training Loss: 0.5908, Validation Loss: 0.5450\n",
      "[Trial 198] Epoch 26/60, Training Loss: 0.7202, Validation Loss: 0.6191\n",
      "[Trial 191] Epoch 56/60, Training Loss: 0.5349, Validation Loss: 0.4677\n",
      "[Trial 197] Epoch 31/60, Training Loss: 0.6759, Validation Loss: 0.5964\n",
      "[Trial 196] Epoch 35/60, Training Loss: 0.5936, Validation Loss: 0.5367\n",
      "[Trial 192] Epoch 45/60, Training Loss: 0.5683, Validation Loss: 0.4980\n",
      "[Trial 193] Epoch 40/60, Training Loss: 0.5941, Validation Loss: 0.5035\n",
      "[Trial 199] Epoch 24/60, Training Loss: 0.7068, Validation Loss: 0.6621\n",
      "[Trial 195] Epoch 37/60, Training Loss: 0.5712, Validation Loss: 0.5252\n",
      "[Trial 194] Epoch 38/60, Training Loss: 0.5950, Validation Loss: 0.5298\n",
      "[Trial 198] Epoch 27/60, Training Loss: 0.7020, Validation Loss: 0.5985\n",
      "[Trial 191] Epoch 57/60, Training Loss: 0.5277, Validation Loss: 0.4585\n",
      "[Trial 197] Epoch 32/60, Training Loss: 0.6796, Validation Loss: 0.6142\n",
      "[Trial 196] Epoch 36/60, Training Loss: 0.5906, Validation Loss: 0.5227\n",
      "[Trial 192] Epoch 46/60, Training Loss: 0.5677, Validation Loss: 0.5176\n",
      "[Trial 193] Epoch 41/60, Training Loss: 0.5808, Validation Loss: 0.4904\n",
      "[Trial 199] Epoch 25/60, Training Loss: 0.7000, Validation Loss: 0.6133\n",
      "[Trial 195] Epoch 38/60, Training Loss: 0.5734, Validation Loss: 0.5117\n",
      "[Trial 194] Epoch 39/60, Training Loss: 0.5903, Validation Loss: 0.5247\n",
      "[Trial 198] Epoch 28/60, Training Loss: 0.7236, Validation Loss: 0.6129\n",
      "[Trial 191] Epoch 58/60, Training Loss: 0.5256, Validation Loss: 0.4623\n",
      "[Trial 197] Epoch 33/60, Training Loss: 0.6710, Validation Loss: 0.6406\n",
      "[Trial 196] Epoch 37/60, Training Loss: 0.5936, Validation Loss: 0.5184\n",
      "[Trial 192] Epoch 47/60, Training Loss: 0.5708, Validation Loss: 0.4957\n",
      "[Trial 193] Epoch 42/60, Training Loss: 0.5847, Validation Loss: 0.4914\n",
      "[Trial 199] Epoch 26/60, Training Loss: 0.7146, Validation Loss: 0.6052\n",
      "[Trial 195] Epoch 39/60, Training Loss: 0.5710, Validation Loss: 0.5177\n",
      "[Trial 194] Epoch 40/60, Training Loss: 0.5573, Validation Loss: 0.4977\n",
      "[Trial 198] Epoch 29/60, Training Loss: 0.6910, Validation Loss: 0.6473\n",
      "[Trial 191] Epoch 59/60, Training Loss: 0.5252, Validation Loss: 0.4630\n",
      "[Trial 197] Epoch 34/60, Training Loss: 0.6157, Validation Loss: 0.5096\n",
      "[Trial 192] Epoch 48/60, Training Loss: 0.5633, Validation Loss: 0.5085\n",
      "[Trial 196] Epoch 38/60, Training Loss: 0.5900, Validation Loss: 0.5010\n",
      "[Trial 193] Epoch 43/60, Training Loss: 0.5761, Validation Loss: 0.4885\n",
      "[Trial 199] Epoch 27/60, Training Loss: 0.6942, Validation Loss: 0.6193\n",
      "[Trial 195] Epoch 40/60, Training Loss: 0.5644, Validation Loss: 0.5015\n",
      "[Trial 194] Epoch 41/60, Training Loss: 0.5582, Validation Loss: 0.4940\n",
      "[Trial 198] Epoch 30/60, Training Loss: 0.7208, Validation Loss: 0.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:15:59,313] Trial 191 finished with value: 0.4560003240903219 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007787666369939919, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 191] Epoch 60/60, Training Loss: 0.5255, Validation Loss: 0.4611\n",
      "[Trial 191] Early stopping after 60 epochs.\n",
      "[Trial 192] Epoch 49/60, Training Loss: 0.5513, Validation Loss: 0.4863\n",
      "[Trial 197] Epoch 35/60, Training Loss: 0.5896, Validation Loss: 0.5606\n",
      "[Trial 196] Epoch 39/60, Training Loss: 0.5936, Validation Loss: 0.5339\n",
      "[Trial 193] Epoch 44/60, Training Loss: 0.5759, Validation Loss: 0.4892\n",
      "[Trial 195] Epoch 41/60, Training Loss: 0.5670, Validation Loss: 0.5017\n",
      "[Trial 199] Epoch 28/60, Training Loss: 0.6827, Validation Loss: 0.6300\n",
      "[Trial 194] Epoch 42/60, Training Loss: 0.5532, Validation Loss: 0.5070\n",
      "[Trial 198] Epoch 31/60, Training Loss: 0.6987, Validation Loss: 0.6054\n",
      "[Trial 192] Epoch 50/60, Training Loss: 0.5461, Validation Loss: 0.4886\n",
      "[Trial 197] Epoch 36/60, Training Loss: 0.6012, Validation Loss: 0.5444\n",
      "[Trial 196] Epoch 40/60, Training Loss: 0.5910, Validation Loss: 0.5190\n",
      "[Trial 193] Epoch 45/60, Training Loss: 0.5782, Validation Loss: 0.4859\n",
      "[Trial 195] Epoch 42/60, Training Loss: 0.5675, Validation Loss: 0.5197\n",
      "[Trial 199] Epoch 29/60, Training Loss: 0.6294, Validation Loss: 0.5153\n",
      "[Trial 194] Epoch 43/60, Training Loss: 0.5534, Validation Loss: 0.4824\n",
      "[Trial 198] Epoch 32/60, Training Loss: 0.6906, Validation Loss: 0.5925\n",
      "[Trial 192] Epoch 51/60, Training Loss: 0.5444, Validation Loss: 0.4694\n",
      "[Trial 196] Epoch 41/60, Training Loss: 0.6054, Validation Loss: 0.5149\n",
      "[Trial 197] Epoch 37/60, Training Loss: 0.6019, Validation Loss: 0.5445\n",
      "[Trial 193] Epoch 46/60, Training Loss: 0.5777, Validation Loss: 0.4856\n",
      "[Trial 195] Epoch 43/60, Training Loss: 0.5679, Validation Loss: 0.5082\n",
      "[Trial 199] Epoch 30/60, Training Loss: 0.6119, Validation Loss: 0.5330\n",
      "[Trial 194] Epoch 44/60, Training Loss: 0.5522, Validation Loss: 0.4932\n",
      "[Trial 198] Epoch 33/60, Training Loss: 0.6894, Validation Loss: 0.5819\n",
      "[Trial 192] Epoch 52/60, Training Loss: 0.5387, Validation Loss: 0.4719\n",
      "[Trial 196] Epoch 42/60, Training Loss: 0.5917, Validation Loss: 0.5109\n",
      "[Trial 197] Epoch 38/60, Training Loss: 0.6117, Validation Loss: 0.5595\n",
      "[Trial 193] Epoch 47/60, Training Loss: 0.5754, Validation Loss: 0.4873\n",
      "[Trial 195] Epoch 44/60, Training Loss: 0.5663, Validation Loss: 0.5073\n",
      "[Trial 199] Epoch 31/60, Training Loss: 0.6256, Validation Loss: 0.5026\n",
      "[Trial 194] Epoch 45/60, Training Loss: 0.5549, Validation Loss: 0.4915\n",
      "[Trial 198] Epoch 34/60, Training Loss: 0.6729, Validation Loss: 0.6060\n",
      "[Trial 192] Epoch 53/60, Training Loss: 0.5373, Validation Loss: 0.4838\n",
      "[Trial 196] Epoch 43/60, Training Loss: 0.5941, Validation Loss: 0.5287\n",
      "[Trial 197] Epoch 39/60, Training Loss: 0.5971, Validation Loss: 0.5651\n",
      "[Trial 195] Epoch 45/60, Training Loss: 0.5582, Validation Loss: 0.4956\n",
      "[Trial 193] Epoch 48/60, Training Loss: 0.5735, Validation Loss: 0.4796\n",
      "[Trial 199] Epoch 32/60, Training Loss: 0.6123, Validation Loss: 0.5060\n",
      "[Trial 194] Epoch 46/60, Training Loss: 0.5549, Validation Loss: 0.5054\n",
      "[Trial 198] Epoch 35/60, Training Loss: 0.6846, Validation Loss: 0.6390\n",
      "[Trial 192] Epoch 54/60, Training Loss: 0.5359, Validation Loss: 0.4864\n",
      "[Trial 195] Epoch 46/60, Training Loss: 0.5569, Validation Loss: 0.5247\n",
      "[Trial 196] Epoch 44/60, Training Loss: 0.5546, Validation Loss: 0.5103\n",
      "[Trial 193] Epoch 49/60, Training Loss: 0.5855, Validation Loss: 0.4905\n",
      "[Trial 197] Epoch 40/60, Training Loss: 0.5680, Validation Loss: 0.4969\n",
      "[Trial 199] Epoch 33/60, Training Loss: 0.6208, Validation Loss: 0.5108\n",
      "[Trial 194] Epoch 47/60, Training Loss: 0.5498, Validation Loss: 0.5063\n",
      "[Trial 198] Epoch 36/60, Training Loss: 0.6723, Validation Loss: 0.6003\n",
      "[Trial 195] Epoch 47/60, Training Loss: 0.5654, Validation Loss: 0.5089\n",
      "[Trial 192] Epoch 55/60, Training Loss: 0.5404, Validation Loss: 0.4789\n",
      "[Trial 196] Epoch 45/60, Training Loss: 0.5541, Validation Loss: 0.5072\n",
      "[Trial 193] Epoch 50/60, Training Loss: 0.5754, Validation Loss: 0.4935\n",
      "[Trial 197] Epoch 41/60, Training Loss: 0.5653, Validation Loss: 0.5187\n",
      "[Trial 199] Epoch 34/60, Training Loss: 0.6154, Validation Loss: 0.5100\n",
      "[Trial 194] Epoch 48/60, Training Loss: 0.5609, Validation Loss: 0.5245\n",
      "[Trial 198] Epoch 37/60, Training Loss: 0.6837, Validation Loss: 0.6443\n",
      "[Trial 195] Epoch 48/60, Training Loss: 0.5615, Validation Loss: 0.5014\n",
      "[Trial 192] Epoch 56/60, Training Loss: 0.5334, Validation Loss: 0.4740\n",
      "[Trial 196] Epoch 46/60, Training Loss: 0.5507, Validation Loss: 0.5030\n",
      "[Trial 193] Epoch 51/60, Training Loss: 0.5723, Validation Loss: 0.4847\n",
      "[Trial 197] Epoch 42/60, Training Loss: 0.5664, Validation Loss: 0.5167\n",
      "[Trial 199] Epoch 35/60, Training Loss: 0.6128, Validation Loss: 0.5250\n",
      "[Trial 194] Epoch 49/60, Training Loss: 0.5386, Validation Loss: 0.4847\n",
      "[Trial 198] Epoch 38/60, Training Loss: 0.6692, Validation Loss: 0.5671\n",
      "[Trial 195] Epoch 49/60, Training Loss: 0.5509, Validation Loss: 0.4902\n",
      "[Trial 192] Epoch 57/60, Training Loss: 0.5227, Validation Loss: 0.4642\n",
      "[Trial 196] Epoch 47/60, Training Loss: 0.5548, Validation Loss: 0.4978\n",
      "[Trial 193] Epoch 52/60, Training Loss: 0.5711, Validation Loss: 0.4824\n",
      "[Trial 197] Epoch 43/60, Training Loss: 0.5678, Validation Loss: 0.5005\n",
      "[Trial 199] Epoch 36/60, Training Loss: 0.6180, Validation Loss: 0.5187\n",
      "[Trial 194] Epoch 50/60, Training Loss: 0.5377, Validation Loss: 0.4740\n",
      "[Trial 195] Epoch 50/60, Training Loss: 0.5549, Validation Loss: 0.5210\n",
      "[Trial 198] Epoch 39/60, Training Loss: 0.6535, Validation Loss: 0.5608\n",
      "[Trial 192] Epoch 58/60, Training Loss: 0.5269, Validation Loss: 0.4655\n",
      "[Trial 196] Epoch 48/60, Training Loss: 0.5482, Validation Loss: 0.4982\n",
      "[Trial 193] Epoch 53/60, Training Loss: 0.5676, Validation Loss: 0.4869\n",
      "[Trial 197] Epoch 44/60, Training Loss: 0.5578, Validation Loss: 0.5006\n",
      "[Trial 199] Epoch 37/60, Training Loss: 0.5824, Validation Loss: 0.4913\n",
      "[Trial 195] Epoch 51/60, Training Loss: 0.5615, Validation Loss: 0.5148\n",
      "[Trial 194] Epoch 51/60, Training Loss: 0.5349, Validation Loss: 0.4838\n",
      "[Trial 198] Epoch 40/60, Training Loss: 0.6673, Validation Loss: 0.5738\n",
      "[Trial 192] Epoch 59/60, Training Loss: 0.5251, Validation Loss: 0.4672\n",
      "[Trial 196] Epoch 49/60, Training Loss: 0.5580, Validation Loss: 0.5032\n",
      "[Trial 193] Epoch 54/60, Training Loss: 0.5669, Validation Loss: 0.4729\n",
      "[Trial 197] Epoch 45/60, Training Loss: 0.5686, Validation Loss: 0.5042\n",
      "[Trial 199] Epoch 38/60, Training Loss: 0.5778, Validation Loss: 0.4885\n",
      "[Trial 195] Epoch 52/60, Training Loss: 0.5705, Validation Loss: 0.4935\n",
      "[Trial 194] Epoch 52/60, Training Loss: 0.5313, Validation Loss: 0.4734\n",
      "[Trial 198] Epoch 41/60, Training Loss: 0.6594, Validation Loss: 0.5713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:19:16,820] Trial 192 finished with value: 0.46053740481535593 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008154189116543474, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 192] Epoch 60/60, Training Loss: 0.5211, Validation Loss: 0.4605\n",
      "[Trial 193] Epoch 55/60, Training Loss: 0.5617, Validation Loss: 0.4748\n",
      "[Trial 196] Epoch 50/60, Training Loss: 0.5470, Validation Loss: 0.4744\n",
      "[Trial 197] Epoch 46/60, Training Loss: 0.5560, Validation Loss: 0.5144\n",
      "[Trial 199] Epoch 39/60, Training Loss: 0.5740, Validation Loss: 0.4726\n",
      "[Trial 195] Epoch 53/60, Training Loss: 0.5566, Validation Loss: 0.4779\n",
      "[Trial 194] Epoch 53/60, Training Loss: 0.5292, Validation Loss: 0.4758\n",
      "[Trial 198] Epoch 42/60, Training Loss: 0.6539, Validation Loss: 0.5678\n",
      "[Trial 193] Epoch 56/60, Training Loss: 0.5593, Validation Loss: 0.4711\n",
      "[Trial 196] Epoch 51/60, Training Loss: 0.5502, Validation Loss: 0.4827\n",
      "[Trial 197] Epoch 47/60, Training Loss: 0.5448, Validation Loss: 0.4802\n",
      "[Trial 199] Epoch 40/60, Training Loss: 0.5780, Validation Loss: 0.4816\n",
      "[Trial 195] Epoch 54/60, Training Loss: 0.5578, Validation Loss: 0.5179\n",
      "[Trial 194] Epoch 54/60, Training Loss: 0.5343, Validation Loss: 0.4819\n",
      "[Trial 198] Epoch 43/60, Training Loss: 0.6484, Validation Loss: 0.5811\n",
      "[Trial 193] Epoch 57/60, Training Loss: 0.5605, Validation Loss: 0.4679\n",
      "[Trial 196] Epoch 52/60, Training Loss: 0.5469, Validation Loss: 0.4908\n",
      "[Trial 197] Epoch 48/60, Training Loss: 0.5431, Validation Loss: 0.4935\n",
      "[Trial 195] Epoch 55/60, Training Loss: 0.5559, Validation Loss: 0.4996\n",
      "[Trial 199] Epoch 41/60, Training Loss: 0.5760, Validation Loss: 0.4879\n",
      "[Trial 194] Epoch 55/60, Training Loss: 0.5307, Validation Loss: 0.4846\n",
      "[Trial 198] Epoch 44/60, Training Loss: 0.6493, Validation Loss: 0.5514\n",
      "[Trial 193] Epoch 58/60, Training Loss: 0.5636, Validation Loss: 0.4697\n",
      "[Trial 196] Epoch 53/60, Training Loss: 0.5459, Validation Loss: 0.4903\n",
      "[Trial 197] Epoch 49/60, Training Loss: 0.5462, Validation Loss: 0.4929\n",
      "[Trial 195] Epoch 56/60, Training Loss: 0.5485, Validation Loss: 0.4896\n",
      "[Trial 199] Epoch 42/60, Training Loss: 0.5767, Validation Loss: 0.4923\n",
      "[Trial 194] Epoch 56/60, Training Loss: 0.5315, Validation Loss: 0.4758\n",
      "[Trial 198] Epoch 45/60, Training Loss: 0.6400, Validation Loss: 0.5950\n",
      "[Trial 193] Epoch 59/60, Training Loss: 0.5583, Validation Loss: 0.4716\n",
      "[Trial 196] Epoch 54/60, Training Loss: 0.5506, Validation Loss: 0.4810\n",
      "[Trial 197] Epoch 50/60, Training Loss: 0.5513, Validation Loss: 0.4885\n",
      "[Trial 195] Epoch 57/60, Training Loss: 0.5504, Validation Loss: 0.5095\n",
      "[Trial 199] Epoch 43/60, Training Loss: 0.5734, Validation Loss: 0.4806\n",
      "[Trial 194] Epoch 57/60, Training Loss: 0.5286, Validation Loss: 0.4875\n",
      "[Trial 198] Epoch 46/60, Training Loss: 0.6446, Validation Loss: 0.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:20:32,387] Trial 193 finished with value: 0.46793051262696583 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008007160380205047, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 193] Epoch 60/60, Training Loss: 0.5586, Validation Loss: 0.4807\n",
      "[Trial 196] Epoch 55/60, Training Loss: 0.5431, Validation Loss: 0.4758\n",
      "[Trial 197] Epoch 51/60, Training Loss: 0.5482, Validation Loss: 0.4959\n",
      "[Trial 195] Epoch 58/60, Training Loss: 0.5493, Validation Loss: 0.5197\n",
      "[Trial 199] Epoch 44/60, Training Loss: 0.5716, Validation Loss: 0.4761\n",
      "[Trial 198] Epoch 47/60, Training Loss: 0.6384, Validation Loss: 0.5715\n",
      "[Trial 194] Epoch 58/60, Training Loss: 0.5225, Validation Loss: 0.4767\n",
      "[Trial 196] Epoch 56/60, Training Loss: 0.5331, Validation Loss: 0.4801\n",
      "[Trial 197] Epoch 52/60, Training Loss: 0.5468, Validation Loss: 0.4985\n",
      "[Trial 195] Epoch 59/60, Training Loss: 0.5360, Validation Loss: 0.4866\n",
      "[Trial 199] Epoch 45/60, Training Loss: 0.5521, Validation Loss: 0.4648\n",
      "[Trial 198] Epoch 48/60, Training Loss: 0.6471, Validation Loss: 0.5501\n",
      "[Trial 194] Epoch 59/60, Training Loss: 0.5208, Validation Loss: 0.4723\n",
      "[Trial 196] Epoch 57/60, Training Loss: 0.5262, Validation Loss: 0.4696\n",
      "[Trial 197] Epoch 53/60, Training Loss: 0.5331, Validation Loss: 0.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:21:05,026] Trial 195 finished with value: 0.46982522507508595 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.00819258156198726, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 195] Epoch 60/60, Training Loss: 0.5274, Validation Loss: 0.4698\n",
      "[Trial 199] Epoch 46/60, Training Loss: 0.5518, Validation Loss: 0.4736\n",
      "[Trial 198] Epoch 49/60, Training Loss: 0.6371, Validation Loss: 0.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:21:10,281] Trial 194 finished with value: 0.4650254835685094 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007136792271873303, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 194] Epoch 60/60, Training Loss: 0.5171, Validation Loss: 0.4650\n",
      "[Trial 196] Epoch 58/60, Training Loss: 0.5271, Validation Loss: 0.4835\n",
      "[Trial 197] Epoch 54/60, Training Loss: 0.5319, Validation Loss: 0.4873\n",
      "[Trial 198] Epoch 50/60, Training Loss: 0.6344, Validation Loss: 0.5385\n",
      "[Trial 199] Epoch 47/60, Training Loss: 0.5544, Validation Loss: 0.4743\n",
      "[Trial 196] Epoch 59/60, Training Loss: 0.5261, Validation Loss: 0.4777\n",
      "[Trial 197] Epoch 55/60, Training Loss: 0.5306, Validation Loss: 0.4844\n",
      "[Trial 198] Epoch 51/60, Training Loss: 0.6334, Validation Loss: 0.5540\n",
      "[Trial 199] Epoch 48/60, Training Loss: 0.5492, Validation Loss: 0.4682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:21:27,827] Trial 196 finished with value: 0.46959772109985354 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008609598494700322, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 196] Epoch 60/60, Training Loss: 0.5252, Validation Loss: 0.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:21:30,372] Trial 197 finished with value: 0.4801958233118057 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.008219023863378512, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 197] Epoch 56/60, Training Loss: 0.5342, Validation Loss: 0.4895\n",
      "[Trial 197] Early stopping after 56 epochs.\n",
      "[Trial 198] Epoch 52/60, Training Loss: 0.6324, Validation Loss: 0.5311\n",
      "[Trial 199] Epoch 49/60, Training Loss: 0.5474, Validation Loss: 0.4530\n",
      "[Trial 198] Epoch 53/60, Training Loss: 0.6296, Validation Loss: 0.6114\n",
      "[Trial 199] Epoch 50/60, Training Loss: 0.5530, Validation Loss: 0.4667\n",
      "[Trial 198] Epoch 54/60, Training Loss: 0.6261, Validation Loss: 0.5561\n",
      "[Trial 199] Epoch 51/60, Training Loss: 0.5527, Validation Loss: 0.4708\n",
      "[Trial 198] Epoch 55/60, Training Loss: 0.6264, Validation Loss: 0.5393\n",
      "[Trial 199] Epoch 52/60, Training Loss: 0.5503, Validation Loss: 0.4556\n",
      "[Trial 198] Epoch 56/60, Training Loss: 0.6341, Validation Loss: 0.5487\n",
      "[Trial 199] Epoch 53/60, Training Loss: 0.5496, Validation Loss: 0.4802\n",
      "[Trial 198] Epoch 57/60, Training Loss: 0.6198, Validation Loss: 0.5203\n",
      "[Trial 199] Epoch 54/60, Training Loss: 0.5458, Validation Loss: 0.4637\n",
      "[Trial 198] Epoch 58/60, Training Loss: 0.6142, Validation Loss: 0.5651\n",
      "[Trial 199] Epoch 55/60, Training Loss: 0.5371, Validation Loss: 0.4621\n",
      "[Trial 198] Epoch 59/60, Training Loss: 0.6222, Validation Loss: 0.5392\n",
      "[Trial 199] Epoch 56/60, Training Loss: 0.5337, Validation Loss: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:22:08,496] Trial 198 finished with value: 0.5202610691388448 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.003539554833064167, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 198] Epoch 60/60, Training Loss: 0.6143, Validation Loss: 0.5590\n",
      "[Trial 199] Epoch 57/60, Training Loss: 0.5345, Validation Loss: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:22:11,773] Trial 199 finished with value: 0.45304592450459796 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.007825788237151509, 'batch_size': 32, 'patience': 9}. Best is trial 171 with value: 0.4382066955169042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 199] Epoch 58/60, Training Loss: 0.5331, Validation Loss: 0.4628\n",
      "[Trial 199] Early stopping after 58 epochs.\n",
      "\n",
      "Best Trial Number: 171\n",
      "Best Parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.004250162901723459, 'batch_size': 32, 'patience': 9}\n",
      "Best Value (Objective): 0.4382066955169042\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "# Note: VGAE, VGEncoder, VGDecoder classes are already defined in the main code\n",
    "\n",
    "def loss_function(recon_x, x, recon_edge_attr, edge_attr, mu, logvar):\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    # Reconstruction losses\n",
    "    node_recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    edge_recon_loss = 2.0 * F.mse_loss(recon_edge_attr, edge_attr, reduction='sum')\n",
    "    \n",
    "    # KL divergence \n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Diversity enhancement\n",
    "    repulsion_loss = -torch.pdist(mu).mean()\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = (node_recon_loss + \n",
    "                 edge_recon_loss + \n",
    "                 0.1 * kl_divergence +\n",
    "                 0.05 * repulsion_loss)\n",
    "    \n",
    "    return total_loss / batch_size\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to search\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512, step=64)\n",
    "    latent_dim = trial.suggest_int(\"latent_dim\", 32, 128, step=32)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_ratio = 0.8\n",
    "    valid_ratio = 0.2\n",
    "\n",
    "    num_train = int(len(pyg_dataset) * train_ratio)\n",
    "    num_valid = len(pyg_dataset) - num_train\n",
    "\n",
    "    train_dataset, valid_dataset = random_split(pyg_dataset, [num_train, num_valid])\n",
    "    train_loader = PyGDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = PyGDataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = VGAE(node_features, edge_features, hidden_dim, latent_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience // 2)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x, recon_edge_attr, mu, logvar = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "            loss = loss_function(recon_x, data.x, recon_edge_attr, data.edge_attr, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_data = val_data.to(device)\n",
    "                recon_x_val, recon_edge_attr_val, mu_val, logvar_val = model(\n",
    "                    val_data.x, val_data.edge_index, val_data.edge_attr\n",
    "                )\n",
    "                val_loss = loss_function(\n",
    "                    recon_x_val, val_data.x, recon_edge_attr_val, \n",
    "                    val_data.edge_attr, mu_val, logvar_val\n",
    "                )\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        # Print training and validation losses for every epoch\n",
    "        print(f\"[Trial {trial.number}] Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"[Trial {trial.number}] Early stopping after {epoch + 1} epochs.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "# Run the study with Optuna\n",
    "if __name__ == \"__main__\":\n",
    "    import multiprocessing\n",
    "\n",
    "    num_jobs = multiprocessing.cpu_count()  # Use up to 7 cores\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=200, n_jobs=num_jobs)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"\\nBest Trial Number: {best_trial.number}\")\n",
    "    print(\"Best Parameters:\", best_trial.params)\n",
    "    print(\"Best Value (Objective):\", best_trial.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
