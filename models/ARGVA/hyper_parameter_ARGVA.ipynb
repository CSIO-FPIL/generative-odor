{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import multiprocessing\n",
    "   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv , TransformerConv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "class DeepChemToPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        \"\"\"\n",
    "        Converts a list of PyG `Data` objects into an InMemoryDataset.\n",
    "        \n",
    "        Args:\n",
    "            data_list (list of Data): List of PyG Data objects.\n",
    "            transform (callable, optional): Optional transform applied to each data object.\n",
    "        \"\"\"\n",
    "        super(DeepChemToPyGDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data object at the specified index.\n",
    "        \"\"\"\n",
    "        return super().get(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_20704\\811436411.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load(r'C:\\Users\\sarab\\OneDrive\\Desktop\\CSIR\\generative_model_compare\\Convertors\\cleaned_frag_pyg_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "pyg_dataset = torch.load(r'C:\\Users\\sarab\\OneDrive\\Desktop\\CSIR\\generative_model_compare\\Convertors\\cleaned_frag_pyg_dataset.pth')\n",
    "dataset=pyg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    pyg_dataset = torch.load(r'C:\\Users\\sarab\\OneDrive\\Desktop\\CSIR\\generative_model_compare\\Convertors\\cleaned_frag_pyg_dataset.pth')\n",
    "    dataset_length = len(pyg_dataset)\n",
    "\n",
    "    # 80% training, 20% validation split\n",
    "    train_size = int(0.8 * dataset_length)\n",
    "    val_size = dataset_length - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        pyg_dataset, [train_size, val_size]\n",
    "    )\n",
    "    return train_dataset, val_dataset, pyg_dataset[0].num_features, pyg_dataset[0].edge_attr.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = pyg_dataset[0].x.shape[1]  # Should be 134 based on your description\n",
    "edge_features = pyg_dataset[0].edge_attr.shape[1]  # Should be 6 based on your description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new simple model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool\n",
    "\n",
    "class ARGVA(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(ARGVA, self).__init__()\n",
    "        self.encoder = VariationalEncoder(node_features, edge_features, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, node_features, edge_features)\n",
    "        self.discriminator = Discriminator(latent_dim, hidden_dim)\n",
    "        \n",
    "    def encode(self, x, edge_index, edge_attr, batch=None):\n",
    "        return self.encoder(x, edge_index, edge_attr, batch)\n",
    "\n",
    "    def decode(self, z, edge_index, batch=None):\n",
    "        return self.decoder(z, edge_index, batch)\n",
    "\n",
    "    def discriminate(self, z):\n",
    "        return self.discriminator(z)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        mu, logvar = self.encode(x, edge_index, edge_attr, batch)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed_x, reconstructed_edge_attr = self.decode(z, edge_index, batch)\n",
    "        return reconstructed_x, reconstructed_edge_attr, mu, logvar\n",
    "\n",
    "    def generate_multiple_outputs(self, x, edge_index, edge_attr, num_samples=5):\n",
    "        outputs = []\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = self.encode(x, edge_index, edge_attr)\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            \n",
    "            for _ in range(num_samples):\n",
    "                # Temperature annealing for diversity\n",
    "                temperature = 1.0 / (1.0 + 0.1 * _)\n",
    "                \n",
    "                # Sample from latent space\n",
    "                z = mu + temperature * std * torch.randn_like(std)\n",
    "                \n",
    "                # Decode\n",
    "                reconstructed_x, reconstructed_edge_attr = self.decode(z, edge_index)\n",
    "                \n",
    "                # Apply temperature-scaled softmax\n",
    "                reconstructed_x = torch.softmax(reconstructed_x / temperature, dim=-1)\n",
    "                reconstructed_edge_attr = torch.softmax(reconstructed_edge_attr / temperature, dim=-1)\n",
    "                \n",
    "                outputs.append((reconstructed_x, reconstructed_edge_attr, edge_index))\n",
    "        return outputs\n",
    "\n",
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        \n",
    "        # Multiple GCN layers with increasing expressiveness\n",
    "        self.conv1 = GCNConv(node_features + edge_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim * 2)\n",
    "        self.conv3 = GCNConv(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        # Feature transformation\n",
    "        self.transform = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # Latent space projections with more capacity\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "        self.logvar = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        # Combine node features with edge features\n",
    "        row, col = edge_index\n",
    "        edge_attr_repeated = edge_attr.repeat(1, 1) if edge_attr.dim() == 3 else edge_attr\n",
    "        \n",
    "        # Aggregate edge features to nodes by averaging\n",
    "        edge_feat_by_node = torch.zeros(x.size(0), edge_attr.size(1), device=x.device)\n",
    "        for i in range(row.size(0)):\n",
    "            edge_feat_by_node[row[i]] += edge_attr[i]\n",
    "        \n",
    "        # Normalize by counting occurrences of each node\n",
    "        unique_nodes, counts = torch.unique(row, return_counts=True)\n",
    "        edge_feat_by_node[unique_nodes] /= counts.float().unsqueeze(1)\n",
    "        \n",
    "        # Concatenate node features with aggregated edge features\n",
    "        x = torch.cat([x, edge_feat_by_node], dim=-1)\n",
    "        \n",
    "        # Multi-layer graph convolutions with residual connections\n",
    "        x1 = F.leaky_relu(self.conv1(x, edge_index))\n",
    "        x2 = F.leaky_relu(self.conv2(x1, edge_index))\n",
    "        x3 = F.leaky_relu(self.conv3(x2, edge_index))\n",
    "        \n",
    "        # Residual connection\n",
    "        x = x3 + x1\n",
    "        \n",
    "        # Transform features\n",
    "        x = self.transform(x)\n",
    "        \n",
    "        # Global pooling with both mean and max\n",
    "        if batch is not None:\n",
    "            x_mean = global_mean_pool(x, batch)\n",
    "            x_max = global_max_pool(x, batch)\n",
    "            x = (x_mean + x_max) / 2\n",
    "        else:\n",
    "            x = x.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # Project to latent space\n",
    "        return self.mu(x), self.logvar(x)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, node_features, edge_features):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Increased network capacity with multiple hidden layers\n",
    "        self.node_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim * 2),\n",
    "            nn.LayerNorm(hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, node_features)\n",
    "        )\n",
    "        \n",
    "        # Separate networks for different edge features to allow specialization\n",
    "        self.edge_feature_nets = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(latent_dim * 2, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            ) for _ in range(edge_features)\n",
    "        ])\n",
    "        \n",
    "        # Attention mechanism for edge features\n",
    "        self.edge_attention = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, edge_features)\n",
    "        )\n",
    "        \n",
    "        # Feature mixing layer\n",
    "        self.feature_mixing = nn.Sequential(\n",
    "            nn.Linear(edge_features, edge_features),\n",
    "            nn.LayerNorm(edge_features),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.edge_features = edge_features\n",
    "        \n",
    "    def add_noise_to_latent(self, z, noise_factor=0.1):\n",
    "        \"\"\"Add small amount of noise to prevent mode collapse\"\"\"\n",
    "        if self.training:\n",
    "            noise = torch.randn_like(z) * noise_factor\n",
    "            return z + noise\n",
    "        return z\n",
    "        \n",
    "    def forward(self, z, edge_index, batch=None):\n",
    "        # Add noise to latent representations during training\n",
    "        z = self.add_noise_to_latent(z)\n",
    "        \n",
    "        # Handle batching\n",
    "        if batch is not None:\n",
    "            z = z[batch]\n",
    "        else:\n",
    "            z = z.repeat(edge_index.max().item() + 1, 1)\n",
    "            \n",
    "        # Reconstruct nodes\n",
    "        reconstructed_x = self.node_decoder(z)\n",
    "        \n",
    "        # Edge reconstruction with attention and feature specialization\n",
    "        row, col = edge_index\n",
    "        edge_input = torch.cat([z[row], z[col]], dim=1)\n",
    "        \n",
    "        # Calculate attention weights for edge features\n",
    "        attention_weights = F.softmax(self.edge_attention(edge_input), dim=-1)\n",
    "        \n",
    "        # Process each edge feature separately\n",
    "        edge_outputs = []\n",
    "        for i, net in enumerate(self.edge_feature_nets):\n",
    "            feature_output = net(edge_input)\n",
    "            weighted_output = feature_output * attention_weights[:, i].unsqueeze(1)\n",
    "            edge_outputs.append(weighted_output)\n",
    "        \n",
    "        # Combine edge features\n",
    "        edge_features = torch.cat(edge_outputs, dim=1)\n",
    "        \n",
    "        # Mix features to allow for feature interactions\n",
    "        reconstructed_edge_attr = self.feature_mixing(edge_features)\n",
    "        \n",
    "        # Residual connection for edge features\n",
    "        reconstructed_edge_attr = reconstructed_edge_attr + edge_features\n",
    "        \n",
    "        return reconstructed_x, reconstructed_edge_attr\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return torch.sigmoid(self.net(z))\n",
    "# [Rest of the code remains exactly the same as before - Decoder and Discriminator classes are unchanged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Fixed hyperparameter\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_argva_with_early_stopping(\n",
    "    model, train_dataset, val_dataset, num_epochs, batch_size, lr, device, patience\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the ARGVA model with early stopping based on validation loss.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): ARGVA model instance\n",
    "        train_dataset: Training dataset\n",
    "        val_dataset: Validation dataset\n",
    "        num_epochs (int): Maximum number of epochs for training\n",
    "        batch_size (int): Batch size for training\n",
    "        lr (float): Learning rate for the optimizer\n",
    "        device (torch.device): Device to use for training ('cpu' or 'cuda')\n",
    "        patience (int): Number of epochs to wait for improvement before stopping\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The best-trained model\n",
    "    \"\"\"\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience//2, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = total_recon_loss = total_kl_loss = total_adv_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Variational autoencoder forward pass\n",
    "            reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "            )\n",
    "\n",
    "            # Reconstruction loss\n",
    "            recon_loss = F.mse_loss(reconstructed_x, batch.x) + \\\n",
    "                        F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "\n",
    "            # KL divergence loss\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "            # Adversarial loss\n",
    "            z = model.reparameterize(mu, logvar)\n",
    "            real_z = torch.randn_like(z)\n",
    "            \n",
    "            real_scores = model.discriminate(real_z)\n",
    "            fake_scores = model.discriminate(z)\n",
    "            \n",
    "            adv_loss = -torch.mean(torch.log(real_scores + 1e-8) + torch.log(1 - fake_scores + 1e-8))\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            # Total loss (with beta-VAE formulation)\n",
    "            beta = 0.8  # Can be adjusted to control KL divergence impact # Orignal beta = 1\n",
    "            loss = recon_loss + beta * kl_loss + 0.8 * adv_loss        #adv weight was 0.1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "            total_adv_loss += adv_loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_recon_loss = total_recon_loss / len(train_loader)\n",
    "        avg_kl_loss = total_kl_loss / len(train_loader)\n",
    "        avg_adv_loss = total_adv_loss / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                    batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "                )\n",
    "\n",
    "                recon_loss = F.mse_loss(reconstructed_x, batch.x) + \\\n",
    "                            F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                \n",
    "                val_loss = recon_loss + beta * kl_loss\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        # Print progress\n",
    "        print(\n",
    "            f'Epoch [{epoch+1}/{num_epochs}] - '\n",
    "            f'Loss: {avg_loss:.4f} '\n",
    "            f'(Recon: {avg_recon_loss:.4f}, '\n",
    "            f'KL: {avg_kl_loss:.4f}, '\n",
    "            f'Adv: {avg_adv_loss:.4f}) - '\n",
    "            f'Val Loss: {avg_val_loss:.4f}'\n",
    "        )\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f'New best model saved with validation loss: {best_val_loss:.4f}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'No improvement. Patience counter: {patience_counter}/{patience}')\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping triggered.')\n",
    "            break\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print('Best model state restored.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import optuna\n",
    "import multiprocessing\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512, step=64)\n",
    "    latent_dim = trial.suggest_int(\"latent_dim\", 32, 128, step=32)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Create model and data loaders\n",
    "    model = ARGVA(\n",
    "        node_features=134,\n",
    "        edge_features=6,\n",
    "        hidden_dim=hidden_dim,\n",
    "        latent_dim=latent_dim,\n",
    "    ).to(device)\n",
    "    print(f\"\\n[Trial {trial.number}] Starting with parameters: {trial.params}\")\n",
    "    train_ratio = 0.8\n",
    "    pyg_dataset = torch.load(r'C:\\Users\\sarab\\OneDrive\\Desktop\\CSIR\\generative_model_compare\\Convertors\\cleaned_frag_pyg_dataset.pth')\n",
    "    num_train = int(len(pyg_dataset) * train_ratio)\n",
    "    num_valid = len(pyg_dataset) - num_train\n",
    "    \n",
    "    train_dataset, valid_dataset = random_split(pyg_dataset, [num_train, num_valid])\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = PyGDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = PyGDataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(50):  # Set a max epoch limit\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "            )\n",
    "\n",
    "            # Loss calculation\n",
    "            recon_loss = F.mse_loss(reconstructed_x, batch.x) + \\\n",
    "                        F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss = recon_loss + 0.8 * kl_loss  # Adjust beta weight as needed\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                    batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "                )\n",
    "\n",
    "                recon_loss = F.mse_loss(reconstructed_x, batch.x) + \\\n",
    "                            F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                val_loss += (recon_loss + 0.8 * kl_loss).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Trial: {trial.number}, Epoch: {epoch}, Train Loss: {total_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    return best_val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:01:11,091] A new study created in memory with name: no-name-658b121d-34d7-4962-8c72-a44024240546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 12] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 1.8521640242697503e-05, 'batch_size': 16, 'patience': 5}\n",
      "\n",
      "[Trial 15] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0001271547083066484, 'batch_size': 32, 'patience': 7}\n",
      "\n",
      "[Trial 13] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 2.4129905873466902e-05, 'batch_size': 64, 'patience': 6}\n",
      "\n",
      "[Trial 11] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0037979731323002277, 'batch_size': 64, 'patience': 7}\n",
      "\n",
      "[Trial 4] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.012377766412990019, 'batch_size': 32, 'patience': 6}\n",
      "\n",
      "[Trial 6] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.028291624277561673, 'batch_size': 64, 'patience': 8}\n",
      "\n",
      "[Trial 14] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.034565586212728594, 'batch_size': 16, 'patience': 4}\n",
      "\n",
      "[Trial 10] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.0006330251375332808, 'batch_size': 64, 'patience': 10}\n",
      "\n",
      "[Trial 0] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.001155211724603464, 'batch_size': 16, 'patience': 5}\n",
      "\n",
      "[Trial 7] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.018314159872050883, 'batch_size': 8, 'patience': 7}\n",
      "\n",
      "[Trial 5] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 1.527162761938593e-05, 'batch_size': 32, 'patience': 4}\n",
      "\n",
      "[Trial 3] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 1.1534763474491681e-05, 'batch_size': 16, 'patience': 6}\n",
      "\n",
      "[Trial 8] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.0015568931842321742, 'batch_size': 8, 'patience': 9}\n",
      "\n",
      "[Trial 2] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.0007586879325312465, 'batch_size': 64, 'patience': 8}\n",
      "\n",
      "[Trial 1] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 6.179358984748825e-05, 'batch_size': 16, 'patience': 10}\n",
      "\n",
      "[Trial 9] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 2.2833425562099492e-05, 'batch_size': 64, 'patience': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_20704\\3486618961.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load(r'C:\\Users\\sarab\\OneDrive\\Desktop\\CSIR\\generative_model_compare\\Convertors\\cleaned_frag_pyg_dataset.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 13, Epoch: 0, Train Loss: 53.9171, Val Loss: 0.5042\n",
      "Trial: 11, Epoch: 0, Train Loss: 18.1106, Val Loss: 0.1384\n",
      "Trial: 2, Epoch: 0, Train Loss: 13.0751, Val Loss: 0.2097\n",
      "Trial: 9, Epoch: 0, Train Loss: 34.3219, Val Loss: 0.5527\n",
      "Trial: 10, Epoch: 0, Train Loss: 16.4376, Val Loss: 0.2255\n",
      "Trial: 6, Epoch: 0, Train Loss: 2669.1687, Val Loss: 2.8701\n",
      "Trial: 5, Epoch: 0, Train Loss: 96.8008, Val Loss: 0.4497\n",
      "Trial: 15, Epoch: 0, Train Loss: 31.7767, Val Loss: 0.2200\n",
      "Trial: 4, Epoch: 0, Train Loss: 224.7597, Val Loss: 0.2469\n",
      "Trial: 12, Epoch: 0, Train Loss: 214.4782, Val Loss: 0.5481\n",
      "Trial: 0, Epoch: 0, Train Loss: 42.1634, Val Loss: 0.1634\n",
      "Trial: 3, Epoch: 0, Train Loss: 104.8348, Val Loss: 0.9674\n",
      "Trial: 1, Epoch: 0, Train Loss: 89.2637, Val Loss: 0.5089\n",
      "Trial: 14, Epoch: 0, Train Loss: 24389.5296, Val Loss: 291.0067\n",
      "Trial: 13, Epoch: 1, Train Loss: 30.7203, Val Loss: 0.6795\n",
      "Trial: 11, Epoch: 1, Train Loss: 7.9594, Val Loss: 0.1257\n",
      "Trial: 2, Epoch: 1, Train Loss: 8.2132, Val Loss: 0.2332\n",
      "Trial: 9, Epoch: 1, Train Loss: 25.7404, Val Loss: 0.5782\n",
      "Trial: 10, Epoch: 1, Train Loss: 9.9283, Val Loss: 0.1851\n",
      "Trial: 7, Epoch: 0, Train Loss: 65.4757, Val Loss: 0.1289\n",
      "Trial: 6, Epoch: 1, Train Loss: 127.7844, Val Loss: 1.3276\n",
      "Trial: 5, Epoch: 1, Train Loss: 73.1507, Val Loss: 0.6089\n",
      "Trial: 8, Epoch: 0, Train Loss: 76.4596, Val Loss: 0.1407\n",
      "Trial: 15, Epoch: 1, Train Loss: 19.1496, Val Loss: 0.1673\n",
      "Trial: 4, Epoch: 1, Train Loss: 24.8442, Val Loss: 0.1289\n",
      "Trial: 13, Epoch: 2, Train Loss: 25.8303, Val Loss: 0.6244\n",
      "Trial: 12, Epoch: 1, Train Loss: 136.3504, Val Loss: 0.3325\n",
      "Trial: 11, Epoch: 2, Train Loss: 7.7477, Val Loss: 0.1265\n",
      "Trial: 2, Epoch: 2, Train Loss: 7.8146, Val Loss: 0.2175\n",
      "Trial: 0, Epoch: 1, Train Loss: 30.1056, Val Loss: 0.1252\n",
      "Trial: 10, Epoch: 2, Train Loss: 8.4719, Val Loss: 0.2575\n",
      "Trial: 9, Epoch: 2, Train Loss: 22.3189, Val Loss: 0.4633\n",
      "Trial: 3, Epoch: 1, Train Loss: 68.1452, Val Loss: 0.9203\n",
      "Trial: 1, Epoch: 1, Train Loss: 50.0335, Val Loss: 0.5467\n",
      "Trial: 14, Epoch: 1, Train Loss: 1396.7272, Val Loss: 0.1549\n",
      "Trial: 5, Epoch: 2, Train Loss: 57.5623, Val Loss: 0.6764\n",
      "Trial: 15, Epoch: 2, Train Loss: 17.0387, Val Loss: 0.1740\n",
      "Trial: 4, Epoch: 2, Train Loss: 15.5998, Val Loss: 0.1263\n",
      "Trial: 6, Epoch: 2, Train Loss: 100.6714, Val Loss: 6.4775\n",
      "Trial: 13, Epoch: 3, Train Loss: 23.1612, Val Loss: 0.5822\n",
      "Trial: 11, Epoch: 3, Train Loss: 7.6263, Val Loss: 0.1484\n",
      "Trial: 2, Epoch: 3, Train Loss: 7.5893, Val Loss: 0.1863\n",
      "Trial: 10, Epoch: 3, Train Loss: 7.8315, Val Loss: 0.1787\n",
      "Trial: 9, Epoch: 3, Train Loss: 19.9220, Val Loss: 0.4893\n",
      "Trial: 7, Epoch: 1, Train Loss: 60.3172, Val Loss: 0.1209\n",
      "Trial: 12, Epoch: 2, Train Loss: 96.4967, Val Loss: 0.2763\n",
      "Trial: 0, Epoch: 2, Train Loss: 29.4310, Val Loss: 0.1191\n",
      "Trial: 8, Epoch: 1, Train Loss: 61.9937, Val Loss: 0.1122\n",
      "Trial: 5, Epoch: 3, Train Loss: 49.8546, Val Loss: 0.6580\n",
      "Trial: 13, Epoch: 4, Train Loss: 21.2274, Val Loss: 0.5452\n",
      "Trial: 3, Epoch: 2, Train Loss: 57.2636, Val Loss: 0.7684\n",
      "Trial: 15, Epoch: 3, Train Loss: 16.4517, Val Loss: 0.1746\n",
      "Trial: 1, Epoch: 2, Train Loss: 42.3445, Val Loss: 0.4556\n",
      "Trial: 4, Epoch: 3, Train Loss: 15.2505, Val Loss: 0.1272\n",
      "Trial: 11, Epoch: 4, Train Loss: 7.1268, Val Loss: 0.1500\n",
      "Trial: 6, Epoch: 3, Train Loss: 12512184.9924, Val Loss: 217.0584\n",
      "Trial: 2, Epoch: 4, Train Loss: 7.4590, Val Loss: 0.1481\n",
      "Trial: 14, Epoch: 2, Train Loss: 32.9804, Val Loss: 0.1320\n",
      "Trial: 10, Epoch: 4, Train Loss: 7.5839, Val Loss: 0.1950\n",
      "Trial: 9, Epoch: 4, Train Loss: 17.9869, Val Loss: 1.0420\n",
      "Trial: 13, Epoch: 5, Train Loss: 19.9038, Val Loss: 0.5123\n",
      "Trial: 5, Epoch: 4, Train Loss: 45.2233, Val Loss: 0.6044\n",
      "Early stopping triggered.\n",
      "Trial: 12, Epoch: 3, Train Loss: 77.0660, Val Loss: 0.2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:18:53,139] Trial 5 finished with value: 0.4497102419535319 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 1.527162761938593e-05, 'batch_size': 32, 'patience': 4}. Best is trial 5 with value: 0.4497102419535319.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 16] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 1.4926436023702518e-05, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 11, Epoch: 5, Train Loss: 7.0650, Val Loss: 0.1159\n",
      "Trial: 2, Epoch: 5, Train Loss: 7.3571, Val Loss: 0.1409\n",
      "Trial: 15, Epoch: 4, Train Loss: 16.1884, Val Loss: 0.1670\n",
      "Trial: 4, Epoch: 4, Train Loss: 15.1751, Val Loss: 0.1276\n",
      "Trial: 6, Epoch: 4, Train Loss: 2991.6930, Val Loss: 4.2787\n",
      "Trial: 10, Epoch: 5, Train Loss: 7.4675, Val Loss: 0.1379\n",
      "Trial: 0, Epoch: 3, Train Loss: 29.1446, Val Loss: 0.1216\n",
      "Trial: 9, Epoch: 5, Train Loss: 16.4828, Val Loss: 1.0906\n",
      "Trial: 3, Epoch: 3, Train Loss: 51.4307, Val Loss: 0.6818\n",
      "Trial: 1, Epoch: 3, Train Loss: 37.0526, Val Loss: 0.3191\n",
      "Trial: 7, Epoch: 2, Train Loss: 60.1802, Val Loss: 0.1122\n",
      "Trial: 13, Epoch: 6, Train Loss: 18.9067, Val Loss: 0.4994\n",
      "Trial: 14, Epoch: 3, Train Loss: 30.6470, Val Loss: 0.1288\n",
      "Trial: 11, Epoch: 6, Train Loss: 6.9918, Val Loss: 0.1482\n",
      "Trial: 8, Epoch: 2, Train Loss: 61.3624, Val Loss: 0.1254\n",
      "Trial: 2, Epoch: 6, Train Loss: 7.3079, Val Loss: 0.1405\n",
      "Trial: 10, Epoch: 6, Train Loss: 7.2935, Val Loss: 0.1650\n",
      "Trial: 15, Epoch: 5, Train Loss: 15.8794, Val Loss: 0.1817\n",
      "Trial: 4, Epoch: 5, Train Loss: 15.1727, Val Loss: 0.1257\n",
      "Trial: 9, Epoch: 6, Train Loss: 15.4399, Val Loss: 0.9431\n",
      "Trial: 12, Epoch: 4, Train Loss: 66.9554, Val Loss: 0.2618\n",
      "Trial: 6, Epoch: 5, Train Loss: 201.3347, Val Loss: 2.8609\n",
      "Trial: 16, Epoch: 0, Train Loss: 92.5723, Val Loss: 0.7548\n",
      "Trial: 13, Epoch: 7, Train Loss: 18.0099, Val Loss: 0.4858\n",
      "Trial: 0, Epoch: 4, Train Loss: 28.8538, Val Loss: 0.1214\n",
      "Trial: 3, Epoch: 4, Train Loss: 47.5325, Val Loss: 0.6034\n",
      "Trial: 11, Epoch: 7, Train Loss: 6.8959, Val Loss: 0.1428\n",
      "Trial: 1, Epoch: 4, Train Loss: 33.3119, Val Loss: 0.3068\n",
      "Trial: 2, Epoch: 7, Train Loss: 7.2341, Val Loss: 0.1369\n",
      "Trial: 10, Epoch: 7, Train Loss: 7.1993, Val Loss: 0.1476\n",
      "Trial: 9, Epoch: 7, Train Loss: 14.6583, Val Loss: 0.7666\n",
      "Trial: 14, Epoch: 4, Train Loss: 30.3112, Val Loss: 0.1281\n",
      "Trial: 15, Epoch: 6, Train Loss: 15.7472, Val Loss: 0.1614\n",
      "Trial: 4, Epoch: 6, Train Loss: 15.1677, Val Loss: 0.1260\n",
      "Trial: 6, Epoch: 6, Train Loss: 127.5205, Val Loss: 1.7002\n",
      "Trial: 7, Epoch: 3, Train Loss: 60.1112, Val Loss: 0.1131\n",
      "Trial: 13, Epoch: 8, Train Loss: 17.4043, Val Loss: 0.4746\n",
      "Trial: 12, Epoch: 5, Train Loss: 61.5324, Val Loss: 0.2705\n",
      "Trial: 11, Epoch: 8, Train Loss: 6.8941, Val Loss: 0.1331\n",
      "Trial: 2, Epoch: 8, Train Loss: 7.2047, Val Loss: 0.1222\n",
      "Trial: 16, Epoch: 1, Train Loss: 62.3660, Val Loss: 0.5548\n",
      "Trial: 8, Epoch: 3, Train Loss: 61.2817, Val Loss: 0.1201\n",
      "Trial: 10, Epoch: 8, Train Loss: 7.1286, Val Loss: 0.1568\n",
      "Trial: 0, Epoch: 5, Train Loss: 28.6369, Val Loss: 0.1207\n",
      "Trial: 9, Epoch: 8, Train Loss: 13.8619, Val Loss: 0.6419\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:28:05,699] Trial 9 finished with value: 0.46331137816111245 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 2.2833425562099492e-05, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.4497102419535319.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 17] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'learning_rate': 0.03510675839834266, 'batch_size': 64, 'patience': 9}\n",
      "Trial: 3, Epoch: 5, Train Loss: 44.7962, Val Loss: 0.5766\n",
      "Trial: 1, Epoch: 5, Train Loss: 32.0357, Val Loss: 0.2957\n",
      "Trial: 15, Epoch: 7, Train Loss: 15.6311, Val Loss: 0.1637\n",
      "Trial: 4, Epoch: 7, Train Loss: 15.0862, Val Loss: 0.1264\n",
      "Trial: 6, Epoch: 7, Train Loss: 92.5127, Val Loss: 1.4519\n",
      "Trial: 13, Epoch: 9, Train Loss: 16.7685, Val Loss: 0.4675\n",
      "Trial: 11, Epoch: 9, Train Loss: 6.7335, Val Loss: 0.1839\n",
      "Trial: 2, Epoch: 9, Train Loss: 7.2042, Val Loss: 0.1240\n",
      "Trial: 14, Epoch: 5, Train Loss: 30.1836, Val Loss: 0.1277\n",
      "Trial: 10, Epoch: 9, Train Loss: 7.0825, Val Loss: 0.1424\n",
      "Trial: 12, Epoch: 6, Train Loss: 57.8848, Val Loss: 0.2690\n",
      "Trial: 17, Epoch: 0, Train Loss: 580.8958, Val Loss: 0.7232\n",
      "Trial: 16, Epoch: 2, Train Loss: 53.6189, Val Loss: 0.4782\n",
      "Trial: 13, Epoch: 10, Train Loss: 16.3043, Val Loss: 0.4689\n",
      "Trial: 7, Epoch: 4, Train Loss: 59.7253, Val Loss: 0.1177\n",
      "Trial: 15, Epoch: 8, Train Loss: 15.4294, Val Loss: 0.1555\n",
      "Trial: 6, Epoch: 8, Train Loss: 99.2984, Val Loss: 2.1268\n",
      "Trial: 0, Epoch: 6, Train Loss: 28.4644, Val Loss: 0.1248\n",
      "Trial: 4, Epoch: 8, Train Loss: 15.1249, Val Loss: 0.1279\n",
      "Trial: 11, Epoch: 10, Train Loss: 6.6172, Val Loss: 0.2587\n",
      "Trial: 3, Epoch: 6, Train Loss: 42.5479, Val Loss: 0.5719\n",
      "Trial: 2, Epoch: 10, Train Loss: 7.2076, Val Loss: 0.1213\n",
      "Trial: 1, Epoch: 6, Train Loss: 31.4123, Val Loss: 0.2991\n",
      "Trial: 10, Epoch: 10, Train Loss: 7.0537, Val Loss: 0.1585\n",
      "Trial: 8, Epoch: 4, Train Loss: 60.5066, Val Loss: 0.1211\n",
      "Trial: 17, Epoch: 1, Train Loss: 37.0878, Val Loss: 0.2899\n",
      "Trial: 13, Epoch: 11, Train Loss: 15.8975, Val Loss: 0.4625\n",
      "Trial: 12, Epoch: 7, Train Loss: 55.7926, Val Loss: 0.2619\n",
      "Trial: 14, Epoch: 6, Train Loss: 30.1284, Val Loss: 0.1297\n",
      "Trial: 2, Epoch: 11, Train Loss: 7.1334, Val Loss: 0.1253\n",
      "Trial: 11, Epoch: 11, Train Loss: 6.5567, Val Loss: 0.1881\n",
      "Trial: 15, Epoch: 9, Train Loss: 15.3758, Val Loss: 0.1549\n",
      "Trial: 6, Epoch: 9, Train Loss: 95.1967, Val Loss: 1.3576\n",
      "Early stopping triggered.\n",
      "Trial: 4, Epoch: 9, Train Loss: 15.1115, Val Loss: 0.1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:35:19,188] Trial 6 finished with value: 1.3275708278020224 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.028291624277561673, 'batch_size': 64, 'patience': 8}. Best is trial 5 with value: 0.4497102419535319.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 18] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.007755011466589083, 'batch_size': 64, 'patience': 7}\n",
      "Trial: 10, Epoch: 11, Train Loss: 6.9714, Val Loss: 0.1775\n",
      "Trial: 16, Epoch: 3, Train Loss: 48.5001, Val Loss: 0.5301\n",
      "Trial: 0, Epoch: 7, Train Loss: 28.3393, Val Loss: 0.1165\n",
      "Trial: 3, Epoch: 7, Train Loss: 40.8469, Val Loss: 0.5648\n",
      "Trial: 1, Epoch: 7, Train Loss: 31.0334, Val Loss: 0.2821\n",
      "Trial: 13, Epoch: 12, Train Loss: 15.5167, Val Loss: 0.4553\n",
      "Trial: 17, Epoch: 2, Train Loss: 30.6980, Val Loss: 3.3974\n",
      "Trial: 7, Epoch: 5, Train Loss: 59.6909, Val Loss: 0.1147\n",
      "Trial: 2, Epoch: 12, Train Loss: 7.0759, Val Loss: 0.1194\n",
      "Trial: 11, Epoch: 12, Train Loss: 6.5342, Val Loss: 0.1452\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:37:40,738] Trial 11 finished with value: 0.11593900819619497 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0037979731323002277, 'batch_size': 64, 'patience': 7}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 19] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.00011850523066638164, 'batch_size': 64, 'patience': 8}\n",
      "Trial: 12, Epoch: 8, Train Loss: 53.7153, Val Loss: 0.2480\n",
      "Trial: 18, Epoch: 0, Train Loss: 16.7424, Val Loss: 0.1490\n",
      "Trial: 15, Epoch: 10, Train Loss: 15.2922, Val Loss: 0.1663\n",
      "Trial: 4, Epoch: 10, Train Loss: 15.1119, Val Loss: 0.1268\n",
      "Trial: 10, Epoch: 12, Train Loss: 6.9346, Val Loss: 0.1913\n",
      "Trial: 14, Epoch: 7, Train Loss: 30.1074, Val Loss: 0.1272\n",
      "Trial: 13, Epoch: 13, Train Loss: 14.9979, Val Loss: 0.4560\n",
      "Trial: 8, Epoch: 5, Train Loss: 60.0111, Val Loss: 0.1050\n",
      "Trial: 17, Epoch: 3, Train Loss: 54.3894, Val Loss: 0.1729\n",
      "Trial: 16, Epoch: 4, Train Loss: 45.2968, Val Loss: 0.6196\n",
      "Trial: 2, Epoch: 13, Train Loss: 7.0782, Val Loss: 0.1251\n",
      "Trial: 0, Epoch: 8, Train Loss: 28.0733, Val Loss: 0.1330\n",
      "Trial: 3, Epoch: 8, Train Loss: 39.3918, Val Loss: 0.5573\n",
      "Trial: 1, Epoch: 8, Train Loss: 30.5998, Val Loss: 0.2990\n",
      "Trial: 19, Epoch: 0, Train Loss: 26.4389, Val Loss: 0.6956\n",
      "Trial: 18, Epoch: 1, Train Loss: 7.9540, Val Loss: 0.1333\n",
      "Trial: 10, Epoch: 13, Train Loss: 6.8583, Val Loss: 0.2020\n",
      "Trial: 15, Epoch: 11, Train Loss: 15.2179, Val Loss: 0.1605\n",
      "Trial: 4, Epoch: 11, Train Loss: 15.1123, Val Loss: 0.1264\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:41:34,402] Trial 4 finished with value: 0.12570004959901174 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.012377766412990019, 'batch_size': 32, 'patience': 6}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 20] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 2.2101815975750862e-05, 'batch_size': 8, 'patience': 7}\n",
      "Trial: 12, Epoch: 9, Train Loss: 51.9627, Val Loss: 0.2340\n",
      "Trial: 13, Epoch: 14, Train Loss: 14.7049, Val Loss: 0.4553\n",
      "Trial: 2, Epoch: 14, Train Loss: 7.0203, Val Loss: 0.1460\n",
      "Trial: 17, Epoch: 4, Train Loss: 12.8199, Val Loss: 0.1334\n",
      "Trial: 14, Epoch: 8, Train Loss: 30.1672, Val Loss: 0.1269\n",
      "Trial: 7, Epoch: 6, Train Loss: 59.4320, Val Loss: 0.1099\n",
      "Trial: 19, Epoch: 1, Train Loss: 13.4174, Val Loss: 0.5723\n",
      "Trial: 18, Epoch: 2, Train Loss: 7.8071, Val Loss: 0.1332\n",
      "Trial: 10, Epoch: 14, Train Loss: 6.8118, Val Loss: 0.1821\n",
      "Trial: 16, Epoch: 5, Train Loss: 43.0270, Val Loss: 0.6370\n",
      "Trial: 0, Epoch: 9, Train Loss: 27.5806, Val Loss: 0.1352\n",
      "Trial: 15, Epoch: 12, Train Loss: 15.1730, Val Loss: 0.1778\n",
      "Trial: 3, Epoch: 9, Train Loss: 38.1460, Val Loss: 0.5281\n",
      "Trial: 1, Epoch: 9, Train Loss: 30.3455, Val Loss: 0.2823\n",
      "Trial: 13, Epoch: 15, Train Loss: 14.4075, Val Loss: 0.4511\n",
      "Trial: 2, Epoch: 15, Train Loss: 6.9850, Val Loss: 0.1518\n",
      "Trial: 17, Epoch: 5, Train Loss: 8.2694, Val Loss: 0.1284\n",
      "Trial: 8, Epoch: 6, Train Loss: 59.9077, Val Loss: 0.1242\n",
      "Trial: 12, Epoch: 10, Train Loss: 51.3293, Val Loss: 0.2281\n",
      "Trial: 18, Epoch: 3, Train Loss: 7.7186, Val Loss: 0.1351\n",
      "Trial: 19, Epoch: 2, Train Loss: 11.6344, Val Loss: 0.5452\n",
      "Trial: 10, Epoch: 15, Train Loss: 6.7509, Val Loss: 0.1964\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:46:26,003] Trial 10 finished with value: 0.13788900872071583 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.0006330251375332808, 'batch_size': 64, 'patience': 10}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 21] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0008487884652373777, 'batch_size': 8, 'patience': 7}\n",
      "Trial: 14, Epoch: 9, Train Loss: 30.0655, Val Loss: 0.1290\n",
      "Trial: 13, Epoch: 16, Train Loss: 13.9930, Val Loss: 0.4492\n",
      "Trial: 15, Epoch: 13, Train Loss: 15.0826, Val Loss: 0.1619\n",
      "Trial: 20, Epoch: 0, Train Loss: 142.8262, Val Loss: 0.2279\n",
      "Trial: 2, Epoch: 16, Train Loss: 6.9226, Val Loss: 0.1492\n",
      "Trial: 16, Epoch: 6, Train Loss: 41.1262, Val Loss: 0.5556\n",
      "Trial: 0, Epoch: 10, Train Loss: 27.3688, Val Loss: 0.1355\n",
      "Trial: 17, Epoch: 6, Train Loss: 7.6974, Val Loss: 0.1271\n",
      "Trial: 3, Epoch: 10, Train Loss: 37.0232, Val Loss: 0.5590\n",
      "Trial: 18, Epoch: 4, Train Loss: 7.6714, Val Loss: 0.1338\n",
      "Trial: 1, Epoch: 10, Train Loss: 29.9116, Val Loss: 0.3035\n",
      "Trial: 7, Epoch: 7, Train Loss: 59.6049, Val Loss: 0.1173\n",
      "Trial: 19, Epoch: 3, Train Loss: 10.7773, Val Loss: 0.4530\n",
      "Trial: 12, Epoch: 11, Train Loss: 50.0741, Val Loss: 0.2218\n",
      "Trial: 13, Epoch: 17, Train Loss: 13.6722, Val Loss: 0.4352\n",
      "Trial: 2, Epoch: 17, Train Loss: 6.8982, Val Loss: 0.1363\n",
      "Trial: 15, Epoch: 14, Train Loss: 15.0415, Val Loss: 0.1806\n",
      "Trial: 17, Epoch: 7, Train Loss: 7.6663, Val Loss: 0.1282\n",
      "Trial: 18, Epoch: 5, Train Loss: 7.6123, Val Loss: 0.1309\n",
      "Trial: 8, Epoch: 7, Train Loss: 59.3711, Val Loss: 0.1122\n",
      "Trial: 19, Epoch: 4, Train Loss: 10.0337, Val Loss: 0.4151\n",
      "Trial: 14, Epoch: 10, Train Loss: 30.0798, Val Loss: 0.1275\n",
      "Trial: 16, Epoch: 7, Train Loss: 39.4633, Val Loss: 0.4988\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:52:11,281] Trial 16 finished with value: 0.47819625089565915 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 1.4926436023702518e-05, 'batch_size': 16, 'patience': 5}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 22] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0010315756916705722, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 0, Epoch: 11, Train Loss: 27.2793, Val Loss: 0.1306\n",
      "Trial: 21, Epoch: 0, Train Loss: 82.4197, Val Loss: 0.1886\n",
      "Trial: 13, Epoch: 18, Train Loss: 13.3949, Val Loss: 0.4268\n",
      "Trial: 3, Epoch: 11, Train Loss: 36.1613, Val Loss: 0.5233\n",
      "Trial: 1, Epoch: 11, Train Loss: 29.5948, Val Loss: 0.3429\n",
      "Trial: 2, Epoch: 18, Train Loss: 6.8766, Val Loss: 0.1332\n",
      "Trial: 20, Epoch: 1, Train Loss: 88.4193, Val Loss: 0.2054\n",
      "Trial: 12, Epoch: 12, Train Loss: 49.1167, Val Loss: 0.2114\n",
      "Trial: 18, Epoch: 6, Train Loss: 7.6006, Val Loss: 0.1301\n",
      "Trial: 15, Epoch: 15, Train Loss: 15.0696, Val Loss: 0.1642\n",
      "Trial: 17, Epoch: 8, Train Loss: 7.6224, Val Loss: 0.1270\n",
      "Trial: 19, Epoch: 5, Train Loss: 9.3936, Val Loss: 0.3209\n",
      "Trial: 7, Epoch: 8, Train Loss: 59.3906, Val Loss: 0.1096\n",
      "Trial: 13, Epoch: 19, Train Loss: 13.0473, Val Loss: 0.4141\n",
      "Trial: 2, Epoch: 19, Train Loss: 6.8531, Val Loss: 0.1313\n",
      "Trial: 14, Epoch: 11, Train Loss: 30.0056, Val Loss: 0.1285\n",
      "Trial: 0, Epoch: 12, Train Loss: 27.0420, Val Loss: 0.1339\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:56:16,852] Trial 0 finished with value: 0.11651708371937275 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.001155211724603464, 'batch_size': 16, 'patience': 5}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 23] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 2.091851584760188e-05, 'batch_size': 64, 'patience': 8}\n",
      "Trial: 18, Epoch: 7, Train Loss: 7.5515, Val Loss: 0.1301\n",
      "Trial: 22, Epoch: 0, Train Loss: 41.0569, Val Loss: 0.2117\n",
      "Trial: 3, Epoch: 12, Train Loss: 35.0538, Val Loss: 0.5158\n",
      "Trial: 1, Epoch: 12, Train Loss: 29.2870, Val Loss: 0.3734\n",
      "Trial: 17, Epoch: 9, Train Loss: 7.6088, Val Loss: 0.1272\n",
      "Trial: 19, Epoch: 6, Train Loss: 8.7728, Val Loss: 0.3424\n",
      "Trial: 15, Epoch: 16, Train Loss: 15.0133, Val Loss: 0.1768\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:57:00,492] Trial 15 finished with value: 0.15490390261014303 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0001271547083066484, 'batch_size': 32, 'patience': 7}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 24] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.013651369474990523, 'batch_size': 8, 'patience': 6}\n",
      "Trial: 8, Epoch: 8, Train Loss: 59.7454, Val Loss: 0.1201\n",
      "Trial: 12, Epoch: 13, Train Loss: 48.2332, Val Loss: 0.2046\n",
      "Trial: 13, Epoch: 20, Train Loss: 12.7719, Val Loss: 0.3960\n",
      "Trial: 21, Epoch: 1, Train Loss: 61.3191, Val Loss: 0.1423\n",
      "Trial: 2, Epoch: 20, Train Loss: 6.8479, Val Loss: 0.1364\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 01:58:25,320] Trial 2 finished with value: 0.11944196820259094 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.0007586879325312465, 'batch_size': 64, 'patience': 8}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 25] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.08700542843883471, 'batch_size': 8, 'patience': 3}\n",
      "Trial: 18, Epoch: 8, Train Loss: 7.5432, Val Loss: 0.1309\n",
      "Trial: 20, Epoch: 2, Train Loss: 75.9410, Val Loss: 0.1760\n",
      "Trial: 23, Epoch: 0, Train Loss: 41.8754, Val Loss: 0.5098\n",
      "Trial: 17, Epoch: 10, Train Loss: 7.6182, Val Loss: 0.1270\n",
      "Trial: 19, Epoch: 7, Train Loss: 8.2480, Val Loss: 0.4514\n",
      "Trial: 7, Epoch: 9, Train Loss: 59.1794, Val Loss: 0.1150\n",
      "Trial: 14, Epoch: 12, Train Loss: 30.0522, Val Loss: 0.1280\n",
      "Early stopping triggered.\n",
      "Trial: 13, Epoch: 21, Train Loss: 12.3983, Val Loss: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:00:12,807] Trial 14 finished with value: 0.1268717565884193 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.034565586212728594, 'batch_size': 16, 'patience': 4}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 26] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.00460757274008274, 'batch_size': 8, 'patience': 3}\n",
      "Trial: 3, Epoch: 13, Train Loss: 34.0410, Val Loss: 0.4960\n",
      "Trial: 1, Epoch: 13, Train Loss: 28.9971, Val Loss: 0.3860\n",
      "Trial: 22, Epoch: 1, Train Loss: 28.7252, Val Loss: 0.1584\n",
      "Trial: 12, Epoch: 14, Train Loss: 46.9914, Val Loss: 0.2007\n",
      "Trial: 18, Epoch: 9, Train Loss: 7.5193, Val Loss: 0.1377\n",
      "Trial: 23, Epoch: 1, Train Loss: 26.8608, Val Loss: 1.2437\n",
      "Trial: 19, Epoch: 8, Train Loss: 7.9046, Val Loss: 0.4195\n",
      "Trial: 17, Epoch: 11, Train Loss: 7.6018, Val Loss: 0.1272\n",
      "Trial: 13, Epoch: 22, Train Loss: 12.0991, Val Loss: 0.3459\n",
      "Trial: 24, Epoch: 0, Train Loss: 66.8459, Val Loss: 0.1230\n",
      "Trial: 8, Epoch: 9, Train Loss: 59.1333, Val Loss: 0.1205\n",
      "Trial: 21, Epoch: 2, Train Loss: 60.0077, Val Loss: 0.1616\n",
      "Trial: 18, Epoch: 10, Train Loss: 7.5204, Val Loss: 0.1290\n",
      "Trial: 3, Epoch: 14, Train Loss: 33.3318, Val Loss: 0.5032\n",
      "Trial: 25, Epoch: 0, Train Loss: 210878.2974, Val Loss: 0.2633\n",
      "Trial: 1, Epoch: 14, Train Loss: 28.9737, Val Loss: 0.3909\n",
      "Trial: 20, Epoch: 3, Train Loss: 70.6593, Val Loss: 0.1564\n",
      "Trial: 22, Epoch: 2, Train Loss: 28.0706, Val Loss: 0.1667\n",
      "Trial: 19, Epoch: 9, Train Loss: 7.7090, Val Loss: 0.4003\n",
      "Trial: 23, Epoch: 2, Train Loss: 22.1211, Val Loss: 1.5065\n",
      "Trial: 12, Epoch: 15, Train Loss: 46.3441, Val Loss: 0.1877\n",
      "Trial: 17, Epoch: 12, Train Loss: 7.5718, Val Loss: 0.1271\n",
      "Trial: 13, Epoch: 23, Train Loss: 11.8010, Val Loss: 0.3406\n",
      "Trial: 7, Epoch: 10, Train Loss: 58.8514, Val Loss: 0.1180\n",
      "Trial: 26, Epoch: 0, Train Loss: 72.3207, Val Loss: 0.1257\n",
      "Trial: 18, Epoch: 11, Train Loss: 7.5338, Val Loss: 0.1281\n",
      "Trial: 19, Epoch: 10, Train Loss: 7.6372, Val Loss: 0.3369\n",
      "Trial: 23, Epoch: 3, Train Loss: 20.1434, Val Loss: 1.4969\n",
      "Trial: 13, Epoch: 24, Train Loss: 11.5996, Val Loss: 0.3243\n",
      "Trial: 17, Epoch: 13, Train Loss: 7.5625, Val Loss: 0.1271\n",
      "Trial: 24, Epoch: 1, Train Loss: 57.7542, Val Loss: 0.1159\n",
      "Trial: 3, Epoch: 15, Train Loss: 33.0873, Val Loss: 0.4621\n",
      "Trial: 1, Epoch: 15, Train Loss: 28.8113, Val Loss: 0.3772\n",
      "Trial: 22, Epoch: 3, Train Loss: 27.5072, Val Loss: 0.1593\n",
      "Trial: 12, Epoch: 16, Train Loss: 45.4983, Val Loss: 0.1837\n",
      "Trial: 8, Epoch: 10, Train Loss: 59.4277, Val Loss: 0.1067\n",
      "Trial: 18, Epoch: 12, Train Loss: 7.5143, Val Loss: 0.1253\n",
      "Trial: 21, Epoch: 3, Train Loss: 59.3238, Val Loss: 0.1195\n",
      "Trial: 19, Epoch: 11, Train Loss: 7.5632, Val Loss: 0.3392\n",
      "Trial: 13, Epoch: 25, Train Loss: 11.3868, Val Loss: 0.3288\n",
      "Trial: 20, Epoch: 4, Train Loss: 68.0452, Val Loss: 0.1516\n",
      "Trial: 23, Epoch: 4, Train Loss: 18.8253, Val Loss: 1.3811\n",
      "Trial: 25, Epoch: 1, Train Loss: 73.7354, Val Loss: 0.1331\n",
      "Trial: 17, Epoch: 14, Train Loss: 7.5677, Val Loss: 0.1278\n",
      "Trial: 7, Epoch: 11, Train Loss: 58.3095, Val Loss: 0.1193\n",
      "Trial: 18, Epoch: 13, Train Loss: 7.5097, Val Loss: 0.1249\n",
      "Trial: 26, Epoch: 1, Train Loss: 57.1153, Val Loss: 0.1280\n",
      "Trial: 3, Epoch: 16, Train Loss: 32.2824, Val Loss: 0.4231\n",
      "Trial: 12, Epoch: 17, Train Loss: 44.7911, Val Loss: 0.1785\n",
      "Trial: 1, Epoch: 16, Train Loss: 28.6719, Val Loss: 0.3519\n",
      "Trial: 19, Epoch: 12, Train Loss: 7.4857, Val Loss: 0.3248\n",
      "Trial: 22, Epoch: 4, Train Loss: 27.0291, Val Loss: 0.1718\n",
      "Trial: 13, Epoch: 26, Train Loss: 11.2408, Val Loss: 0.3251\n",
      "Trial: 23, Epoch: 5, Train Loss: 17.7397, Val Loss: 1.2006\n",
      "Trial: 17, Epoch: 15, Train Loss: 7.5697, Val Loss: 0.1268\n",
      "Trial: 24, Epoch: 2, Train Loss: 57.2542, Val Loss: 0.1162\n",
      "Trial: 18, Epoch: 14, Train Loss: 7.4939, Val Loss: 0.1182\n",
      "Trial: 8, Epoch: 11, Train Loss: 59.1795, Val Loss: 0.1420\n",
      "Trial: 21, Epoch: 4, Train Loss: 58.5755, Val Loss: 0.1220\n",
      "Trial: 13, Epoch: 27, Train Loss: 10.9940, Val Loss: 0.3166\n",
      "Trial: 19, Epoch: 13, Train Loss: 7.4536, Val Loss: 0.3139\n",
      "Trial: 23, Epoch: 6, Train Loss: 16.8501, Val Loss: 0.9665\n",
      "Trial: 20, Epoch: 5, Train Loss: 66.6306, Val Loss: 0.1540\n",
      "Trial: 25, Epoch: 2, Train Loss: 230.6132, Val Loss: 0.7897\n",
      "Trial: 17, Epoch: 16, Train Loss: 7.5625, Val Loss: 0.1267\n",
      "Trial: 12, Epoch: 18, Train Loss: 44.0967, Val Loss: 0.1731\n",
      "Trial: 3, Epoch: 17, Train Loss: 31.8922, Val Loss: 0.4359\n",
      "Trial: 1, Epoch: 17, Train Loss: 28.4865, Val Loss: 0.3510\n",
      "Early stopping triggered.\n",
      "Trial: 7, Epoch: 12, Train Loss: 58.4719, Val Loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:16:42,239] Trial 1 finished with value: 0.28205979565779365 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 6.179358984748825e-05, 'batch_size': 16, 'patience': 10}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 27] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.00329366055966922, 'batch_size': 8, 'patience': 3}\n",
      "Trial: 18, Epoch: 15, Train Loss: 7.4990, Val Loss: 0.1159\n",
      "Trial: 22, Epoch: 5, Train Loss: 26.2647, Val Loss: 0.1503\n",
      "Trial: 26, Epoch: 2, Train Loss: 54.7411, Val Loss: 0.1184\n",
      "Trial: 13, Epoch: 28, Train Loss: 10.7453, Val Loss: 0.3023\n",
      "Trial: 19, Epoch: 14, Train Loss: 7.4151, Val Loss: 0.3182\n",
      "Trial: 23, Epoch: 7, Train Loss: 15.9955, Val Loss: 0.7986\n",
      "Trial: 17, Epoch: 17, Train Loss: 7.5476, Val Loss: 0.1267\n",
      "Trial: 18, Epoch: 16, Train Loss: 7.4907, Val Loss: 0.1181\n",
      "Trial: 24, Epoch: 3, Train Loss: 57.0005, Val Loss: 0.1189\n",
      "Trial: 12, Epoch: 19, Train Loss: 43.2776, Val Loss: 0.1688\n",
      "Trial: 21, Epoch: 5, Train Loss: 58.4447, Val Loss: 0.1274\n",
      "Trial: 8, Epoch: 12, Train Loss: 59.3488, Val Loss: 0.1096\n",
      "Trial: 3, Epoch: 18, Train Loss: 31.4812, Val Loss: 0.4180\n",
      "Trial: 13, Epoch: 29, Train Loss: 10.5508, Val Loss: 0.2973\n",
      "Trial: 19, Epoch: 15, Train Loss: 7.3338, Val Loss: 0.3386\n",
      "Trial: 22, Epoch: 6, Train Loss: 26.0666, Val Loss: 0.1636\n",
      "Trial: 23, Epoch: 8, Train Loss: 15.3982, Val Loss: 0.6402\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:21:31,384] Trial 23 finished with value: 0.5097639977931976 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 2.091851584760188e-05, 'batch_size': 64, 'patience': 8}. Best is trial 11 with value: 0.11593900819619497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 28] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.004607339952169951, 'batch_size': 8, 'patience': 3}\n",
      "Trial: 20, Epoch: 6, Train Loss: 65.3702, Val Loss: 0.1505\n",
      "Trial: 18, Epoch: 17, Train Loss: 7.4842, Val Loss: 0.1137\n",
      "Trial: 17, Epoch: 18, Train Loss: 7.5576, Val Loss: 0.1269\n",
      "Trial: 25, Epoch: 3, Train Loss: 80.0258, Val Loss: 0.1308\n",
      "Trial: 7, Epoch: 13, Train Loss: 58.5309, Val Loss: 0.1110\n",
      "Trial: 27, Epoch: 0, Train Loss: 69.4350, Val Loss: 0.1303\n",
      "Trial: 26, Epoch: 3, Train Loss: 54.5238, Val Loss: 0.1065\n",
      "Trial: 13, Epoch: 30, Train Loss: 10.4467, Val Loss: 0.2925\n",
      "Trial: 19, Epoch: 16, Train Loss: 7.2790, Val Loss: 0.3909\n",
      "Trial: 12, Epoch: 20, Train Loss: 42.6388, Val Loss: 0.1641\n",
      "Trial: 18, Epoch: 18, Train Loss: 7.4423, Val Loss: 0.1166\n",
      "Trial: 3, Epoch: 19, Train Loss: 31.2158, Val Loss: 0.4502\n",
      "Trial: 17, Epoch: 19, Train Loss: 7.5564, Val Loss: 0.1272\n",
      "Trial: 22, Epoch: 7, Train Loss: 25.9375, Val Loss: 0.1769\n",
      "Trial: 24, Epoch: 4, Train Loss: 56.5617, Val Loss: 0.1181\n",
      "Trial: 13, Epoch: 31, Train Loss: 10.3346, Val Loss: 0.2893\n",
      "Trial: 21, Epoch: 6, Train Loss: 58.3701, Val Loss: 0.1383\n",
      "Trial: 19, Epoch: 17, Train Loss: 7.1864, Val Loss: 0.4543\n",
      "Trial: 8, Epoch: 13, Train Loss: 59.0519, Val Loss: 0.1208\n",
      "Trial: 18, Epoch: 19, Train Loss: 7.4066, Val Loss: 0.1160\n",
      "Trial: 20, Epoch: 7, Train Loss: 64.4391, Val Loss: 0.1492\n",
      "Trial: 28, Epoch: 0, Train Loss: 79.8417, Val Loss: 0.1153\n",
      "Trial: 7, Epoch: 14, Train Loss: 58.6999, Val Loss: 0.1144\n",
      "Trial: 12, Epoch: 21, Train Loss: 41.7383, Val Loss: 0.1611\n",
      "Trial: 17, Epoch: 20, Train Loss: 7.5926, Val Loss: 0.1317\n",
      "Trial: 25, Epoch: 4, Train Loss: 60.6435, Val Loss: 0.1336\n",
      "Trial: 13, Epoch: 32, Train Loss: 10.1590, Val Loss: 0.2764\n",
      "Trial: 27, Epoch: 1, Train Loss: 55.7204, Val Loss: 0.1386\n",
      "Trial: 3, Epoch: 20, Train Loss: 30.8548, Val Loss: 0.3969\n",
      "Trial: 26, Epoch: 4, Train Loss: 53.9856, Val Loss: 0.1185\n",
      "Trial: 19, Epoch: 18, Train Loss: 7.1223, Val Loss: 0.4211\n",
      "Trial: 22, Epoch: 8, Train Loss: 25.8376, Val Loss: 0.1925\n",
      "Trial: 18, Epoch: 20, Train Loss: 7.4834, Val Loss: 0.1119\n",
      "Trial: 17, Epoch: 21, Train Loss: 7.6362, Val Loss: 0.1265\n",
      "Trial: 24, Epoch: 5, Train Loss: 56.7511, Val Loss: 0.1137\n",
      "Trial: 13, Epoch: 33, Train Loss: 10.0000, Val Loss: 0.2725\n",
      "Trial: 21, Epoch: 7, Train Loss: 58.2527, Val Loss: 0.1239\n",
      "Trial: 19, Epoch: 19, Train Loss: 7.0825, Val Loss: 0.4635\n",
      "Trial: 12, Epoch: 22, Train Loss: 41.1542, Val Loss: 0.1562\n",
      "Trial: 8, Epoch: 14, Train Loss: 59.4125, Val Loss: 0.1124\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:31:55,093] Trial 8 finished with value: 0.1049827314725443 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'learning_rate': 0.0015568931842321742, 'batch_size': 8, 'patience': 9}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 29] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.004497036336225431, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 18, Epoch: 21, Train Loss: 7.3920, Val Loss: 0.1186\n",
      "Trial: 3, Epoch: 21, Train Loss: 30.5832, Val Loss: 0.4231\n",
      "Trial: 22, Epoch: 9, Train Loss: 25.7998, Val Loss: 0.1490\n",
      "Trial: 20, Epoch: 8, Train Loss: 63.5356, Val Loss: 0.1534\n",
      "Trial: 7, Epoch: 15, Train Loss: 58.2913, Val Loss: 0.1162\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:33:13,099] Trial 7 finished with value: 0.10963146138091047 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.018314159872050883, 'batch_size': 8, 'patience': 7}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 30] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.004554554242289562, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 28, Epoch: 1, Train Loss: 56.2808, Val Loss: 0.1321\n",
      "Trial: 13, Epoch: 34, Train Loss: 9.8943, Val Loss: 0.2602\n",
      "Trial: 17, Epoch: 22, Train Loss: 7.5544, Val Loss: 0.1265\n",
      "Trial: 25, Epoch: 5, Train Loss: 100.8252, Val Loss: 0.1288\n",
      "Trial: 19, Epoch: 20, Train Loss: 7.0445, Val Loss: 0.4418\n",
      "Trial: 27, Epoch: 2, Train Loss: 54.7525, Val Loss: 0.1212\n",
      "Trial: 26, Epoch: 5, Train Loss: 53.8645, Val Loss: 0.1201\n",
      "Trial: 18, Epoch: 22, Train Loss: 7.4262, Val Loss: 0.1142\n",
      "Trial: 12, Epoch: 23, Train Loss: 40.9026, Val Loss: 0.1539\n",
      "Trial: 13, Epoch: 35, Train Loss: 9.7705, Val Loss: 0.2472\n",
      "Trial: 24, Epoch: 6, Train Loss: 56.6618, Val Loss: 0.1154\n",
      "Trial: 17, Epoch: 23, Train Loss: 7.5567, Val Loss: 0.1267\n",
      "Trial: 3, Epoch: 22, Train Loss: 30.1981, Val Loss: 0.4041\n",
      "Trial: 19, Epoch: 21, Train Loss: 6.9982, Val Loss: 0.5140\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:36:39,876] Trial 19 finished with value: 0.31389007170995076 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.00011850523066638164, 'batch_size': 64, 'patience': 8}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 31] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.006018202462937895, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 21, Epoch: 8, Train Loss: 57.9011, Val Loss: 0.1158\n",
      "Trial: 22, Epoch: 10, Train Loss: 25.7388, Val Loss: 0.1578\n",
      "Trial: 18, Epoch: 23, Train Loss: 7.4459, Val Loss: 0.1132\n",
      "Trial: 29, Epoch: 0, Train Loss: 79.2860, Val Loss: 0.1930\n",
      "Trial: 13, Epoch: 36, Train Loss: 9.5727, Val Loss: 0.2396\n",
      "Trial: 20, Epoch: 9, Train Loss: 62.9517, Val Loss: 0.1449\n",
      "Trial: 28, Epoch: 2, Train Loss: 54.9201, Val Loss: 0.1124\n",
      "Trial: 12, Epoch: 24, Train Loss: 40.1075, Val Loss: 0.1532\n",
      "Trial: 17, Epoch: 24, Train Loss: 7.5501, Val Loss: 0.1266\n",
      "Trial: 30, Epoch: 0, Train Loss: 72.3510, Val Loss: 0.1155\n",
      "Trial: 25, Epoch: 6, Train Loss: 60.7078, Val Loss: 0.1288\n",
      "Trial: 18, Epoch: 24, Train Loss: 7.4063, Val Loss: 0.1116\n",
      "Trial: 26, Epoch: 6, Train Loss: 53.9847, Val Loss: 0.1134\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:39:35,207] Trial 26 finished with value: 0.10652636110532183 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.00460757274008274, 'batch_size': 8, 'patience': 3}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 32] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0057288665036225785, 'batch_size': 8, 'patience': 3}\n",
      "Trial: 27, Epoch: 3, Train Loss: 53.9603, Val Loss: 0.1127\n",
      "Trial: 3, Epoch: 23, Train Loss: 30.0689, Val Loss: 0.4297\n",
      "Trial: 22, Epoch: 11, Train Loss: 25.7031, Val Loss: 0.1532\n",
      "Trial: 13, Epoch: 37, Train Loss: 9.5338, Val Loss: 0.2438\n",
      "Trial: 24, Epoch: 7, Train Loss: 56.6306, Val Loss: 0.1186\n",
      "Trial: 17, Epoch: 25, Train Loss: 7.5436, Val Loss: 0.1266\n",
      "Trial: 18, Epoch: 25, Train Loss: 7.3859, Val Loss: 0.1205\n",
      "Trial: 21, Epoch: 9, Train Loss: 58.1376, Val Loss: 0.1162\n",
      "Trial: 31, Epoch: 0, Train Loss: 67.4920, Val Loss: 0.1074\n",
      "Trial: 12, Epoch: 25, Train Loss: 39.5472, Val Loss: 0.1495\n",
      "Trial: 13, Epoch: 38, Train Loss: 9.4171, Val Loss: 0.2325\n",
      "Trial: 29, Epoch: 1, Train Loss: 57.5867, Val Loss: 0.1212\n",
      "Trial: 3, Epoch: 24, Train Loss: 29.8945, Val Loss: 0.4214\n",
      "Trial: 20, Epoch: 10, Train Loss: 62.4925, Val Loss: 0.1472\n",
      "Trial: 18, Epoch: 26, Train Loss: 7.3949, Val Loss: 0.1199\n",
      "Trial: 28, Epoch: 3, Train Loss: 54.3884, Val Loss: 0.1112\n",
      "Trial: 30, Epoch: 1, Train Loss: 60.5998, Val Loss: 0.1076\n",
      "Trial: 17, Epoch: 26, Train Loss: 7.5393, Val Loss: 0.1264\n",
      "Trial: 22, Epoch: 12, Train Loss: 25.6039, Val Loss: 0.1294\n",
      "Trial: 25, Epoch: 7, Train Loss: 72.9276, Val Loss: 0.1336\n",
      "Trial: 27, Epoch: 4, Train Loss: 53.7436, Val Loss: 0.1158\n",
      "Trial: 32, Epoch: 0, Train Loss: 81.8941, Val Loss: 0.1241\n",
      "Trial: 13, Epoch: 39, Train Loss: 9.2869, Val Loss: 0.2298\n",
      "Trial: 12, Epoch: 26, Train Loss: 39.1976, Val Loss: 0.1490\n",
      "Trial: 18, Epoch: 27, Train Loss: 7.3428, Val Loss: 0.1191\n",
      "Trial: 24, Epoch: 8, Train Loss: 55.6710, Val Loss: 0.1188\n",
      "Trial: 17, Epoch: 27, Train Loss: 7.5372, Val Loss: 0.1277\n",
      "Trial: 31, Epoch: 1, Train Loss: 59.9577, Val Loss: 0.1102\n",
      "Trial: 21, Epoch: 10, Train Loss: 57.7608, Val Loss: 0.1178\n",
      "Trial: 3, Epoch: 25, Train Loss: 29.8002, Val Loss: 0.4046\n",
      "Trial: 13, Epoch: 40, Train Loss: 9.1282, Val Loss: 0.2337\n",
      "Trial: 22, Epoch: 13, Train Loss: 25.6493, Val Loss: 0.1363\n",
      "Trial: 29, Epoch: 2, Train Loss: 55.7179, Val Loss: 0.1125\n",
      "Trial: 18, Epoch: 28, Train Loss: 7.3617, Val Loss: 0.1192\n",
      "Trial: 20, Epoch: 11, Train Loss: 62.0921, Val Loss: 0.1502\n",
      "Trial: 30, Epoch: 2, Train Loss: 59.8537, Val Loss: 0.1132\n",
      "Trial: 12, Epoch: 27, Train Loss: 38.7552, Val Loss: 0.1463\n",
      "Trial: 28, Epoch: 4, Train Loss: 54.2579, Val Loss: 0.1092\n",
      "Trial: 17, Epoch: 28, Train Loss: 7.5741, Val Loss: 0.1272\n",
      "Trial: 25, Epoch: 8, Train Loss: 60.3613, Val Loss: 0.1294\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:50:29,517] Trial 25 finished with value: 0.12883468742380624 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.08700542843883471, 'batch_size': 8, 'patience': 3}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 33] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.004559883976310757, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 27, Epoch: 5, Train Loss: 53.9928, Val Loss: 0.1177\n",
      "Trial: 13, Epoch: 41, Train Loss: 9.0579, Val Loss: 0.2357\n",
      "Trial: 32, Epoch: 1, Train Loss: 60.2976, Val Loss: 0.1233\n",
      "Trial: 3, Epoch: 26, Train Loss: 29.6193, Val Loss: 0.4159\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:51:32,235] Trial 3 finished with value: 0.3969169192016125 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 1.1534763474491681e-05, 'batch_size': 16, 'patience': 6}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 34] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.002706688622194781, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 18, Epoch: 29, Train Loss: 7.3545, Val Loss: 0.1261\n",
      "Trial: 24, Epoch: 9, Train Loss: 54.7508, Val Loss: 0.1239\n",
      "Trial: 22, Epoch: 14, Train Loss: 25.5084, Val Loss: 0.1368\n",
      "Trial: 17, Epoch: 29, Train Loss: 7.5551, Val Loss: 0.1267\n",
      "Trial: 31, Epoch: 2, Train Loss: 59.4270, Val Loss: 0.1163\n",
      "Trial: 21, Epoch: 11, Train Loss: 57.7093, Val Loss: 0.1187\n",
      "Trial: 13, Epoch: 42, Train Loss: 8.9664, Val Loss: 0.2477\n",
      "Trial: 12, Epoch: 28, Train Loss: 38.0677, Val Loss: 0.1446\n",
      "Trial: 18, Epoch: 30, Train Loss: 7.2486, Val Loss: 0.1143\n",
      "Trial: 29, Epoch: 3, Train Loss: 55.0235, Val Loss: 0.1155\n",
      "Trial: 20, Epoch: 12, Train Loss: 61.6840, Val Loss: 0.1458\n",
      "Trial: 30, Epoch: 3, Train Loss: 59.3816, Val Loss: 0.1054\n",
      "Trial: 28, Epoch: 5, Train Loss: 53.8510, Val Loss: 0.1031\n",
      "Trial: 17, Epoch: 30, Train Loss: 7.5639, Val Loss: 0.1269\n",
      "Trial: 13, Epoch: 43, Train Loss: 8.8387, Val Loss: 0.2778\n",
      "Trial: 27, Epoch: 6, Train Loss: 53.5742, Val Loss: 0.1093\n",
      "Trial: 22, Epoch: 15, Train Loss: 25.4226, Val Loss: 0.1466\n",
      "Trial: 32, Epoch: 2, Train Loss: 60.1244, Val Loss: 0.1235\n",
      "Trial: 33, Epoch: 0, Train Loss: 91.9938, Val Loss: 0.1362\n",
      "Trial: 18, Epoch: 31, Train Loss: 7.2964, Val Loss: 0.1199\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 02:56:46,035] Trial 18 finished with value: 0.11159260918696721 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.007755011466589083, 'batch_size': 64, 'patience': 7}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 35] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0026827482606724368, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 12, Epoch: 29, Train Loss: 37.8904, Val Loss: 0.1440\n",
      "Trial: 34, Epoch: 0, Train Loss: 82.6198, Val Loss: 0.1115\n",
      "Trial: 24, Epoch: 10, Train Loss: 54.3774, Val Loss: 0.1186\n",
      "Trial: 31, Epoch: 3, Train Loss: 59.4041, Val Loss: 0.1097\n",
      "Trial: 13, Epoch: 44, Train Loss: 8.7596, Val Loss: 0.2794\n",
      "Trial: 17, Epoch: 31, Train Loss: 7.5457, Val Loss: 0.1264\n",
      "Trial: 21, Epoch: 12, Train Loss: 57.6977, Val Loss: 0.1160\n",
      "Trial: 22, Epoch: 16, Train Loss: 25.4599, Val Loss: 0.1311\n",
      "Trial: 29, Epoch: 4, Train Loss: 54.5443, Val Loss: 0.1163\n",
      "Trial: 20, Epoch: 13, Train Loss: 61.2099, Val Loss: 0.1413\n",
      "Trial: 13, Epoch: 45, Train Loss: 8.6620, Val Loss: 0.3080\n",
      "Early stopping triggered.\n",
      "Trial: 30, Epoch: 4, Train Loss: 59.0514, Val Loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:00:35,978] Trial 13 finished with value: 0.22982805569966633 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 2.4129905873466902e-05, 'batch_size': 64, 'patience': 6}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 36] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0016071838216800071, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 12, Epoch: 30, Train Loss: 37.6832, Val Loss: 0.1416\n",
      "Trial: 17, Epoch: 32, Train Loss: 7.5561, Val Loss: 0.1272\n",
      "Trial: 28, Epoch: 6, Train Loss: 53.7859, Val Loss: 0.1068\n",
      "Trial: 27, Epoch: 7, Train Loss: 53.4292, Val Loss: 0.1079\n",
      "Trial: 32, Epoch: 3, Train Loss: 60.2413, Val Loss: 0.1233\n",
      "Trial: 33, Epoch: 1, Train Loss: 63.1465, Val Loss: 0.1280\n",
      "Trial: 35, Epoch: 0, Train Loss: 80.9141, Val Loss: 0.1454\n",
      "Trial: 34, Epoch: 1, Train Loss: 56.1621, Val Loss: 0.1134\n",
      "Trial: 24, Epoch: 11, Train Loss: 54.4341, Val Loss: 0.1188\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:03:04,159] Trial 24 finished with value: 0.11367259594071813 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.013651369474990523, 'batch_size': 8, 'patience': 6}. Best is trial 8 with value: 0.1049827314725443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 37] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0024019008442483954, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 31, Epoch: 4, Train Loss: 59.1718, Val Loss: 0.1096\n",
      "Trial: 21, Epoch: 13, Train Loss: 57.6829, Val Loss: 0.1119\n",
      "Trial: 17, Epoch: 33, Train Loss: 7.5596, Val Loss: 0.1269\n",
      "Trial: 22, Epoch: 17, Train Loss: 25.4088, Val Loss: 0.1565\n",
      "Trial: 12, Epoch: 31, Train Loss: 37.1990, Val Loss: 0.1394\n",
      "Trial: 20, Epoch: 14, Train Loss: 60.9833, Val Loss: 0.1463\n",
      "Trial: 29, Epoch: 5, Train Loss: 54.0725, Val Loss: 0.1115\n",
      "Trial: 30, Epoch: 5, Train Loss: 58.5133, Val Loss: 0.1099\n",
      "Trial: 36, Epoch: 0, Train Loss: 70.2810, Val Loss: 0.1128\n",
      "Trial: 17, Epoch: 34, Train Loss: 7.5588, Val Loss: 0.1280\n",
      "Trial: 28, Epoch: 7, Train Loss: 53.1516, Val Loss: 0.1070\n",
      "Trial: 32, Epoch: 4, Train Loss: 60.0405, Val Loss: 0.1247\n",
      "Trial: 27, Epoch: 8, Train Loss: 53.6436, Val Loss: 0.1101\n",
      "Trial: 33, Epoch: 2, Train Loss: 58.9090, Val Loss: 0.1412\n",
      "Trial: 22, Epoch: 18, Train Loss: 25.4856, Val Loss: 0.1327\n",
      "Trial: 35, Epoch: 1, Train Loss: 57.1639, Val Loss: 0.1171\n",
      "Trial: 12, Epoch: 32, Train Loss: 36.8892, Val Loss: 0.1388\n",
      "Trial: 34, Epoch: 2, Train Loss: 54.6146, Val Loss: 0.1309\n",
      "Trial: 31, Epoch: 5, Train Loss: 59.1922, Val Loss: 0.1073\n",
      "Trial: 37, Epoch: 0, Train Loss: 72.5932, Val Loss: 0.1133\n",
      "Trial: 21, Epoch: 14, Train Loss: 57.8530, Val Loss: 0.1144\n",
      "Trial: 17, Epoch: 35, Train Loss: 7.5392, Val Loss: 0.1266\n",
      "Trial: 20, Epoch: 15, Train Loss: 60.6619, Val Loss: 0.1427\n",
      "Trial: 30, Epoch: 6, Train Loss: 58.2714, Val Loss: 0.1139\n",
      "Trial: 29, Epoch: 6, Train Loss: 54.2438, Val Loss: 0.1115\n",
      "Trial: 36, Epoch: 1, Train Loss: 59.8924, Val Loss: 0.1080\n",
      "Trial: 22, Epoch: 19, Train Loss: 25.3893, Val Loss: 0.1203\n",
      "Trial: 12, Epoch: 33, Train Loss: 36.6400, Val Loss: 0.1367\n",
      "Trial: 17, Epoch: 36, Train Loss: 7.5420, Val Loss: 0.1272\n",
      "Trial: 28, Epoch: 8, Train Loss: 52.3228, Val Loss: 0.1204\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:12:03,149] Trial 28 finished with value: 0.10313907822891444 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.004607339952169951, 'batch_size': 8, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 38] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0025217625071258447, 'batch_size': 8, 'patience': 3}\n",
      "Trial: 32, Epoch: 5, Train Loss: 60.1660, Val Loss: 0.1238\n",
      "Trial: 27, Epoch: 9, Train Loss: 53.4079, Val Loss: 0.1137\n",
      "Trial: 33, Epoch: 3, Train Loss: 55.8870, Val Loss: 0.1203\n",
      "Trial: 35, Epoch: 2, Train Loss: 55.6553, Val Loss: 0.1165\n",
      "Trial: 31, Epoch: 6, Train Loss: 58.8821, Val Loss: 0.1090\n",
      "Trial: 34, Epoch: 3, Train Loss: 52.4603, Val Loss: 0.1465\n",
      "Trial: 37, Epoch: 1, Train Loss: 60.1581, Val Loss: 0.1096\n",
      "Trial: 21, Epoch: 15, Train Loss: 57.8177, Val Loss: 0.1143\n",
      "Trial: 17, Epoch: 37, Train Loss: 7.5354, Val Loss: 0.1275\n",
      "Trial: 12, Epoch: 34, Train Loss: 36.2234, Val Loss: 0.1358\n",
      "Trial: 22, Epoch: 20, Train Loss: 25.4558, Val Loss: 0.1425\n",
      "Trial: 20, Epoch: 16, Train Loss: 60.4942, Val Loss: 0.1401\n",
      "Trial: 30, Epoch: 7, Train Loss: 58.0766, Val Loss: 0.1119\n",
      "Trial: 36, Epoch: 2, Train Loss: 59.3624, Val Loss: 0.1087\n",
      "Trial: 29, Epoch: 7, Train Loss: 53.7827, Val Loss: 0.1351\n",
      "Trial: 17, Epoch: 38, Train Loss: 7.5520, Val Loss: 0.1278\n",
      "Trial: 38, Epoch: 0, Train Loss: 77.9444, Val Loss: 0.1285\n",
      "Trial: 32, Epoch: 6, Train Loss: 60.0082, Val Loss: 0.1238\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:18:05,058] Trial 32 finished with value: 0.12330788261249286 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0057288665036225785, 'batch_size': 8, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 39] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.002415233276625643, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 27, Epoch: 10, Train Loss: 53.0672, Val Loss: 0.1201\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:18:12,361] Trial 27 finished with value: 0.10790941425982643 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.00329366055966922, 'batch_size': 8, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 40] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0017729050154395765, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 33, Epoch: 4, Train Loss: 55.1067, Val Loss: 0.1139\n",
      "Trial: 31, Epoch: 7, Train Loss: 58.8206, Val Loss: 0.1083\n",
      "Trial: 35, Epoch: 3, Train Loss: 53.7681, Val Loss: 0.1260\n",
      "Trial: 12, Epoch: 35, Train Loss: 35.8569, Val Loss: 0.1345\n",
      "Trial: 34, Epoch: 4, Train Loss: 52.1226, Val Loss: 0.1159\n",
      "Trial: 37, Epoch: 2, Train Loss: 59.2023, Val Loss: 0.1073\n",
      "Trial: 22, Epoch: 21, Train Loss: 25.3268, Val Loss: 0.1492\n",
      "Trial: 21, Epoch: 16, Train Loss: 57.8153, Val Loss: 0.1127\n",
      "Trial: 17, Epoch: 39, Train Loss: 7.5328, Val Loss: 0.1268\n",
      "Trial: 20, Epoch: 17, Train Loss: 60.6313, Val Loss: 0.1540\n",
      "Trial: 30, Epoch: 8, Train Loss: 58.1596, Val Loss: 0.1145\n",
      "Trial: 36, Epoch: 3, Train Loss: 59.1400, Val Loss: 0.1069\n",
      "Trial: 29, Epoch: 8, Train Loss: 53.7345, Val Loss: 0.1150\n",
      "Trial: 12, Epoch: 36, Train Loss: 35.7490, Val Loss: 0.1329\n",
      "Trial: 17, Epoch: 40, Train Loss: 7.5501, Val Loss: 0.1265\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:23:01,121] Trial 17 finished with value: 0.12638548761606216 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'learning_rate': 0.03510675839834266, 'batch_size': 64, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 41] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0016834011116775294, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 22, Epoch: 22, Train Loss: 25.3563, Val Loss: 0.1383\n",
      "Trial: 38, Epoch: 1, Train Loss: 55.9266, Val Loss: 0.1207\n",
      "Trial: 39, Epoch: 0, Train Loss: 64.2045, Val Loss: 0.1198\n",
      "Trial: 40, Epoch: 0, Train Loss: 70.6787, Val Loss: 0.1316\n",
      "Trial: 33, Epoch: 5, Train Loss: 54.9526, Val Loss: 0.1062\n",
      "Trial: 31, Epoch: 8, Train Loss: 58.2336, Val Loss: 0.1103\n",
      "Trial: 35, Epoch: 4, Train Loss: 52.5197, Val Loss: 0.1246\n",
      "Trial: 34, Epoch: 5, Train Loss: 51.5990, Val Loss: 0.1134\n",
      "Trial: 37, Epoch: 3, Train Loss: 59.6326, Val Loss: 0.1081\n",
      "Trial: 21, Epoch: 17, Train Loss: 57.6478, Val Loss: 0.1118\n",
      "Trial: 12, Epoch: 37, Train Loss: 35.4903, Val Loss: 0.1325\n",
      "Trial: 20, Epoch: 18, Train Loss: 60.2368, Val Loss: 0.1436\n",
      "Trial: 30, Epoch: 9, Train Loss: 58.1058, Val Loss: 0.1193\n",
      "Trial: 22, Epoch: 23, Train Loss: 25.2852, Val Loss: 0.1329\n",
      "Trial: 36, Epoch: 4, Train Loss: 59.2260, Val Loss: 0.1077\n",
      "Trial: 29, Epoch: 9, Train Loss: 53.2697, Val Loss: 0.1086\n",
      "Trial: 41, Epoch: 0, Train Loss: 71.0361, Val Loss: 0.1276\n",
      "Trial: 38, Epoch: 2, Train Loss: 55.6775, Val Loss: 0.1155\n",
      "Trial: 39, Epoch: 1, Train Loss: 54.2699, Val Loss: 0.1235\n",
      "Trial: 31, Epoch: 9, Train Loss: 58.5301, Val Loss: 0.1134\n",
      "Trial: 40, Epoch: 1, Train Loss: 55.8122, Val Loss: 0.1194\n",
      "Trial: 33, Epoch: 6, Train Loss: 54.0329, Val Loss: 0.1163\n",
      "Trial: 35, Epoch: 5, Train Loss: 52.0323, Val Loss: 0.1564\n",
      "Trial: 34, Epoch: 6, Train Loss: 51.6799, Val Loss: 0.1165\n",
      "Trial: 37, Epoch: 4, Train Loss: 59.2945, Val Loss: 0.1112\n",
      "Trial: 12, Epoch: 38, Train Loss: 35.1339, Val Loss: 0.1305\n",
      "Trial: 21, Epoch: 18, Train Loss: 57.6765, Val Loss: 0.1100\n",
      "Trial: 22, Epoch: 24, Train Loss: 25.2926, Val Loss: 0.1258\n",
      "Trial: 36, Epoch: 5, Train Loss: 58.7553, Val Loss: 0.1068\n",
      "Trial: 30, Epoch: 10, Train Loss: 58.0998, Val Loss: 0.1095\n",
      "Trial: 20, Epoch: 19, Train Loss: 60.1722, Val Loss: 0.1412\n",
      "Trial: 29, Epoch: 10, Train Loss: 52.4216, Val Loss: 0.1227\n",
      "Trial: 12, Epoch: 39, Train Loss: 34.8920, Val Loss: 0.1289\n",
      "Trial: 41, Epoch: 1, Train Loss: 55.0051, Val Loss: 0.1270\n",
      "Trial: 39, Epoch: 2, Train Loss: 53.5808, Val Loss: 0.1201\n",
      "Trial: 38, Epoch: 3, Train Loss: 55.0417, Val Loss: 0.1191\n",
      "Trial: 31, Epoch: 10, Train Loss: 58.1855, Val Loss: 0.1116\n",
      "Trial: 40, Epoch: 2, Train Loss: 54.6648, Val Loss: 0.1146\n",
      "Trial: 22, Epoch: 25, Train Loss: 25.2956, Val Loss: 0.1345\n",
      "Trial: 33, Epoch: 7, Train Loss: 52.6085, Val Loss: 0.1154\n",
      "Trial: 37, Epoch: 5, Train Loss: 59.3007, Val Loss: 0.1133\n",
      "Trial: 35, Epoch: 6, Train Loss: 51.6835, Val Loss: 0.1188\n",
      "Trial: 34, Epoch: 7, Train Loss: 51.1121, Val Loss: 0.1232\n",
      "Trial: 21, Epoch: 19, Train Loss: 57.8184, Val Loss: 0.1102\n",
      "Trial: 12, Epoch: 40, Train Loss: 34.4386, Val Loss: 0.1279\n",
      "Trial: 36, Epoch: 6, Train Loss: 58.5160, Val Loss: 0.1092\n",
      "Trial: 30, Epoch: 11, Train Loss: 57.7538, Val Loss: 0.1122\n",
      "Trial: 20, Epoch: 20, Train Loss: 59.8890, Val Loss: 0.1399\n",
      "Trial: 29, Epoch: 11, Train Loss: 51.5410, Val Loss: 0.1154\n",
      "Trial: 22, Epoch: 26, Train Loss: 25.2445, Val Loss: 0.1289\n",
      "Trial: 41, Epoch: 2, Train Loss: 53.9565, Val Loss: 0.1182\n",
      "Trial: 39, Epoch: 3, Train Loss: 53.1797, Val Loss: 0.1131\n",
      "Trial: 31, Epoch: 11, Train Loss: 58.1348, Val Loss: 0.1102\n",
      "Trial: 38, Epoch: 4, Train Loss: 54.4372, Val Loss: 0.1207\n",
      "Trial: 40, Epoch: 3, Train Loss: 53.8877, Val Loss: 0.1152\n",
      "Trial: 33, Epoch: 8, Train Loss: 51.7562, Val Loss: 0.1222\n",
      "Trial: 37, Epoch: 6, Train Loss: 59.2951, Val Loss: 0.1101\n",
      "Trial: 34, Epoch: 8, Train Loss: 51.1735, Val Loss: 0.1286\n",
      "Trial: 35, Epoch: 7, Train Loss: 51.6176, Val Loss: 0.1148\n",
      "Trial: 12, Epoch: 41, Train Loss: 34.3221, Val Loss: 0.1280\n",
      "Trial: 21, Epoch: 20, Train Loss: 57.6340, Val Loss: 0.1130\n",
      "Trial: 22, Epoch: 27, Train Loss: 25.2993, Val Loss: 0.1203\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:42:45,615] Trial 22 finished with value: 0.12031829270223776 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0010315756916705722, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 42] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0021827101263327555, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 36, Epoch: 7, Train Loss: 57.9805, Val Loss: 0.1141\n",
      "Trial: 30, Epoch: 12, Train Loss: 57.8551, Val Loss: 0.1175\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:43:12,450] Trial 30 finished with value: 0.10544252874595779 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.004554554242289562, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 43] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0021678865632156928, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 20, Epoch: 21, Train Loss: 59.9482, Val Loss: 0.1504\n",
      "Trial: 29, Epoch: 12, Train Loss: 51.1279, Val Loss: 0.1275\n",
      "Trial: 12, Epoch: 42, Train Loss: 34.0481, Val Loss: 0.1257\n",
      "Trial: 31, Epoch: 12, Train Loss: 58.0377, Val Loss: 0.1108\n",
      "Trial: 41, Epoch: 3, Train Loss: 53.7975, Val Loss: 0.1124\n",
      "Trial: 39, Epoch: 4, Train Loss: 53.0844, Val Loss: 0.1123\n",
      "Trial: 38, Epoch: 5, Train Loss: 54.4867, Val Loss: 0.1167\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:45:28,062] Trial 38 finished with value: 0.11546421802344442 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0025217625071258447, 'batch_size': 8, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 44] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0003837628780035764, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 40, Epoch: 4, Train Loss: 53.7309, Val Loss: 0.1077\n",
      "Trial: 37, Epoch: 7, Train Loss: 59.3094, Val Loss: 0.1090\n",
      "Trial: 33, Epoch: 9, Train Loss: 51.2866, Val Loss: 0.1147\n",
      "Trial: 34, Epoch: 9, Train Loss: 51.0104, Val Loss: 0.1182\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:46:07,310] Trial 34 finished with value: 0.11150425672531128 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.002706688622194781, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 45] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0014646349252214487, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 35, Epoch: 8, Train Loss: 51.3720, Val Loss: 0.1275\n",
      "Trial: 21, Epoch: 21, Train Loss: 57.2676, Val Loss: 0.1136\n",
      "Trial: 12, Epoch: 43, Train Loss: 33.8040, Val Loss: 0.1244\n",
      "Trial: 36, Epoch: 8, Train Loss: 57.5727, Val Loss: 0.1090\n",
      "Trial: 42, Epoch: 0, Train Loss: 68.6333, Val Loss: 0.1314\n",
      "Trial: 20, Epoch: 22, Train Loss: 59.8212, Val Loss: 0.1380\n",
      "Trial: 43, Epoch: 0, Train Loss: 73.5509, Val Loss: 0.1222\n",
      "Trial: 29, Epoch: 13, Train Loss: 51.0205, Val Loss: 0.1239\n",
      "Trial: 31, Epoch: 13, Train Loss: 58.0664, Val Loss: 0.1100\n",
      "Trial: 39, Epoch: 5, Train Loss: 52.9518, Val Loss: 0.1141\n",
      "Trial: 41, Epoch: 4, Train Loss: 53.2950, Val Loss: 0.1171\n",
      "Trial: 40, Epoch: 5, Train Loss: 53.6669, Val Loss: 0.1067\n",
      "Trial: 37, Epoch: 8, Train Loss: 58.9315, Val Loss: 0.1092\n",
      "Trial: 44, Epoch: 0, Train Loss: 102.4823, Val Loss: 0.2853\n",
      "Trial: 33, Epoch: 10, Train Loss: 51.0401, Val Loss: 0.1213\n",
      "Trial: 35, Epoch: 9, Train Loss: 51.2647, Val Loss: 0.1209\n",
      "Trial: 45, Epoch: 0, Train Loss: 80.0553, Val Loss: 0.1264\n",
      "Trial: 12, Epoch: 44, Train Loss: 33.6703, Val Loss: 0.1243\n",
      "Trial: 21, Epoch: 22, Train Loss: 57.4420, Val Loss: 0.1172\n",
      "Trial: 36, Epoch: 9, Train Loss: 57.8594, Val Loss: 0.1162\n",
      "Trial: 42, Epoch: 1, Train Loss: 55.2025, Val Loss: 0.1224\n",
      "Trial: 20, Epoch: 23, Train Loss: 59.5886, Val Loss: 0.1319\n",
      "Trial: 43, Epoch: 1, Train Loss: 60.7296, Val Loss: 0.1120\n",
      "Trial: 31, Epoch: 14, Train Loss: 58.1457, Val Loss: 0.1149\n",
      "Early stopping triggered.\n",
      "Trial: 29, Epoch: 14, Train Loss: 50.9138, Val Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 03:55:00,323] Trial 31 finished with value: 0.1072902111571376 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.006018202462937895, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 46] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.00040455623225381116, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 12, Epoch: 45, Train Loss: 33.4253, Val Loss: 0.1236\n",
      "Trial: 39, Epoch: 6, Train Loss: 52.9645, Val Loss: 0.1156\n",
      "Trial: 41, Epoch: 5, Train Loss: 52.7915, Val Loss: 0.1111\n",
      "Trial: 40, Epoch: 6, Train Loss: 53.2089, Val Loss: 0.1093\n",
      "Trial: 37, Epoch: 9, Train Loss: 58.8395, Val Loss: 0.1066\n",
      "Trial: 44, Epoch: 1, Train Loss: 63.1197, Val Loss: 0.1931\n",
      "Trial: 45, Epoch: 1, Train Loss: 60.2249, Val Loss: 0.1188\n",
      "Trial: 35, Epoch: 10, Train Loss: 51.0500, Val Loss: 0.1184\n",
      "Trial: 33, Epoch: 11, Train Loss: 51.0563, Val Loss: 0.1221\n",
      "Trial: 21, Epoch: 23, Train Loss: 57.7771, Val Loss: 0.1104\n",
      "Trial: 36, Epoch: 10, Train Loss: 58.0937, Val Loss: 0.1118\n",
      "Trial: 12, Epoch: 46, Train Loss: 33.0824, Val Loss: 0.1217\n",
      "Trial: 42, Epoch: 2, Train Loss: 54.1862, Val Loss: 0.1152\n",
      "Trial: 20, Epoch: 24, Train Loss: 59.5321, Val Loss: 0.1367\n",
      "Trial: 43, Epoch: 2, Train Loss: 59.7814, Val Loss: 0.1137\n",
      "Trial: 29, Epoch: 15, Train Loss: 50.5233, Val Loss: 0.1237\n",
      "Trial: 46, Epoch: 0, Train Loss: 114.0668, Val Loss: 0.3207\n",
      "Trial: 39, Epoch: 7, Train Loss: 52.6458, Val Loss: 0.1150\n",
      "Trial: 41, Epoch: 6, Train Loss: 52.4766, Val Loss: 0.1121\n",
      "Trial: 40, Epoch: 7, Train Loss: 52.1492, Val Loss: 0.1119\n",
      "Trial: 37, Epoch: 10, Train Loss: 58.7251, Val Loss: 0.1080\n",
      "Trial: 44, Epoch: 2, Train Loss: 61.3768, Val Loss: 0.1688\n",
      "Trial: 45, Epoch: 2, Train Loss: 60.0341, Val Loss: 0.1219\n",
      "Trial: 35, Epoch: 11, Train Loss: 51.2010, Val Loss: 0.1112\n",
      "Trial: 12, Epoch: 47, Train Loss: 32.7672, Val Loss: 0.1217\n",
      "Trial: 33, Epoch: 12, Train Loss: 51.2147, Val Loss: 0.1392\n",
      "Trial: 21, Epoch: 24, Train Loss: 57.5381, Val Loss: 0.1107\n",
      "Trial: 36, Epoch: 11, Train Loss: 57.8203, Val Loss: 0.1192\n",
      "Trial: 42, Epoch: 3, Train Loss: 53.9488, Val Loss: 0.1119\n",
      "Trial: 20, Epoch: 25, Train Loss: 59.6192, Val Loss: 0.1283\n",
      "Trial: 43, Epoch: 3, Train Loss: 59.5426, Val Loss: 0.1140\n",
      "Trial: 46, Epoch: 1, Train Loss: 64.4259, Val Loss: 0.2429\n",
      "Trial: 12, Epoch: 48, Train Loss: 32.5544, Val Loss: 0.1200\n",
      "Trial: 29, Epoch: 16, Train Loss: 50.4644, Val Loss: 0.1202\n",
      "Trial: 39, Epoch: 8, Train Loss: 52.2333, Val Loss: 0.1164\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:05:54,373] Trial 39 finished with value: 0.11227874626882937 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.002415233276625643, 'batch_size': 8, 'patience': 4}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 47] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0015816863404200055, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 41, Epoch: 7, Train Loss: 51.8011, Val Loss: 0.1153\n",
      "Trial: 37, Epoch: 11, Train Loss: 58.8405, Val Loss: 0.1086\n",
      "Trial: 40, Epoch: 8, Train Loss: 51.4462, Val Loss: 0.1106\n",
      "Trial: 45, Epoch: 3, Train Loss: 59.4105, Val Loss: 0.1179\n",
      "Trial: 44, Epoch: 3, Train Loss: 60.1043, Val Loss: 0.1582\n",
      "Trial: 35, Epoch: 12, Train Loss: 51.1148, Val Loss: 0.1123\n",
      "Trial: 21, Epoch: 25, Train Loss: 57.4954, Val Loss: 0.1147\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:07:38,179] Trial 21 finished with value: 0.11000484869885846 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0008487884652373777, 'batch_size': 8, 'patience': 7}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 48] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.00028702002317463455, 'batch_size': 8, 'patience': 10}\n",
      "Trial: 33, Epoch: 13, Train Loss: 50.9104, Val Loss: 0.1208\n",
      "Trial: 36, Epoch: 12, Train Loss: 57.6125, Val Loss: 0.1156\n",
      "Trial: 12, Epoch: 49, Train Loss: 32.5685, Val Loss: 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:09:20,316] Trial 12 finished with value: 0.1190275785823663 and parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 1.8521640242697503e-05, 'batch_size': 16, 'patience': 5}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 49] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0013678685333310158, 'batch_size': 8, 'patience': 10}\n",
      "Trial: 20, Epoch: 26, Train Loss: 59.3923, Val Loss: 0.1345\n",
      "Trial: 42, Epoch: 4, Train Loss: 53.4322, Val Loss: 0.1138\n",
      "Trial: 43, Epoch: 4, Train Loss: 59.5979, Val Loss: 0.1146\n",
      "Trial: 46, Epoch: 2, Train Loss: 61.6268, Val Loss: 0.1843\n",
      "Trial: 29, Epoch: 17, Train Loss: 50.3711, Val Loss: 0.1392\n",
      "Trial: 41, Epoch: 8, Train Loss: 51.0439, Val Loss: 0.1176\n",
      "Trial: 47, Epoch: 0, Train Loss: 70.0264, Val Loss: 0.1342\n",
      "Trial: 45, Epoch: 4, Train Loss: 59.0909, Val Loss: 0.1114\n",
      "Trial: 37, Epoch: 12, Train Loss: 58.5076, Val Loss: 0.1123\n",
      "Trial: 40, Epoch: 9, Train Loss: 50.9004, Val Loss: 0.1161\n",
      "Trial: 44, Epoch: 4, Train Loss: 60.1949, Val Loss: 0.1364\n",
      "Trial: 35, Epoch: 13, Train Loss: 50.9311, Val Loss: 0.1236\n",
      "Trial: 33, Epoch: 14, Train Loss: 50.9404, Val Loss: 0.1592\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:13:06,991] Trial 33 finished with value: 0.10624656366074786 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.004559883976310757, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 50] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.00038105620436826163, 'batch_size': 8, 'patience': 10}\n",
      "Trial: 48, Epoch: 0, Train Loss: 127.4514, Val Loss: 0.1889\n",
      "Trial: 36, Epoch: 13, Train Loss: 57.5943, Val Loss: 0.1214\n",
      "Trial: 20, Epoch: 27, Train Loss: 59.5752, Val Loss: 0.1404\n",
      "Trial: 42, Epoch: 5, Train Loss: 53.4094, Val Loss: 0.1083\n",
      "Trial: 49, Epoch: 0, Train Loss: 77.7281, Val Loss: 0.1969\n",
      "Trial: 43, Epoch: 5, Train Loss: 59.1753, Val Loss: 0.1181\n",
      "Trial: 46, Epoch: 3, Train Loss: 60.2278, Val Loss: 0.1896\n",
      "Trial: 29, Epoch: 18, Train Loss: 50.5372, Val Loss: 0.1252\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:16:35,132] Trial 29 finished with value: 0.10864376990484591 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.004497036336225431, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 51] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0017007838456663952, 'batch_size': 8, 'patience': 10}\n",
      "Trial: 47, Epoch: 1, Train Loss: 60.4144, Val Loss: 0.1207\n",
      "Trial: 41, Epoch: 9, Train Loss: 50.7384, Val Loss: 0.1218\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:16:41,590] Trial 41 finished with value: 0.11114350687555906 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0016834011116775294, 'batch_size': 8, 'patience': 4}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 52] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.00047697764787181626, 'batch_size': 8, 'patience': 10}\n",
      "Trial: 45, Epoch: 5, Train Loss: 58.6976, Val Loss: 0.1122\n",
      "Trial: 37, Epoch: 13, Train Loss: 58.4045, Val Loss: 0.1146\n",
      "Trial: 40, Epoch: 10, Train Loss: 50.8243, Val Loss: 0.1100\n",
      "Trial: 44, Epoch: 5, Train Loss: 59.3718, Val Loss: 0.1397\n",
      "Trial: 35, Epoch: 14, Train Loss: 50.6706, Val Loss: 0.1106\n",
      "Trial: 48, Epoch: 1, Train Loss: 67.5010, Val Loss: 0.2033\n",
      "Trial: 50, Epoch: 0, Train Loss: 81.6687, Val Loss: 0.1742\n",
      "Trial: 36, Epoch: 14, Train Loss: 57.7054, Val Loss: 0.1138\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:19:05,626] Trial 36 finished with value: 0.10683679899999074 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0016071838216800071, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 53] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0004449717982515018, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 20, Epoch: 28, Train Loss: 59.3632, Val Loss: 0.1284\n",
      "Trial: 42, Epoch: 6, Train Loss: 53.1674, Val Loss: 0.1106\n",
      "Trial: 49, Epoch: 1, Train Loss: 60.7904, Val Loss: 0.1292\n",
      "Trial: 43, Epoch: 6, Train Loss: 59.1459, Val Loss: 0.1110\n",
      "Trial: 46, Epoch: 4, Train Loss: 59.3255, Val Loss: 0.1835\n",
      "Trial: 47, Epoch: 2, Train Loss: 59.7549, Val Loss: 0.1121\n",
      "Trial: 45, Epoch: 6, Train Loss: 59.0607, Val Loss: 0.1123\n",
      "Trial: 51, Epoch: 0, Train Loss: 77.4093, Val Loss: 0.1249\n",
      "Trial: 37, Epoch: 14, Train Loss: 57.9097, Val Loss: 0.1183\n",
      "Trial: 53, Epoch: 0, Train Loss: 25.9151, Val Loss: 0.2433\n",
      "Trial: 52, Epoch: 0, Train Loss: 81.3107, Val Loss: 0.1871\n",
      "Trial: 44, Epoch: 6, Train Loss: 59.1817, Val Loss: 0.1392\n",
      "Trial: 40, Epoch: 11, Train Loss: 50.7426, Val Loss: 0.1098\n",
      "Trial: 35, Epoch: 15, Train Loss: 50.5182, Val Loss: 0.1092\n",
      "Trial: 48, Epoch: 2, Train Loss: 63.6595, Val Loss: 0.1891\n",
      "Trial: 50, Epoch: 1, Train Loss: 62.8689, Val Loss: 0.1783\n",
      "Trial: 49, Epoch: 2, Train Loss: 60.0531, Val Loss: 0.1165\n",
      "Trial: 20, Epoch: 29, Train Loss: 59.4798, Val Loss: 0.1298\n",
      "Trial: 42, Epoch: 7, Train Loss: 52.8730, Val Loss: 0.1134\n",
      "Trial: 53, Epoch: 1, Train Loss: 16.3046, Val Loss: 0.2222\n",
      "Trial: 43, Epoch: 7, Train Loss: 58.9311, Val Loss: 0.1166\n",
      "Trial: 46, Epoch: 5, Train Loss: 58.8927, Val Loss: 0.1769\n",
      "Trial: 47, Epoch: 3, Train Loss: 59.5800, Val Loss: 0.1167\n",
      "Trial: 45, Epoch: 7, Train Loss: 58.6765, Val Loss: 0.1091\n",
      "Trial: 37, Epoch: 15, Train Loss: 57.5886, Val Loss: 0.1190\n",
      "Trial: 51, Epoch: 1, Train Loss: 62.3588, Val Loss: 0.1100\n",
      "Trial: 52, Epoch: 1, Train Loss: 62.2604, Val Loss: 0.1416\n",
      "Trial: 44, Epoch: 7, Train Loss: 58.6962, Val Loss: 0.1282\n",
      "Trial: 40, Epoch: 12, Train Loss: 50.7565, Val Loss: 0.1120\n",
      "Trial: 53, Epoch: 2, Train Loss: 15.4747, Val Loss: 0.1801\n",
      "Trial: 35, Epoch: 16, Train Loss: 50.4490, Val Loss: 0.1091\n",
      "Trial: 48, Epoch: 3, Train Loss: 62.0188, Val Loss: 0.1751\n",
      "Trial: 50, Epoch: 2, Train Loss: 61.1846, Val Loss: 0.1407\n",
      "Trial: 49, Epoch: 3, Train Loss: 59.4057, Val Loss: 0.1130\n",
      "Trial: 20, Epoch: 30, Train Loss: 59.3811, Val Loss: 0.1367\n",
      "Trial: 42, Epoch: 8, Train Loss: 52.1468, Val Loss: 0.1198\n",
      "Trial: 53, Epoch: 3, Train Loss: 15.1111, Val Loss: 0.1797\n",
      "Trial: 43, Epoch: 8, Train Loss: 58.4640, Val Loss: 0.1218\n",
      "Trial: 46, Epoch: 6, Train Loss: 58.3769, Val Loss: 0.1523\n",
      "Trial: 47, Epoch: 4, Train Loss: 59.5098, Val Loss: 0.1106\n",
      "Trial: 45, Epoch: 8, Train Loss: 58.5569, Val Loss: 0.1169\n",
      "Trial: 37, Epoch: 16, Train Loss: 57.7995, Val Loss: 0.1227\n",
      "Trial: 51, Epoch: 2, Train Loss: 61.6880, Val Loss: 0.1115\n",
      "Trial: 44, Epoch: 8, Train Loss: 58.6253, Val Loss: 0.1260\n",
      "Trial: 52, Epoch: 2, Train Loss: 60.1743, Val Loss: 0.1192\n",
      "Trial: 40, Epoch: 13, Train Loss: 50.5336, Val Loss: 0.1121\n",
      "Trial: 53, Epoch: 4, Train Loss: 14.6581, Val Loss: 0.1912\n",
      "Trial: 35, Epoch: 17, Train Loss: 50.5522, Val Loss: 0.1146\n",
      "Trial: 48, Epoch: 4, Train Loss: 61.3411, Val Loss: 0.1590\n",
      "Trial: 50, Epoch: 3, Train Loss: 60.3958, Val Loss: 0.1462\n",
      "Trial: 49, Epoch: 4, Train Loss: 59.2274, Val Loss: 0.1134\n",
      "Trial: 20, Epoch: 31, Train Loss: 59.3616, Val Loss: 0.1302\n",
      "Trial: 42, Epoch: 9, Train Loss: 51.2758, Val Loss: 0.1157\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:35:44,470] Trial 42 finished with value: 0.10828962543306231 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0021827101263327555, 'batch_size': 8, 'patience': 4}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 54] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.00043386717162467573, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 43, Epoch: 9, Train Loss: 58.2252, Val Loss: 0.1163\n",
      "Trial: 46, Epoch: 7, Train Loss: 58.2716, Val Loss: 0.1631\n",
      "Trial: 53, Epoch: 5, Train Loss: 14.3124, Val Loss: 0.2785\n",
      "Trial: 47, Epoch: 5, Train Loss: 59.4453, Val Loss: 0.1088\n",
      "Trial: 45, Epoch: 9, Train Loss: 57.9253, Val Loss: 0.1205\n",
      "Trial: 37, Epoch: 17, Train Loss: 57.8908, Val Loss: 0.1150\n",
      "Trial: 51, Epoch: 3, Train Loss: 61.1921, Val Loss: 0.1307\n",
      "Trial: 44, Epoch: 9, Train Loss: 58.3053, Val Loss: 0.1294\n",
      "Trial: 52, Epoch: 3, Train Loss: 59.9004, Val Loss: 0.1164\n",
      "Trial: 40, Epoch: 14, Train Loss: 50.4505, Val Loss: 0.1175\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:38:46,570] Trial 40 finished with value: 0.10674294572667915 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0017729050154395765, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 55] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0004293691353813541, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 54, Epoch: 0, Train Loss: 24.7347, Val Loss: 0.2646\n",
      "Trial: 35, Epoch: 18, Train Loss: 50.5302, Val Loss: 0.1121\n",
      "Trial: 53, Epoch: 6, Train Loss: 14.0685, Val Loss: 0.2119\n",
      "Trial: 48, Epoch: 5, Train Loss: 60.4793, Val Loss: 0.1555\n",
      "Trial: 50, Epoch: 4, Train Loss: 59.7270, Val Loss: 0.1547\n",
      "Trial: 49, Epoch: 5, Train Loss: 58.9409, Val Loss: 0.1252\n",
      "Trial: 20, Epoch: 32, Train Loss: 59.4206, Val Loss: 0.1285\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:41:05,149] Trial 20 finished with value: 0.12828996633531667 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 2.2101815975750862e-05, 'batch_size': 8, 'patience': 7}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 56] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.0004480744250687994, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 46, Epoch: 8, Train Loss: 58.4481, Val Loss: 0.1447\n",
      "Trial: 43, Epoch: 10, Train Loss: 58.0684, Val Loss: 0.1153\n",
      "Trial: 54, Epoch: 1, Train Loss: 16.5139, Val Loss: 0.3063\n",
      "Trial: 55, Epoch: 0, Train Loss: 28.5248, Val Loss: 0.2636\n",
      "Trial: 47, Epoch: 6, Train Loss: 58.9854, Val Loss: 0.1105\n",
      "Trial: 45, Epoch: 10, Train Loss: 57.9103, Val Loss: 0.1145\n",
      "Trial: 53, Epoch: 7, Train Loss: 13.9870, Val Loss: 0.2503\n",
      "Trial: 37, Epoch: 18, Train Loss: 57.6590, Val Loss: 0.1114\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 04:43:32,918] Trial 37 finished with value: 0.10663603934921137 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0024019008442483954, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 57] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008897684932241393, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 44, Epoch: 10, Train Loss: 58.2236, Val Loss: 0.1230\n",
      "Trial: 51, Epoch: 4, Train Loss: 60.7998, Val Loss: 0.1077\n",
      "Trial: 52, Epoch: 4, Train Loss: 59.5644, Val Loss: 0.1254\n",
      "Trial: 56, Epoch: 0, Train Loss: 31.3496, Val Loss: 0.2118\n",
      "Trial: 35, Epoch: 19, Train Loss: 50.5345, Val Loss: 0.1201\n",
      "Trial: 54, Epoch: 2, Train Loss: 15.4524, Val Loss: 0.2681\n",
      "Trial: 55, Epoch: 1, Train Loss: 16.7807, Val Loss: 0.1832\n",
      "Trial: 48, Epoch: 6, Train Loss: 60.0533, Val Loss: 0.1433\n",
      "Trial: 53, Epoch: 8, Train Loss: 13.9656, Val Loss: 0.2076\n",
      "Trial: 49, Epoch: 6, Train Loss: 59.1488, Val Loss: 0.1339\n",
      "Trial: 50, Epoch: 5, Train Loss: 58.9406, Val Loss: 0.1762\n",
      "Trial: 57, Epoch: 0, Train Loss: 61.7296, Val Loss: 0.1416\n",
      "Trial: 46, Epoch: 9, Train Loss: 58.2382, Val Loss: 0.1468\n",
      "Trial: 43, Epoch: 11, Train Loss: 58.0298, Val Loss: 0.1154\n",
      "Trial: 56, Epoch: 1, Train Loss: 19.4484, Val Loss: 0.1395\n",
      "Trial: 45, Epoch: 11, Train Loss: 58.0627, Val Loss: 0.1104\n",
      "Trial: 54, Epoch: 3, Train Loss: 15.1075, Val Loss: 0.2302\n",
      "Trial: 47, Epoch: 7, Train Loss: 59.1544, Val Loss: 0.1140\n",
      "Trial: 55, Epoch: 2, Train Loss: 15.9766, Val Loss: 0.1678\n",
      "Trial: 53, Epoch: 9, Train Loss: 13.7781, Val Loss: 0.2109\n",
      "Trial: 44, Epoch: 11, Train Loss: 58.4109, Val Loss: 0.1225\n",
      "Trial: 51, Epoch: 5, Train Loss: 61.1602, Val Loss: 0.1143\n",
      "Trial: 52, Epoch: 5, Train Loss: 59.1208, Val Loss: 0.1145\n",
      "Trial: 57, Epoch: 1, Train Loss: 16.0981, Val Loss: 0.1385\n",
      "Trial: 56, Epoch: 2, Train Loss: 16.2890, Val Loss: 0.1694\n",
      "Trial: 35, Epoch: 20, Train Loss: 50.4801, Val Loss: 0.1074\n",
      "Trial: 48, Epoch: 7, Train Loss: 59.8711, Val Loss: 0.1473\n",
      "Trial: 54, Epoch: 4, Train Loss: 14.8446, Val Loss: 0.2254\n",
      "Trial: 55, Epoch: 3, Train Loss: 15.5727, Val Loss: 0.1558\n",
      "Trial: 49, Epoch: 7, Train Loss: 58.2681, Val Loss: 0.1145\n",
      "Trial: 53, Epoch: 10, Train Loss: 13.8099, Val Loss: 0.2172\n",
      "Trial: 50, Epoch: 6, Train Loss: 58.7671, Val Loss: 0.1454\n",
      "Trial: 46, Epoch: 10, Train Loss: 57.8989, Val Loss: 0.1485\n",
      "Trial: 43, Epoch: 12, Train Loss: 57.8082, Val Loss: 0.1132\n",
      "Trial: 57, Epoch: 2, Train Loss: 15.7897, Val Loss: 0.1345\n",
      "Trial: 56, Epoch: 3, Train Loss: 15.0360, Val Loss: 0.1457\n",
      "Trial: 45, Epoch: 12, Train Loss: 58.2193, Val Loss: 0.1124\n",
      "Trial: 47, Epoch: 8, Train Loss: 59.1720, Val Loss: 0.1104\n",
      "Trial: 54, Epoch: 5, Train Loss: 14.5913, Val Loss: 0.2359\n",
      "Trial: 55, Epoch: 4, Train Loss: 15.2231, Val Loss: 0.1522\n",
      "Trial: 53, Epoch: 11, Train Loss: 13.7504, Val Loss: 0.1867\n",
      "Trial: 44, Epoch: 12, Train Loss: 57.9263, Val Loss: 0.1218\n",
      "Trial: 51, Epoch: 6, Train Loss: 60.3920, Val Loss: 0.1316\n",
      "Trial: 52, Epoch: 6, Train Loss: 59.0835, Val Loss: 0.1201\n",
      "Trial: 57, Epoch: 3, Train Loss: 15.7169, Val Loss: 0.1369\n",
      "Trial: 35, Epoch: 21, Train Loss: 50.2728, Val Loss: 0.1212\n",
      "Trial: 56, Epoch: 4, Train Loss: 14.5799, Val Loss: 0.1349\n",
      "Trial: 48, Epoch: 8, Train Loss: 58.9873, Val Loss: 0.1558\n",
      "Trial: 49, Epoch: 8, Train Loss: 58.3411, Val Loss: 0.1204\n",
      "Trial: 54, Epoch: 6, Train Loss: 14.2612, Val Loss: 0.2327\n",
      "Trial: 55, Epoch: 5, Train Loss: 15.1948, Val Loss: 0.1407\n",
      "Trial: 50, Epoch: 7, Train Loss: 58.2907, Val Loss: 0.1487\n",
      "Trial: 46, Epoch: 11, Train Loss: 57.8610, Val Loss: 0.1369\n",
      "Trial: 53, Epoch: 12, Train Loss: 13.7428, Val Loss: 0.1934\n",
      "Trial: 43, Epoch: 13, Train Loss: 57.9224, Val Loss: 0.1211\n",
      "Trial: 45, Epoch: 13, Train Loss: 57.6723, Val Loss: 0.1114\n",
      "Trial: 47, Epoch: 9, Train Loss: 59.2585, Val Loss: 0.1081\n",
      "Trial: 56, Epoch: 5, Train Loss: 14.4055, Val Loss: 0.1325\n",
      "Trial: 57, Epoch: 4, Train Loss: 15.4919, Val Loss: 0.1278\n",
      "Trial: 54, Epoch: 7, Train Loss: 14.0903, Val Loss: 0.2378\n",
      "Trial: 55, Epoch: 6, Train Loss: 15.0701, Val Loss: 0.1378\n",
      "Trial: 44, Epoch: 13, Train Loss: 58.1455, Val Loss: 0.1214\n",
      "Trial: 53, Epoch: 13, Train Loss: 13.7075, Val Loss: 0.1741\n",
      "Trial: 51, Epoch: 7, Train Loss: 60.0278, Val Loss: 0.1174\n",
      "Trial: 52, Epoch: 7, Train Loss: 58.5919, Val Loss: 0.1149\n",
      "Trial: 35, Epoch: 22, Train Loss: 50.4555, Val Loss: 0.1128\n",
      "Trial: 48, Epoch: 9, Train Loss: 59.0172, Val Loss: 0.1538\n",
      "Trial: 49, Epoch: 9, Train Loss: 57.8397, Val Loss: 0.1128\n",
      "Trial: 56, Epoch: 6, Train Loss: 14.2646, Val Loss: 0.1214\n",
      "Trial: 57, Epoch: 5, Train Loss: 15.2242, Val Loss: 0.1301\n",
      "Trial: 46, Epoch: 12, Train Loss: 57.6327, Val Loss: 0.1393\n",
      "Trial: 50, Epoch: 8, Train Loss: 58.3060, Val Loss: 0.1554\n",
      "Trial: 54, Epoch: 8, Train Loss: 14.0320, Val Loss: 0.2525\n",
      "Trial: 55, Epoch: 7, Train Loss: 14.9591, Val Loss: 0.1520\n",
      "Trial: 53, Epoch: 14, Train Loss: 13.5735, Val Loss: 0.1711\n",
      "Trial: 43, Epoch: 14, Train Loss: 57.7930, Val Loss: 0.1199\n",
      "Trial: 45, Epoch: 14, Train Loss: 57.5546, Val Loss: 0.1139\n",
      "Trial: 47, Epoch: 10, Train Loss: 58.6277, Val Loss: 0.1135\n",
      "Trial: 56, Epoch: 7, Train Loss: 14.1579, Val Loss: 0.1211\n",
      "Trial: 57, Epoch: 6, Train Loss: 15.0592, Val Loss: 0.1271\n",
      "Trial: 44, Epoch: 14, Train Loss: 57.9983, Val Loss: 0.1167\n",
      "Trial: 54, Epoch: 9, Train Loss: 13.8842, Val Loss: 0.2057\n",
      "Trial: 55, Epoch: 8, Train Loss: 14.9389, Val Loss: 0.1398\n",
      "Trial: 51, Epoch: 8, Train Loss: 59.7581, Val Loss: 0.1139\n",
      "Trial: 52, Epoch: 8, Train Loss: 59.0468, Val Loss: 0.1128\n",
      "Trial: 53, Epoch: 15, Train Loss: 13.5818, Val Loss: 0.1795\n",
      "Trial: 35, Epoch: 23, Train Loss: 50.3545, Val Loss: 0.1137\n",
      "Trial: 48, Epoch: 10, Train Loss: 58.8580, Val Loss: 0.1285\n",
      "Trial: 49, Epoch: 10, Train Loss: 57.8692, Val Loss: 0.1138\n",
      "Trial: 56, Epoch: 8, Train Loss: 13.9820, Val Loss: 0.1316\n",
      "Trial: 57, Epoch: 7, Train Loss: 14.9795, Val Loss: 0.1272\n",
      "Trial: 46, Epoch: 13, Train Loss: 57.5405, Val Loss: 0.1254\n",
      "Trial: 50, Epoch: 9, Train Loss: 58.3461, Val Loss: 0.1344\n",
      "Trial: 54, Epoch: 10, Train Loss: 13.8095, Val Loss: 0.2201\n",
      "Trial: 43, Epoch: 15, Train Loss: 57.5347, Val Loss: 0.1175\n",
      "Early stopping triggered.\n",
      "Trial: 45, Epoch: 15, Train Loss: 57.5798, Val Loss: 0.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:08:58,064] Trial 43 finished with value: 0.11102853890727549 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0021678865632156928, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 58] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008654030655989998, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 55, Epoch: 9, Train Loss: 14.7977, Val Loss: 0.1383\n",
      "Trial: 47, Epoch: 11, Train Loss: 58.9816, Val Loss: 0.1149\n",
      "Trial: 53, Epoch: 16, Train Loss: 13.5811, Val Loss: 0.1568\n",
      "Trial: 56, Epoch: 9, Train Loss: 13.9392, Val Loss: 0.1239\n",
      "Trial: 57, Epoch: 8, Train Loss: 14.9281, Val Loss: 0.1271\n",
      "Trial: 44, Epoch: 15, Train Loss: 57.6942, Val Loss: 0.1215\n",
      "Trial: 51, Epoch: 9, Train Loss: 59.4976, Val Loss: 0.1146\n",
      "Trial: 54, Epoch: 11, Train Loss: 13.7280, Val Loss: 0.1970\n",
      "Trial: 52, Epoch: 9, Train Loss: 58.6001, Val Loss: 0.1106\n",
      "Trial: 55, Epoch: 10, Train Loss: 14.6833, Val Loss: 0.1721\n",
      "Trial: 49, Epoch: 11, Train Loss: 57.9151, Val Loss: 0.1260\n",
      "Trial: 48, Epoch: 11, Train Loss: 58.7780, Val Loss: 0.1291\n",
      "Trial: 35, Epoch: 24, Train Loss: 50.3439, Val Loss: 0.1422\n",
      "Trial: 58, Epoch: 0, Train Loss: 71.1275, Val Loss: 0.1749\n",
      "Trial: 53, Epoch: 17, Train Loss: 13.5468, Val Loss: 0.1498\n",
      "Trial: 46, Epoch: 14, Train Loss: 57.6773, Val Loss: 0.1267\n",
      "Trial: 56, Epoch: 10, Train Loss: 13.9988, Val Loss: 0.1220\n",
      "Trial: 57, Epoch: 9, Train Loss: 14.9479, Val Loss: 0.1273\n",
      "Trial: 50, Epoch: 10, Train Loss: 58.2298, Val Loss: 0.1221\n",
      "Trial: 45, Epoch: 16, Train Loss: 57.8921, Val Loss: 0.1137\n",
      "Trial: 47, Epoch: 12, Train Loss: 58.2392, Val Loss: 0.1229\n",
      "Trial: 54, Epoch: 12, Train Loss: 13.6858, Val Loss: 0.1963\n",
      "Trial: 55, Epoch: 11, Train Loss: 14.6680, Val Loss: 0.1766\n",
      "Trial: 53, Epoch: 18, Train Loss: 13.5279, Val Loss: 0.1599\n",
      "Trial: 58, Epoch: 1, Train Loss: 16.4604, Val Loss: 0.1273\n",
      "Trial: 56, Epoch: 11, Train Loss: 14.0147, Val Loss: 0.1219\n",
      "Trial: 44, Epoch: 16, Train Loss: 57.9358, Val Loss: 0.1168\n",
      "Trial: 57, Epoch: 10, Train Loss: 14.9306, Val Loss: 0.1282\n",
      "Trial: 51, Epoch: 10, Train Loss: 58.9852, Val Loss: 0.1339\n",
      "Trial: 52, Epoch: 10, Train Loss: 58.5832, Val Loss: 0.1298\n",
      "Trial: 49, Epoch: 12, Train Loss: 57.5915, Val Loss: 0.1197\n",
      "Trial: 54, Epoch: 13, Train Loss: 13.6906, Val Loss: 0.1734\n",
      "Trial: 48, Epoch: 12, Train Loss: 58.7429, Val Loss: 0.1253\n",
      "Trial: 35, Epoch: 25, Train Loss: 50.3630, Val Loss: 0.1119\n",
      "Trial: 55, Epoch: 12, Train Loss: 14.6410, Val Loss: 0.1648\n",
      "Trial: 53, Epoch: 19, Train Loss: 13.5557, Val Loss: 0.1515\n",
      "Trial: 58, Epoch: 2, Train Loss: 15.1232, Val Loss: 0.1263\n",
      "Trial: 46, Epoch: 15, Train Loss: 57.6721, Val Loss: 0.1239\n",
      "Trial: 56, Epoch: 12, Train Loss: 13.8810, Val Loss: 0.1158\n",
      "Trial: 50, Epoch: 11, Train Loss: 58.0343, Val Loss: 0.1282\n",
      "Trial: 45, Epoch: 17, Train Loss: 57.8131, Val Loss: 0.1102\n",
      "Trial: 57, Epoch: 11, Train Loss: 14.9400, Val Loss: 0.1269\n",
      "Trial: 47, Epoch: 13, Train Loss: 57.8572, Val Loss: 0.1139\n",
      "Trial: 54, Epoch: 14, Train Loss: 13.6124, Val Loss: 0.1727\n",
      "Trial: 55, Epoch: 13, Train Loss: 14.5739, Val Loss: 0.1470\n",
      "Trial: 53, Epoch: 20, Train Loss: 13.4922, Val Loss: 0.1508\n",
      "Trial: 58, Epoch: 3, Train Loss: 15.0725, Val Loss: 0.1288\n",
      "Trial: 44, Epoch: 17, Train Loss: 57.6526, Val Loss: 0.1169\n",
      "Trial: 56, Epoch: 13, Train Loss: 13.7874, Val Loss: 0.1375\n",
      "Trial: 51, Epoch: 11, Train Loss: 59.0524, Val Loss: 0.1325\n",
      "Trial: 49, Epoch: 13, Train Loss: 57.6662, Val Loss: 0.1178\n",
      "Trial: 57, Epoch: 12, Train Loss: 14.9133, Val Loss: 0.1273\n",
      "Trial: 52, Epoch: 11, Train Loss: 58.5462, Val Loss: 0.1568\n",
      "Trial: 48, Epoch: 13, Train Loss: 58.3300, Val Loss: 0.1237\n",
      "Trial: 35, Epoch: 26, Train Loss: 50.3717, Val Loss: 0.1189\n",
      "Trial: 54, Epoch: 15, Train Loss: 13.5931, Val Loss: 0.1656\n",
      "Trial: 46, Epoch: 16, Train Loss: 57.5171, Val Loss: 0.1203\n",
      "Trial: 55, Epoch: 14, Train Loss: 14.5627, Val Loss: 0.1521\n",
      "Trial: 53, Epoch: 21, Train Loss: 13.5368, Val Loss: 0.1331\n",
      "Trial: 58, Epoch: 4, Train Loss: 15.0150, Val Loss: 0.1266\n",
      "Trial: 45, Epoch: 18, Train Loss: 57.5740, Val Loss: 0.1101\n",
      "Trial: 50, Epoch: 12, Train Loss: 58.2748, Val Loss: 0.1211\n",
      "Trial: 56, Epoch: 14, Train Loss: 13.8105, Val Loss: 0.1275\n",
      "Trial: 47, Epoch: 14, Train Loss: 57.7726, Val Loss: 0.1220\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:25:23,886] Trial 47 finished with value: 0.10811802250247042 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0015816863404200055, 'batch_size': 8, 'patience': 5}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 59] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0004617688575311478, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 57, Epoch: 13, Train Loss: 14.9465, Val Loss: 0.1272\n",
      "Trial: 54, Epoch: 16, Train Loss: 13.5923, Val Loss: 0.1616\n",
      "Trial: 55, Epoch: 15, Train Loss: 14.6077, Val Loss: 0.1458\n",
      "Trial: 44, Epoch: 18, Train Loss: 57.7520, Val Loss: 0.1195\n",
      "Trial: 53, Epoch: 22, Train Loss: 13.5540, Val Loss: 0.1279\n",
      "Trial: 58, Epoch: 5, Train Loss: 14.9964, Val Loss: 0.1271\n",
      "Trial: 56, Epoch: 15, Train Loss: 13.7267, Val Loss: 0.1299\n",
      "Trial: 49, Epoch: 14, Train Loss: 57.5234, Val Loss: 0.1171\n",
      "Trial: 51, Epoch: 12, Train Loss: 58.5823, Val Loss: 0.1186\n",
      "Trial: 52, Epoch: 12, Train Loss: 57.7464, Val Loss: 0.1287\n",
      "Trial: 48, Epoch: 14, Train Loss: 58.1759, Val Loss: 0.1239\n",
      "Trial: 59, Epoch: 0, Train Loss: 28.2823, Val Loss: 0.3243\n",
      "Trial: 57, Epoch: 14, Train Loss: 14.9194, Val Loss: 0.1270\n",
      "Trial: 35, Epoch: 27, Train Loss: 50.1559, Val Loss: 0.1112\n",
      "Trial: 46, Epoch: 17, Train Loss: 57.6412, Val Loss: 0.1321\n",
      "Trial: 54, Epoch: 17, Train Loss: 13.5684, Val Loss: 0.1547\n",
      "Trial: 45, Epoch: 19, Train Loss: 57.5453, Val Loss: 0.1179\n",
      "Trial: 55, Epoch: 16, Train Loss: 14.6154, Val Loss: 0.1370\n",
      "Trial: 53, Epoch: 23, Train Loss: 13.5034, Val Loss: 0.1367\n",
      "Trial: 58, Epoch: 6, Train Loss: 14.9894, Val Loss: 0.1268\n",
      "Trial: 50, Epoch: 13, Train Loss: 58.3561, Val Loss: 0.1271\n",
      "Trial: 56, Epoch: 16, Train Loss: 13.7680, Val Loss: 0.1184\n",
      "Trial: 59, Epoch: 1, Train Loss: 16.5255, Val Loss: 0.3763\n",
      "Trial: 57, Epoch: 15, Train Loss: 14.9259, Val Loss: 0.1271\n",
      "Trial: 54, Epoch: 18, Train Loss: 13.5353, Val Loss: 0.1521\n",
      "Trial: 44, Epoch: 19, Train Loss: 57.6638, Val Loss: 0.1153\n",
      "Trial: 55, Epoch: 17, Train Loss: 14.4954, Val Loss: 0.1304\n",
      "Trial: 53, Epoch: 24, Train Loss: 13.4753, Val Loss: 0.1306\n",
      "Trial: 49, Epoch: 15, Train Loss: 57.6524, Val Loss: 0.1182\n",
      "Trial: 58, Epoch: 7, Train Loss: 15.0263, Val Loss: 0.1263\n",
      "Trial: 51, Epoch: 13, Train Loss: 58.8445, Val Loss: 0.1123\n",
      "Trial: 56, Epoch: 17, Train Loss: 13.7214, Val Loss: 0.1188\n",
      "Trial: 52, Epoch: 13, Train Loss: 57.9177, Val Loss: 0.1523\n",
      "Trial: 48, Epoch: 15, Train Loss: 58.1412, Val Loss: 0.1214\n",
      "Trial: 35, Epoch: 28, Train Loss: 50.2138, Val Loss: 0.1159\n",
      "Trial: 46, Epoch: 18, Train Loss: 57.5076, Val Loss: 0.1179\n",
      "Trial: 59, Epoch: 2, Train Loss: 15.7176, Val Loss: 0.3341\n",
      "Trial: 57, Epoch: 16, Train Loss: 14.9092, Val Loss: 0.1271\n",
      "Trial: 45, Epoch: 20, Train Loss: 57.3370, Val Loss: 0.1115\n",
      "Trial: 54, Epoch: 19, Train Loss: 13.5184, Val Loss: 0.1485\n",
      "Trial: 55, Epoch: 18, Train Loss: 14.5924, Val Loss: 0.1339\n",
      "Trial: 50, Epoch: 14, Train Loss: 57.8913, Val Loss: 0.1214\n",
      "Trial: 53, Epoch: 25, Train Loss: 13.5011, Val Loss: 0.1341\n",
      "Trial: 58, Epoch: 8, Train Loss: 14.9829, Val Loss: 0.1264\n",
      "Trial: 56, Epoch: 18, Train Loss: 13.7445, Val Loss: 0.1194\n",
      "Trial: 59, Epoch: 3, Train Loss: 15.0911, Val Loss: 0.2545\n",
      "Trial: 57, Epoch: 17, Train Loss: 14.9120, Val Loss: 0.1270\n",
      "Trial: 44, Epoch: 20, Train Loss: 57.7872, Val Loss: 0.1136\n",
      "Trial: 54, Epoch: 20, Train Loss: 13.4551, Val Loss: 0.1583\n",
      "Trial: 49, Epoch: 16, Train Loss: 57.3623, Val Loss: 0.1143\n",
      "Trial: 55, Epoch: 19, Train Loss: 14.5410, Val Loss: 0.1292\n",
      "Trial: 53, Epoch: 26, Train Loss: 13.4624, Val Loss: 0.1251\n",
      "Trial: 51, Epoch: 14, Train Loss: 58.3679, Val Loss: 0.1174\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:39:29,047] Trial 51 finished with value: 0.10769727099843386 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0017007838456663952, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 60] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.00033762800998407935, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 58, Epoch: 9, Train Loss: 14.9720, Val Loss: 0.1267\n",
      "Trial: 48, Epoch: 16, Train Loss: 58.0932, Val Loss: 0.1170\n",
      "Trial: 52, Epoch: 14, Train Loss: 57.6009, Val Loss: 0.1287\n",
      "Trial: 56, Epoch: 19, Train Loss: 13.6858, Val Loss: 0.1352\n",
      "Trial: 46, Epoch: 19, Train Loss: 57.4243, Val Loss: 0.1158\n",
      "Trial: 35, Epoch: 29, Train Loss: 50.2980, Val Loss: 0.1124\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:40:05,126] Trial 35 finished with value: 0.1073655946915891 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0026827482606724368, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 61] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.00037928669850137886, 'batch_size': 32, 'patience': 10}\n",
      "Trial: 45, Epoch: 21, Train Loss: 57.4426, Val Loss: 0.1130\n",
      "Trial: 59, Epoch: 4, Train Loss: 14.7438, Val Loss: 0.2932\n",
      "Trial: 57, Epoch: 18, Train Loss: 14.9216, Val Loss: 0.1281\n",
      "Trial: 54, Epoch: 21, Train Loss: 13.5041, Val Loss: 0.1416\n",
      "Trial: 50, Epoch: 15, Train Loss: 58.0325, Val Loss: 0.1256\n",
      "Trial: 53, Epoch: 27, Train Loss: 13.4294, Val Loss: 0.1280\n",
      "Trial: 55, Epoch: 20, Train Loss: 14.5491, Val Loss: 0.1333\n",
      "Trial: 58, Epoch: 10, Train Loss: 14.9584, Val Loss: 0.1270\n",
      "Trial: 56, Epoch: 20, Train Loss: 13.5789, Val Loss: 0.1288\n",
      "Trial: 60, Epoch: 0, Train Loss: 31.8107, Val Loss: 0.2450\n",
      "Trial: 61, Epoch: 0, Train Loss: 38.0582, Val Loss: 0.2259\n",
      "Trial: 44, Epoch: 21, Train Loss: 57.4071, Val Loss: 0.1177\n",
      "Trial: 59, Epoch: 5, Train Loss: 14.3958, Val Loss: 0.2842\n",
      "Trial: 57, Epoch: 19, Train Loss: 14.9767, Val Loss: 0.1273\n",
      "Trial: 49, Epoch: 17, Train Loss: 57.3838, Val Loss: 0.1126\n",
      "Trial: 54, Epoch: 22, Train Loss: 13.4513, Val Loss: 0.1347\n",
      "Trial: 48, Epoch: 17, Train Loss: 58.1623, Val Loss: 0.1188\n",
      "Trial: 53, Epoch: 28, Train Loss: 13.4667, Val Loss: 0.1213\n",
      "Trial: 46, Epoch: 20, Train Loss: 57.5145, Val Loss: 0.1195\n",
      "Trial: 52, Epoch: 15, Train Loss: 57.5124, Val Loss: 0.1289\n",
      "Trial: 55, Epoch: 21, Train Loss: 14.5065, Val Loss: 0.1307\n",
      "Trial: 58, Epoch: 11, Train Loss: 14.9685, Val Loss: 0.1264\n",
      "Trial: 56, Epoch: 21, Train Loss: 13.5346, Val Loss: 0.1373\n",
      "Trial: 60, Epoch: 1, Train Loss: 17.7986, Val Loss: 0.2096\n",
      "Trial: 45, Epoch: 22, Train Loss: 57.5615, Val Loss: 0.1109\n",
      "Trial: 61, Epoch: 1, Train Loss: 20.7648, Val Loss: 0.1958\n",
      "Trial: 59, Epoch: 6, Train Loss: 14.2241, Val Loss: 0.2798\n",
      "Trial: 57, Epoch: 20, Train Loss: 14.9376, Val Loss: 0.1269\n",
      "Trial: 50, Epoch: 16, Train Loss: 57.7936, Val Loss: 0.1196\n",
      "Trial: 54, Epoch: 23, Train Loss: 13.4931, Val Loss: 0.1355\n",
      "Trial: 53, Epoch: 29, Train Loss: 13.4028, Val Loss: 0.1251\n",
      "Trial: 55, Epoch: 22, Train Loss: 14.4736, Val Loss: 0.1314\n",
      "Trial: 58, Epoch: 12, Train Loss: 14.9572, Val Loss: 0.1270\n",
      "Early stopping triggered.\n",
      "Trial: 56, Epoch: 22, Train Loss: 13.3501, Val Loss: 0.1398\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:48:39,179] Trial 58 finished with value: 0.12630487183729808 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008654030655989998, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 62] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.00046112276114643105, 'batch_size': 32, 'patience': 8}\n",
      "Trial: 60, Epoch: 2, Train Loss: 15.8165, Val Loss: 0.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:48:41,412] Trial 56 finished with value: 0.11582887123028437 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.0004480744250687994, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 63] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0004821792251396847, 'batch_size': 8, 'patience': 8}\n",
      "Trial: 44, Epoch: 22, Train Loss: 57.3279, Val Loss: 0.1211\n",
      "Trial: 61, Epoch: 2, Train Loss: 16.9946, Val Loss: 0.3222\n",
      "Trial: 49, Epoch: 18, Train Loss: 57.4232, Val Loss: 0.1112\n",
      "Trial: 59, Epoch: 7, Train Loss: 14.0944, Val Loss: 0.2680\n",
      "Trial: 57, Epoch: 21, Train Loss: 14.9027, Val Loss: 0.1274\n",
      "Trial: 54, Epoch: 24, Train Loss: 13.4828, Val Loss: 0.1348\n",
      "Trial: 46, Epoch: 21, Train Loss: 57.2885, Val Loss: 0.1154\n",
      "Trial: 48, Epoch: 18, Train Loss: 58.2056, Val Loss: 0.1211\n",
      "Trial: 52, Epoch: 16, Train Loss: 57.9499, Val Loss: 0.1217\n",
      "Trial: 53, Epoch: 30, Train Loss: 13.4465, Val Loss: 0.1260\n",
      "Trial: 45, Epoch: 23, Train Loss: 57.5522, Val Loss: 0.1130\n",
      "Trial: 55, Epoch: 23, Train Loss: 14.5025, Val Loss: 0.1325\n",
      "Trial: 60, Epoch: 3, Train Loss: 15.3999, Val Loss: 0.1991\n",
      "Trial: 62, Epoch: 0, Train Loss: 29.1173, Val Loss: 0.1996\n",
      "Trial: 61, Epoch: 3, Train Loss: 15.7326, Val Loss: 0.3220\n",
      "Trial: 59, Epoch: 8, Train Loss: 14.0696, Val Loss: 0.2480\n",
      "Trial: 57, Epoch: 22, Train Loss: 14.8970, Val Loss: 0.1270\n",
      "Trial: 50, Epoch: 17, Train Loss: 57.6194, Val Loss: 0.1228\n",
      "Trial: 54, Epoch: 25, Train Loss: 13.4724, Val Loss: 0.1315\n",
      "Trial: 53, Epoch: 31, Train Loss: 13.4463, Val Loss: 0.1260\n",
      "Trial: 55, Epoch: 24, Train Loss: 14.4506, Val Loss: 0.1341\n",
      "Trial: 44, Epoch: 23, Train Loss: 57.5773, Val Loss: 0.1187\n",
      "Trial: 60, Epoch: 4, Train Loss: 15.0869, Val Loss: 0.1754\n",
      "Trial: 63, Epoch: 0, Train Loss: 76.4515, Val Loss: 0.3027\n",
      "Trial: 49, Epoch: 19, Train Loss: 57.2401, Val Loss: 0.1204\n",
      "Trial: 62, Epoch: 1, Train Loss: 16.9965, Val Loss: 0.1520\n",
      "Trial: 61, Epoch: 4, Train Loss: 15.2775, Val Loss: 0.2466\n",
      "Trial: 59, Epoch: 9, Train Loss: 13.9341, Val Loss: 0.2580\n",
      "Trial: 57, Epoch: 23, Train Loss: 14.9160, Val Loss: 0.1281\n",
      "Trial: 46, Epoch: 22, Train Loss: 57.3796, Val Loss: 0.1187\n",
      "Trial: 48, Epoch: 19, Train Loss: 58.1554, Val Loss: 0.1161\n",
      "Trial: 52, Epoch: 17, Train Loss: 57.3836, Val Loss: 0.1310\n",
      "Trial: 54, Epoch: 26, Train Loss: 13.4152, Val Loss: 0.1320\n",
      "Trial: 45, Epoch: 24, Train Loss: 57.5976, Val Loss: 0.1157\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 05:56:46,472] Trial 45 finished with value: 0.10823073213090416 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'learning_rate': 0.0014646349252214487, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 64] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0005100260565163904, 'batch_size': 32, 'patience': 8}\n",
      "Trial: 53, Epoch: 32, Train Loss: 13.4297, Val Loss: 0.1262\n",
      "Trial: 55, Epoch: 25, Train Loss: 14.4606, Val Loss: 0.1323\n",
      "Trial: 60, Epoch: 5, Train Loss: 14.8768, Val Loss: 0.1726\n",
      "Trial: 62, Epoch: 2, Train Loss: 15.3847, Val Loss: 0.1385\n",
      "Trial: 61, Epoch: 5, Train Loss: 15.0990, Val Loss: 0.2065\n",
      "Trial: 59, Epoch: 10, Train Loss: 13.9008, Val Loss: 0.2493\n",
      "Trial: 50, Epoch: 18, Train Loss: 58.0485, Val Loss: 0.1198\n",
      "Trial: 57, Epoch: 24, Train Loss: 14.9137, Val Loss: 0.1269\n",
      "Trial: 54, Epoch: 27, Train Loss: 13.4451, Val Loss: 0.1277\n",
      "Trial: 44, Epoch: 24, Train Loss: 57.4157, Val Loss: 0.1154\n",
      "Trial: 53, Epoch: 33, Train Loss: 13.4285, Val Loss: 0.1246\n",
      "Trial: 64, Epoch: 0, Train Loss: 31.1628, Val Loss: 0.3543\n",
      "Trial: 63, Epoch: 1, Train Loss: 58.3184, Val Loss: 0.3126\n",
      "Trial: 49, Epoch: 20, Train Loss: 57.4256, Val Loss: 0.1187\n",
      "Trial: 55, Epoch: 26, Train Loss: 14.4830, Val Loss: 0.1277\n",
      "Trial: 60, Epoch: 6, Train Loss: 14.6820, Val Loss: 0.1808\n",
      "Trial: 61, Epoch: 6, Train Loss: 14.8752, Val Loss: 0.2054\n",
      "Trial: 62, Epoch: 3, Train Loss: 14.8083, Val Loss: 0.1327\n",
      "Trial: 59, Epoch: 11, Train Loss: 13.8423, Val Loss: 0.2332\n",
      "Trial: 46, Epoch: 23, Train Loss: 57.3557, Val Loss: 0.1205\n",
      "Trial: 48, Epoch: 20, Train Loss: 57.9358, Val Loss: 0.1207\n",
      "Trial: 57, Epoch: 25, Train Loss: 14.9239, Val Loss: 0.1267\n",
      "Trial: 52, Epoch: 18, Train Loss: 57.4859, Val Loss: 0.1246\n",
      "Trial: 54, Epoch: 28, Train Loss: 13.4487, Val Loss: 0.1234\n",
      "Trial: 53, Epoch: 34, Train Loss: 13.4164, Val Loss: 0.1336\n",
      "Trial: 64, Epoch: 1, Train Loss: 16.9226, Val Loss: 0.2223\n",
      "Trial: 60, Epoch: 7, Train Loss: 14.4820, Val Loss: 0.1774\n",
      "Trial: 55, Epoch: 27, Train Loss: 14.4346, Val Loss: 0.1298\n",
      "Trial: 61, Epoch: 7, Train Loss: 14.7643, Val Loss: 0.1743\n",
      "Trial: 62, Epoch: 4, Train Loss: 14.5884, Val Loss: 0.1364\n",
      "Trial: 59, Epoch: 12, Train Loss: 13.8072, Val Loss: 0.2297\n",
      "Trial: 50, Epoch: 19, Train Loss: 57.7924, Val Loss: 0.1192\n",
      "Trial: 57, Epoch: 26, Train Loss: 14.9132, Val Loss: 0.1270\n",
      "Trial: 44, Epoch: 25, Train Loss: 57.2682, Val Loss: 0.1162\n",
      "Trial: 54, Epoch: 29, Train Loss: 13.3981, Val Loss: 0.1333\n",
      "Trial: 49, Epoch: 21, Train Loss: 57.4344, Val Loss: 0.1125\n",
      "Trial: 63, Epoch: 2, Train Loss: 57.1264, Val Loss: 0.2492\n",
      "Trial: 53, Epoch: 35, Train Loss: 13.4290, Val Loss: 0.1195\n",
      "Trial: 64, Epoch: 2, Train Loss: 15.2894, Val Loss: 0.2843\n",
      "Trial: 60, Epoch: 8, Train Loss: 14.2885, Val Loss: 0.1915\n",
      "Trial: 55, Epoch: 28, Train Loss: 14.4712, Val Loss: 0.1334\n",
      "Trial: 61, Epoch: 8, Train Loss: 14.7047, Val Loss: 0.1567\n",
      "Trial: 46, Epoch: 24, Train Loss: 57.3417, Val Loss: 0.1178\n",
      "Trial: 62, Epoch: 5, Train Loss: 14.2101, Val Loss: 0.1333\n",
      "Trial: 48, Epoch: 21, Train Loss: 57.7925, Val Loss: 0.1156\n",
      "Trial: 59, Epoch: 13, Train Loss: 13.8128, Val Loss: 0.2289\n",
      "Trial: 52, Epoch: 19, Train Loss: 57.4950, Val Loss: 0.1283\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:07:58,253] Trial 52 finished with value: 0.11062486832883178 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.00047697764787181626, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 65] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.019372882263522, 'batch_size': 32, 'patience': 8}\n",
      "Trial: 57, Epoch: 27, Train Loss: 14.9176, Val Loss: 0.1270\n",
      "Trial: 54, Epoch: 30, Train Loss: 13.3907, Val Loss: 0.1316\n",
      "Trial: 53, Epoch: 36, Train Loss: 13.4185, Val Loss: 0.1246\n",
      "Trial: 64, Epoch: 3, Train Loss: 14.8585, Val Loss: 0.2779\n",
      "Trial: 60, Epoch: 9, Train Loss: 14.1217, Val Loss: 0.1996\n",
      "Trial: 55, Epoch: 29, Train Loss: 14.4094, Val Loss: 0.1236\n",
      "Trial: 61, Epoch: 9, Train Loss: 14.5568, Val Loss: 0.1470\n",
      "Trial: 62, Epoch: 6, Train Loss: 14.0196, Val Loss: 0.1494\n",
      "Trial: 50, Epoch: 20, Train Loss: 57.5692, Val Loss: 0.1217\n",
      "Trial: 59, Epoch: 14, Train Loss: 13.7569, Val Loss: 0.2070\n",
      "Trial: 44, Epoch: 26, Train Loss: 57.6015, Val Loss: 0.1173\n",
      "Trial: 57, Epoch: 28, Train Loss: 14.9317, Val Loss: 0.1277\n",
      "Trial: 49, Epoch: 22, Train Loss: 57.4120, Val Loss: 0.1189\n",
      "Trial: 65, Epoch: 0, Train Loss: 375.1851, Val Loss: 0.7939\n",
      "Trial: 54, Epoch: 31, Train Loss: 13.3844, Val Loss: 0.1359\n",
      "Trial: 63, Epoch: 3, Train Loss: 55.9240, Val Loss: 0.1708\n",
      "Trial: 53, Epoch: 37, Train Loss: 13.4087, Val Loss: 0.1197\n",
      "Trial: 46, Epoch: 25, Train Loss: 57.3313, Val Loss: 0.1171\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:12:28,173] Trial 46 finished with value: 0.11539022730929512 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.00040455623225381116, 'batch_size': 8, 'patience': 4}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 66] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.009797169782467745, 'batch_size': 8, 'patience': 8}\n",
      "Trial: 64, Epoch: 4, Train Loss: 14.5291, Val Loss: 0.2229\n",
      "Trial: 60, Epoch: 10, Train Loss: 14.0089, Val Loss: 0.1981\n",
      "Trial: 61, Epoch: 10, Train Loss: 14.5201, Val Loss: 0.1385\n",
      "Trial: 55, Epoch: 30, Train Loss: 14.4193, Val Loss: 0.1218\n",
      "Trial: 48, Epoch: 22, Train Loss: 57.9374, Val Loss: 0.1159\n",
      "Trial: 62, Epoch: 7, Train Loss: 13.7731, Val Loss: 0.1896\n",
      "Trial: 59, Epoch: 15, Train Loss: 13.7387, Val Loss: 0.2012\n",
      "Trial: 57, Epoch: 29, Train Loss: 14.9122, Val Loss: 0.1267\n",
      "Trial: 65, Epoch: 1, Train Loss: 73.9124, Val Loss: 0.1360\n",
      "Trial: 54, Epoch: 32, Train Loss: 13.3379, Val Loss: 0.1249\n",
      "Trial: 53, Epoch: 38, Train Loss: 13.3954, Val Loss: 0.1238\n",
      "Trial: 60, Epoch: 11, Train Loss: 13.9406, Val Loss: 0.1777\n",
      "Trial: 64, Epoch: 5, Train Loss: 14.2580, Val Loss: 0.2483\n",
      "Trial: 61, Epoch: 11, Train Loss: 14.4801, Val Loss: 0.1344\n",
      "Trial: 55, Epoch: 31, Train Loss: 14.3891, Val Loss: 0.1212\n",
      "Trial: 50, Epoch: 21, Train Loss: 57.7840, Val Loss: 0.1167\n",
      "Trial: 62, Epoch: 8, Train Loss: 13.4955, Val Loss: 0.1951\n",
      "Trial: 59, Epoch: 16, Train Loss: 13.6923, Val Loss: 0.2066\n",
      "Trial: 44, Epoch: 27, Train Loss: 57.2719, Val Loss: 0.1203\n",
      "Trial: 49, Epoch: 23, Train Loss: 56.9793, Val Loss: 0.1157\n",
      "Trial: 57, Epoch: 30, Train Loss: 14.8973, Val Loss: 0.1270\n",
      "Trial: 63, Epoch: 4, Train Loss: 55.7691, Val Loss: 0.1881\n",
      "Trial: 54, Epoch: 33, Train Loss: 13.3690, Val Loss: 0.1224\n",
      "Trial: 65, Epoch: 2, Train Loss: 18.5531, Val Loss: 0.1317\n",
      "Trial: 53, Epoch: 39, Train Loss: 13.3916, Val Loss: 0.1165\n",
      "Trial: 48, Epoch: 23, Train Loss: 57.6998, Val Loss: 0.1121\n",
      "Trial: 60, Epoch: 12, Train Loss: 13.8793, Val Loss: 0.1976\n",
      "Trial: 66, Epoch: 0, Train Loss: 257.0579, Val Loss: 0.1276\n",
      "Trial: 64, Epoch: 6, Train Loss: 14.0008, Val Loss: 0.2730\n",
      "Trial: 61, Epoch: 12, Train Loss: 14.4822, Val Loss: 0.1298\n",
      "Trial: 55, Epoch: 32, Train Loss: 14.4899, Val Loss: 0.1223\n",
      "Trial: 62, Epoch: 9, Train Loss: 13.4517, Val Loss: 0.2078\n",
      "Trial: 59, Epoch: 17, Train Loss: 13.6806, Val Loss: 0.1775\n",
      "Trial: 57, Epoch: 31, Train Loss: 14.9092, Val Loss: 0.1269\n",
      "Trial: 54, Epoch: 34, Train Loss: 13.4013, Val Loss: 0.1228\n",
      "Trial: 65, Epoch: 3, Train Loss: 15.7309, Val Loss: 0.1275\n",
      "Trial: 53, Epoch: 40, Train Loss: 13.4421, Val Loss: 0.1209\n",
      "Trial: 60, Epoch: 13, Train Loss: 13.7780, Val Loss: 0.1792\n",
      "Trial: 50, Epoch: 22, Train Loss: 57.7243, Val Loss: 0.1164\n",
      "Trial: 61, Epoch: 13, Train Loss: 14.3957, Val Loss: 0.1371\n",
      "Trial: 64, Epoch: 7, Train Loss: 13.7389, Val Loss: 0.3125\n",
      "Trial: 55, Epoch: 33, Train Loss: 14.4174, Val Loss: 0.1274\n",
      "Trial: 44, Epoch: 28, Train Loss: 57.5056, Val Loss: 0.1154\n",
      "Trial: 62, Epoch: 10, Train Loss: 13.3827, Val Loss: 0.1922\n",
      "Trial: 49, Epoch: 24, Train Loss: 57.2080, Val Loss: 0.1200\n",
      "Trial: 59, Epoch: 18, Train Loss: 13.7267, Val Loss: 0.1985\n",
      "Trial: 63, Epoch: 5, Train Loss: 55.5880, Val Loss: 0.1729\n",
      "Trial: 57, Epoch: 32, Train Loss: 14.9464, Val Loss: 0.1274\n",
      "Trial: 54, Epoch: 35, Train Loss: 13.3466, Val Loss: 0.1238\n",
      "Trial: 48, Epoch: 24, Train Loss: 57.6613, Val Loss: 0.1128\n",
      "Trial: 65, Epoch: 4, Train Loss: 15.2183, Val Loss: 0.1277\n",
      "Trial: 53, Epoch: 41, Train Loss: 13.4075, Val Loss: 0.1193\n",
      "Trial: 66, Epoch: 1, Train Loss: 60.6207, Val Loss: 0.1254\n",
      "Trial: 60, Epoch: 14, Train Loss: 13.7398, Val Loss: 0.1806\n",
      "Trial: 61, Epoch: 14, Train Loss: 14.3242, Val Loss: 0.1306\n",
      "Trial: 64, Epoch: 8, Train Loss: 13.5688, Val Loss: 0.3909\n",
      "Trial: 55, Epoch: 34, Train Loss: 14.3684, Val Loss: 0.1228\n",
      "Trial: 62, Epoch: 11, Train Loss: 13.3016, Val Loss: 0.2037\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:25:16,065] Trial 62 finished with value: 0.1326969509323438 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.00046112276114643105, 'batch_size': 32, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 67] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.010154673391248835, 'batch_size': 8, 'patience': 8}\n",
      "Trial: 59, Epoch: 19, Train Loss: 13.7019, Val Loss: 0.1661\n",
      "Trial: 57, Epoch: 33, Train Loss: 14.9203, Val Loss: 0.1279\n",
      "Trial: 54, Epoch: 36, Train Loss: 13.4288, Val Loss: 0.1238\n",
      "Trial: 65, Epoch: 5, Train Loss: 15.1145, Val Loss: 0.1273\n",
      "Trial: 53, Epoch: 42, Train Loss: 13.3729, Val Loss: 0.1214\n",
      "Trial: 50, Epoch: 23, Train Loss: 57.6904, Val Loss: 0.1290\n",
      "Trial: 60, Epoch: 15, Train Loss: 13.7105, Val Loss: 0.1802\n",
      "Early stopping triggered.\n",
      "Trial: 44, Epoch: 29, Train Loss: 57.1420, Val Loss: 0.1175\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:27:44,120] Trial 60 finished with value: 0.17255749603112538 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.00033762800998407935, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 68] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.018570502295540293, 'batch_size': 8, 'patience': 8}\n",
      "Trial: 61, Epoch: 15, Train Loss: 14.2040, Val Loss: 0.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:27:44,990] Trial 44 finished with value: 0.11360250851687263 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0003837628780035764, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 69] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.01814154538404995, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 49, Epoch: 25, Train Loss: 57.2374, Val Loss: 0.1199\n",
      "Trial: 64, Epoch: 9, Train Loss: 13.5111, Val Loss: 0.3935\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:28:12,840] Trial 64 finished with value: 0.2222556526462237 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0005100260565163904, 'batch_size': 32, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 70] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 64, 'learning_rate': 0.021712674378533834, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 55, Epoch: 35, Train Loss: 14.4231, Val Loss: 0.1203\n",
      "Trial: 59, Epoch: 20, Train Loss: 13.6417, Val Loss: 0.1827\n",
      "Trial: 63, Epoch: 6, Train Loss: 55.0334, Val Loss: 0.1518\n",
      "Trial: 57, Epoch: 34, Train Loss: 14.9233, Val Loss: 0.1269\n",
      "Trial: 48, Epoch: 25, Train Loss: 57.7767, Val Loss: 0.1127\n",
      "Trial: 54, Epoch: 37, Train Loss: 13.3434, Val Loss: 0.1205\n",
      "Trial: 66, Epoch: 2, Train Loss: 60.3174, Val Loss: 0.1310\n",
      "Trial: 53, Epoch: 43, Train Loss: 13.3784, Val Loss: 0.1191\n",
      "Trial: 65, Epoch: 6, Train Loss: 15.0557, Val Loss: 0.1265\n",
      "Trial: 61, Epoch: 16, Train Loss: 14.0754, Val Loss: 0.1505\n",
      "Trial: 67, Epoch: 0, Train Loss: 92.7493, Val Loss: 0.1281\n",
      "Trial: 55, Epoch: 36, Train Loss: 14.3807, Val Loss: 0.1192\n",
      "Trial: 59, Epoch: 21, Train Loss: 13.6072, Val Loss: 0.1876\n",
      "Trial: 57, Epoch: 35, Train Loss: 14.9071, Val Loss: 0.1276\n",
      "Early stopping triggered.\n",
      "Trial: 69, Epoch: 0, Train Loss: 485.1924, Val Loss: 0.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:32:35,560] Trial 57 finished with value: 0.12667742843429247 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008897684932241393, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 71] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.021221884532071383, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 54, Epoch: 38, Train Loss: 13.3206, Val Loss: 0.1254\n",
      "Trial: 70, Epoch: 0, Train Loss: 669.3167, Val Loss: 0.4274\n",
      "Trial: 53, Epoch: 44, Train Loss: 13.3848, Val Loss: 0.1217\n",
      "Trial: 50, Epoch: 24, Train Loss: 57.9031, Val Loss: 0.1207\n",
      "Trial: 65, Epoch: 7, Train Loss: 15.0394, Val Loss: 0.1271\n",
      "Trial: 49, Epoch: 26, Train Loss: 57.5288, Val Loss: 0.1124\n",
      "Trial: 61, Epoch: 17, Train Loss: 13.9298, Val Loss: 0.1573\n",
      "Trial: 68, Epoch: 0, Train Loss: 431.5068, Val Loss: 0.1604\n",
      "Trial: 55, Epoch: 37, Train Loss: 14.3969, Val Loss: 0.1235\n",
      "Trial: 59, Epoch: 22, Train Loss: 13.6499, Val Loss: 0.1704\n",
      "Trial: 63, Epoch: 7, Train Loss: 54.9372, Val Loss: 0.1476\n",
      "Trial: 48, Epoch: 26, Train Loss: 57.9272, Val Loss: 0.1173\n",
      "Trial: 54, Epoch: 39, Train Loss: 13.3662, Val Loss: 0.1231\n",
      "Trial: 66, Epoch: 3, Train Loss: 60.1620, Val Loss: 0.1253\n",
      "Trial: 53, Epoch: 45, Train Loss: 13.3747, Val Loss: 0.1136\n",
      "Trial: 61, Epoch: 18, Train Loss: 13.8751, Val Loss: 0.1500\n",
      "Trial: 65, Epoch: 8, Train Loss: 15.0309, Val Loss: 0.1268\n",
      "Trial: 71, Epoch: 0, Train Loss: 34.3540, Val Loss: 0.1622\n",
      "Trial: 69, Epoch: 1, Train Loss: 41.0126, Val Loss: 0.1244\n",
      "Trial: 67, Epoch: 1, Train Loss: 59.9417, Val Loss: 0.1274\n",
      "Trial: 59, Epoch: 23, Train Loss: 13.5951, Val Loss: 0.1656\n",
      "Trial: 55, Epoch: 38, Train Loss: 14.4190, Val Loss: 0.1253\n",
      "Trial: 70, Epoch: 1, Train Loss: 144.6095, Val Loss: 0.1275\n",
      "Trial: 54, Epoch: 40, Train Loss: 13.3393, Val Loss: 0.1243\n",
      "Trial: 49, Epoch: 27, Train Loss: 57.3667, Val Loss: 0.1183\n",
      "Trial: 50, Epoch: 25, Train Loss: 57.6114, Val Loss: 0.1166\n",
      "Trial: 53, Epoch: 46, Train Loss: 13.3786, Val Loss: 0.1150\n",
      "Trial: 61, Epoch: 19, Train Loss: 13.8110, Val Loss: 0.1310\n",
      "Trial: 65, Epoch: 9, Train Loss: 14.9896, Val Loss: 0.1268\n",
      "Trial: 59, Epoch: 24, Train Loss: 13.5688, Val Loss: 0.1704\n",
      "Trial: 55, Epoch: 39, Train Loss: 14.3943, Val Loss: 0.1172\n",
      "Trial: 68, Epoch: 1, Train Loss: 62.5599, Val Loss: 0.1294\n",
      "Trial: 71, Epoch: 1, Train Loss: 28.0883, Val Loss: 0.1102\n",
      "Trial: 48, Epoch: 27, Train Loss: 57.6792, Val Loss: 0.1157\n",
      "Trial: 63, Epoch: 8, Train Loss: 54.1715, Val Loss: 0.1549\n",
      "Trial: 69, Epoch: 2, Train Loss: 30.9439, Val Loss: 0.1224\n",
      "Trial: 54, Epoch: 41, Train Loss: 13.3081, Val Loss: 0.1167\n",
      "Trial: 66, Epoch: 4, Train Loss: 60.1129, Val Loss: 0.1253\n",
      "Trial: 70, Epoch: 2, Train Loss: 30.5179, Val Loss: 0.1258\n",
      "Trial: 61, Epoch: 20, Train Loss: 13.7786, Val Loss: 0.1420\n",
      "Trial: 53, Epoch: 47, Train Loss: 13.3440, Val Loss: 0.1183\n",
      "Trial: 67, Epoch: 2, Train Loss: 59.7584, Val Loss: 0.1275\n",
      "Trial: 65, Epoch: 10, Train Loss: 14.9977, Val Loss: 0.1271\n",
      "Trial: 59, Epoch: 25, Train Loss: 13.5977, Val Loss: 0.1647\n",
      "Trial: 55, Epoch: 40, Train Loss: 14.3464, Val Loss: 0.1221\n",
      "Trial: 71, Epoch: 2, Train Loss: 27.7282, Val Loss: 0.1142\n",
      "Trial: 49, Epoch: 28, Train Loss: 57.3131, Val Loss: 0.1126\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:44:31,590] Trial 49 finished with value: 0.11124752728002411 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.0013678685333310158, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 72] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.018005849537320817, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 54, Epoch: 42, Train Loss: 13.2989, Val Loss: 0.1204\n",
      "Trial: 50, Epoch: 26, Train Loss: 57.8871, Val Loss: 0.1228\n",
      "Trial: 61, Epoch: 21, Train Loss: 13.7412, Val Loss: 0.1355\n",
      "Trial: 53, Epoch: 48, Train Loss: 13.3855, Val Loss: 0.1178\n",
      "Trial: 69, Epoch: 3, Train Loss: 30.5795, Val Loss: 0.1239\n",
      "Trial: 65, Epoch: 11, Train Loss: 15.0000, Val Loss: 0.1267\n",
      "Trial: 59, Epoch: 26, Train Loss: 13.5090, Val Loss: 0.1655\n",
      "Trial: 55, Epoch: 41, Train Loss: 14.4221, Val Loss: 0.1218\n",
      "Trial: 68, Epoch: 2, Train Loss: 67.8392, Val Loss: 0.1286\n",
      "Trial: 48, Epoch: 28, Train Loss: 57.7009, Val Loss: 0.1124\n",
      "Trial: 70, Epoch: 3, Train Loss: 30.2625, Val Loss: 0.1264\n",
      "Trial: 63, Epoch: 9, Train Loss: 53.1293, Val Loss: 0.1545\n",
      "Trial: 66, Epoch: 5, Train Loss: 60.0785, Val Loss: 0.1258\n",
      "Trial: 54, Epoch: 43, Train Loss: 13.3530, Val Loss: 0.1234\n",
      "Trial: 61, Epoch: 22, Train Loss: 13.7302, Val Loss: 0.1373\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:47:59,693] Trial 61 finished with value: 0.12984440252184867 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.00037928669850137886, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 73] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.020048005009294666, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 53, Epoch: 49, Train Loss: 13.4161, Val Loss: 0.1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:48:12,800] Trial 53 finished with value: 0.11356778840223948 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0004449717982515018, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 74] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 0.02092300776763564, 'batch_size': 16, 'patience': 8}\n",
      "Trial: 71, Epoch: 3, Train Loss: 27.8066, Val Loss: 0.1148\n",
      "Trial: 67, Epoch: 3, Train Loss: 59.9248, Val Loss: 0.1278\n",
      "Trial: 59, Epoch: 27, Train Loss: 13.5677, Val Loss: 0.1649\n",
      "Trial: 65, Epoch: 12, Train Loss: 14.9973, Val Loss: 0.1265\n",
      "Trial: 72, Epoch: 0, Train Loss: 3617.4737, Val Loss: 5.2734\n",
      "Trial: 55, Epoch: 42, Train Loss: 14.3860, Val Loss: 0.1166\n",
      "Trial: 69, Epoch: 4, Train Loss: 30.5492, Val Loss: 0.1233\n",
      "Trial: 50, Epoch: 27, Train Loss: 57.6518, Val Loss: 0.1204\n",
      "Trial: 54, Epoch: 44, Train Loss: 13.3646, Val Loss: 0.1170\n",
      "Trial: 70, Epoch: 4, Train Loss: 30.2108, Val Loss: 0.1262\n",
      "Trial: 59, Epoch: 28, Train Loss: 13.5166, Val Loss: 0.1562\n",
      "Trial: 65, Epoch: 13, Train Loss: 14.9960, Val Loss: 0.1266\n",
      "Trial: 71, Epoch: 4, Train Loss: 27.6757, Val Loss: 0.1179\n",
      "Trial: 48, Epoch: 29, Train Loss: 57.7500, Val Loss: 0.1123\n",
      "Trial: 74, Epoch: 0, Train Loss: 38.2236, Val Loss: 0.1320\n",
      "Trial: 55, Epoch: 43, Train Loss: 14.3888, Val Loss: 0.1208\n",
      "Trial: 68, Epoch: 3, Train Loss: 60.8634, Val Loss: 0.1272\n",
      "Trial: 73, Epoch: 0, Train Loss: 1605.7373, Val Loss: 9.3895\n",
      "Trial: 63, Epoch: 10, Train Loss: 52.9461, Val Loss: 0.1526\n",
      "Trial: 72, Epoch: 1, Train Loss: 1420.6487, Val Loss: 32.5319\n",
      "Trial: 54, Epoch: 45, Train Loss: 13.2727, Val Loss: 0.1214\n",
      "Trial: 66, Epoch: 6, Train Loss: 60.0381, Val Loss: 0.1256\n",
      "Trial: 67, Epoch: 4, Train Loss: 59.8827, Val Loss: 0.1276\n",
      "Trial: 69, Epoch: 5, Train Loss: 30.5375, Val Loss: 0.1248\n",
      "Trial: 59, Epoch: 29, Train Loss: 13.5247, Val Loss: 0.1488\n",
      "Trial: 65, Epoch: 14, Train Loss: 14.9847, Val Loss: 0.1278\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 06:55:01,287] Trial 65 finished with value: 0.12645081703861555 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.019372882263522, 'batch_size': 32, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 75] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004426374886913112, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 55, Epoch: 44, Train Loss: 14.3640, Val Loss: 0.1217\n",
      "Trial: 71, Epoch: 5, Train Loss: 27.5156, Val Loss: 0.1092\n",
      "Trial: 70, Epoch: 5, Train Loss: 30.2766, Val Loss: 0.1263\n",
      "Trial: 74, Epoch: 1, Train Loss: 30.1828, Val Loss: 0.1258\n",
      "Trial: 50, Epoch: 28, Train Loss: 57.5910, Val Loss: 0.1213\n",
      "Trial: 54, Epoch: 46, Train Loss: 13.2987, Val Loss: 0.1282\n",
      "Trial: 73, Epoch: 1, Train Loss: 552.0016, Val Loss: 0.2560\n",
      "Trial: 48, Epoch: 30, Train Loss: 57.3619, Val Loss: 0.1101\n",
      "Trial: 59, Epoch: 30, Train Loss: 13.4787, Val Loss: 0.1466\n",
      "Trial: 72, Epoch: 2, Train Loss: 1312.9801, Val Loss: 0.1505\n",
      "Trial: 55, Epoch: 45, Train Loss: 14.4286, Val Loss: 0.1214\n",
      "Trial: 69, Epoch: 6, Train Loss: 30.2977, Val Loss: 0.1222\n",
      "Trial: 63, Epoch: 11, Train Loss: 52.5486, Val Loss: 0.1418\n",
      "Trial: 68, Epoch: 4, Train Loss: 60.3987, Val Loss: 0.1278\n",
      "Trial: 75, Epoch: 0, Train Loss: 36.2049, Val Loss: 0.1137\n",
      "Trial: 71, Epoch: 6, Train Loss: 27.3612, Val Loss: 0.1037\n",
      "Trial: 74, Epoch: 2, Train Loss: 30.1429, Val Loss: 0.1260\n",
      "Trial: 67, Epoch: 5, Train Loss: 59.6649, Val Loss: 0.1278\n",
      "Trial: 54, Epoch: 47, Train Loss: 13.3241, Val Loss: 0.1193\n",
      "Trial: 66, Epoch: 7, Train Loss: 59.9474, Val Loss: 0.1275\n",
      "Trial: 70, Epoch: 6, Train Loss: 30.3516, Val Loss: 0.1265\n",
      "Trial: 59, Epoch: 31, Train Loss: 13.5202, Val Loss: 0.1347\n",
      "Trial: 73, Epoch: 2, Train Loss: 729.6778, Val Loss: 0.3529\n",
      "Trial: 55, Epoch: 46, Train Loss: 14.3082, Val Loss: 0.1163\n",
      "Trial: 50, Epoch: 29, Train Loss: 57.6597, Val Loss: 0.1134\n",
      "Trial: 72, Epoch: 3, Train Loss: 615.1481, Val Loss: 5.7342\n",
      "Trial: 54, Epoch: 48, Train Loss: 13.3087, Val Loss: 0.1200\n",
      "Trial: 75, Epoch: 1, Train Loss: 27.4578, Val Loss: 0.1176\n",
      "Trial: 69, Epoch: 7, Train Loss: 30.2532, Val Loss: 0.1257\n",
      "Trial: 48, Epoch: 31, Train Loss: 57.6618, Val Loss: 0.1094\n",
      "Trial: 74, Epoch: 3, Train Loss: 29.9859, Val Loss: 0.1259\n",
      "Trial: 59, Epoch: 32, Train Loss: 13.5403, Val Loss: 0.1366\n",
      "Trial: 71, Epoch: 7, Train Loss: 27.4053, Val Loss: 0.1112\n",
      "Trial: 55, Epoch: 47, Train Loss: 14.3610, Val Loss: 0.1197\n",
      "Trial: 63, Epoch: 12, Train Loss: 52.5403, Val Loss: 0.1391\n",
      "Trial: 70, Epoch: 7, Train Loss: 30.1798, Val Loss: 0.1270\n",
      "Trial: 68, Epoch: 5, Train Loss: 60.2082, Val Loss: 0.1279\n",
      "Trial: 67, Epoch: 6, Train Loss: 59.6953, Val Loss: 0.1283\n",
      "Trial: 66, Epoch: 8, Train Loss: 60.0189, Val Loss: 0.1250\n",
      "Trial: 54, Epoch: 49, Train Loss: 13.3033, Val Loss: 0.1215\n",
      "Trial: 73, Epoch: 3, Train Loss: 53.3456, Val Loss: 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:05:45,282] Trial 54 finished with value: 0.11672280877828597 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.00043386717162467573, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 76] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004340404609266826, 'batch_size': 16, 'patience': 9}\n",
      "Trial: 59, Epoch: 33, Train Loss: 13.4794, Val Loss: 0.1562\n",
      "Trial: 75, Epoch: 2, Train Loss: 26.9423, Val Loss: 0.1096\n",
      "Trial: 72, Epoch: 4, Train Loss: 112.5147, Val Loss: 0.1391\n",
      "Trial: 74, Epoch: 4, Train Loss: 30.0077, Val Loss: 0.1257\n",
      "Trial: 69, Epoch: 8, Train Loss: 30.2725, Val Loss: 0.1223\n",
      "Trial: 71, Epoch: 8, Train Loss: 27.0418, Val Loss: 0.1064\n",
      "Trial: 55, Epoch: 48, Train Loss: 14.3678, Val Loss: 0.1197\n",
      "Trial: 50, Epoch: 30, Train Loss: 57.7813, Val Loss: 0.1117\n",
      "Trial: 48, Epoch: 32, Train Loss: 57.2770, Val Loss: 0.1097\n",
      "Trial: 59, Epoch: 34, Train Loss: 13.4294, Val Loss: 0.1392\n",
      "Trial: 70, Epoch: 8, Train Loss: 30.1713, Val Loss: 0.1271\n",
      "Trial: 76, Epoch: 0, Train Loss: 38.7735, Val Loss: 0.1155\n",
      "Trial: 73, Epoch: 4, Train Loss: 36.6566, Val Loss: 0.1265\n",
      "Trial: 75, Epoch: 3, Train Loss: 26.9803, Val Loss: 0.1105\n",
      "Trial: 55, Epoch: 49, Train Loss: 14.3752, Val Loss: 0.1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:10:19,303] Trial 55 finished with value: 0.11633675595124562 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.0004293691353813541, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 77] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004860068842630981, 'batch_size': 16, 'patience': 9}\n",
      "Trial: 63, Epoch: 13, Train Loss: 52.4214, Val Loss: 0.1312\n",
      "Trial: 74, Epoch: 5, Train Loss: 29.9840, Val Loss: 0.1273\n",
      "Trial: 67, Epoch: 7, Train Loss: 59.7909, Val Loss: 0.1275\n",
      "Trial: 71, Epoch: 9, Train Loss: 26.8131, Val Loss: 0.1115\n",
      "Trial: 72, Epoch: 5, Train Loss: 1313.0409, Val Loss: 8.6443\n",
      "Trial: 68, Epoch: 6, Train Loss: 60.1463, Val Loss: 0.1283\n",
      "Trial: 69, Epoch: 9, Train Loss: 30.2230, Val Loss: 0.1222\n",
      "Trial: 66, Epoch: 9, Train Loss: 59.9327, Val Loss: 0.1252\n",
      "Trial: 59, Epoch: 35, Train Loss: 13.4622, Val Loss: 0.1357\n",
      "Trial: 76, Epoch: 1, Train Loss: 27.7177, Val Loss: 0.1073\n",
      "Trial: 50, Epoch: 31, Train Loss: 57.4355, Val Loss: 0.1266\n",
      "Trial: 75, Epoch: 4, Train Loss: 26.9341, Val Loss: 0.1091\n",
      "Trial: 48, Epoch: 33, Train Loss: 57.5487, Val Loss: 0.1123\n",
      "Trial: 70, Epoch: 9, Train Loss: 30.1083, Val Loss: 0.1265\n",
      "Trial: 74, Epoch: 6, Train Loss: 29.9768, Val Loss: 0.1259\n",
      "Trial: 73, Epoch: 5, Train Loss: 30.1337, Val Loss: 0.1374\n",
      "Trial: 77, Epoch: 0, Train Loss: 37.2453, Val Loss: 0.1090\n",
      "Trial: 71, Epoch: 10, Train Loss: 26.4740, Val Loss: 0.1036\n",
      "Trial: 59, Epoch: 36, Train Loss: 13.4287, Val Loss: 0.1379\n",
      "Trial: 72, Epoch: 6, Train Loss: 120.4942, Val Loss: 0.1298\n",
      "Trial: 69, Epoch: 10, Train Loss: 30.2148, Val Loss: 0.1229\n",
      "Trial: 63, Epoch: 14, Train Loss: 52.2709, Val Loss: 0.1347\n",
      "Trial: 67, Epoch: 8, Train Loss: 59.6779, Val Loss: 0.1276\n",
      "Trial: 66, Epoch: 10, Train Loss: 60.0800, Val Loss: 0.1250\n",
      "Trial: 76, Epoch: 2, Train Loss: 26.9964, Val Loss: 0.1078\n",
      "Trial: 68, Epoch: 7, Train Loss: 60.0337, Val Loss: 0.1270\n",
      "Trial: 75, Epoch: 5, Train Loss: 26.6039, Val Loss: 0.1065\n",
      "Trial: 59, Epoch: 37, Train Loss: 13.4458, Val Loss: 0.1358\n",
      "Trial: 74, Epoch: 7, Train Loss: 29.9706, Val Loss: 0.1258\n",
      "Trial: 77, Epoch: 1, Train Loss: 27.5180, Val Loss: 0.1082\n",
      "Trial: 70, Epoch: 10, Train Loss: 30.0896, Val Loss: 0.1260\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:18:22,671] Trial 70 finished with value: 0.12584239579737186 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'learning_rate': 0.021712674378533834, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 78] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004160963535612333, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 71, Epoch: 11, Train Loss: 26.1246, Val Loss: 0.1036\n",
      "Trial: 73, Epoch: 6, Train Loss: 31.4874, Val Loss: 0.1264\n",
      "Trial: 48, Epoch: 34, Train Loss: 57.4119, Val Loss: 0.1147\n",
      "Trial: 50, Epoch: 32, Train Loss: 57.5380, Val Loss: 0.1244\n",
      "Trial: 72, Epoch: 7, Train Loss: 29.9011, Val Loss: 0.1316\n",
      "Trial: 69, Epoch: 11, Train Loss: 30.1785, Val Loss: 0.1224\n",
      "Trial: 59, Epoch: 38, Train Loss: 13.4310, Val Loss: 0.1284\n",
      "Trial: 76, Epoch: 3, Train Loss: 26.3951, Val Loss: 0.1116\n",
      "Trial: 75, Epoch: 6, Train Loss: 26.6627, Val Loss: 0.1078\n",
      "Trial: 74, Epoch: 8, Train Loss: 29.9771, Val Loss: 0.1277\n",
      "Trial: 77, Epoch: 2, Train Loss: 27.1636, Val Loss: 0.1133\n",
      "Trial: 63, Epoch: 15, Train Loss: 52.2925, Val Loss: 0.1309\n",
      "Trial: 67, Epoch: 9, Train Loss: 59.7886, Val Loss: 0.1282\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:22:01,762] Trial 67 finished with value: 0.12744803094312923 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'learning_rate': 0.010154673391248835, 'batch_size': 8, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 79] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004286426737553629, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 71, Epoch: 12, Train Loss: 26.0278, Val Loss: 0.1064\n",
      "Trial: 66, Epoch: 11, Train Loss: 59.9492, Val Loss: 0.1252\n",
      "Trial: 73, Epoch: 7, Train Loss: 30.0686, Val Loss: 0.1265\n",
      "Trial: 68, Epoch: 8, Train Loss: 59.8808, Val Loss: 0.1274\n",
      "Trial: 59, Epoch: 39, Train Loss: 13.4297, Val Loss: 0.1276\n",
      "Trial: 69, Epoch: 12, Train Loss: 30.2153, Val Loss: 0.1230\n",
      "Trial: 72, Epoch: 8, Train Loss: 62.0661, Val Loss: 0.1296\n",
      "Trial: 78, Epoch: 0, Train Loss: 65.3590, Val Loss: 0.1044\n",
      "Trial: 48, Epoch: 35, Train Loss: 57.2606, Val Loss: 0.1101\n",
      "Trial: 76, Epoch: 4, Train Loss: 25.9122, Val Loss: 0.1119\n",
      "Trial: 50, Epoch: 33, Train Loss: 57.4478, Val Loss: 0.1172\n",
      "Trial: 75, Epoch: 7, Train Loss: 26.6616, Val Loss: 0.1088\n",
      "Trial: 74, Epoch: 9, Train Loss: 29.9581, Val Loss: 0.1257\n",
      "Trial: 77, Epoch: 3, Train Loss: 26.8324, Val Loss: 0.1078\n",
      "Trial: 71, Epoch: 13, Train Loss: 25.9634, Val Loss: 0.1109\n",
      "Trial: 59, Epoch: 40, Train Loss: 13.3850, Val Loss: 0.1251\n",
      "Trial: 73, Epoch: 8, Train Loss: 30.0207, Val Loss: 0.1261\n",
      "Trial: 63, Epoch: 16, Train Loss: 52.1194, Val Loss: 0.1291\n",
      "Trial: 79, Epoch: 0, Train Loss: 64.2164, Val Loss: 0.1098\n",
      "Trial: 69, Epoch: 13, Train Loss: 30.2222, Val Loss: 0.1225\n",
      "Trial: 72, Epoch: 9, Train Loss: 29.8498, Val Loss: 0.1294\n",
      "Trial: 76, Epoch: 5, Train Loss: 25.7117, Val Loss: 0.1117\n",
      "Trial: 66, Epoch: 12, Train Loss: 59.9555, Val Loss: 0.1253\n",
      "Trial: 75, Epoch: 8, Train Loss: 26.0969, Val Loss: 0.1098\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:28:31,543] Trial 75 finished with value: 0.10649866697688898 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004426374886913112, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 80] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004478915337057289, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 74, Epoch: 10, Train Loss: 29.9668, Val Loss: 0.1258\n",
      "Trial: 77, Epoch: 4, Train Loss: 26.8385, Val Loss: 0.1079\n",
      "Trial: 68, Epoch: 9, Train Loss: 59.8190, Val Loss: 0.1275\n",
      "Trial: 59, Epoch: 41, Train Loss: 13.4162, Val Loss: 0.1233\n",
      "Trial: 78, Epoch: 1, Train Loss: 54.7121, Val Loss: 0.1077\n",
      "Trial: 71, Epoch: 14, Train Loss: 25.8239, Val Loss: 0.1035\n",
      "Trial: 48, Epoch: 36, Train Loss: 57.6384, Val Loss: 0.1109\n",
      "Trial: 50, Epoch: 34, Train Loss: 57.4552, Val Loss: 0.1144\n",
      "Trial: 73, Epoch: 9, Train Loss: 29.9540, Val Loss: 0.1266\n",
      "Trial: 76, Epoch: 6, Train Loss: 25.7534, Val Loss: 0.1095\n",
      "Trial: 59, Epoch: 42, Train Loss: 13.4232, Val Loss: 0.1320\n",
      "Trial: 69, Epoch: 14, Train Loss: 30.2590, Val Loss: 0.1233\n",
      "Trial: 72, Epoch: 10, Train Loss: 30.2544, Val Loss: 0.1301\n",
      "Trial: 74, Epoch: 11, Train Loss: 29.9361, Val Loss: 0.1259\n",
      "Trial: 80, Epoch: 0, Train Loss: 36.3294, Val Loss: 0.1184\n",
      "Trial: 77, Epoch: 5, Train Loss: 26.5383, Val Loss: 0.1106\n",
      "Trial: 63, Epoch: 17, Train Loss: 52.0923, Val Loss: 0.1374\n",
      "Trial: 79, Epoch: 1, Train Loss: 54.8427, Val Loss: 0.1103\n",
      "Trial: 71, Epoch: 15, Train Loss: 25.6191, Val Loss: 0.1055\n",
      "Trial: 66, Epoch: 13, Train Loss: 59.9295, Val Loss: 0.1251\n",
      "Trial: 78, Epoch: 2, Train Loss: 54.2387, Val Loss: 0.1045\n",
      "Trial: 59, Epoch: 43, Train Loss: 13.3980, Val Loss: 0.1315\n",
      "Trial: 68, Epoch: 10, Train Loss: 60.8586, Val Loss: 0.1276\n",
      "Trial: 48, Epoch: 37, Train Loss: 57.0681, Val Loss: 0.1120\n",
      "Trial: 76, Epoch: 7, Train Loss: 25.6880, Val Loss: 0.1072\n",
      "Trial: 50, Epoch: 35, Train Loss: 57.2980, Val Loss: 0.1148\n",
      "Trial: 73, Epoch: 10, Train Loss: 30.0110, Val Loss: 0.1267\n",
      "Trial: 74, Epoch: 12, Train Loss: 30.0026, Val Loss: 0.1257\n",
      "Trial: 80, Epoch: 1, Train Loss: 27.8199, Val Loss: 0.1114\n",
      "Trial: 69, Epoch: 15, Train Loss: 30.2550, Val Loss: 0.1228\n",
      "Trial: 77, Epoch: 6, Train Loss: 26.1839, Val Loss: 0.1093\n",
      "Trial: 72, Epoch: 11, Train Loss: 29.9800, Val Loss: 0.1314\n",
      "Trial: 71, Epoch: 16, Train Loss: 25.5809, Val Loss: 0.1172\n",
      "Trial: 59, Epoch: 44, Train Loss: 13.4098, Val Loss: 0.1246\n",
      "Trial: 79, Epoch: 2, Train Loss: 54.4791, Val Loss: 0.1112\n",
      "Trial: 63, Epoch: 18, Train Loss: 52.0192, Val Loss: 0.1210\n",
      "Trial: 76, Epoch: 8, Train Loss: 25.4573, Val Loss: 0.1055\n",
      "Trial: 66, Epoch: 14, Train Loss: 59.8911, Val Loss: 0.1255\n",
      "Trial: 74, Epoch: 13, Train Loss: 29.9853, Val Loss: 0.1261\n",
      "Trial: 80, Epoch: 2, Train Loss: 27.4366, Val Loss: 0.1133\n",
      "Trial: 78, Epoch: 3, Train Loss: 53.8557, Val Loss: 0.1049\n",
      "Trial: 73, Epoch: 11, Train Loss: 30.0516, Val Loss: 0.1272\n",
      "Trial: 77, Epoch: 7, Train Loss: 25.7259, Val Loss: 0.1120\n",
      "Trial: 48, Epoch: 38, Train Loss: 57.4292, Val Loss: 0.1124\n",
      "Trial: 69, Epoch: 16, Train Loss: 30.2600, Val Loss: 0.1231\n",
      "Trial: 71, Epoch: 17, Train Loss: 25.3462, Val Loss: 0.1224\n",
      "Trial: 72, Epoch: 12, Train Loss: 29.8225, Val Loss: 0.1306\n",
      "Trial: 59, Epoch: 45, Train Loss: 13.4308, Val Loss: 0.1177\n",
      "Trial: 68, Epoch: 11, Train Loss: 60.0302, Val Loss: 0.1284\n",
      "Trial: 50, Epoch: 36, Train Loss: 57.5986, Val Loss: 0.1252\n",
      "Trial: 76, Epoch: 9, Train Loss: 25.5172, Val Loss: 0.1134\n",
      "Trial: 74, Epoch: 14, Train Loss: 29.9996, Val Loss: 0.1265\n",
      "Trial: 80, Epoch: 3, Train Loss: 27.1358, Val Loss: 0.1052\n",
      "Trial: 79, Epoch: 3, Train Loss: 54.0940, Val Loss: 0.1047\n",
      "Trial: 59, Epoch: 46, Train Loss: 13.3979, Val Loss: 0.1246\n",
      "Trial: 77, Epoch: 8, Train Loss: 25.5653, Val Loss: 0.1066\n",
      "Trial: 63, Epoch: 19, Train Loss: 51.9268, Val Loss: 0.1205\n",
      "Trial: 71, Epoch: 18, Train Loss: 25.4999, Val Loss: 0.1244\n",
      "Trial: 73, Epoch: 12, Train Loss: 30.1154, Val Loss: 0.1282\n",
      "Trial: 69, Epoch: 17, Train Loss: 30.2070, Val Loss: 0.1226\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:44:46,638] Trial 69 finished with value: 0.12219076479474704 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.01814154538404995, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 81] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004388981128435687, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 66, Epoch: 15, Train Loss: 60.0409, Val Loss: 0.1259\n",
      "Trial: 72, Epoch: 13, Train Loss: 29.8926, Val Loss: 0.1312\n",
      "Trial: 78, Epoch: 4, Train Loss: 53.6719, Val Loss: 0.1038\n",
      "Trial: 48, Epoch: 39, Train Loss: 57.3147, Val Loss: 0.1115\n",
      "Trial: 76, Epoch: 10, Train Loss: 25.4594, Val Loss: 0.1082\n",
      "Trial: 59, Epoch: 47, Train Loss: 13.3900, Val Loss: 0.1304\n",
      "Trial: 50, Epoch: 37, Train Loss: 57.3482, Val Loss: 0.1251\n",
      "Trial: 74, Epoch: 15, Train Loss: 29.9283, Val Loss: 0.1259\n",
      "Trial: 68, Epoch: 12, Train Loss: 59.8704, Val Loss: 0.1281\n",
      "Trial: 80, Epoch: 4, Train Loss: 26.9315, Val Loss: 0.1136\n",
      "Trial: 77, Epoch: 9, Train Loss: 25.5295, Val Loss: 0.1106\n",
      "Trial: 71, Epoch: 19, Train Loss: 25.5003, Val Loss: 0.1223\n",
      "Trial: 73, Epoch: 13, Train Loss: 30.0226, Val Loss: 0.1263\n",
      "Trial: 81, Epoch: 0, Train Loss: 38.9688, Val Loss: 0.1315\n",
      "Trial: 79, Epoch: 4, Train Loss: 53.4974, Val Loss: 0.1076\n",
      "Trial: 72, Epoch: 14, Train Loss: 29.8701, Val Loss: 0.1293\n",
      "Trial: 59, Epoch: 48, Train Loss: 13.3442, Val Loss: 0.1363\n",
      "Trial: 63, Epoch: 20, Train Loss: 51.6703, Val Loss: 0.1234\n",
      "Trial: 76, Epoch: 11, Train Loss: 25.3709, Val Loss: 0.1114\n",
      "Trial: 66, Epoch: 16, Train Loss: 60.0532, Val Loss: 0.1253\n",
      "Early stopping triggered.\n",
      "Trial: 78, Epoch: 5, Train Loss: 53.8200, Val Loss: 0.1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:50:21,852] Trial 66 finished with value: 0.12500224563003587 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.009797169782467745, 'batch_size': 8, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 82] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00432167542781895, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 74, Epoch: 16, Train Loss: 29.9621, Val Loss: 0.1258\n",
      "Trial: 80, Epoch: 5, Train Loss: 26.8398, Val Loss: 0.1055\n",
      "Trial: 48, Epoch: 40, Train Loss: 57.3238, Val Loss: 0.1153\n",
      "Trial: 77, Epoch: 10, Train Loss: 25.4191, Val Loss: 0.1085\n",
      "Trial: 71, Epoch: 20, Train Loss: 25.3981, Val Loss: 0.1123\n",
      "Trial: 50, Epoch: 38, Train Loss: 57.3147, Val Loss: 0.1192\n",
      "Trial: 59, Epoch: 49, Train Loss: 13.4187, Val Loss: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:52:24,338] Trial 59 finished with value: 0.11765224859118462 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0004617688575311478, 'batch_size': 32, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 83] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0042241506405416, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 81, Epoch: 1, Train Loss: 28.0116, Val Loss: 0.1097\n",
      "Trial: 73, Epoch: 14, Train Loss: 30.0358, Val Loss: 0.1266\n",
      "Trial: 68, Epoch: 13, Train Loss: 59.8125, Val Loss: 0.1271\n",
      "Trial: 72, Epoch: 15, Train Loss: 30.4049, Val Loss: 0.1312\n",
      "Trial: 76, Epoch: 12, Train Loss: 25.3965, Val Loss: 0.1077\n",
      "Trial: 74, Epoch: 17, Train Loss: 29.9248, Val Loss: 0.1262\n",
      "Trial: 79, Epoch: 5, Train Loss: 53.3344, Val Loss: 0.1068\n",
      "Trial: 82, Epoch: 0, Train Loss: 40.9182, Val Loss: 0.1209\n",
      "Trial: 80, Epoch: 6, Train Loss: 26.7901, Val Loss: 0.1053\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:54:25,712] Trial 80 finished with value: 0.1051865176608165 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004478915337057289, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 84] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004322619315448169, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 63, Epoch: 21, Train Loss: 51.6422, Val Loss: 0.1221\n",
      "Trial: 77, Epoch: 11, Train Loss: 25.3000, Val Loss: 0.1148\n",
      "Trial: 71, Epoch: 21, Train Loss: 25.3866, Val Loss: 0.1110\n",
      "Trial: 78, Epoch: 6, Train Loss: 53.2761, Val Loss: 0.1051\n",
      "Trial: 81, Epoch: 2, Train Loss: 27.4016, Val Loss: 0.1096\n",
      "Trial: 48, Epoch: 41, Train Loss: 56.9579, Val Loss: 0.1102\n",
      "Early stopping triggered.\n",
      "Trial: 83, Epoch: 0, Train Loss: 34.4674, Val Loss: 0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:56:22,864] Trial 48 finished with value: 0.10940570728618558 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'learning_rate': 0.00028702002317463455, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 85] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004127542555112081, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 73, Epoch: 15, Train Loss: 43.8654, Val Loss: 0.1272\n",
      "Trial: 76, Epoch: 13, Train Loss: 25.4283, Val Loss: 0.1051\n",
      "Trial: 72, Epoch: 16, Train Loss: 51.0855, Val Loss: 0.1299\n",
      "Trial: 50, Epoch: 39, Train Loss: 57.6555, Val Loss: 0.1254\n",
      "Trial: 74, Epoch: 18, Train Loss: 29.9344, Val Loss: 0.1263\n",
      "Trial: 82, Epoch: 1, Train Loss: 28.4904, Val Loss: 0.1055\n",
      "Trial: 84, Epoch: 0, Train Loss: 39.4830, Val Loss: 0.1220\n",
      "Trial: 77, Epoch: 12, Train Loss: 25.2928, Val Loss: 0.1193\n",
      "Trial: 68, Epoch: 14, Train Loss: 59.8655, Val Loss: 0.1276\n",
      "Trial: 71, Epoch: 22, Train Loss: 25.4227, Val Loss: 0.1247\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 07:59:01,825] Trial 71 finished with value: 0.10353756348292033 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.021221884532071383, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 86] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004421818884043103, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 79, Epoch: 6, Train Loss: 52.7560, Val Loss: 0.1068\n",
      "Trial: 81, Epoch: 3, Train Loss: 27.0775, Val Loss: 0.1051\n",
      "Trial: 83, Epoch: 1, Train Loss: 27.3332, Val Loss: 0.1125\n",
      "Trial: 63, Epoch: 22, Train Loss: 51.9165, Val Loss: 0.1183\n",
      "Trial: 85, Epoch: 0, Train Loss: 35.2771, Val Loss: 0.1181\n",
      "Trial: 78, Epoch: 7, Train Loss: 53.0725, Val Loss: 0.1046\n",
      "Trial: 76, Epoch: 14, Train Loss: 25.3091, Val Loss: 0.1040\n",
      "Trial: 73, Epoch: 16, Train Loss: 29.9760, Val Loss: 0.1263\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:01:09,235] Trial 73 finished with value: 0.12609174152215322 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.020048005009294666, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 87] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004916494714259083, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 74, Epoch: 19, Train Loss: 29.9460, Val Loss: 0.1257\n",
      "Trial: 72, Epoch: 17, Train Loss: 30.5154, Val Loss: 0.1303\n",
      "Trial: 82, Epoch: 2, Train Loss: 27.4780, Val Loss: 0.1043\n",
      "Trial: 84, Epoch: 1, Train Loss: 28.1886, Val Loss: 0.1141\n",
      "Trial: 77, Epoch: 13, Train Loss: 25.2397, Val Loss: 0.1181\n",
      "Trial: 50, Epoch: 40, Train Loss: 57.6559, Val Loss: 0.1141\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:02:56,299] Trial 50 finished with value: 0.11165965755446618 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'learning_rate': 0.00038105620436826163, 'batch_size': 8, 'patience': 10}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 88] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003983299095625788, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 86, Epoch: 0, Train Loss: 35.0622, Val Loss: 0.1134\n",
      "Trial: 83, Epoch: 2, Train Loss: 27.0561, Val Loss: 0.1052\n",
      "Trial: 81, Epoch: 4, Train Loss: 26.8713, Val Loss: 0.1064\n",
      "Trial: 85, Epoch: 1, Train Loss: 27.2566, Val Loss: 0.1120\n",
      "Trial: 76, Epoch: 15, Train Loss: 25.3614, Val Loss: 0.1104\n",
      "Trial: 68, Epoch: 15, Train Loss: 60.2027, Val Loss: 0.1276\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:04:32,989] Trial 68 finished with value: 0.12697454861232213 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.018570502295540293, 'batch_size': 8, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 89] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005217222945574223, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 79, Epoch: 7, Train Loss: 51.7527, Val Loss: 0.1161\n",
      "Trial: 74, Epoch: 20, Train Loss: 29.9375, Val Loss: 0.1258\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:04:50,259] Trial 74 finished with value: 0.12567789368331433 and parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 0.02092300776763564, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 90] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0044655378415699755, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 82, Epoch: 3, Train Loss: 27.2950, Val Loss: 0.1126\n",
      "Trial: 87, Epoch: 0, Train Loss: 35.1965, Val Loss: 0.1083\n",
      "Trial: 72, Epoch: 18, Train Loss: 31.5924, Val Loss: 0.1304\n",
      "Trial: 63, Epoch: 23, Train Loss: 51.4999, Val Loss: 0.1211\n",
      "Trial: 84, Epoch: 2, Train Loss: 27.3958, Val Loss: 0.1175\n",
      "Trial: 78, Epoch: 8, Train Loss: 52.1951, Val Loss: 0.1052\n",
      "Trial: 77, Epoch: 14, Train Loss: 25.3355, Val Loss: 0.1144\n",
      "Trial: 86, Epoch: 1, Train Loss: 27.3641, Val Loss: 0.1142\n",
      "Trial: 88, Epoch: 0, Train Loss: 39.4071, Val Loss: 0.1123\n",
      "Trial: 83, Epoch: 3, Train Loss: 26.8641, Val Loss: 0.1084\n",
      "Trial: 81, Epoch: 5, Train Loss: 26.7783, Val Loss: 0.1032\n",
      "Trial: 85, Epoch: 2, Train Loss: 26.9294, Val Loss: 0.1097\n",
      "Trial: 76, Epoch: 16, Train Loss: 25.3246, Val Loss: 0.1160\n",
      "Trial: 82, Epoch: 4, Train Loss: 27.0279, Val Loss: 0.1088\n",
      "Trial: 89, Epoch: 0, Train Loss: 38.6893, Val Loss: 0.1206\n",
      "Trial: 87, Epoch: 1, Train Loss: 27.9176, Val Loss: 0.1055\n",
      "Trial: 90, Epoch: 0, Train Loss: 34.3604, Val Loss: 0.1192\n",
      "Trial: 84, Epoch: 3, Train Loss: 27.2093, Val Loss: 0.1125\n",
      "Trial: 72, Epoch: 19, Train Loss: 30.1082, Val Loss: 0.1310\n",
      "Trial: 77, Epoch: 15, Train Loss: 25.1620, Val Loss: 0.1084\n",
      "Trial: 79, Epoch: 8, Train Loss: 51.2385, Val Loss: 0.1196\n",
      "Trial: 86, Epoch: 2, Train Loss: 27.0335, Val Loss: 0.1171\n",
      "Trial: 88, Epoch: 1, Train Loss: 28.0740, Val Loss: 0.1095\n",
      "Trial: 83, Epoch: 4, Train Loss: 26.8126, Val Loss: 0.1078\n",
      "Trial: 81, Epoch: 6, Train Loss: 26.7815, Val Loss: 0.1054\n",
      "Trial: 78, Epoch: 9, Train Loss: 51.5102, Val Loss: 0.1087\n",
      "Trial: 63, Epoch: 24, Train Loss: 51.5363, Val Loss: 0.1172\n",
      "Trial: 85, Epoch: 3, Train Loss: 26.7040, Val Loss: 0.1079\n",
      "Trial: 76, Epoch: 17, Train Loss: 25.3537, Val Loss: 0.1105\n",
      "Trial: 82, Epoch: 5, Train Loss: 27.0235, Val Loss: 0.1071\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:12:04,985] Trial 82 finished with value: 0.10429589735964934 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00432167542781895, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 91] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006079284553544241, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 87, Epoch: 2, Train Loss: 27.2204, Val Loss: 0.1060\n",
      "Trial: 89, Epoch: 1, Train Loss: 28.2936, Val Loss: 0.1085\n",
      "Trial: 90, Epoch: 1, Train Loss: 27.4327, Val Loss: 0.1132\n",
      "Trial: 84, Epoch: 4, Train Loss: 26.8902, Val Loss: 0.1109\n",
      "Trial: 77, Epoch: 16, Train Loss: 25.1805, Val Loss: 0.1087\n",
      "Trial: 72, Epoch: 20, Train Loss: 29.9433, Val Loss: 0.1311\n",
      "Trial: 86, Epoch: 3, Train Loss: 26.9387, Val Loss: 0.1172\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:13:53,987] Trial 86 finished with value: 0.1133696643014749 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004421818884043103, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 92] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005971796549482727, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 83, Epoch: 5, Train Loss: 26.7392, Val Loss: 0.1094\n",
      "Early stopping triggered.\n",
      "Trial: 88, Epoch: 2, Train Loss: 27.6355, Val Loss: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:14:06,644] Trial 83 finished with value: 0.10515666604042054 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0042241506405416, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 93] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006458825629113211, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 81, Epoch: 7, Train Loss: 26.6409, Val Loss: 0.1088\n",
      "Trial: 85, Epoch: 4, Train Loss: 26.5431, Val Loss: 0.1113\n",
      "Trial: 79, Epoch: 9, Train Loss: 51.0063, Val Loss: 0.1135\n",
      "Trial: 76, Epoch: 18, Train Loss: 25.3191, Val Loss: 0.1112\n",
      "Trial: 87, Epoch: 3, Train Loss: 26.9932, Val Loss: 0.1080\n",
      "Trial: 89, Epoch: 2, Train Loss: 27.3158, Val Loss: 0.1111\n",
      "Trial: 90, Epoch: 2, Train Loss: 27.0232, Val Loss: 0.1127\n",
      "Trial: 78, Epoch: 10, Train Loss: 51.1887, Val Loss: 0.1108\n",
      "Trial: 91, Epoch: 0, Train Loss: 33.8580, Val Loss: 0.1072\n",
      "Trial: 63, Epoch: 25, Train Loss: 51.4051, Val Loss: 0.1251\n",
      "Trial: 84, Epoch: 5, Train Loss: 26.8649, Val Loss: 0.1120\n",
      "Trial: 77, Epoch: 17, Train Loss: 25.1786, Val Loss: 0.1224\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:16:40,312] Trial 77 finished with value: 0.10664332136511803 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004860068842630981, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 94] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.07178345909159707, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 72, Epoch: 21, Train Loss: 30.7130, Val Loss: 0.1301\n",
      "Trial: 88, Epoch: 3, Train Loss: 27.1636, Val Loss: 0.1101\n",
      "Trial: 92, Epoch: 0, Train Loss: 39.8476, Val Loss: 0.1086\n",
      "Trial: 81, Epoch: 8, Train Loss: 26.2993, Val Loss: 0.1129\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:17:57,070] Trial 81 finished with value: 0.10320442530016104 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004388981128435687, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 95] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.04993880849229204, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 93, Epoch: 0, Train Loss: 33.0783, Val Loss: 0.1209\n",
      "Trial: 85, Epoch: 5, Train Loss: 26.0763, Val Loss: 0.1125\n",
      "Trial: 76, Epoch: 19, Train Loss: 25.3477, Val Loss: 0.1097\n",
      "Trial: 87, Epoch: 4, Train Loss: 26.8373, Val Loss: 0.1090\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:19:15,783] Trial 87 finished with value: 0.10552814342081547 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004916494714259083, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 96] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006842591065272225, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 90, Epoch: 3, Train Loss: 26.4182, Val Loss: 0.1136\n",
      "Trial: 89, Epoch: 3, Train Loss: 27.0514, Val Loss: 0.1069\n",
      "Trial: 91, Epoch: 1, Train Loss: 27.2617, Val Loss: 0.1091\n",
      "Trial: 84, Epoch: 6, Train Loss: 26.6775, Val Loss: 0.1084\n",
      "Trial: 79, Epoch: 10, Train Loss: 50.7183, Val Loss: 0.1136\n",
      "Trial: 94, Epoch: 0, Train Loss: 108.8706, Val Loss: 0.1281\n",
      "Trial: 78, Epoch: 11, Train Loss: 51.0187, Val Loss: 0.1101\n",
      "Trial: 72, Epoch: 22, Train Loss: 30.6865, Val Loss: 0.1386\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:21:16,384] Trial 72 finished with value: 0.12933729750414688 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.018005849537320817, 'batch_size': 16, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 88, Epoch: 4, Train Loss: 26.9913, Val Loss: 0.1067\n",
      "\n",
      "[Trial 97] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006688141484300457, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 63, Epoch: 26, Train Loss: 51.4874, Val Loss: 0.1296\n",
      "Trial: 92, Epoch: 1, Train Loss: 27.9965, Val Loss: 0.1083\n",
      "Trial: 93, Epoch: 1, Train Loss: 27.4938, Val Loss: 0.1121\n",
      "Trial: 95, Epoch: 0, Train Loss: 59.0819, Val Loss: 0.1250\n",
      "Trial: 85, Epoch: 6, Train Loss: 25.7927, Val Loss: 0.1129\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:21:58,252] Trial 85 finished with value: 0.10787756964564324 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004127542555112081, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 98] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006328172313734254, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 76, Epoch: 20, Train Loss: 25.2299, Val Loss: 0.1077\n",
      "Trial: 90, Epoch: 4, Train Loss: 25.8940, Val Loss: 0.1142\n",
      "Trial: 89, Epoch: 4, Train Loss: 26.8698, Val Loss: 0.1073\n",
      "Trial: 91, Epoch: 2, Train Loss: 27.1466, Val Loss: 0.1108\n",
      "Trial: 96, Epoch: 0, Train Loss: 37.6667, Val Loss: 0.1191\n",
      "Trial: 84, Epoch: 7, Train Loss: 26.7877, Val Loss: 0.1123\n",
      "Trial: 94, Epoch: 1, Train Loss: 30.2940, Val Loss: 0.1262\n",
      "Trial: 88, Epoch: 5, Train Loss: 26.7615, Val Loss: 0.1057\n",
      "Trial: 93, Epoch: 2, Train Loss: 27.1246, Val Loss: 0.1098\n",
      "Trial: 92, Epoch: 2, Train Loss: 27.3478, Val Loss: 0.1058\n",
      "Trial: 97, Epoch: 0, Train Loss: 33.9373, Val Loss: 0.1205\n",
      "Trial: 95, Epoch: 1, Train Loss: 30.3552, Val Loss: 0.1248\n",
      "Trial: 79, Epoch: 11, Train Loss: 50.8261, Val Loss: 0.1138\n",
      "Trial: 76, Epoch: 21, Train Loss: 25.1884, Val Loss: 0.1099\n",
      "Trial: 98, Epoch: 0, Train Loss: 33.9679, Val Loss: 0.1093\n",
      "Trial: 78, Epoch: 12, Train Loss: 50.8853, Val Loss: 0.1033\n",
      "Trial: 90, Epoch: 5, Train Loss: 25.6689, Val Loss: 0.1201\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:26:25,460] Trial 90 finished with value: 0.11272084241112074 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0044655378415699755, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 99] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006447208759377448, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 91, Epoch: 3, Train Loss: 27.0663, Val Loss: 0.1128\n",
      "Early stopping triggered.\n",
      "Trial: 89, Epoch: 5, Train Loss: 26.7008, Val Loss: 0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:26:33,649] Trial 91 finished with value: 0.1071957646558682 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006079284553544241, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 100] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003440618340650632, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 63, Epoch: 27, Train Loss: 51.3937, Val Loss: 0.1196\n",
      "Trial: 96, Epoch: 1, Train Loss: 28.1405, Val Loss: 0.1140\n",
      "Trial: 84, Epoch: 8, Train Loss: 26.6069, Val Loss: 0.1060\n",
      "Trial: 94, Epoch: 2, Train Loss: 30.2803, Val Loss: 0.1261\n",
      "Trial: 88, Epoch: 6, Train Loss: 26.6640, Val Loss: 0.1064\n",
      "Trial: 93, Epoch: 3, Train Loss: 26.7856, Val Loss: 0.1140\n",
      "Trial: 97, Epoch: 1, Train Loss: 27.7699, Val Loss: 0.1110\n",
      "Trial: 92, Epoch: 3, Train Loss: 27.1532, Val Loss: 0.1067\n",
      "Trial: 95, Epoch: 2, Train Loss: 30.2307, Val Loss: 0.1248\n",
      "Trial: 76, Epoch: 22, Train Loss: 25.2293, Val Loss: 0.1123\n",
      "Trial: 98, Epoch: 1, Train Loss: 27.3808, Val Loss: 0.1075\n",
      "Trial: 89, Epoch: 6, Train Loss: 26.8145, Val Loss: 0.1055\n",
      "Trial: 96, Epoch: 2, Train Loss: 27.4690, Val Loss: 0.1052\n",
      "Trial: 99, Epoch: 0, Train Loss: 32.4071, Val Loss: 0.1238\n",
      "Trial: 100, Epoch: 0, Train Loss: 36.3162, Val Loss: 0.1100\n",
      "Trial: 79, Epoch: 12, Train Loss: 50.5426, Val Loss: 0.1183\n",
      "Early stopping triggered.\n",
      "Trial: 84, Epoch: 9, Train Loss: 26.5831, Val Loss: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:30:41,580] Trial 79 finished with value: 0.10465392482881787 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004286426737553629, 'batch_size': 8, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 101] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0030668665466399994, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 78, Epoch: 13, Train Loss: 50.8118, Val Loss: 0.1093\n",
      "Trial: 94, Epoch: 3, Train Loss: 30.2023, Val Loss: 0.1286\n",
      "Trial: 63, Epoch: 28, Train Loss: 51.4996, Val Loss: 0.1321\n",
      "Trial: 88, Epoch: 7, Train Loss: 26.6488, Val Loss: 0.1048\n",
      "Trial: 93, Epoch: 4, Train Loss: 26.8978, Val Loss: 0.1093\n",
      "Trial: 97, Epoch: 2, Train Loss: 27.5072, Val Loss: 0.1065\n",
      "Trial: 92, Epoch: 4, Train Loss: 27.0150, Val Loss: 0.1097\n",
      "Trial: 95, Epoch: 3, Train Loss: 30.2214, Val Loss: 0.1258\n",
      "Trial: 76, Epoch: 23, Train Loss: 25.1752, Val Loss: 0.1069\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:32:54,643] Trial 76 finished with value: 0.10401382396618525 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004340404609266826, 'batch_size': 16, 'patience': 9}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 102] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0032965752831307107, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 98, Epoch: 2, Train Loss: 27.0557, Val Loss: 0.1072\n",
      "Trial: 96, Epoch: 3, Train Loss: 27.0702, Val Loss: 0.1109\n",
      "Trial: 89, Epoch: 7, Train Loss: 26.6396, Val Loss: 0.1054\n",
      "Trial: 99, Epoch: 1, Train Loss: 27.7636, Val Loss: 0.1109\n",
      "Trial: 100, Epoch: 1, Train Loss: 27.6005, Val Loss: 0.1104\n",
      "Trial: 84, Epoch: 10, Train Loss: 26.3664, Val Loss: 0.1085\n",
      "Trial: 101, Epoch: 0, Train Loss: 40.9049, Val Loss: 0.1162\n",
      "Trial: 94, Epoch: 4, Train Loss: 30.1613, Val Loss: 0.1268\n",
      "Trial: 88, Epoch: 8, Train Loss: 26.6504, Val Loss: 0.1065\n",
      "Trial: 93, Epoch: 5, Train Loss: 26.7045, Val Loss: 0.1133\n",
      "Trial: 97, Epoch: 3, Train Loss: 27.0294, Val Loss: 0.1144\n",
      "Trial: 92, Epoch: 5, Train Loss: 26.9963, Val Loss: 0.1055\n",
      "Trial: 78, Epoch: 14, Train Loss: 50.6875, Val Loss: 0.1105\n",
      "Trial: 95, Epoch: 4, Train Loss: 30.1802, Val Loss: 0.1252\n",
      "Trial: 98, Epoch: 3, Train Loss: 27.0581, Val Loss: 0.1094\n",
      "Trial: 102, Epoch: 0, Train Loss: 38.7076, Val Loss: 0.1211\n",
      "Trial: 63, Epoch: 29, Train Loss: 51.3030, Val Loss: 0.1176\n",
      "Trial: 96, Epoch: 4, Train Loss: 27.0284, Val Loss: 0.1098\n",
      "Trial: 99, Epoch: 2, Train Loss: 27.0420, Val Loss: 0.1117\n",
      "Trial: 89, Epoch: 8, Train Loss: 26.4777, Val Loss: 0.1054\n",
      "Trial: 100, Epoch: 2, Train Loss: 27.1793, Val Loss: 0.1082\n",
      "Trial: 84, Epoch: 11, Train Loss: 25.9458, Val Loss: 0.1166\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:37:48,128] Trial 84 finished with value: 0.10604702246685822 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004322619315448169, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 103] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0031994019670615846, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 101, Epoch: 1, Train Loss: 28.6575, Val Loss: 0.1079\n",
      "Trial: 94, Epoch: 5, Train Loss: 30.2062, Val Loss: 0.1271\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:38:29,134] Trial 94 finished with value: 0.12611463579038779 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.07178345909159707, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 104] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0031285766166656193, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 93, Epoch: 6, Train Loss: 26.2600, Val Loss: 0.1112\n",
      "Trial: 97, Epoch: 4, Train Loss: 26.9962, Val Loss: 0.1071\n",
      "Trial: 88, Epoch: 9, Train Loss: 26.8156, Val Loss: 0.1054\n",
      "Trial: 92, Epoch: 6, Train Loss: 26.7673, Val Loss: 0.1060\n",
      "Trial: 95, Epoch: 5, Train Loss: 30.0927, Val Loss: 0.1247\n",
      "Trial: 98, Epoch: 4, Train Loss: 26.9701, Val Loss: 0.1056\n",
      "Trial: 102, Epoch: 1, Train Loss: 28.0216, Val Loss: 0.1108\n",
      "Trial: 96, Epoch: 5, Train Loss: 26.9757, Val Loss: 0.1084\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:40:44,487] Trial 96 finished with value: 0.10519575849175453 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006842591065272225, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 105] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0034276296347136915, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 99, Epoch: 3, Train Loss: 26.9251, Val Loss: 0.1109\n",
      "Trial: 89, Epoch: 9, Train Loss: 26.5820, Val Loss: 0.1105\n",
      "Trial: 100, Epoch: 3, Train Loss: 27.1430, Val Loss: 0.1052\n",
      "Trial: 78, Epoch: 15, Train Loss: 50.6189, Val Loss: 0.1061\n",
      "Trial: 103, Epoch: 0, Train Loss: 38.0777, Val Loss: 0.1154\n",
      "Trial: 101, Epoch: 2, Train Loss: 27.6135, Val Loss: 0.1028\n",
      "Trial: 63, Epoch: 30, Train Loss: 51.2973, Val Loss: 0.1218\n",
      "Trial: 104, Epoch: 0, Train Loss: 38.0345, Val Loss: 0.1215\n",
      "Trial: 97, Epoch: 5, Train Loss: 26.6890, Val Loss: 0.1082\n",
      "Early stopping triggered.\n",
      "Trial: 93, Epoch: 7, Train Loss: 25.8829, Val Loss: 0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:42:38,778] Trial 97 finished with value: 0.10654951818287373 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006688141484300457, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 106] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0032432002890416525, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 88, Epoch: 10, Train Loss: 26.5094, Val Loss: 0.1058\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:42:44,699] Trial 88 finished with value: 0.10475160454710325 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003983299095625788, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 107] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00337690897268262, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 92, Epoch: 7, Train Loss: 26.8025, Val Loss: 0.1071\n",
      "Trial: 95, Epoch: 6, Train Loss: 29.9823, Val Loss: 0.1250\n",
      "Trial: 98, Epoch: 5, Train Loss: 27.0607, Val Loss: 0.1120\n",
      "Trial: 102, Epoch: 2, Train Loss: 27.3119, Val Loss: 0.1142\n",
      "Trial: 99, Epoch: 4, Train Loss: 26.8166, Val Loss: 0.1207\n",
      "Trial: 100, Epoch: 4, Train Loss: 26.8403, Val Loss: 0.1033\n",
      "Trial: 89, Epoch: 10, Train Loss: 26.5330, Val Loss: 0.1074\n",
      "Trial: 105, Epoch: 0, Train Loss: 35.8388, Val Loss: 0.1297\n",
      "Trial: 103, Epoch: 1, Train Loss: 27.7200, Val Loss: 0.1110\n",
      "Trial: 101, Epoch: 3, Train Loss: 27.4280, Val Loss: 0.1015\n",
      "Trial: 104, Epoch: 1, Train Loss: 27.5520, Val Loss: 0.1182\n",
      "Trial: 93, Epoch: 8, Train Loss: 25.7345, Val Loss: 0.1119\n",
      "Trial: 78, Epoch: 16, Train Loss: 50.5373, Val Loss: 0.1099\n",
      "Trial: 106, Epoch: 0, Train Loss: 38.4260, Val Loss: 0.1183\n",
      "Trial: 92, Epoch: 8, Train Loss: 26.9340, Val Loss: 0.1020\n",
      "Trial: 107, Epoch: 0, Train Loss: 36.0462, Val Loss: 0.1103\n",
      "Trial: 95, Epoch: 7, Train Loss: 30.1072, Val Loss: 0.1253\n",
      "Trial: 98, Epoch: 6, Train Loss: 26.7576, Val Loss: 0.1042\n",
      "Trial: 102, Epoch: 3, Train Loss: 27.1454, Val Loss: 0.1080\n",
      "Trial: 63, Epoch: 31, Train Loss: 51.1185, Val Loss: 0.1278\n",
      "Trial: 99, Epoch: 5, Train Loss: 26.7798, Val Loss: 0.1141\n",
      "Trial: 100, Epoch: 5, Train Loss: 26.8002, Val Loss: 0.1059\n",
      "Trial: 89, Epoch: 11, Train Loss: 26.2439, Val Loss: 0.1081\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:48:06,566] Trial 89 finished with value: 0.10537206704417865 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005217222945574223, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 108] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0032185586570475334, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 105, Epoch: 1, Train Loss: 27.7425, Val Loss: 0.1199\n",
      "Trial: 103, Epoch: 2, Train Loss: 27.3140, Val Loss: 0.1100\n",
      "Trial: 101, Epoch: 4, Train Loss: 27.2562, Val Loss: 0.1051\n",
      "Trial: 104, Epoch: 2, Train Loss: 27.1984, Val Loss: 0.1087\n",
      "Trial: 93, Epoch: 9, Train Loss: 25.4819, Val Loss: 0.1188\n",
      "Trial: 106, Epoch: 1, Train Loss: 27.9382, Val Loss: 0.1126\n",
      "Trial: 92, Epoch: 9, Train Loss: 26.6643, Val Loss: 0.1062\n",
      "Trial: 107, Epoch: 1, Train Loss: 27.8002, Val Loss: 0.1113\n",
      "Trial: 95, Epoch: 8, Train Loss: 30.0682, Val Loss: 0.1265\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:50:29,660] Trial 95 finished with value: 0.12468669364849726 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.04993880849229204, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 109] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0031675636464845594, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 98, Epoch: 7, Train Loss: 26.7288, Val Loss: 0.1032\n",
      "Trial: 102, Epoch: 4, Train Loss: 26.9816, Val Loss: 0.1095\n",
      "Trial: 78, Epoch: 17, Train Loss: 50.5827, Val Loss: 0.1111\n",
      "Trial: 99, Epoch: 6, Train Loss: 26.4337, Val Loss: 0.1096\n",
      "Trial: 100, Epoch: 6, Train Loss: 26.7498, Val Loss: 0.1103\n",
      "Trial: 105, Epoch: 2, Train Loss: 27.0880, Val Loss: 0.1246\n",
      "Trial: 108, Epoch: 0, Train Loss: 39.4065, Val Loss: 0.1209\n",
      "Trial: 103, Epoch: 3, Train Loss: 27.1753, Val Loss: 0.1068\n",
      "Trial: 101, Epoch: 5, Train Loss: 27.1498, Val Loss: 0.1052\n",
      "Trial: 63, Epoch: 32, Train Loss: 51.2810, Val Loss: 0.1305\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:52:44,540] Trial 63 finished with value: 0.11723927092276701 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0004821792251396847, 'batch_size': 8, 'patience': 8}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 110] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0031925900001321767, 'batch_size': 64, 'patience': 4}\n",
      "Trial: 104, Epoch: 3, Train Loss: 27.0505, Val Loss: 0.1072\n",
      "Trial: 93, Epoch: 10, Train Loss: 25.4436, Val Loss: 0.1201\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:53:11,879] Trial 93 finished with value: 0.1075559658308824 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006458825629113211, 'batch_size': 16, 'patience': 3}. Best is trial 28 with value: 0.10313907822891444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 111] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.003260241367546941, 'batch_size': 64, 'patience': 4}\n",
      "Trial: 106, Epoch: 2, Train Loss: 27.2961, Val Loss: 0.1110\n",
      "Trial: 92, Epoch: 10, Train Loss: 26.6364, Val Loss: 0.1107\n",
      "Trial: 107, Epoch: 2, Train Loss: 27.3587, Val Loss: 0.1075\n",
      "Trial: 102, Epoch: 5, Train Loss: 26.8659, Val Loss: 0.1154\n",
      "Trial: 98, Epoch: 8, Train Loss: 26.6962, Val Loss: 0.1044\n",
      "Trial: 109, Epoch: 0, Train Loss: 40.2917, Val Loss: 0.1568\n",
      "Trial: 99, Epoch: 7, Train Loss: 26.4958, Val Loss: 0.1177\n",
      "Trial: 100, Epoch: 7, Train Loss: 26.7261, Val Loss: 0.1063\n",
      "Trial: 105, Epoch: 3, Train Loss: 27.1468, Val Loss: 0.1180\n",
      "Trial: 110, Epoch: 0, Train Loss: 17.1768, Val Loss: 0.1449\n",
      "Trial: 108, Epoch: 1, Train Loss: 27.8497, Val Loss: 0.1126\n",
      "Trial: 111, Epoch: 0, Train Loss: 14.4628, Val Loss: 0.1348\n",
      "Trial: 103, Epoch: 4, Train Loss: 26.9319, Val Loss: 0.1075\n",
      "Trial: 101, Epoch: 6, Train Loss: 26.8868, Val Loss: 0.1044\n",
      "Trial: 78, Epoch: 18, Train Loss: 50.5688, Val Loss: 0.1086\n",
      "Trial: 104, Epoch: 4, Train Loss: 26.6979, Val Loss: 0.1038\n",
      "Trial: 106, Epoch: 3, Train Loss: 27.0053, Val Loss: 0.1105\n",
      "Trial: 92, Epoch: 11, Train Loss: 26.4783, Val Loss: 0.1138\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:57:18,662] Trial 92 finished with value: 0.10201600082218647 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005971796549482727, 'batch_size': 16, 'patience': 3}. Best is trial 92 with value: 0.10201600082218647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 112] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0033014546825493258, 'batch_size': 64, 'patience': 4}\n",
      "Trial: 107, Epoch: 3, Train Loss: 27.0418, Val Loss: 0.1044\n",
      "Trial: 110, Epoch: 1, Train Loss: 9.1689, Val Loss: 0.1265\n",
      "Trial: 102, Epoch: 6, Train Loss: 26.7374, Val Loss: 0.1106\n",
      "Trial: 98, Epoch: 9, Train Loss: 26.7548, Val Loss: 0.1048\n",
      "Trial: 109, Epoch: 1, Train Loss: 28.4013, Val Loss: 0.1211\n",
      "Trial: 111, Epoch: 1, Train Loss: 7.8142, Val Loss: 0.1175\n",
      "Trial: 99, Epoch: 8, Train Loss: 26.1376, Val Loss: 0.1137\n",
      "Trial: 100, Epoch: 8, Train Loss: 26.7483, Val Loss: 0.1052\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:58:27,573] Trial 100 finished with value: 0.10328497278193632 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003440618340650632, 'batch_size': 16, 'patience': 4}. Best is trial 92 with value: 0.10201600082218647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 113] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0030853175504211143, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 105, Epoch: 4, Train Loss: 26.8690, Val Loss: 0.1130\n",
      "Trial: 108, Epoch: 2, Train Loss: 27.4589, Val Loss: 0.1085\n",
      "Trial: 103, Epoch: 5, Train Loss: 26.8533, Val Loss: 0.1052\n",
      "Trial: 101, Epoch: 7, Train Loss: 27.0049, Val Loss: 0.1021\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 08:59:50,471] Trial 101 finished with value: 0.10151587203145027 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0030668665466399994, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 114] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.003252651288601155, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 112, Epoch: 0, Train Loss: 11.0720, Val Loss: 0.1436\n",
      "Trial: 110, Epoch: 2, Train Loss: 8.2706, Val Loss: 0.1180\n",
      "Trial: 104, Epoch: 5, Train Loss: 26.8303, Val Loss: 0.1057\n",
      "Trial: 106, Epoch: 4, Train Loss: 26.7475, Val Loss: 0.1121\n",
      "Trial: 111, Epoch: 2, Train Loss: 7.2658, Val Loss: 0.1150\n",
      "Trial: 107, Epoch: 4, Train Loss: 26.9161, Val Loss: 0.1109\n",
      "Trial: 78, Epoch: 19, Train Loss: 50.3031, Val Loss: 0.1083\n",
      "Trial: 102, Epoch: 7, Train Loss: 26.6382, Val Loss: 0.1126\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:01:33,412] Trial 102 finished with value: 0.10803884429236253 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0032965752831307107, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 115] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.01193444999569206, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 98, Epoch: 10, Train Loss: 26.9135, Val Loss: 0.1132\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:01:40,123] Trial 98 finished with value: 0.10318582244217396 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006328172313734254, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 109, Epoch: 2, Train Loss: 27.8773, Val Loss: 0.1127\n",
      "\n",
      "[Trial 116] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.003218284754300633, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 99, Epoch: 9, Train Loss: 26.0954, Val Loss: 0.1148\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:01:58,250] Trial 99 finished with value: 0.10961401673654715 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.006447208759377448, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 117] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0034656688000037393, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 113, Epoch: 0, Train Loss: 36.9836, Val Loss: 0.1186\n",
      "Trial: 105, Epoch: 5, Train Loss: 26.6948, Val Loss: 0.1159\n",
      "Trial: 112, Epoch: 1, Train Loss: 7.1990, Val Loss: 0.1268\n",
      "Trial: 110, Epoch: 3, Train Loss: 7.4387, Val Loss: 0.1205\n",
      "Trial: 108, Epoch: 3, Train Loss: 27.1152, Val Loss: 0.1089\n",
      "Trial: 111, Epoch: 3, Train Loss: 7.0655, Val Loss: 0.1084\n",
      "Trial: 103, Epoch: 6, Train Loss: 26.6214, Val Loss: 0.1075\n",
      "Trial: 114, Epoch: 0, Train Loss: 37.3992, Val Loss: 0.1227\n",
      "Trial: 104, Epoch: 6, Train Loss: 26.7818, Val Loss: 0.1047\n",
      "Trial: 106, Epoch: 5, Train Loss: 26.7962, Val Loss: 0.1102\n",
      "Trial: 107, Epoch: 5, Train Loss: 26.8222, Val Loss: 0.1086\n",
      "Trial: 110, Epoch: 4, Train Loss: 7.1765, Val Loss: 0.1204\n",
      "Trial: 112, Epoch: 2, Train Loss: 6.9276, Val Loss: 0.1136\n",
      "Trial: 109, Epoch: 3, Train Loss: 27.5000, Val Loss: 0.1121\n",
      "Trial: 111, Epoch: 4, Train Loss: 6.9510, Val Loss: 0.1233\n",
      "Trial: 115, Epoch: 0, Train Loss: 44.8178, Val Loss: 0.1226\n",
      "Trial: 116, Epoch: 0, Train Loss: 42.7858, Val Loss: 0.1195\n",
      "Trial: 117, Epoch: 0, Train Loss: 36.4103, Val Loss: 0.1220\n",
      "Trial: 113, Epoch: 1, Train Loss: 28.0481, Val Loss: 0.1308\n",
      "Trial: 105, Epoch: 6, Train Loss: 26.3375, Val Loss: 0.1214\n",
      "Trial: 78, Epoch: 20, Train Loss: 50.5016, Val Loss: 0.1088\n",
      "Trial: 108, Epoch: 4, Train Loss: 27.0625, Val Loss: 0.1115\n",
      "Trial: 103, Epoch: 7, Train Loss: 26.5288, Val Loss: 0.1060\n",
      "Trial: 110, Epoch: 5, Train Loss: 7.0445, Val Loss: 0.1124\n",
      "Trial: 112, Epoch: 3, Train Loss: 6.8418, Val Loss: 0.1167\n",
      "Trial: 114, Epoch: 1, Train Loss: 28.4206, Val Loss: 0.1162\n",
      "Trial: 104, Epoch: 7, Train Loss: 26.5476, Val Loss: 0.1092\n",
      "Trial: 106, Epoch: 6, Train Loss: 26.1337, Val Loss: 0.1198\n",
      "Trial: 111, Epoch: 5, Train Loss: 6.9013, Val Loss: 0.1245\n",
      "Trial: 107, Epoch: 6, Train Loss: 26.1501, Val Loss: 0.1097\n",
      "Trial: 109, Epoch: 4, Train Loss: 27.0434, Val Loss: 0.1127\n",
      "Trial: 115, Epoch: 1, Train Loss: 30.2463, Val Loss: 0.1252\n",
      "Trial: 116, Epoch: 1, Train Loss: 28.3935, Val Loss: 0.1163\n",
      "Trial: 117, Epoch: 1, Train Loss: 27.4410, Val Loss: 0.1253\n",
      "Trial: 113, Epoch: 2, Train Loss: 27.5750, Val Loss: 0.1192\n",
      "Trial: 105, Epoch: 7, Train Loss: 26.0056, Val Loss: 0.1267\n",
      "Trial: 110, Epoch: 6, Train Loss: 6.9668, Val Loss: 0.1168\n",
      "Trial: 112, Epoch: 4, Train Loss: 6.8019, Val Loss: 0.1129\n",
      "Trial: 108, Epoch: 5, Train Loss: 26.7689, Val Loss: 0.1110\n",
      "Trial: 111, Epoch: 6, Train Loss: 6.8278, Val Loss: 0.1117\n",
      "Trial: 103, Epoch: 8, Train Loss: 26.1249, Val Loss: 0.1087\n",
      "Trial: 104, Epoch: 8, Train Loss: 26.5000, Val Loss: 0.1082\n",
      "Early stopping triggered.\n",
      "Trial: 114, Epoch: 2, Train Loss: 27.5164, Val Loss: 0.1129\n",
      "Trial: 106, Epoch: 7, Train Loss: 25.7257, Val Loss: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:11:08,781] Trial 104 finished with value: 0.1038272118816773 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0031285766166656193, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 118] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0030738185353686243, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 78, Epoch: 21, Train Loss: 50.5083, Val Loss: 0.1176\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:11:32,016] Trial 78 finished with value: 0.10327730816202003 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.004160963535612333, 'batch_size': 8, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 119] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.013547648157193825, 'batch_size': 64, 'patience': 4}\n",
      "Trial: 107, Epoch: 7, Train Loss: 25.9146, Val Loss: 0.1106\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:11:54,521] Trial 107 finished with value: 0.10440548236171404 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00337690897268262, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 120] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0008426844357980174, 'batch_size': 64, 'patience': 4}\n",
      "Trial: 110, Epoch: 7, Train Loss: 6.8287, Val Loss: 0.1153\n",
      "Trial: 112, Epoch: 5, Train Loss: 6.7576, Val Loss: 0.1128\n",
      "Trial: 109, Epoch: 5, Train Loss: 27.0479, Val Loss: 0.1153\n",
      "Trial: 111, Epoch: 7, Train Loss: 6.8182, Val Loss: 0.1121\n",
      "Early stopping triggered.\n",
      "Trial: 115, Epoch: 2, Train Loss: 30.2151, Val Loss: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:12:44,797] Trial 111 finished with value: 0.10843225071827571 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.003260241367546941, 'batch_size': 64, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 121] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.012309771235537921, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 116, Epoch: 2, Train Loss: 27.5809, Val Loss: 0.1149\n",
      "Trial: 117, Epoch: 2, Train Loss: 27.0932, Val Loss: 0.1184\n",
      "Trial: 113, Epoch: 3, Train Loss: 27.0682, Val Loss: 0.1209\n",
      "Trial: 105, Epoch: 8, Train Loss: 25.7930, Val Loss: 0.1290\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:13:11,198] Trial 105 finished with value: 0.11296271632115046 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0034276296347136915, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 122] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.013233976168051095, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 108, Epoch: 6, Train Loss: 26.7406, Val Loss: 0.1101\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:13:55,601] Trial 108 finished with value: 0.1085186862697204 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0032185586570475334, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 123] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0010648800747274725, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 103, Epoch: 9, Train Loss: 25.8353, Val Loss: 0.1127\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:14:04,084] Trial 103 finished with value: 0.10522824712097645 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0031994019670615846, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 124] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.01352054312755608, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 119, Epoch: 0, Train Loss: 23.4920, Val Loss: 0.1329\n",
      "Trial: 110, Epoch: 8, Train Loss: 6.7156, Val Loss: 0.1359\n",
      "Trial: 106, Epoch: 8, Train Loss: 25.6432, Val Loss: 0.1164\n",
      "Trial: 112, Epoch: 6, Train Loss: 6.7414, Val Loss: 0.1076\n",
      "Trial: 120, Epoch: 0, Train Loss: 14.5061, Val Loss: 0.1403\n",
      "Trial: 114, Epoch: 3, Train Loss: 27.2672, Val Loss: 0.1180\n",
      "Trial: 118, Epoch: 0, Train Loss: 38.6416, Val Loss: 0.1230\n",
      "Trial: 109, Epoch: 6, Train Loss: 26.9148, Val Loss: 0.1089\n",
      "Trial: 115, Epoch: 3, Train Loss: 30.1758, Val Loss: 0.1223\n",
      "Trial: 116, Epoch: 3, Train Loss: 27.4071, Val Loss: 0.1134\n",
      "Trial: 113, Epoch: 4, Train Loss: 26.9645, Val Loss: 0.1120\n",
      "Trial: 119, Epoch: 1, Train Loss: 7.8827, Val Loss: 0.1281\n",
      "Trial: 117, Epoch: 3, Train Loss: 26.7060, Val Loss: 0.1094\n",
      "Trial: 121, Epoch: 0, Train Loss: 41.2741, Val Loss: 0.1326\n",
      "Trial: 110, Epoch: 9, Train Loss: 6.6392, Val Loss: 0.1228\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:16:56,331] Trial 110 finished with value: 0.11241130481163661 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0031925900001321767, 'batch_size': 64, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 125] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.012959509491539135, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 112, Epoch: 7, Train Loss: 6.7183, Val Loss: 0.1162\n",
      "Trial: 120, Epoch: 1, Train Loss: 8.8203, Val Loss: 0.1718\n",
      "Trial: 122, Epoch: 0, Train Loss: 48.6059, Val Loss: 0.1276\n",
      "Trial: 123, Epoch: 0, Train Loss: 45.5960, Val Loss: 0.1407\n",
      "Trial: 124, Epoch: 0, Train Loss: 41.5846, Val Loss: 0.1272\n",
      "Trial: 106, Epoch: 9, Train Loss: 25.5992, Val Loss: 0.1188\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:18:20,586] Trial 106 finished with value: 0.11019454188644887 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0032432002890416525, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 126] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002016957638512919, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 114, Epoch: 4, Train Loss: 26.9418, Val Loss: 0.1120\n",
      "Trial: 118, Epoch: 1, Train Loss: 27.9309, Val Loss: 0.1148\n",
      "Trial: 119, Epoch: 2, Train Loss: 7.6044, Val Loss: 0.1282\n",
      "Trial: 112, Epoch: 8, Train Loss: 6.7406, Val Loss: 0.1169\n",
      "Trial: 120, Epoch: 2, Train Loss: 7.8362, Val Loss: 0.1638\n",
      "Trial: 109, Epoch: 7, Train Loss: 26.7959, Val Loss: 0.1061\n",
      "Trial: 115, Epoch: 4, Train Loss: 30.1811, Val Loss: 0.1228\n",
      "Trial: 113, Epoch: 5, Train Loss: 26.6830, Val Loss: 0.1116\n",
      "Trial: 116, Epoch: 4, Train Loss: 27.2531, Val Loss: 0.1116\n",
      "Trial: 117, Epoch: 4, Train Loss: 26.6629, Val Loss: 0.1173\n",
      "Trial: 121, Epoch: 1, Train Loss: 29.8332, Val Loss: 0.1134\n",
      "Trial: 122, Epoch: 1, Train Loss: 30.3673, Val Loss: 0.1278\n",
      "Trial: 125, Epoch: 0, Train Loss: 51.8715, Val Loss: 0.1338\n",
      "Trial: 119, Epoch: 3, Train Loss: 7.5611, Val Loss: 0.1283\n",
      "Trial: 123, Epoch: 1, Train Loss: 29.2963, Val Loss: 0.1527\n",
      "Trial: 124, Epoch: 1, Train Loss: 30.3435, Val Loss: 0.1270\n",
      "Trial: 112, Epoch: 9, Train Loss: 6.6918, Val Loss: 0.1130\n",
      "Trial: 120, Epoch: 3, Train Loss: 7.4049, Val Loss: 0.1631\n",
      "Trial: 114, Epoch: 5, Train Loss: 26.7754, Val Loss: 0.1094\n",
      "Trial: 126, Epoch: 0, Train Loss: 36.4367, Val Loss: 0.1311\n",
      "Trial: 118, Epoch: 2, Train Loss: 27.4256, Val Loss: 0.1156\n",
      "Trial: 109, Epoch: 8, Train Loss: 26.6129, Val Loss: 0.1069\n",
      "Trial: 115, Epoch: 5, Train Loss: 30.1707, Val Loss: 0.1221\n",
      "Trial: 113, Epoch: 6, Train Loss: 26.6570, Val Loss: 0.1093\n",
      "Trial: 119, Epoch: 4, Train Loss: 7.5391, Val Loss: 0.1276\n",
      "Trial: 121, Epoch: 2, Train Loss: 28.2951, Val Loss: 0.1209\n",
      "Trial: 117, Epoch: 5, Train Loss: 26.5696, Val Loss: 0.1117\n",
      "Trial: 116, Epoch: 5, Train Loss: 27.0625, Val Loss: 0.1092\n",
      "Trial: 122, Epoch: 2, Train Loss: 30.1053, Val Loss: 0.1271\n",
      "Trial: 125, Epoch: 1, Train Loss: 30.3768, Val Loss: 0.1286\n",
      "Trial: 112, Epoch: 10, Train Loss: 6.6760, Val Loss: 0.1187\n",
      "Early stopping triggered.\n",
      "Trial: 120, Epoch: 4, Train Loss: 7.1882, Val Loss: 0.1591\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:24:33,444] Trial 112 finished with value: 0.10763698468605677 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0033014546825493258, 'batch_size': 64, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 127] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0019817439717754112, 'batch_size': 16, 'patience': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:24:34,497] Trial 120 finished with value: 0.14030460019906363 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0008426844357980174, 'batch_size': 64, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 128] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.012450007506592014, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 123, Epoch: 2, Train Loss: 27.9868, Val Loss: 0.1473\n",
      "Trial: 124, Epoch: 2, Train Loss: 30.1113, Val Loss: 0.1255\n",
      "Trial: 126, Epoch: 1, Train Loss: 28.0215, Val Loss: 0.1246\n",
      "Trial: 114, Epoch: 6, Train Loss: 26.8137, Val Loss: 0.1117\n",
      "Trial: 118, Epoch: 3, Train Loss: 27.0369, Val Loss: 0.1155\n",
      "Trial: 119, Epoch: 5, Train Loss: 7.5230, Val Loss: 0.1278\n",
      "Trial: 109, Epoch: 9, Train Loss: 26.7798, Val Loss: 0.1040\n",
      "Trial: 115, Epoch: 6, Train Loss: 30.1013, Val Loss: 0.1225\n",
      "Trial: 113, Epoch: 7, Train Loss: 26.7277, Val Loss: 0.1107\n",
      "Trial: 121, Epoch: 3, Train Loss: 27.5602, Val Loss: 0.1254\n",
      "Trial: 117, Epoch: 6, Train Loss: 26.6690, Val Loss: 0.1083\n",
      "Trial: 116, Epoch: 6, Train Loss: 26.6499, Val Loss: 0.1128\n",
      "Trial: 122, Epoch: 3, Train Loss: 30.0239, Val Loss: 0.1260\n",
      "Trial: 125, Epoch: 2, Train Loss: 30.1413, Val Loss: 0.1271\n",
      "Trial: 127, Epoch: 0, Train Loss: 36.3609, Val Loss: 0.1183\n",
      "Trial: 128, Epoch: 0, Train Loss: 37.4342, Val Loss: 0.1202\n",
      "Trial: 119, Epoch: 6, Train Loss: 7.5135, Val Loss: 0.1273\n",
      "Trial: 123, Epoch: 3, Train Loss: 27.5543, Val Loss: 0.1217\n",
      "Trial: 124, Epoch: 3, Train Loss: 30.1116, Val Loss: 0.1254\n",
      "Trial: 126, Epoch: 2, Train Loss: 27.5835, Val Loss: 0.1143\n",
      "Trial: 114, Epoch: 7, Train Loss: 26.4386, Val Loss: 0.1185\n",
      "Trial: 118, Epoch: 4, Train Loss: 26.9432, Val Loss: 0.1061\n",
      "Trial: 109, Epoch: 10, Train Loss: 26.7844, Val Loss: 0.1062\n",
      "Trial: 115, Epoch: 7, Train Loss: 30.1484, Val Loss: 0.1224\n",
      "Trial: 113, Epoch: 8, Train Loss: 26.1853, Val Loss: 0.1136\n",
      "Trial: 119, Epoch: 7, Train Loss: 7.5298, Val Loss: 0.1276\n",
      "Trial: 121, Epoch: 4, Train Loss: 27.4746, Val Loss: 0.1191\n",
      "Trial: 117, Epoch: 7, Train Loss: 26.6161, Val Loss: 0.1132\n",
      "Trial: 116, Epoch: 7, Train Loss: 25.9056, Val Loss: 0.1159\n",
      "Trial: 125, Epoch: 3, Train Loss: 29.7139, Val Loss: 0.1129\n",
      "Trial: 122, Epoch: 4, Train Loss: 30.0328, Val Loss: 0.1258\n",
      "Trial: 127, Epoch: 1, Train Loss: 27.6298, Val Loss: 0.1130\n",
      "Trial: 128, Epoch: 1, Train Loss: 28.0254, Val Loss: 0.1129\n",
      "Trial: 123, Epoch: 4, Train Loss: 27.3129, Val Loss: 0.1303\n",
      "Trial: 124, Epoch: 4, Train Loss: 30.0083, Val Loss: 0.1256\n",
      "Trial: 126, Epoch: 3, Train Loss: 27.0999, Val Loss: 0.1134\n",
      "Trial: 114, Epoch: 8, Train Loss: 25.9595, Val Loss: 0.1415\n",
      "Trial: 118, Epoch: 5, Train Loss: 26.9856, Val Loss: 0.1106\n",
      "Trial: 119, Epoch: 8, Train Loss: 7.5272, Val Loss: 0.1273\n",
      "Trial: 115, Epoch: 8, Train Loss: 30.1772, Val Loss: 0.1223\n",
      "Trial: 109, Epoch: 11, Train Loss: 26.5338, Val Loss: 0.1064\n",
      "Trial: 113, Epoch: 9, Train Loss: 25.8954, Val Loss: 0.1205\n",
      "Trial: 121, Epoch: 5, Train Loss: 27.2468, Val Loss: 0.1116\n",
      "Trial: 117, Epoch: 8, Train Loss: 26.4654, Val Loss: 0.1103\n",
      "Trial: 116, Epoch: 8, Train Loss: 25.7238, Val Loss: 0.1152\n",
      "Trial: 125, Epoch: 4, Train Loss: 27.8071, Val Loss: 0.1102\n",
      "Trial: 122, Epoch: 5, Train Loss: 29.9993, Val Loss: 0.1260\n",
      "Trial: 127, Epoch: 2, Train Loss: 27.0416, Val Loss: 0.1133\n",
      "Trial: 128, Epoch: 2, Train Loss: 27.7479, Val Loss: 0.1144\n",
      "Trial: 119, Epoch: 9, Train Loss: 7.5161, Val Loss: 0.1274\n",
      "Trial: 123, Epoch: 5, Train Loss: 27.2226, Val Loss: 0.1182\n",
      "Trial: 124, Epoch: 5, Train Loss: 30.0156, Val Loss: 0.1254\n",
      "Trial: 126, Epoch: 4, Train Loss: 26.9089, Val Loss: 0.1034\n",
      "Trial: 114, Epoch: 9, Train Loss: 25.7951, Val Loss: 0.1264\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:36:50,314] Trial 114 finished with value: 0.10940238138039907 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.003252651288601155, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 129] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.011813496600272862, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 118, Epoch: 6, Train Loss: 26.8083, Val Loss: 0.1116\n",
      "Trial: 115, Epoch: 9, Train Loss: 30.1360, Val Loss: 0.1223\n",
      "Trial: 109, Epoch: 12, Train Loss: 26.2629, Val Loss: 0.1153\n",
      "Trial: 113, Epoch: 10, Train Loss: 25.6894, Val Loss: 0.1151\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:38:13,208] Trial 113 finished with value: 0.10929994036753972 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0030853175504211143, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 130] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.013480171247978599, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 119, Epoch: 10, Train Loss: 7.5212, Val Loss: 0.1275\n",
      "Trial: 121, Epoch: 6, Train Loss: 26.9393, Val Loss: 0.1075\n",
      "Trial: 117, Epoch: 9, Train Loss: 26.3413, Val Loss: 0.1177\n",
      "Trial: 116, Epoch: 9, Train Loss: 25.6416, Val Loss: 0.1235\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:38:35,036] Trial 116 finished with value: 0.10917587988078595 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.003218284754300633, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 131] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.011724235620834442, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 125, Epoch: 5, Train Loss: 27.4429, Val Loss: 0.1076\n",
      "Trial: 122, Epoch: 6, Train Loss: 29.9412, Val Loss: 0.1260\n",
      "Trial: 127, Epoch: 3, Train Loss: 26.8888, Val Loss: 0.1090\n",
      "Trial: 128, Epoch: 3, Train Loss: 27.7315, Val Loss: 0.1143\n",
      "Trial: 123, Epoch: 6, Train Loss: 27.2061, Val Loss: 0.1171\n",
      "Trial: 126, Epoch: 5, Train Loss: 26.8040, Val Loss: 0.1065\n",
      "Trial: 124, Epoch: 6, Train Loss: 29.9895, Val Loss: 0.1267\n",
      "Trial: 119, Epoch: 11, Train Loss: 7.5372, Val Loss: 0.1285\n",
      "Trial: 118, Epoch: 7, Train Loss: 26.7749, Val Loss: 0.1100\n",
      "Trial: 129, Epoch: 0, Train Loss: 34.7359, Val Loss: 0.1120\n",
      "Trial: 115, Epoch: 10, Train Loss: 30.1020, Val Loss: 0.1229\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:41:51,633] Trial 115 finished with value: 0.12213252956668535 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.01193444999569206, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 132] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0021148185889511752, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 109, Epoch: 13, Train Loss: 25.8830, Val Loss: 0.1184\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:41:56,273] Trial 109 finished with value: 0.10398743748664856 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0031675636464845594, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 133] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002051132046514457, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 121, Epoch: 7, Train Loss: 26.9223, Val Loss: 0.1157\n",
      "Trial: 117, Epoch: 10, Train Loss: 26.2968, Val Loss: 0.1132\n",
      "Trial: 130, Epoch: 0, Train Loss: 36.2917, Val Loss: 0.1201\n",
      "Trial: 125, Epoch: 6, Train Loss: 27.1731, Val Loss: 0.1055\n",
      "Trial: 122, Epoch: 7, Train Loss: 30.0012, Val Loss: 0.1263\n",
      "Trial: 131, Epoch: 0, Train Loss: 34.3598, Val Loss: 0.1063\n",
      "Trial: 127, Epoch: 4, Train Loss: 26.8374, Val Loss: 0.1118\n",
      "Trial: 119, Epoch: 12, Train Loss: 7.5001, Val Loss: 0.1273\n",
      "Early stopping triggered.\n",
      "Trial: 128, Epoch: 4, Train Loss: 27.2320, Val Loss: 0.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:43:12,770] Trial 119 finished with value: 0.1272593835989634 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.013547648157193825, 'batch_size': 64, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 134] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002059649931687306, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 126, Epoch: 6, Train Loss: 26.6634, Val Loss: 0.1056\n",
      "Trial: 123, Epoch: 7, Train Loss: 26.9330, Val Loss: 0.1075\n",
      "Trial: 124, Epoch: 7, Train Loss: 30.0166, Val Loss: 0.1257\n",
      "Trial: 118, Epoch: 8, Train Loss: 26.5767, Val Loss: 0.1088\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:44:31,422] Trial 118 finished with value: 0.1060673492650191 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0030738185353686243, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 135] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0019114639131686518, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 129, Epoch: 1, Train Loss: 27.7178, Val Loss: 0.1097\n",
      "Trial: 121, Epoch: 8, Train Loss: 26.9161, Val Loss: 0.1198\n",
      "Trial: 130, Epoch: 1, Train Loss: 27.9417, Val Loss: 0.1155\n",
      "Trial: 117, Epoch: 11, Train Loss: 26.2350, Val Loss: 0.1156\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:45:47,654] Trial 117 finished with value: 0.10834182103474935 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0034656688000037393, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 136] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002076186285775375, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 132, Epoch: 0, Train Loss: 37.0696, Val Loss: 0.1108\n",
      "Trial: 133, Epoch: 0, Train Loss: 42.4822, Val Loss: 0.1339\n",
      "Trial: 125, Epoch: 7, Train Loss: 27.0475, Val Loss: 0.1053\n",
      "Trial: 122, Epoch: 8, Train Loss: 29.9515, Val Loss: 0.1261\n",
      "Trial: 131, Epoch: 1, Train Loss: 27.7216, Val Loss: 0.1093\n",
      "Trial: 127, Epoch: 5, Train Loss: 26.4731, Val Loss: 0.1054\n",
      "Trial: 128, Epoch: 5, Train Loss: 27.1624, Val Loss: 0.1084\n",
      "Trial: 126, Epoch: 7, Train Loss: 26.2810, Val Loss: 0.1124\n",
      "Trial: 134, Epoch: 0, Train Loss: 35.4898, Val Loss: 0.1183\n",
      "Trial: 123, Epoch: 8, Train Loss: 26.8453, Val Loss: 0.1119\n",
      "Trial: 124, Epoch: 8, Train Loss: 29.9870, Val Loss: 0.1262\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:47:25,311] Trial 124 finished with value: 0.1253742725898822 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.01352054312755608, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 137] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0020336913576187938, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 129, Epoch: 2, Train Loss: 27.2173, Val Loss: 0.1094\n",
      "Trial: 135, Epoch: 0, Train Loss: 36.5022, Val Loss: 0.1218\n",
      "Trial: 121, Epoch: 9, Train Loss: 26.8346, Val Loss: 0.1083\n",
      "Trial: 130, Epoch: 2, Train Loss: 27.4436, Val Loss: 0.1091\n",
      "Trial: 132, Epoch: 1, Train Loss: 27.9427, Val Loss: 0.1089\n",
      "Trial: 125, Epoch: 8, Train Loss: 27.1006, Val Loss: 0.1093\n",
      "Trial: 133, Epoch: 1, Train Loss: 27.8559, Val Loss: 0.1125\n",
      "Trial: 136, Epoch: 0, Train Loss: 44.3380, Val Loss: 0.1232\n",
      "Trial: 122, Epoch: 9, Train Loss: 29.9419, Val Loss: 0.1261\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:49:46,092] Trial 122 finished with value: 0.12579911773403485 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.013233976168051095, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 138] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0011566345789677716, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 131, Epoch: 2, Train Loss: 27.1279, Val Loss: 0.1158\n",
      "Trial: 127, Epoch: 6, Train Loss: 26.0062, Val Loss: 0.1086\n",
      "Trial: 128, Epoch: 6, Train Loss: 26.8122, Val Loss: 0.1077\n",
      "Trial: 126, Epoch: 8, Train Loss: 25.8973, Val Loss: 0.1057\n",
      "Trial: 134, Epoch: 1, Train Loss: 27.5111, Val Loss: 0.1086\n",
      "Trial: 123, Epoch: 9, Train Loss: 26.7355, Val Loss: 0.1132\n",
      "Trial: 137, Epoch: 0, Train Loss: 40.5836, Val Loss: 0.1094\n",
      "Trial: 129, Epoch: 3, Train Loss: 27.1671, Val Loss: 0.1157\n",
      "Trial: 135, Epoch: 1, Train Loss: 27.5044, Val Loss: 0.1167\n",
      "Trial: 121, Epoch: 10, Train Loss: 26.6929, Val Loss: 0.1066\n",
      "Trial: 130, Epoch: 3, Train Loss: 27.1952, Val Loss: 0.1200\n",
      "Trial: 132, Epoch: 2, Train Loss: 27.5261, Val Loss: 0.1085\n",
      "Trial: 125, Epoch: 9, Train Loss: 27.0748, Val Loss: 0.1069\n",
      "Trial: 133, Epoch: 2, Train Loss: 27.2953, Val Loss: 0.1098\n",
      "Trial: 136, Epoch: 1, Train Loss: 29.0478, Val Loss: 0.1098\n",
      "Trial: 131, Epoch: 3, Train Loss: 27.1732, Val Loss: 0.1086\n",
      "Trial: 138, Epoch: 0, Train Loss: 40.8068, Val Loss: 0.1166\n",
      "Trial: 127, Epoch: 7, Train Loss: 25.7627, Val Loss: 0.1098\n",
      "Trial: 128, Epoch: 7, Train Loss: 26.9464, Val Loss: 0.1077\n",
      "Trial: 126, Epoch: 9, Train Loss: 25.8216, Val Loss: 0.1108\n",
      "Early stopping triggered.\n",
      "Trial: 134, Epoch: 2, Train Loss: 27.2633, Val Loss: 0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 09:54:05,697] Trial 126 finished with value: 0.10337618875006835 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002016957638512919, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 139] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0021547548144749623, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 123, Epoch: 10, Train Loss: 26.6873, Val Loss: 0.1116\n",
      "Trial: 137, Epoch: 1, Train Loss: 28.1548, Val Loss: 0.1065\n",
      "Trial: 129, Epoch: 4, Train Loss: 26.8097, Val Loss: 0.1080\n",
      "Trial: 135, Epoch: 2, Train Loss: 27.0304, Val Loss: 0.1180\n",
      "Trial: 121, Epoch: 11, Train Loss: 25.9390, Val Loss: 0.1068\n",
      "Trial: 130, Epoch: 4, Train Loss: 26.7007, Val Loss: 0.1139\n",
      "Trial: 132, Epoch: 3, Train Loss: 27.2537, Val Loss: 0.1088\n",
      "Trial: 125, Epoch: 10, Train Loss: 26.7750, Val Loss: 0.1067\n",
      "Trial: 133, Epoch: 3, Train Loss: 27.1138, Val Loss: 0.1128\n",
      "Trial: 136, Epoch: 2, Train Loss: 27.4588, Val Loss: 0.1090\n",
      "Trial: 131, Epoch: 4, Train Loss: 26.9661, Val Loss: 0.1110\n",
      "Trial: 138, Epoch: 1, Train Loss: 28.6574, Val Loss: 0.1188\n",
      "Trial: 127, Epoch: 8, Train Loss: 25.6017, Val Loss: 0.1088\n",
      "Trial: 128, Epoch: 8, Train Loss: 26.9350, Val Loss: 0.1035\n",
      "Trial: 134, Epoch: 3, Train Loss: 26.7041, Val Loss: 0.1082\n",
      "Trial: 139, Epoch: 0, Train Loss: 42.6763, Val Loss: 0.1320\n",
      "Trial: 123, Epoch: 11, Train Loss: 26.6246, Val Loss: 0.1150\n",
      "Trial: 137, Epoch: 2, Train Loss: 27.3706, Val Loss: 0.1083\n",
      "Trial: 129, Epoch: 5, Train Loss: 26.7848, Val Loss: 0.1065\n",
      "Trial: 135, Epoch: 3, Train Loss: 27.0980, Val Loss: 0.1097\n",
      "Trial: 130, Epoch: 5, Train Loss: 26.2255, Val Loss: 0.1095\n",
      "Trial: 121, Epoch: 12, Train Loss: 25.6298, Val Loss: 0.1114\n",
      "Trial: 132, Epoch: 4, Train Loss: 27.0534, Val Loss: 0.1027\n",
      "Trial: 125, Epoch: 11, Train Loss: 26.8390, Val Loss: 0.1122\n",
      "Trial: 133, Epoch: 4, Train Loss: 26.7097, Val Loss: 0.1111\n",
      "Trial: 136, Epoch: 3, Train Loss: 27.1752, Val Loss: 0.1086\n",
      "Trial: 131, Epoch: 5, Train Loss: 26.8390, Val Loss: 0.1060\n",
      "Trial: 138, Epoch: 2, Train Loss: 27.4030, Val Loss: 0.1224\n",
      "Trial: 127, Epoch: 9, Train Loss: 25.3296, Val Loss: 0.1127\n",
      "Trial: 128, Epoch: 9, Train Loss: 26.8909, Val Loss: 0.1028\n",
      "Trial: 134, Epoch: 4, Train Loss: 26.4599, Val Loss: 0.1101\n",
      "Trial: 139, Epoch: 1, Train Loss: 30.1796, Val Loss: 0.1120\n",
      "Trial: 123, Epoch: 12, Train Loss: 26.1763, Val Loss: 0.1143\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:01:45,806] Trial 123 finished with value: 0.10745524254937967 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.0010648800747274725, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 140] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002103260979501323, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 137, Epoch: 3, Train Loss: 27.0142, Val Loss: 0.1053\n",
      "Trial: 129, Epoch: 6, Train Loss: 26.9117, Val Loss: 0.1113\n",
      "Trial: 135, Epoch: 4, Train Loss: 26.8249, Val Loss: 0.1114\n",
      "Trial: 130, Epoch: 6, Train Loss: 25.8185, Val Loss: 0.1125\n",
      "Trial: 121, Epoch: 13, Train Loss: 25.5139, Val Loss: 0.1156\n",
      "Trial: 132, Epoch: 5, Train Loss: 27.0599, Val Loss: 0.1089\n",
      "Trial: 125, Epoch: 12, Train Loss: 26.2699, Val Loss: 0.1095\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:03:37,870] Trial 125 finished with value: 0.1053497868279616 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.012959509491539135, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 141] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0022913915124634222, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 136, Epoch: 4, Train Loss: 26.8917, Val Loss: 0.1061\n",
      "Trial: 133, Epoch: 5, Train Loss: 26.7036, Val Loss: 0.1063\n",
      "Trial: 131, Epoch: 6, Train Loss: 26.7168, Val Loss: 0.1118\n",
      "Trial: 138, Epoch: 3, Train Loss: 27.0827, Val Loss: 0.1155\n",
      "Trial: 134, Epoch: 5, Train Loss: 26.0512, Val Loss: 0.1148\n",
      "Trial: 127, Epoch: 10, Train Loss: 25.3414, Val Loss: 0.1168\n",
      "Early stopping triggered.\n",
      "Trial: 128, Epoch: 10, Train Loss: 26.6668, Val Loss: 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:04:39,435] Trial 127 finished with value: 0.1054280649870634 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0019817439717754112, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 142] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002559797657235342, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 139, Epoch: 2, Train Loss: 27.7692, Val Loss: 0.1092\n",
      "Trial: 137, Epoch: 4, Train Loss: 26.9262, Val Loss: 0.1053\n",
      "Trial: 140, Epoch: 0, Train Loss: 41.8562, Val Loss: 0.1279\n",
      "Trial: 129, Epoch: 7, Train Loss: 26.9278, Val Loss: 0.1173\n",
      "Trial: 135, Epoch: 5, Train Loss: 26.7834, Val Loss: 0.1145\n",
      "Trial: 130, Epoch: 7, Train Loss: 25.7395, Val Loss: 0.1117\n",
      "Trial: 121, Epoch: 14, Train Loss: 25.5943, Val Loss: 0.1089\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:06:49,362] Trial 121 finished with value: 0.10663409146169821 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.012309771235537921, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 143] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0025332698785768635, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 132, Epoch: 6, Train Loss: 26.8869, Val Loss: 0.1036\n",
      "Trial: 136, Epoch: 5, Train Loss: 26.8875, Val Loss: 0.1070\n",
      "Trial: 133, Epoch: 6, Train Loss: 26.6694, Val Loss: 0.1063\n",
      "Trial: 141, Epoch: 0, Train Loss: 45.4067, Val Loss: 0.1205\n",
      "Trial: 131, Epoch: 7, Train Loss: 26.1632, Val Loss: 0.1097\n",
      "Trial: 138, Epoch: 4, Train Loss: 26.8987, Val Loss: 0.1167\n",
      "Trial: 134, Epoch: 6, Train Loss: 25.8212, Val Loss: 0.1104\n",
      "Trial: 128, Epoch: 11, Train Loss: 26.0142, Val Loss: 0.1086\n",
      "Trial: 139, Epoch: 3, Train Loss: 27.4196, Val Loss: 0.1124\n",
      "Trial: 142, Epoch: 0, Train Loss: 38.2636, Val Loss: 0.1163\n",
      "Trial: 137, Epoch: 5, Train Loss: 26.7352, Val Loss: 0.1049\n",
      "Trial: 140, Epoch: 1, Train Loss: 28.0084, Val Loss: 0.1120\n",
      "Trial: 129, Epoch: 8, Train Loss: 26.6340, Val Loss: 0.1065\n",
      "Trial: 135, Epoch: 6, Train Loss: 26.6609, Val Loss: 0.1068\n",
      "Trial: 130, Epoch: 8, Train Loss: 25.5881, Val Loss: 0.1134\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:10:09,689] Trial 130 finished with value: 0.1091185811907053 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.013480171247978599, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 144] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0012922875483766768, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 132, Epoch: 7, Train Loss: 26.7887, Val Loss: 0.1064\n",
      "Trial: 143, Epoch: 0, Train Loss: 41.1900, Val Loss: 0.1193\n",
      "Trial: 136, Epoch: 6, Train Loss: 26.6690, Val Loss: 0.1064\n",
      "Trial: 133, Epoch: 7, Train Loss: 26.7364, Val Loss: 0.1062\n",
      "Trial: 141, Epoch: 1, Train Loss: 28.6386, Val Loss: 0.1164\n",
      "Trial: 131, Epoch: 8, Train Loss: 25.8280, Val Loss: 0.1109\n",
      "Trial: 138, Epoch: 5, Train Loss: 26.6025, Val Loss: 0.1156\n",
      "Trial: 134, Epoch: 7, Train Loss: 25.6892, Val Loss: 0.1103\n",
      "Trial: 128, Epoch: 12, Train Loss: 25.8254, Val Loss: 0.1072\n",
      "Trial: 139, Epoch: 4, Train Loss: 27.1225, Val Loss: 0.1086\n",
      "Trial: 142, Epoch: 1, Train Loss: 28.2979, Val Loss: 0.1188\n",
      "Trial: 137, Epoch: 6, Train Loss: 26.2898, Val Loss: 0.1091\n",
      "Trial: 140, Epoch: 2, Train Loss: 27.0828, Val Loss: 0.1118\n",
      "Trial: 129, Epoch: 9, Train Loss: 26.6838, Val Loss: 0.1102\n",
      "Trial: 135, Epoch: 7, Train Loss: 26.5876, Val Loss: 0.1115\n",
      "Trial: 144, Epoch: 0, Train Loss: 39.9903, Val Loss: 0.1216\n",
      "Trial: 132, Epoch: 8, Train Loss: 26.7608, Val Loss: 0.1083\n",
      "Trial: 143, Epoch: 1, Train Loss: 28.0647, Val Loss: 0.1181\n",
      "Trial: 136, Epoch: 7, Train Loss: 26.5733, Val Loss: 0.1053\n",
      "Trial: 141, Epoch: 2, Train Loss: 27.3285, Val Loss: 0.1173\n",
      "Trial: 133, Epoch: 8, Train Loss: 26.7055, Val Loss: 0.1074\n",
      "Trial: 131, Epoch: 9, Train Loss: 25.6951, Val Loss: 0.1109\n",
      "Trial: 138, Epoch: 6, Train Loss: 26.1756, Val Loss: 0.1239\n",
      "Trial: 134, Epoch: 8, Train Loss: 25.6657, Val Loss: 0.1112\n",
      "Trial: 139, Epoch: 5, Train Loss: 27.0074, Val Loss: 0.1086\n",
      "Trial: 128, Epoch: 13, Train Loss: 25.5906, Val Loss: 0.1125\n",
      "Trial: 142, Epoch: 2, Train Loss: 27.6835, Val Loss: 0.1155\n",
      "Trial: 137, Epoch: 7, Train Loss: 25.9842, Val Loss: 0.1114\n",
      "Trial: 140, Epoch: 3, Train Loss: 27.0132, Val Loss: 0.1090\n",
      "Trial: 129, Epoch: 10, Train Loss: 26.7500, Val Loss: 0.1060\n",
      "Trial: 135, Epoch: 8, Train Loss: 26.5010, Val Loss: 0.1077\n",
      "Trial: 144, Epoch: 1, Train Loss: 28.1131, Val Loss: 0.1166\n",
      "Trial: 132, Epoch: 9, Train Loss: 26.6578, Val Loss: 0.1082\n",
      "Early stopping triggered.\n",
      "Trial: 143, Epoch: 2, Train Loss: 27.2101, Val Loss: 0.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:17:39,828] Trial 132 finished with value: 0.1026540782302618 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0021148185889511752, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 145] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002438069186793156, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 136, Epoch: 8, Train Loss: 26.3699, Val Loss: 0.1072\n",
      "Trial: 141, Epoch: 3, Train Loss: 27.0773, Val Loss: 0.1202\n",
      "Trial: 133, Epoch: 9, Train Loss: 26.5163, Val Loss: 0.1070\n",
      "Trial: 138, Epoch: 7, Train Loss: 25.8674, Val Loss: 0.1244\n",
      "Trial: 131, Epoch: 10, Train Loss: 25.5582, Val Loss: 0.1075\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:18:17,320] Trial 131 finished with value: 0.10596080236136914 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.011724235620834442, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 146] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013106404793429111, 'batch_size': 16, 'patience': 6}\n",
      "Trial: 134, Epoch: 9, Train Loss: 25.5856, Val Loss: 0.1123\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:18:31,701] Trial 134 finished with value: 0.10815709307789803 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002059649931687306, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 147] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007800903850071213, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 139, Epoch: 6, Train Loss: 26.8936, Val Loss: 0.1093\n",
      "Trial: 128, Epoch: 14, Train Loss: 25.5956, Val Loss: 0.1171\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:18:55,159] Trial 128 finished with value: 0.10279691480100155 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.012450007506592014, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 148] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.008079228164342573, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 142, Epoch: 3, Train Loss: 27.1372, Val Loss: 0.1145\n",
      "Trial: 137, Epoch: 8, Train Loss: 25.6996, Val Loss: 0.1150\n",
      "Trial: 140, Epoch: 4, Train Loss: 26.7796, Val Loss: 0.1068\n",
      "Trial: 129, Epoch: 11, Train Loss: 26.7978, Val Loss: 0.1082\n",
      "Trial: 135, Epoch: 9, Train Loss: 26.2140, Val Loss: 0.1115\n",
      "Trial: 144, Epoch: 2, Train Loss: 27.4371, Val Loss: 0.1119\n",
      "Trial: 143, Epoch: 3, Train Loss: 26.8970, Val Loss: 0.1137\n",
      "Trial: 136, Epoch: 9, Train Loss: 26.0372, Val Loss: 0.1091\n",
      "Trial: 141, Epoch: 4, Train Loss: 26.9072, Val Loss: 0.1119\n",
      "Trial: 133, Epoch: 10, Train Loss: 26.6183, Val Loss: 0.1051\n",
      "Trial: 145, Epoch: 0, Train Loss: 41.5565, Val Loss: 0.1187\n",
      "Trial: 138, Epoch: 8, Train Loss: 25.6441, Val Loss: 0.1248\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:21:47,631] Trial 138 finished with value: 0.1155088105549415 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0011566345789677716, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 149] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00801488814513114, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 146, Epoch: 0, Train Loss: 47.6133, Val Loss: 0.1147\n",
      "Trial: 139, Epoch: 7, Train Loss: 26.6224, Val Loss: 0.1099\n",
      "Trial: 147, Epoch: 0, Train Loss: 39.7077, Val Loss: 0.1160\n",
      "Trial: 142, Epoch: 4, Train Loss: 27.0913, Val Loss: 0.1126\n",
      "Trial: 148, Epoch: 0, Train Loss: 36.7759, Val Loss: 0.1242\n",
      "Trial: 137, Epoch: 9, Train Loss: 25.6502, Val Loss: 0.1092\n",
      "Trial: 140, Epoch: 5, Train Loss: 26.5100, Val Loss: 0.1102\n",
      "Trial: 129, Epoch: 12, Train Loss: 26.6883, Val Loss: 0.1080\n",
      "Trial: 135, Epoch: 10, Train Loss: 25.9220, Val Loss: 0.1133\n",
      "Trial: 144, Epoch: 3, Train Loss: 27.2357, Val Loss: 0.1057\n",
      "Trial: 143, Epoch: 4, Train Loss: 26.7167, Val Loss: 0.1127\n",
      "Trial: 136, Epoch: 10, Train Loss: 25.6687, Val Loss: 0.1072\n",
      "Trial: 141, Epoch: 5, Train Loss: 26.7718, Val Loss: 0.1130\n",
      "Trial: 145, Epoch: 1, Train Loss: 29.0938, Val Loss: 0.1113\n",
      "Trial: 133, Epoch: 11, Train Loss: 26.4050, Val Loss: 0.1068\n",
      "Trial: 149, Epoch: 0, Train Loss: 34.7654, Val Loss: 0.1251\n",
      "Trial: 146, Epoch: 1, Train Loss: 31.6980, Val Loss: 0.1096\n",
      "Trial: 139, Epoch: 8, Train Loss: 26.7552, Val Loss: 0.1067\n",
      "Trial: 147, Epoch: 1, Train Loss: 28.0798, Val Loss: 0.1131\n",
      "Trial: 142, Epoch: 5, Train Loss: 26.8491, Val Loss: 0.1141\n",
      "Trial: 148, Epoch: 1, Train Loss: 28.0116, Val Loss: 0.1188\n",
      "Trial: 137, Epoch: 10, Train Loss: 25.4576, Val Loss: 0.1165\n",
      "Trial: 140, Epoch: 6, Train Loss: 26.0690, Val Loss: 0.1112\n",
      "Trial: 129, Epoch: 13, Train Loss: 26.5867, Val Loss: 0.1063\n",
      "Trial: 135, Epoch: 11, Train Loss: 25.6135, Val Loss: 0.1224\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:27:42,433] Trial 135 finished with value: 0.10684921542803447 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0019114639131686518, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 150] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007824878379495602, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 144, Epoch: 4, Train Loss: 26.8897, Val Loss: 0.1078\n",
      "Trial: 143, Epoch: 5, Train Loss: 26.6407, Val Loss: 0.1102\n",
      "Trial: 136, Epoch: 11, Train Loss: 25.4866, Val Loss: 0.1127\n",
      "Trial: 141, Epoch: 6, Train Loss: 26.6130, Val Loss: 0.1136\n",
      "Trial: 145, Epoch: 2, Train Loss: 27.8936, Val Loss: 0.1054\n",
      "Trial: 133, Epoch: 12, Train Loss: 26.2559, Val Loss: 0.1082\n",
      "Trial: 149, Epoch: 1, Train Loss: 27.8631, Val Loss: 0.1103\n",
      "Trial: 139, Epoch: 9, Train Loss: 26.5968, Val Loss: 0.1137\n",
      "Trial: 146, Epoch: 2, Train Loss: 28.4002, Val Loss: 0.1138\n",
      "Trial: 147, Epoch: 2, Train Loss: 27.7371, Val Loss: 0.1136\n",
      "Trial: 142, Epoch: 6, Train Loss: 26.6736, Val Loss: 0.1122\n",
      "Trial: 148, Epoch: 2, Train Loss: 27.4626, Val Loss: 0.1081\n",
      "Trial: 137, Epoch: 11, Train Loss: 25.4859, Val Loss: 0.1122\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:30:29,237] Trial 137 finished with value: 0.10490232184529305 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0020336913576187938, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 151] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007683626393029735, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 140, Epoch: 7, Train Loss: 25.7351, Val Loss: 0.1134\n",
      "Trial: 129, Epoch: 14, Train Loss: 26.5850, Val Loss: 0.1094\n",
      "Trial: 144, Epoch: 5, Train Loss: 26.9316, Val Loss: 0.1062\n",
      "Trial: 150, Epoch: 0, Train Loss: 33.7626, Val Loss: 0.1140\n",
      "Trial: 143, Epoch: 6, Train Loss: 26.6830, Val Loss: 0.1123\n",
      "Trial: 136, Epoch: 12, Train Loss: 25.4742, Val Loss: 0.1151\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:31:54,227] Trial 136 finished with value: 0.1052679494023323 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002076186285775375, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 141, Epoch: 7, Train Loss: 26.4362, Val Loss: 0.1126\n",
      "\n",
      "[Trial 152] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.008275857716480184, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 145, Epoch: 3, Train Loss: 27.3995, Val Loss: 0.1055\n",
      "Trial: 133, Epoch: 13, Train Loss: 26.2169, Val Loss: 0.1071\n",
      "Trial: 149, Epoch: 2, Train Loss: 27.6492, Val Loss: 0.1050\n",
      "Trial: 139, Epoch: 10, Train Loss: 26.3299, Val Loss: 0.1108\n",
      "Trial: 146, Epoch: 3, Train Loss: 27.7227, Val Loss: 0.1097\n",
      "Trial: 147, Epoch: 3, Train Loss: 27.0520, Val Loss: 0.1055\n",
      "Trial: 142, Epoch: 7, Train Loss: 26.5977, Val Loss: 0.1160\n",
      "Trial: 148, Epoch: 3, Train Loss: 27.0302, Val Loss: 0.1182\n",
      "Trial: 140, Epoch: 8, Train Loss: 25.6504, Val Loss: 0.1113\n",
      "Trial: 151, Epoch: 0, Train Loss: 39.2426, Val Loss: 0.1158\n",
      "Trial: 129, Epoch: 15, Train Loss: 26.5709, Val Loss: 0.1059\n",
      "Trial: 144, Epoch: 6, Train Loss: 26.7486, Val Loss: 0.1085\n",
      "Trial: 150, Epoch: 1, Train Loss: 27.8005, Val Loss: 0.1227\n",
      "Trial: 143, Epoch: 7, Train Loss: 26.6976, Val Loss: 0.1121\n",
      "Trial: 141, Epoch: 8, Train Loss: 26.0576, Val Loss: 0.1116\n",
      "Trial: 145, Epoch: 4, Train Loss: 27.4058, Val Loss: 0.1061\n",
      "Trial: 152, Epoch: 0, Train Loss: 35.3604, Val Loss: 0.1185\n",
      "Trial: 133, Epoch: 14, Train Loss: 25.8893, Val Loss: 0.1146\n",
      "Trial: 149, Epoch: 3, Train Loss: 27.2209, Val Loss: 0.1087\n",
      "Trial: 139, Epoch: 11, Train Loss: 26.1148, Val Loss: 0.1071\n",
      "Trial: 147, Epoch: 4, Train Loss: 26.9848, Val Loss: 0.1065\n",
      "Trial: 146, Epoch: 4, Train Loss: 27.4951, Val Loss: 0.1026\n",
      "Trial: 142, Epoch: 8, Train Loss: 26.5257, Val Loss: 0.1096\n",
      "Trial: 148, Epoch: 4, Train Loss: 27.1379, Val Loss: 0.1135\n",
      "Trial: 140, Epoch: 9, Train Loss: 25.5893, Val Loss: 0.1157\n",
      "Trial: 151, Epoch: 1, Train Loss: 28.2499, Val Loss: 0.1171\n",
      "Trial: 129, Epoch: 16, Train Loss: 26.1964, Val Loss: 0.1103\n",
      "Trial: 144, Epoch: 7, Train Loss: 26.8389, Val Loss: 0.1038\n",
      "Trial: 143, Epoch: 8, Train Loss: 26.6813, Val Loss: 0.1096\n",
      "Trial: 150, Epoch: 2, Train Loss: 27.7248, Val Loss: 0.1198\n",
      "Trial: 141, Epoch: 9, Train Loss: 25.7910, Val Loss: 0.1164\n",
      "Trial: 145, Epoch: 5, Train Loss: 27.0778, Val Loss: 0.1073\n",
      "Trial: 152, Epoch: 1, Train Loss: 28.0601, Val Loss: 0.1236\n",
      "Trial: 133, Epoch: 15, Train Loss: 25.6047, Val Loss: 0.1132\n",
      "Trial: 149, Epoch: 4, Train Loss: 27.2292, Val Loss: 0.1092\n",
      "Trial: 139, Epoch: 12, Train Loss: 25.6350, Val Loss: 0.1164\n",
      "Trial: 147, Epoch: 5, Train Loss: 26.5842, Val Loss: 0.1076\n",
      "Trial: 146, Epoch: 5, Train Loss: 27.1996, Val Loss: 0.1094\n",
      "Trial: 142, Epoch: 9, Train Loss: 26.4723, Val Loss: 0.1116\n",
      "Trial: 148, Epoch: 5, Train Loss: 26.9815, Val Loss: 0.1102\n",
      "Trial: 140, Epoch: 10, Train Loss: 25.4786, Val Loss: 0.1149\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:41:21,831] Trial 140 finished with value: 0.10678817195196946 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002103260979501323, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 153] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0076958168082868405, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 151, Epoch: 2, Train Loss: 27.9421, Val Loss: 0.1156\n",
      "Trial: 129, Epoch: 17, Train Loss: 25.8958, Val Loss: 0.1088\n",
      "Trial: 144, Epoch: 8, Train Loss: 26.7156, Val Loss: 0.1078\n",
      "Trial: 143, Epoch: 9, Train Loss: 26.5907, Val Loss: 0.1111\n",
      "Trial: 150, Epoch: 3, Train Loss: 27.2804, Val Loss: 0.1073\n",
      "Trial: 141, Epoch: 10, Train Loss: 25.5544, Val Loss: 0.1129\n",
      "Trial: 145, Epoch: 6, Train Loss: 26.9219, Val Loss: 0.1092\n",
      "Trial: 152, Epoch: 2, Train Loss: 27.5386, Val Loss: 0.1136\n",
      "Trial: 133, Epoch: 16, Train Loss: 25.5041, Val Loss: 0.1112\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:42:54,864] Trial 133 finished with value: 0.10511716542144617 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002051132046514457, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 154] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007812520123683862, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 139, Epoch: 13, Train Loss: 25.4339, Val Loss: 0.1125\n",
      "Trial: 149, Epoch: 5, Train Loss: 27.0357, Val Loss: 0.1055\n",
      "Trial: 147, Epoch: 6, Train Loss: 25.9724, Val Loss: 0.1062\n",
      "Trial: 146, Epoch: 6, Train Loss: 27.1298, Val Loss: 0.1071\n",
      "Trial: 142, Epoch: 10, Train Loss: 26.1746, Val Loss: 0.1125\n",
      "Trial: 148, Epoch: 6, Train Loss: 26.7643, Val Loss: 0.1140\n",
      "Trial: 151, Epoch: 3, Train Loss: 27.6051, Val Loss: 0.1150\n",
      "Trial: 153, Epoch: 0, Train Loss: 36.3769, Val Loss: 0.1364\n",
      "Trial: 144, Epoch: 9, Train Loss: 26.7904, Val Loss: 0.1043\n",
      "Trial: 129, Epoch: 18, Train Loss: 25.8364, Val Loss: 0.1139\n",
      "Trial: 143, Epoch: 10, Train Loss: 26.5229, Val Loss: 0.1077\n",
      "Trial: 150, Epoch: 4, Train Loss: 27.3124, Val Loss: 0.1065\n",
      "Trial: 141, Epoch: 11, Train Loss: 25.4469, Val Loss: 0.1173\n",
      "Trial: 145, Epoch: 7, Train Loss: 26.8972, Val Loss: 0.1082\n",
      "Trial: 152, Epoch: 3, Train Loss: 27.3851, Val Loss: 0.1108\n",
      "Trial: 139, Epoch: 14, Train Loss: 25.2984, Val Loss: 0.1183\n",
      "Trial: 149, Epoch: 6, Train Loss: 26.9687, Val Loss: 0.1030\n",
      "Trial: 154, Epoch: 0, Train Loss: 34.2894, Val Loss: 0.1118\n",
      "Trial: 147, Epoch: 7, Train Loss: 25.7081, Val Loss: 0.1104\n",
      "Trial: 146, Epoch: 7, Train Loss: 26.9199, Val Loss: 0.1133\n",
      "Trial: 142, Epoch: 11, Train Loss: 25.8060, Val Loss: 0.1144\n",
      "Trial: 148, Epoch: 7, Train Loss: 26.6477, Val Loss: 0.1152\n",
      "Trial: 151, Epoch: 4, Train Loss: 27.4754, Val Loss: 0.1165\n",
      "Trial: 144, Epoch: 10, Train Loss: 26.6950, Val Loss: 0.1063\n",
      "Trial: 153, Epoch: 1, Train Loss: 27.7476, Val Loss: 0.1067\n",
      "Trial: 129, Epoch: 19, Train Loss: 25.6270, Val Loss: 0.1241\n",
      "Trial: 143, Epoch: 11, Train Loss: 26.4624, Val Loss: 0.1117\n",
      "Trial: 141, Epoch: 12, Train Loss: 25.3466, Val Loss: 0.1127\n",
      "Trial: 150, Epoch: 5, Train Loss: 27.1067, Val Loss: 0.1181\n",
      "Trial: 152, Epoch: 4, Train Loss: 27.0222, Val Loss: 0.1067\n",
      "Trial: 145, Epoch: 8, Train Loss: 26.8137, Val Loss: 0.1087\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:49:46,505] Trial 145 finished with value: 0.10544695556163788 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002438069186793156, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 155] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00783173145318305, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 139, Epoch: 15, Train Loss: 25.2514, Val Loss: 0.1110\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:50:07,975] Trial 139 finished with value: 0.10670686128238836 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0021547548144749623, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 156] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007426019541565703, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 149, Epoch: 7, Train Loss: 27.0384, Val Loss: 0.1097\n",
      "Trial: 147, Epoch: 8, Train Loss: 25.5149, Val Loss: 0.1066\n",
      "Trial: 154, Epoch: 1, Train Loss: 27.6968, Val Loss: 0.1098\n",
      "Trial: 146, Epoch: 8, Train Loss: 26.4397, Val Loss: 0.1074\n",
      "Trial: 142, Epoch: 12, Train Loss: 25.5134, Val Loss: 0.1189\n",
      "Trial: 148, Epoch: 8, Train Loss: 26.2487, Val Loss: 0.1095\n",
      "Trial: 151, Epoch: 5, Train Loss: 27.2092, Val Loss: 0.1095\n",
      "Trial: 144, Epoch: 11, Train Loss: 26.4246, Val Loss: 0.1064\n",
      "Trial: 153, Epoch: 2, Train Loss: 27.1614, Val Loss: 0.1102\n",
      "Trial: 129, Epoch: 20, Train Loss: 25.6205, Val Loss: 0.1206\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:52:29,607] Trial 129 finished with value: 0.10593230289717516 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.011813496600272862, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 157] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007725365006946101, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 143, Epoch: 12, Train Loss: 26.3592, Val Loss: 0.1077\n",
      "Trial: 141, Epoch: 13, Train Loss: 25.3722, Val Loss: 0.1134\n",
      "Trial: 150, Epoch: 6, Train Loss: 26.8290, Val Loss: 0.1099\n",
      "Trial: 152, Epoch: 5, Train Loss: 26.8643, Val Loss: 0.1106\n",
      "Trial: 155, Epoch: 0, Train Loss: 33.8580, Val Loss: 0.1190\n",
      "Trial: 149, Epoch: 8, Train Loss: 26.8177, Val Loss: 0.1073\n",
      "Trial: 147, Epoch: 9, Train Loss: 25.5907, Val Loss: 0.1089\n",
      "Trial: 154, Epoch: 2, Train Loss: 27.1612, Val Loss: 0.1102\n",
      "Trial: 156, Epoch: 0, Train Loss: 36.4180, Val Loss: 0.1138\n",
      "Trial: 146, Epoch: 9, Train Loss: 25.9868, Val Loss: 0.1158\n",
      "Trial: 142, Epoch: 13, Train Loss: 25.3506, Val Loss: 0.1181\n",
      "Trial: 148, Epoch: 9, Train Loss: 25.8620, Val Loss: 0.1103\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:54:56,325] Trial 148 finished with value: 0.10808869438866774 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.008079228164342573, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 158] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005550239910069987, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 151, Epoch: 6, Train Loss: 26.8090, Val Loss: 0.1070\n",
      "Trial: 144, Epoch: 12, Train Loss: 26.1059, Val Loss: 0.1076\n",
      "Trial: 153, Epoch: 3, Train Loss: 26.8542, Val Loss: 0.1087\n",
      "Trial: 143, Epoch: 13, Train Loss: 26.3096, Val Loss: 0.1132\n",
      "Trial: 141, Epoch: 14, Train Loss: 25.2793, Val Loss: 0.1141\n",
      "Trial: 157, Epoch: 0, Train Loss: 33.2873, Val Loss: 0.1104\n",
      "Trial: 150, Epoch: 7, Train Loss: 26.5928, Val Loss: 0.1103\n",
      "Trial: 152, Epoch: 6, Train Loss: 26.9300, Val Loss: 0.1048\n",
      "Trial: 155, Epoch: 1, Train Loss: 27.8229, Val Loss: 0.1248\n",
      "Trial: 149, Epoch: 9, Train Loss: 26.8510, Val Loss: 0.1038\n",
      "Trial: 147, Epoch: 10, Train Loss: 25.4867, Val Loss: 0.1064\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:57:22,172] Trial 147 finished with value: 0.10547855148712794 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007800903850071213, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 159] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.028684135760918994, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 156, Epoch: 1, Train Loss: 27.9113, Val Loss: 0.1135\n",
      "Trial: 154, Epoch: 3, Train Loss: 27.1530, Val Loss: 0.1054\n",
      "Trial: 146, Epoch: 10, Train Loss: 25.8574, Val Loss: 0.1130\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:57:44,850] Trial 146 finished with value: 0.10257348281641801 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013106404793429111, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 160] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001210577941115154, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 142, Epoch: 14, Train Loss: 25.3443, Val Loss: 0.1125\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:58:25,172] Trial 142 finished with value: 0.10962119723359744 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.002559797657235342, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 161] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.027221944227673954, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 158, Epoch: 0, Train Loss: 36.6050, Val Loss: 0.1160\n",
      "Trial: 151, Epoch: 7, Train Loss: 26.2408, Val Loss: 0.1091\n",
      "Trial: 144, Epoch: 13, Train Loss: 25.7751, Val Loss: 0.1115\n",
      "Trial: 153, Epoch: 4, Train Loss: 26.7538, Val Loss: 0.1072\n",
      "Trial: 143, Epoch: 14, Train Loss: 25.9881, Val Loss: 0.1136\n",
      "Trial: 141, Epoch: 15, Train Loss: 25.2187, Val Loss: 0.1117\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 10:59:53,185] Trial 141 finished with value: 0.11163010994593302 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0022913915124634222, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 162] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005186698971923331, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 150, Epoch: 8, Train Loss: 26.6780, Val Loss: 0.1094\n",
      "Trial: 157, Epoch: 1, Train Loss: 27.6194, Val Loss: 0.1168\n",
      "Trial: 152, Epoch: 7, Train Loss: 26.8294, Val Loss: 0.1098\n",
      "Trial: 155, Epoch: 2, Train Loss: 27.2093, Val Loss: 0.1073\n",
      "Trial: 149, Epoch: 10, Train Loss: 26.6875, Val Loss: 0.1130\n",
      "Trial: 156, Epoch: 2, Train Loss: 27.3518, Val Loss: 0.1077\n",
      "Trial: 154, Epoch: 4, Train Loss: 26.6172, Val Loss: 0.1080\n",
      "Trial: 159, Epoch: 0, Train Loss: 45.5522, Val Loss: 0.1263\n",
      "Trial: 160, Epoch: 0, Train Loss: 51.3182, Val Loss: 0.1337\n",
      "Trial: 161, Epoch: 0, Train Loss: 39.2405, Val Loss: 0.1269\n",
      "Trial: 158, Epoch: 1, Train Loss: 27.5521, Val Loss: 0.1126\n",
      "Trial: 144, Epoch: 14, Train Loss: 25.6496, Val Loss: 0.1086\n",
      "Early stopping triggered.\n",
      "Trial: 151, Epoch: 8, Train Loss: 25.7168, Val Loss: 0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:02:47,239] Trial 144 finished with value: 0.1037999818722407 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0012922875483766768, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 163] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001264037217158056, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 153, Epoch: 5, Train Loss: 26.5905, Val Loss: 0.1130\n",
      "Trial: 143, Epoch: 15, Train Loss: 25.6070, Val Loss: 0.1146\n",
      "Trial: 150, Epoch: 9, Train Loss: 26.4729, Val Loss: 0.1060\n",
      "Trial: 157, Epoch: 2, Train Loss: 27.3502, Val Loss: 0.1168\n",
      "Trial: 152, Epoch: 8, Train Loss: 26.6138, Val Loss: 0.1072\n",
      "Trial: 162, Epoch: 0, Train Loss: 38.5087, Val Loss: 0.1257\n",
      "Trial: 155, Epoch: 3, Train Loss: 26.8691, Val Loss: 0.1133\n",
      "Trial: 149, Epoch: 11, Train Loss: 26.3321, Val Loss: 0.1056\n",
      "Trial: 156, Epoch: 3, Train Loss: 27.1528, Val Loss: 0.1111\n",
      "Trial: 154, Epoch: 5, Train Loss: 26.1276, Val Loss: 0.1082\n",
      "Trial: 159, Epoch: 1, Train Loss: 30.1478, Val Loss: 0.1262\n",
      "Trial: 160, Epoch: 1, Train Loss: 33.9476, Val Loss: 0.1212\n",
      "Trial: 161, Epoch: 1, Train Loss: 30.1171, Val Loss: 0.1275\n",
      "Trial: 158, Epoch: 2, Train Loss: 27.1258, Val Loss: 0.1123\n",
      "Trial: 151, Epoch: 9, Train Loss: 25.6500, Val Loss: 0.1110\n",
      "Trial: 163, Epoch: 0, Train Loss: 48.3584, Val Loss: 0.1258\n",
      "Trial: 143, Epoch: 16, Train Loss: 25.4586, Val Loss: 0.1118\n",
      "Early stopping triggered.\n",
      "Trial: 153, Epoch: 6, Train Loss: 26.4036, Val Loss: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:06:43,761] Trial 143 finished with value: 0.10766640367607276 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0025332698785768635, 'batch_size': 16, 'patience': 6}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 164] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013561558559139536, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 150, Epoch: 10, Train Loss: 26.5584, Val Loss: 0.1145\n",
      "Trial: 157, Epoch: 3, Train Loss: 26.9850, Val Loss: 0.1119\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:07:15,321] Trial 157 finished with value: 0.11038653353850046 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007725365006946101, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 152, Epoch: 9, Train Loss: 26.9128, Val Loss: 0.1126\n",
      "\n",
      "[Trial 165] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013606602296146967, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 162, Epoch: 1, Train Loss: 28.1074, Val Loss: 0.1046\n",
      "Trial: 149, Epoch: 12, Train Loss: 25.8957, Val Loss: 0.1070\n",
      "Trial: 155, Epoch: 4, Train Loss: 26.8737, Val Loss: 0.1089\n",
      "Trial: 156, Epoch: 4, Train Loss: 26.8962, Val Loss: 0.1079\n",
      "Trial: 154, Epoch: 6, Train Loss: 25.7698, Val Loss: 0.1081\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:08:14,721] Trial 154 finished with value: 0.10535078085958957 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007812520123683862, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 159, Epoch: 2, Train Loss: 30.1612, Val Loss: 0.1265\n",
      "\n",
      "[Trial 166] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001247249106322453, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 160, Epoch: 2, Train Loss: 30.7502, Val Loss: 0.1208\n",
      "Trial: 161, Epoch: 2, Train Loss: 29.9941, Val Loss: 0.1265\n",
      "Trial: 158, Epoch: 3, Train Loss: 26.9308, Val Loss: 0.1101\n",
      "Trial: 151, Epoch: 10, Train Loss: 25.5187, Val Loss: 0.1107\n",
      "Trial: 163, Epoch: 1, Train Loss: 33.3691, Val Loss: 0.1157\n",
      "Trial: 153, Epoch: 7, Train Loss: 26.0882, Val Loss: 0.1120\n",
      "Trial: 164, Epoch: 0, Train Loss: 36.2809, Val Loss: 0.1336\n",
      "Trial: 150, Epoch: 11, Train Loss: 26.0367, Val Loss: 0.1080\n",
      "Trial: 152, Epoch: 10, Train Loss: 26.7983, Val Loss: 0.1129\n",
      "Trial: 162, Epoch: 2, Train Loss: 27.4986, Val Loss: 0.1072\n",
      "Trial: 165, Epoch: 0, Train Loss: 38.3411, Val Loss: 0.1279\n",
      "Trial: 149, Epoch: 13, Train Loss: 25.6125, Val Loss: 0.1099\n",
      "Early stopping triggered.\n",
      "Trial: 155, Epoch: 5, Train Loss: 26.4499, Val Loss: 0.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:11:25,001] Trial 149 finished with value: 0.10303736031055451 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00801488814513114, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 167] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013290340545583986, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 156, Epoch: 5, Train Loss: 26.7351, Val Loss: 0.1141\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:11:33,261] Trial 156 finished with value: 0.10772813086708387 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007426019541565703, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 168] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005431453039597459, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 159, Epoch: 3, Train Loss: 30.0778, Val Loss: 0.1290\n",
      "Trial: 166, Epoch: 0, Train Loss: 47.3498, Val Loss: 0.1354\n",
      "Trial: 160, Epoch: 3, Train Loss: 28.1916, Val Loss: 0.1110\n",
      "Trial: 161, Epoch: 3, Train Loss: 29.9919, Val Loss: 0.1264\n",
      "Trial: 158, Epoch: 4, Train Loss: 26.6325, Val Loss: 0.1129\n",
      "Trial: 151, Epoch: 11, Train Loss: 25.3968, Val Loss: 0.1092\n",
      "Trial: 163, Epoch: 2, Train Loss: 28.9852, Val Loss: 0.1133\n",
      "Trial: 153, Epoch: 8, Train Loss: 25.7107, Val Loss: 0.1149\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:13:54,795] Trial 153 finished with value: 0.10669859088957309 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0076958168082868405, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 169] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013365048339319448, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 164, Epoch: 1, Train Loss: 27.5155, Val Loss: 0.1180\n",
      "Trial: 152, Epoch: 11, Train Loss: 26.7072, Val Loss: 0.1058\n",
      "Trial: 162, Epoch: 3, Train Loss: 27.1007, Val Loss: 0.1087\n",
      "Trial: 150, Epoch: 12, Train Loss: 25.6878, Val Loss: 0.1117\n",
      "Trial: 165, Epoch: 1, Train Loss: 27.9336, Val Loss: 0.1162\n",
      "Trial: 155, Epoch: 6, Train Loss: 26.7207, Val Loss: 0.1112\n",
      "Trial: 159, Epoch: 4, Train Loss: 30.0414, Val Loss: 0.1274\n",
      "Early stopping triggered.\n",
      "Trial: 167, Epoch: 0, Train Loss: 58.9597, Val Loss: 0.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:15:18,710] Trial 159 finished with value: 0.12622088218728703 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.028684135760918994, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 170] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0014314964066016096, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 168, Epoch: 0, Train Loss: 36.5267, Val Loss: 0.1203\n",
      "Trial: 166, Epoch: 1, Train Loss: 32.5447, Val Loss: 0.1115\n",
      "Trial: 160, Epoch: 4, Train Loss: 27.4280, Val Loss: 0.1106\n",
      "Trial: 161, Epoch: 4, Train Loss: 30.2214, Val Loss: 0.1266\n",
      "Trial: 158, Epoch: 5, Train Loss: 26.6807, Val Loss: 0.1135\n",
      "Trial: 151, Epoch: 12, Train Loss: 25.3508, Val Loss: 0.1092\n",
      "Trial: 163, Epoch: 3, Train Loss: 27.7716, Val Loss: 0.1115\n",
      "Trial: 164, Epoch: 2, Train Loss: 27.0749, Val Loss: 0.1115\n",
      "Trial: 152, Epoch: 12, Train Loss: 26.5538, Val Loss: 0.1094\n",
      "Trial: 162, Epoch: 4, Train Loss: 27.0188, Val Loss: 0.1050\n",
      "Early stopping triggered.\n",
      "Trial: 169, Epoch: 0, Train Loss: 40.4288, Val Loss: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:17:52,608] Trial 162 finished with value: 0.10455313834051291 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005186698971923331, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 171] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 4.3275817518498327e-05, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 150, Epoch: 13, Train Loss: 25.4968, Val Loss: 0.1131\n",
      "Trial: 165, Epoch: 2, Train Loss: 27.1365, Val Loss: 0.1166\n",
      "Trial: 155, Epoch: 7, Train Loss: 26.5870, Val Loss: 0.1105\n",
      "Trial: 167, Epoch: 1, Train Loss: 33.1298, Val Loss: 0.1164\n",
      "Trial: 168, Epoch: 1, Train Loss: 27.7602, Val Loss: 0.1135\n",
      "Trial: 170, Epoch: 0, Train Loss: 36.4904, Val Loss: 0.1410\n",
      "Trial: 166, Epoch: 2, Train Loss: 28.5008, Val Loss: 0.1098\n",
      "Trial: 160, Epoch: 5, Train Loss: 27.2542, Val Loss: 0.1099\n",
      "Trial: 161, Epoch: 5, Train Loss: 30.0569, Val Loss: 0.1266\n",
      "Trial: 158, Epoch: 6, Train Loss: 26.6608, Val Loss: 0.1040\n",
      "Trial: 151, Epoch: 13, Train Loss: 25.2932, Val Loss: 0.1109\n",
      "Early stopping triggered.\n",
      "Trial: 163, Epoch: 4, Train Loss: 27.3671, Val Loss: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:20:41,073] Trial 151 finished with value: 0.10696529634296895 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007683626393029735, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 172] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013617200354204848, 'batch_size': 16, 'patience': 7}\n",
      "Trial: 164, Epoch: 3, Train Loss: 26.6400, Val Loss: 0.1079\n",
      "Trial: 152, Epoch: 13, Train Loss: 26.6849, Val Loss: 0.1100\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:21:21,354] Trial 152 finished with value: 0.10482586386303107 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.008275857716480184, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 173] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0011752831364883034, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 169, Epoch: 1, Train Loss: 28.3174, Val Loss: 0.1230\n",
      "Trial: 150, Epoch: 14, Train Loss: 25.4603, Val Loss: 0.1066\n",
      "Trial: 171, Epoch: 0, Train Loss: 152.4289, Val Loss: 0.3679\n",
      "Trial: 165, Epoch: 3, Train Loss: 26.7377, Val Loss: 0.1121\n",
      "Trial: 155, Epoch: 8, Train Loss: 26.5173, Val Loss: 0.1074\n",
      "Trial: 167, Epoch: 2, Train Loss: 28.9580, Val Loss: 0.1134\n",
      "Trial: 168, Epoch: 2, Train Loss: 26.9570, Val Loss: 0.1107\n",
      "Trial: 170, Epoch: 1, Train Loss: 27.7514, Val Loss: 0.1136\n",
      "Trial: 166, Epoch: 3, Train Loss: 27.5934, Val Loss: 0.1083\n",
      "Trial: 160, Epoch: 6, Train Loss: 26.9868, Val Loss: 0.1109\n",
      "Trial: 161, Epoch: 6, Train Loss: 30.0120, Val Loss: 0.1273\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:23:50,381] Trial 161 finished with value: 0.1264155718187491 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.027221944227673954, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 174] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001461383233255441, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 158, Epoch: 7, Train Loss: 26.6747, Val Loss: 0.1072\n",
      "Trial: 163, Epoch: 5, Train Loss: 27.2528, Val Loss: 0.1098\n",
      "Trial: 172, Epoch: 0, Train Loss: 45.0637, Val Loss: 0.1275\n",
      "Trial: 164, Epoch: 4, Train Loss: 26.7039, Val Loss: 0.1074\n",
      "Trial: 150, Epoch: 15, Train Loss: 25.4191, Val Loss: 0.1103\n",
      "Trial: 169, Epoch: 2, Train Loss: 27.6134, Val Loss: 0.1141\n",
      "Trial: 171, Epoch: 1, Train Loss: 77.2512, Val Loss: 0.2772\n",
      "Trial: 173, Epoch: 0, Train Loss: 52.8219, Val Loss: 0.1465\n",
      "Trial: 165, Epoch: 4, Train Loss: 26.6731, Val Loss: 0.1150\n",
      "Trial: 155, Epoch: 9, Train Loss: 26.4679, Val Loss: 0.1094\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:25:37,529] Trial 155 finished with value: 0.10727593017121156 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00783173145318305, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 175] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 4.131834415773663e-05, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 167, Epoch: 3, Train Loss: 27.7117, Val Loss: 0.1122\n",
      "Trial: 168, Epoch: 3, Train Loss: 26.8480, Val Loss: 0.1159\n",
      "Trial: 170, Epoch: 2, Train Loss: 27.2936, Val Loss: 0.1152\n",
      "Trial: 166, Epoch: 4, Train Loss: 27.1347, Val Loss: 0.1070\n",
      "Trial: 160, Epoch: 7, Train Loss: 26.8807, Val Loss: 0.1075\n",
      "Trial: 158, Epoch: 8, Train Loss: 26.6196, Val Loss: 0.1071\n",
      "Trial: 163, Epoch: 6, Train Loss: 27.1691, Val Loss: 0.1076\n",
      "Trial: 174, Epoch: 0, Train Loss: 46.8656, Val Loss: 0.1199\n",
      "Trial: 164, Epoch: 5, Train Loss: 26.7345, Val Loss: 0.1107\n",
      "Trial: 172, Epoch: 1, Train Loss: 31.6604, Val Loss: 0.1089\n",
      "Trial: 150, Epoch: 16, Train Loss: 25.2219, Val Loss: 0.1102\n",
      "Early stopping triggered.\n",
      "Trial: 169, Epoch: 3, Train Loss: 27.1547, Val Loss: 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:28:40,633] Trial 150 finished with value: 0.10603674526015917 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.007824878379495602, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 176] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0014094584870005438, 'batch_size': 16, 'patience': 9}\n",
      "Trial: 171, Epoch: 2, Train Loss: 61.1767, Val Loss: 0.2428\n",
      "Trial: 173, Epoch: 1, Train Loss: 34.2920, Val Loss: 0.1188\n",
      "Trial: 165, Epoch: 5, Train Loss: 26.4224, Val Loss: 0.1172\n",
      "Trial: 167, Epoch: 4, Train Loss: 27.4599, Val Loss: 0.1142\n",
      "Trial: 168, Epoch: 4, Train Loss: 26.5972, Val Loss: 0.1089\n",
      "Trial: 175, Epoch: 0, Train Loss: 119.8558, Val Loss: 0.4954\n",
      "Trial: 170, Epoch: 3, Train Loss: 27.0185, Val Loss: 0.1140\n",
      "Trial: 166, Epoch: 5, Train Loss: 27.0880, Val Loss: 0.1041\n",
      "Trial: 160, Epoch: 8, Train Loss: 26.6279, Val Loss: 0.1126\n",
      "Trial: 158, Epoch: 9, Train Loss: 26.5442, Val Loss: 0.1069\n",
      "Early stopping triggered.\n",
      "Trial: 163, Epoch: 7, Train Loss: 26.9185, Val Loss: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:31:11,497] Trial 158 finished with value: 0.1039950193837285 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005550239910069987, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 177] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013877435053784412, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 174, Epoch: 1, Train Loss: 30.7928, Val Loss: 0.1113\n",
      "Trial: 164, Epoch: 6, Train Loss: 26.4575, Val Loss: 0.1107\n",
      "Trial: 172, Epoch: 2, Train Loss: 28.4283, Val Loss: 0.1127\n",
      "Trial: 169, Epoch: 4, Train Loss: 27.0088, Val Loss: 0.1126\n",
      "Trial: 171, Epoch: 3, Train Loss: 53.8925, Val Loss: 0.2318\n",
      "Trial: 173, Epoch: 2, Train Loss: 29.8262, Val Loss: 0.1173\n",
      "Trial: 176, Epoch: 0, Train Loss: 45.2621, Val Loss: 0.1266\n",
      "Trial: 165, Epoch: 6, Train Loss: 26.1701, Val Loss: 0.1183\n",
      "Trial: 168, Epoch: 5, Train Loss: 26.5763, Val Loss: 0.1152\n",
      "Trial: 167, Epoch: 5, Train Loss: 27.2357, Val Loss: 0.1122\n",
      "Trial: 175, Epoch: 1, Train Loss: 66.8105, Val Loss: 0.3277\n",
      "Trial: 170, Epoch: 4, Train Loss: 26.8692, Val Loss: 0.1099\n",
      "Trial: 166, Epoch: 6, Train Loss: 26.9323, Val Loss: 0.1057\n",
      "Trial: 160, Epoch: 9, Train Loss: 26.0746, Val Loss: 0.1169\n",
      "Trial: 163, Epoch: 8, Train Loss: 26.8702, Val Loss: 0.1088\n",
      "Trial: 174, Epoch: 2, Train Loss: 27.8041, Val Loss: 0.1055\n",
      "Trial: 177, Epoch: 0, Train Loss: 39.5185, Val Loss: 0.1148\n",
      "Trial: 164, Epoch: 7, Train Loss: 26.4542, Val Loss: 0.1107\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:35:15,051] Trial 164 finished with value: 0.10738594780365626 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013561558559139536, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 178] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001336070267516972, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 172, Epoch: 3, Train Loss: 27.7224, Val Loss: 0.1105\n",
      "Trial: 171, Epoch: 4, Train Loss: 49.4582, Val Loss: 0.2071\n",
      "Trial: 169, Epoch: 5, Train Loss: 26.7217, Val Loss: 0.1119\n",
      "Trial: 173, Epoch: 3, Train Loss: 27.9485, Val Loss: 0.1123\n",
      "Trial: 176, Epoch: 1, Train Loss: 29.0836, Val Loss: 0.1192\n",
      "Trial: 165, Epoch: 7, Train Loss: 25.8162, Val Loss: 0.1217\n",
      "Trial: 168, Epoch: 6, Train Loss: 26.4259, Val Loss: 0.1107\n",
      "Trial: 167, Epoch: 6, Train Loss: 26.9855, Val Loss: 0.1117\n",
      "Trial: 175, Epoch: 2, Train Loss: 54.8078, Val Loss: 0.2480\n",
      "Trial: 170, Epoch: 5, Train Loss: 26.7677, Val Loss: 0.1150\n",
      "Trial: 166, Epoch: 7, Train Loss: 26.3102, Val Loss: 0.1071\n",
      "Trial: 160, Epoch: 10, Train Loss: 25.7393, Val Loss: 0.1201\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:37:26,691] Trial 160 finished with value: 0.10749026015400887 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001210577941115154, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 179] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005808684728033448, 'batch_size': 16, 'patience': 4}\n",
      "Trial: 163, Epoch: 9, Train Loss: 26.7591, Val Loss: 0.1113\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:38:13,470] Trial 163 finished with value: 0.10756546345849832 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001264037217158056, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 180] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005458386773082382, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 174, Epoch: 3, Train Loss: 27.4314, Val Loss: 0.1045\n",
      "Trial: 177, Epoch: 1, Train Loss: 27.5950, Val Loss: 0.1244\n",
      "Trial: 172, Epoch: 4, Train Loss: 27.5389, Val Loss: 0.1086\n",
      "Trial: 178, Epoch: 0, Train Loss: 49.4749, Val Loss: 0.1369\n",
      "Trial: 171, Epoch: 5, Train Loss: 46.3461, Val Loss: 0.1949\n",
      "Trial: 173, Epoch: 4, Train Loss: 27.5252, Val Loss: 0.1110\n",
      "Trial: 169, Epoch: 6, Train Loss: 26.8658, Val Loss: 0.1081\n",
      "Trial: 176, Epoch: 2, Train Loss: 27.5105, Val Loss: 0.1218\n",
      "Trial: 168, Epoch: 7, Train Loss: 26.1086, Val Loss: 0.1124\n",
      "Trial: 165, Epoch: 8, Train Loss: 25.6322, Val Loss: 0.1135\n",
      "Trial: 167, Epoch: 7, Train Loss: 26.8437, Val Loss: 0.1094\n",
      "Trial: 175, Epoch: 3, Train Loss: 49.0610, Val Loss: 0.2141\n",
      "Trial: 170, Epoch: 6, Train Loss: 26.7447, Val Loss: 0.1075\n",
      "Trial: 166, Epoch: 8, Train Loss: 26.0871, Val Loss: 0.1135\n",
      "Trial: 179, Epoch: 0, Train Loss: 35.6005, Val Loss: 0.1096\n",
      "Trial: 174, Epoch: 4, Train Loss: 27.2258, Val Loss: 0.1110\n",
      "Trial: 177, Epoch: 2, Train Loss: 26.9283, Val Loss: 0.1134\n",
      "Trial: 172, Epoch: 5, Train Loss: 27.3530, Val Loss: 0.1058\n",
      "Trial: 178, Epoch: 1, Train Loss: 33.2196, Val Loss: 0.1120\n",
      "Trial: 171, Epoch: 6, Train Loss: 44.1323, Val Loss: 0.1759\n",
      "Trial: 173, Epoch: 5, Train Loss: 27.4348, Val Loss: 0.1083\n",
      "Trial: 169, Epoch: 7, Train Loss: 26.7266, Val Loss: 0.1103\n",
      "Trial: 176, Epoch: 3, Train Loss: 27.1156, Val Loss: 0.1213\n",
      "Trial: 168, Epoch: 8, Train Loss: 25.5594, Val Loss: 0.1121\n",
      "Trial: 167, Epoch: 8, Train Loss: 26.7833, Val Loss: 0.1119\n",
      "Trial: 165, Epoch: 9, Train Loss: 25.4213, Val Loss: 0.1279\n",
      "Trial: 180, Epoch: 0, Train Loss: 65.2519, Val Loss: 0.1071\n",
      "Trial: 175, Epoch: 4, Train Loss: 45.3131, Val Loss: 0.1992\n",
      "Trial: 170, Epoch: 7, Train Loss: 26.7004, Val Loss: 0.1071\n",
      "Trial: 166, Epoch: 9, Train Loss: 25.6972, Val Loss: 0.1051\n",
      "Trial: 179, Epoch: 1, Train Loss: 27.9821, Val Loss: 0.1104\n",
      "Trial: 174, Epoch: 5, Train Loss: 26.9444, Val Loss: 0.1069\n",
      "Trial: 177, Epoch: 3, Train Loss: 26.9399, Val Loss: 0.1138\n",
      "Trial: 172, Epoch: 6, Train Loss: 27.0757, Val Loss: 0.1063\n",
      "Trial: 178, Epoch: 2, Train Loss: 29.1639, Val Loss: 0.1167\n",
      "Trial: 171, Epoch: 7, Train Loss: 42.1702, Val Loss: 0.1626\n",
      "Trial: 173, Epoch: 6, Train Loss: 27.1338, Val Loss: 0.1072\n",
      "Trial: 169, Epoch: 8, Train Loss: 26.5302, Val Loss: 0.1033\n",
      "Trial: 176, Epoch: 4, Train Loss: 27.0266, Val Loss: 0.1161\n",
      "Trial: 168, Epoch: 9, Train Loss: 25.3649, Val Loss: 0.1149\n",
      "Trial: 167, Epoch: 9, Train Loss: 26.6872, Val Loss: 0.1089\n",
      "Trial: 165, Epoch: 10, Train Loss: 25.3002, Val Loss: 0.1267\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:47:07,501] Trial 165 finished with value: 0.1120773463199536 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013606602296146967, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 181] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00571576036991379, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 170, Epoch: 8, Train Loss: 26.6052, Val Loss: 0.1113\n",
      "Trial: 175, Epoch: 5, Train Loss: 42.8948, Val Loss: 0.1823\n",
      "Trial: 166, Epoch: 10, Train Loss: 25.6163, Val Loss: 0.1069\n",
      "Trial: 179, Epoch: 2, Train Loss: 27.2956, Val Loss: 0.1087\n",
      "Trial: 180, Epoch: 1, Train Loss: 54.2737, Val Loss: 0.1087\n",
      "Trial: 174, Epoch: 6, Train Loss: 26.8659, Val Loss: 0.1104\n",
      "Trial: 177, Epoch: 4, Train Loss: 26.7733, Val Loss: 0.1086\n",
      "Trial: 172, Epoch: 7, Train Loss: 26.9706, Val Loss: 0.1087\n",
      "Trial: 178, Epoch: 3, Train Loss: 27.6902, Val Loss: 0.1075\n",
      "Trial: 171, Epoch: 8, Train Loss: 40.4886, Val Loss: 0.1603\n",
      "Trial: 173, Epoch: 7, Train Loss: 26.9873, Val Loss: 0.1092\n",
      "Trial: 169, Epoch: 9, Train Loss: 26.4226, Val Loss: 0.1082\n",
      "Trial: 168, Epoch: 10, Train Loss: 25.2035, Val Loss: 0.1168\n",
      "Trial: 176, Epoch: 5, Train Loss: 26.8254, Val Loss: 0.1132\n",
      "Trial: 167, Epoch: 10, Train Loss: 26.5047, Val Loss: 0.1072\n",
      "Trial: 170, Epoch: 9, Train Loss: 26.5194, Val Loss: 0.1086\n",
      "Trial: 175, Epoch: 6, Train Loss: 40.8490, Val Loss: 0.1726\n",
      "Trial: 166, Epoch: 11, Train Loss: 25.6561, Val Loss: 0.1065\n",
      "Trial: 179, Epoch: 3, Train Loss: 27.0944, Val Loss: 0.1144\n",
      "Trial: 181, Epoch: 0, Train Loss: 67.8638, Val Loss: 0.1172\n",
      "Trial: 174, Epoch: 7, Train Loss: 26.4102, Val Loss: 0.1070\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:52:50,107] Trial 174 finished with value: 0.10450427792966366 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001461383233255441, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 182] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005603526647202378, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 177, Epoch: 5, Train Loss: 26.6753, Val Loss: 0.1095\n",
      "Trial: 172, Epoch: 8, Train Loss: 26.8546, Val Loss: 0.1091\n",
      "Trial: 178, Epoch: 4, Train Loss: 27.4987, Val Loss: 0.1083\n",
      "Trial: 171, Epoch: 9, Train Loss: 39.5219, Val Loss: 0.1524\n",
      "Trial: 173, Epoch: 8, Train Loss: 26.9236, Val Loss: 0.1100\n",
      "Trial: 180, Epoch: 2, Train Loss: 53.7720, Val Loss: 0.1139\n",
      "Trial: 169, Epoch: 10, Train Loss: 26.1181, Val Loss: 0.1050\n",
      "Trial: 168, Epoch: 11, Train Loss: 25.1427, Val Loss: 0.1228\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:53:55,496] Trial 168 finished with value: 0.10890147338310878 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005431453039597459, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 183] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0009088564558050576, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 176, Epoch: 6, Train Loss: 26.5916, Val Loss: 0.1112\n",
      "Trial: 167, Epoch: 11, Train Loss: 26.4690, Val Loss: 0.1081\n",
      "Trial: 170, Epoch: 10, Train Loss: 26.4630, Val Loss: 0.1104\n",
      "Trial: 175, Epoch: 7, Train Loss: 39.6961, Val Loss: 0.1659\n",
      "Trial: 166, Epoch: 12, Train Loss: 25.3827, Val Loss: 0.1074\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 11:55:02,897] Trial 166 finished with value: 0.104054947818319 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001247249106322453, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 184] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006945211602617001, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 179, Epoch: 4, Train Loss: 26.9260, Val Loss: 0.1069\n",
      "Trial: 177, Epoch: 6, Train Loss: 26.5962, Val Loss: 0.1067\n",
      "Trial: 178, Epoch: 5, Train Loss: 27.2219, Val Loss: 0.1069\n",
      "Trial: 172, Epoch: 9, Train Loss: 26.8029, Val Loss: 0.1070\n",
      "Trial: 171, Epoch: 10, Train Loss: 38.6349, Val Loss: 0.1463\n",
      "Trial: 173, Epoch: 9, Train Loss: 26.8565, Val Loss: 0.1070\n",
      "Trial: 169, Epoch: 11, Train Loss: 25.6589, Val Loss: 0.1165\n",
      "Trial: 167, Epoch: 12, Train Loss: 26.3303, Val Loss: 0.1114\n",
      "Trial: 176, Epoch: 7, Train Loss: 26.4580, Val Loss: 0.1112\n",
      "Trial: 170, Epoch: 11, Train Loss: 26.4764, Val Loss: 0.1087\n",
      "Trial: 175, Epoch: 8, Train Loss: 38.3282, Val Loss: 0.1616\n",
      "Trial: 181, Epoch: 1, Train Loss: 55.2127, Val Loss: 0.1104\n",
      "Trial: 182, Epoch: 0, Train Loss: 69.4812, Val Loss: 0.1179\n",
      "Trial: 180, Epoch: 3, Train Loss: 53.8363, Val Loss: 0.1091\n",
      "Trial: 179, Epoch: 5, Train Loss: 26.7038, Val Loss: 0.1055\n",
      "Trial: 183, Epoch: 0, Train Loss: 96.5866, Val Loss: 0.1191\n",
      "Trial: 177, Epoch: 7, Train Loss: 26.5618, Val Loss: 0.1091\n",
      "Trial: 178, Epoch: 6, Train Loss: 27.1948, Val Loss: 0.1064\n",
      "Trial: 172, Epoch: 10, Train Loss: 26.6757, Val Loss: 0.1052\n",
      "Trial: 171, Epoch: 11, Train Loss: 37.5780, Val Loss: 0.1403\n",
      "Trial: 173, Epoch: 10, Train Loss: 26.6829, Val Loss: 0.1040\n",
      "Trial: 184, Epoch: 0, Train Loss: 96.5286, Val Loss: 0.1410\n",
      "Trial: 169, Epoch: 12, Train Loss: 25.6342, Val Loss: 0.1056\n",
      "Trial: 167, Epoch: 13, Train Loss: 25.9425, Val Loss: 0.1130\n",
      "Trial: 176, Epoch: 8, Train Loss: 26.3133, Val Loss: 0.1112\n",
      "Trial: 170, Epoch: 12, Train Loss: 26.0949, Val Loss: 0.1125\n",
      "Trial: 175, Epoch: 9, Train Loss: 37.3409, Val Loss: 0.1610\n",
      "Trial: 179, Epoch: 6, Train Loss: 26.7750, Val Loss: 0.1064\n",
      "Trial: 181, Epoch: 2, Train Loss: 53.9466, Val Loss: 0.1137\n",
      "Trial: 182, Epoch: 1, Train Loss: 56.5251, Val Loss: 0.1126\n",
      "Trial: 178, Epoch: 7, Train Loss: 26.8640, Val Loss: 0.1078\n",
      "Trial: 177, Epoch: 8, Train Loss: 26.6007, Val Loss: 0.1096\n",
      "Trial: 180, Epoch: 4, Train Loss: 53.5933, Val Loss: 0.1120\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:03:43,480] Trial 180 finished with value: 0.10711725813751462 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005458386773082382, 'batch_size': 8, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 185] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.000585721272202218, 'batch_size': 8, 'patience': 4}\n",
      "Trial: 171, Epoch: 12, Train Loss: 36.9902, Val Loss: 0.1359\n",
      "Trial: 172, Epoch: 11, Train Loss: 26.3431, Val Loss: 0.1105\n",
      "Trial: 173, Epoch: 11, Train Loss: 26.7925, Val Loss: 0.1059\n",
      "Trial: 183, Epoch: 1, Train Loss: 62.3555, Val Loss: 0.1162\n",
      "Trial: 169, Epoch: 13, Train Loss: 25.5441, Val Loss: 0.1062\n",
      "Trial: 167, Epoch: 14, Train Loss: 25.5990, Val Loss: 0.1144\n",
      "Trial: 176, Epoch: 9, Train Loss: 25.8754, Val Loss: 0.1205\n",
      "Trial: 170, Epoch: 13, Train Loss: 25.8085, Val Loss: 0.1091\n",
      "Trial: 175, Epoch: 10, Train Loss: 36.0829, Val Loss: 0.1500\n",
      "Trial: 184, Epoch: 1, Train Loss: 65.2684, Val Loss: 0.1182\n",
      "Trial: 179, Epoch: 7, Train Loss: 26.7667, Val Loss: 0.1067\n",
      "Trial: 178, Epoch: 8, Train Loss: 26.8761, Val Loss: 0.1050\n",
      "Trial: 177, Epoch: 9, Train Loss: 26.4159, Val Loss: 0.1143\n",
      "Trial: 171, Epoch: 13, Train Loss: 36.3557, Val Loss: 0.1357\n",
      "Trial: 172, Epoch: 12, Train Loss: 26.0799, Val Loss: 0.1077\n",
      "Trial: 173, Epoch: 12, Train Loss: 26.6000, Val Loss: 0.1074\n",
      "Trial: 167, Epoch: 15, Train Loss: 25.5240, Val Loss: 0.1102\n",
      "Trial: 169, Epoch: 14, Train Loss: 25.4630, Val Loss: 0.1142\n",
      "Trial: 181, Epoch: 3, Train Loss: 53.5627, Val Loss: 0.1110\n",
      "Trial: 170, Epoch: 14, Train Loss: 25.4983, Val Loss: 0.1096\n",
      "Early stopping triggered.\n",
      "Trial: 176, Epoch: 10, Train Loss: 25.5641, Val Loss: 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:08:25,310] Trial 170 finished with value: 0.10709803414841493 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0014314964066016096, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 186] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005883919245001592, 'batch_size': 16, 'patience': 9}\n",
      "Trial: 175, Epoch: 11, Train Loss: 35.5133, Val Loss: 0.1472\n",
      "Trial: 182, Epoch: 2, Train Loss: 56.0149, Val Loss: 0.1163\n",
      "Trial: 185, Epoch: 0, Train Loss: 91.3615, Val Loss: 0.1308\n",
      "Trial: 183, Epoch: 2, Train Loss: 56.1688, Val Loss: 0.1100\n",
      "Trial: 179, Epoch: 8, Train Loss: 26.7641, Val Loss: 0.1078\n",
      "Trial: 178, Epoch: 9, Train Loss: 26.6414, Val Loss: 0.1064\n",
      "Trial: 171, Epoch: 14, Train Loss: 35.7770, Val Loss: 0.1310\n",
      "Trial: 177, Epoch: 10, Train Loss: 26.0501, Val Loss: 0.1181\n",
      "Early stopping triggered.\n",
      "Trial: 184, Epoch: 2, Train Loss: 56.6054, Val Loss: 0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:11:01,344] Trial 177 finished with value: 0.10671599892278512 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013877435053784412, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 187] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.009975135336231034, 'batch_size': 16, 'patience': 9}\n",
      "Trial: 173, Epoch: 13, Train Loss: 26.5501, Val Loss: 0.1087\n",
      "Trial: 172, Epoch: 13, Train Loss: 25.7774, Val Loss: 0.1119\n",
      "Trial: 167, Epoch: 16, Train Loss: 25.4266, Val Loss: 0.1114\n",
      "Trial: 169, Epoch: 15, Train Loss: 25.3891, Val Loss: 0.1118\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:11:52,092] Trial 169 finished with value: 0.10328206357856591 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013365048339319448, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 188] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0009452870490662445, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 176, Epoch: 11, Train Loss: 25.3704, Val Loss: 0.1170\n",
      "Trial: 175, Epoch: 12, Train Loss: 34.7775, Val Loss: 0.1476\n",
      "Trial: 186, Epoch: 0, Train Loss: 35.2234, Val Loss: 0.1134\n",
      "Trial: 181, Epoch: 4, Train Loss: 53.6344, Val Loss: 0.1153\n",
      "Trial: 179, Epoch: 9, Train Loss: 26.5869, Val Loss: 0.1099\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:13:37,977] Trial 179 finished with value: 0.10546652475992839 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005808684728033448, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 189] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0007808272261763102, 'batch_size': 16, 'patience': 5}\n",
      "Trial: 182, Epoch: 3, Train Loss: 55.2704, Val Loss: 0.1042\n",
      "Trial: 178, Epoch: 10, Train Loss: 26.2206, Val Loss: 0.1112\n",
      "Trial: 185, Epoch: 1, Train Loss: 59.4706, Val Loss: 0.1185\n",
      "Trial: 171, Epoch: 15, Train Loss: 35.2175, Val Loss: 0.1278\n",
      "Trial: 183, Epoch: 3, Train Loss: 54.9271, Val Loss: 0.1085\n",
      "Trial: 173, Epoch: 14, Train Loss: 26.3858, Val Loss: 0.1076\n",
      "Early stopping triggered.\n",
      "Trial: 172, Epoch: 14, Train Loss: 25.4822, Val Loss: 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:14:39,993] Trial 173 finished with value: 0.10402136494716009 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0011752831364883034, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 190] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 3.334901367093877e-05, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 187, Epoch: 0, Train Loss: 36.7725, Val Loss: 0.1264\n",
      "Trial: 167, Epoch: 17, Train Loss: 25.3855, Val Loss: 0.1104\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:15:18,398] Trial 167 finished with value: 0.10715354221562544 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013290340545583986, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 191] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006442078930374482, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 176, Epoch: 12, Train Loss: 25.4253, Val Loss: 0.1136\n",
      "Trial: 175, Epoch: 13, Train Loss: 34.0238, Val Loss: 0.1438\n",
      "Trial: 186, Epoch: 1, Train Loss: 27.9343, Val Loss: 0.1164\n",
      "Trial: 188, Epoch: 0, Train Loss: 43.3605, Val Loss: 0.1185\n",
      "Trial: 184, Epoch: 3, Train Loss: 54.3334, Val Loss: 0.1094\n",
      "Trial: 189, Epoch: 0, Train Loss: 48.9000, Val Loss: 0.1297\n",
      "Trial: 178, Epoch: 11, Train Loss: 25.8496, Val Loss: 0.1083\n",
      "Trial: 171, Epoch: 16, Train Loss: 34.9014, Val Loss: 0.1264\n",
      "Trial: 172, Epoch: 15, Train Loss: 25.4749, Val Loss: 0.1094\n",
      "Trial: 187, Epoch: 1, Train Loss: 28.6628, Val Loss: 0.1054\n",
      "Trial: 181, Epoch: 5, Train Loss: 53.2234, Val Loss: 0.1085\n",
      "Trial: 182, Epoch: 4, Train Loss: 54.2233, Val Loss: 0.1035\n",
      "Trial: 176, Epoch: 13, Train Loss: 25.2881, Val Loss: 0.1151\n",
      "Trial: 175, Epoch: 14, Train Loss: 33.5767, Val Loss: 0.1394\n",
      "Trial: 186, Epoch: 2, Train Loss: 27.7444, Val Loss: 0.1122\n",
      "Trial: 185, Epoch: 2, Train Loss: 55.1896, Val Loss: 0.1184\n",
      "Trial: 188, Epoch: 1, Train Loss: 29.5496, Val Loss: 0.1323\n",
      "Trial: 183, Epoch: 4, Train Loss: 54.3914, Val Loss: 0.1110\n",
      "Trial: 190, Epoch: 0, Train Loss: 300.3553, Val Loss: 0.2501\n",
      "Trial: 191, Epoch: 0, Train Loss: 83.1714, Val Loss: 0.1467\n",
      "Trial: 189, Epoch: 1, Train Loss: 32.6836, Val Loss: 0.1198\n",
      "Trial: 184, Epoch: 4, Train Loss: 53.7126, Val Loss: 0.1100\n",
      "Trial: 178, Epoch: 12, Train Loss: 25.6002, Val Loss: 0.1082\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:21:23,710] Trial 178 finished with value: 0.10500241617361704 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.001336070267516972, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 192] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.009761403362619755, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 171, Epoch: 17, Train Loss: 34.1377, Val Loss: 0.1249\n",
      "Trial: 172, Epoch: 16, Train Loss: 25.3100, Val Loss: 0.1099\n",
      "Trial: 187, Epoch: 2, Train Loss: 27.5893, Val Loss: 0.1090\n",
      "Trial: 176, Epoch: 14, Train Loss: 25.2530, Val Loss: 0.1151\n",
      "Trial: 175, Epoch: 15, Train Loss: 32.7321, Val Loss: 0.1383\n",
      "Trial: 186, Epoch: 3, Train Loss: 27.5724, Val Loss: 0.1057\n",
      "Trial: 188, Epoch: 2, Train Loss: 27.5500, Val Loss: 0.1385\n",
      "Trial: 181, Epoch: 6, Train Loss: 53.2355, Val Loss: 0.1103\n",
      "Trial: 182, Epoch: 5, Train Loss: 54.4408, Val Loss: 0.1052\n",
      "Trial: 185, Epoch: 3, Train Loss: 54.3660, Val Loss: 0.1168\n",
      "Trial: 183, Epoch: 5, Train Loss: 54.0062, Val Loss: 0.1083\n",
      "Trial: 189, Epoch: 2, Train Loss: 29.0221, Val Loss: 0.1475\n",
      "Trial: 171, Epoch: 18, Train Loss: 33.7873, Val Loss: 0.1228\n",
      "Trial: 190, Epoch: 1, Train Loss: 138.7558, Val Loss: 0.1880\n",
      "Trial: 172, Epoch: 17, Train Loss: 25.2518, Val Loss: 0.1118\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:25:21,859] Trial 172 finished with value: 0.10524581683178742 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0013617200354204848, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 193] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006994518750663205, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 187, Epoch: 3, Train Loss: 27.2944, Val Loss: 0.1099\n",
      "Trial: 191, Epoch: 1, Train Loss: 57.1580, Val Loss: 0.1418\n",
      "Trial: 176, Epoch: 15, Train Loss: 25.1419, Val Loss: 0.1119\n",
      "Early stopping triggered.\n",
      "Trial: 175, Epoch: 16, Train Loss: 32.2890, Val Loss: 0.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:26:15,803] Trial 176 finished with value: 0.11121567673981189 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0014094584870005438, 'batch_size': 16, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 194] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.01038320820848288, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 186, Epoch: 4, Train Loss: 27.1952, Val Loss: 0.1042\n",
      "Trial: 184, Epoch: 5, Train Loss: 53.6013, Val Loss: 0.1074\n",
      "Trial: 188, Epoch: 3, Train Loss: 27.1737, Val Loss: 0.1089\n",
      "Trial: 192, Epoch: 0, Train Loss: 62.3440, Val Loss: 0.1136\n",
      "Trial: 189, Epoch: 3, Train Loss: 27.6830, Val Loss: 0.1364\n",
      "Trial: 171, Epoch: 19, Train Loss: 33.5155, Val Loss: 0.1238\n",
      "Trial: 181, Epoch: 7, Train Loss: 53.1179, Val Loss: 0.1106\n",
      "Trial: 187, Epoch: 4, Train Loss: 27.1350, Val Loss: 0.1077\n",
      "Trial: 185, Epoch: 4, Train Loss: 53.9746, Val Loss: 0.1142\n",
      "Trial: 182, Epoch: 6, Train Loss: 54.0496, Val Loss: 0.1072\n",
      "Trial: 183, Epoch: 6, Train Loss: 53.9874, Val Loss: 0.1161\n",
      "Trial: 186, Epoch: 5, Train Loss: 27.1979, Val Loss: 0.1024\n",
      "Trial: 175, Epoch: 17, Train Loss: 31.7541, Val Loss: 0.1407\n",
      "Trial: 190, Epoch: 2, Train Loss: 104.4589, Val Loss: 0.1862\n",
      "Trial: 188, Epoch: 4, Train Loss: 26.8749, Val Loss: 0.1091\n",
      "Trial: 193, Epoch: 0, Train Loss: 80.6897, Val Loss: 0.1498\n",
      "Trial: 191, Epoch: 2, Train Loss: 54.7804, Val Loss: 0.1351\n",
      "Trial: 184, Epoch: 6, Train Loss: 53.3459, Val Loss: 0.1080\n",
      "Trial: 194, Epoch: 0, Train Loss: 64.9485, Val Loss: 0.1172\n",
      "Trial: 189, Epoch: 4, Train Loss: 27.3678, Val Loss: 0.1261\n",
      "Trial: 192, Epoch: 1, Train Loss: 54.5868, Val Loss: 0.1062\n",
      "Trial: 171, Epoch: 20, Train Loss: 32.8927, Val Loss: 0.1222\n",
      "Trial: 187, Epoch: 5, Train Loss: 27.0137, Val Loss: 0.1058\n",
      "Trial: 186, Epoch: 6, Train Loss: 26.9938, Val Loss: 0.1043\n",
      "Trial: 175, Epoch: 18, Train Loss: 31.1189, Val Loss: 0.1398\n",
      "Trial: 188, Epoch: 5, Train Loss: 26.6480, Val Loss: 0.1078\n",
      "Trial: 181, Epoch: 8, Train Loss: 52.9440, Val Loss: 0.1094\n",
      "Trial: 185, Epoch: 5, Train Loss: 53.6274, Val Loss: 0.1110\n",
      "Trial: 182, Epoch: 7, Train Loss: 53.8430, Val Loss: 0.1071\n",
      "Trial: 183, Epoch: 7, Train Loss: 53.6231, Val Loss: 0.1111\n",
      "Trial: 190, Epoch: 3, Train Loss: 93.7480, Val Loss: 0.1749\n",
      "Trial: 189, Epoch: 5, Train Loss: 27.0733, Val Loss: 0.1255\n",
      "Trial: 171, Epoch: 21, Train Loss: 32.6332, Val Loss: 0.1213\n",
      "Trial: 193, Epoch: 1, Train Loss: 56.9485, Val Loss: 0.1144\n",
      "Trial: 191, Epoch: 3, Train Loss: 53.8603, Val Loss: 0.1333\n",
      "Trial: 187, Epoch: 6, Train Loss: 26.8792, Val Loss: 0.1067\n",
      "Trial: 184, Epoch: 7, Train Loss: 52.9355, Val Loss: 0.1063\n",
      "Trial: 186, Epoch: 7, Train Loss: 27.0039, Val Loss: 0.1017\n",
      "Trial: 194, Epoch: 1, Train Loss: 54.4651, Val Loss: 0.1159\n",
      "Trial: 175, Epoch: 19, Train Loss: 30.5319, Val Loss: 0.1392\n",
      "Early stopping triggered.\n",
      "Trial: 192, Epoch: 2, Train Loss: 54.2984, Val Loss: 0.1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:36:59,831] Trial 175 finished with value: 0.13826390641431013 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 4.131834415773663e-05, 'batch_size': 16, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 195] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0025710531079060975, 'batch_size': 8, 'patience': 5}\n",
      "Trial: 188, Epoch: 6, Train Loss: 26.6308, Val Loss: 0.1087\n",
      "Trial: 189, Epoch: 6, Train Loss: 27.0186, Val Loss: 0.1213\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:39:01,141] Trial 189 finished with value: 0.11976192134122053 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0007808272261763102, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 196] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003935136400058372, 'batch_size': 8, 'patience': 9}\n",
      "Trial: 171, Epoch: 22, Train Loss: 32.1358, Val Loss: 0.1209\n",
      "Trial: 181, Epoch: 9, Train Loss: 52.0360, Val Loss: 0.1086\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:39:23,418] Trial 181 finished with value: 0.10847360359019592 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.00571576036991379, 'batch_size': 8, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 185, Epoch: 6, Train Loss: 53.4135, Val Loss: 0.1103\n",
      "\n",
      "[Trial 197] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003884579536437998, 'batch_size': 16, 'patience': 9}\n",
      "Trial: 182, Epoch: 8, Train Loss: 53.7635, Val Loss: 0.1019\n",
      "Trial: 183, Epoch: 8, Train Loss: 53.1893, Val Loss: 0.1085\n",
      "Trial: 187, Epoch: 7, Train Loss: 26.6495, Val Loss: 0.1109\n",
      "Trial: 186, Epoch: 8, Train Loss: 26.7476, Val Loss: 0.1041\n",
      "Trial: 190, Epoch: 4, Train Loss: 86.9194, Val Loss: 0.1716\n",
      "Trial: 188, Epoch: 7, Train Loss: 26.6325, Val Loss: 0.1093\n",
      "Trial: 191, Epoch: 4, Train Loss: 53.7803, Val Loss: 0.1198\n",
      "Trial: 193, Epoch: 2, Train Loss: 54.8289, Val Loss: 0.1197\n",
      "Trial: 184, Epoch: 8, Train Loss: 52.7539, Val Loss: 0.1070\n",
      "Trial: 192, Epoch: 3, Train Loss: 53.4386, Val Loss: 0.1209\n",
      "Trial: 194, Epoch: 2, Train Loss: 54.1870, Val Loss: 0.1087\n",
      "Trial: 195, Epoch: 0, Train Loss: 70.5495, Val Loss: 0.1139\n",
      "Trial: 171, Epoch: 23, Train Loss: 31.8423, Val Loss: 0.1178\n",
      "Trial: 197, Epoch: 0, Train Loss: 36.1163, Val Loss: 0.1136\n",
      "Trial: 187, Epoch: 8, Train Loss: 26.2939, Val Loss: 0.1124\n",
      "Trial: 186, Epoch: 9, Train Loss: 26.4985, Val Loss: 0.1019\n",
      "Trial: 185, Epoch: 7, Train Loss: 53.1065, Val Loss: 0.1115\n",
      "Trial: 196, Epoch: 0, Train Loss: 66.0597, Val Loss: 0.1122\n",
      "Trial: 188, Epoch: 8, Train Loss: 26.6538, Val Loss: 0.1097\n",
      "Trial: 183, Epoch: 9, Train Loss: 52.3090, Val Loss: 0.1118\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:44:48,633] Trial 183 finished with value: 0.10834249353208461 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0009088564558050576, 'batch_size': 8, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 198] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003863121003571956, 'batch_size': 16, 'patience': 3}\n",
      "Trial: 182, Epoch: 9, Train Loss: 53.6631, Val Loss: 0.1024\n",
      "Trial: 190, Epoch: 5, Train Loss: 83.3638, Val Loss: 0.1649\n",
      "Trial: 171, Epoch: 24, Train Loss: 31.4942, Val Loss: 0.1191\n",
      "Trial: 191, Epoch: 5, Train Loss: 53.4374, Val Loss: 0.1180\n",
      "Trial: 193, Epoch: 3, Train Loss: 54.2589, Val Loss: 0.1072\n",
      "Trial: 197, Epoch: 1, Train Loss: 28.2008, Val Loss: 0.1077\n",
      "Trial: 184, Epoch: 9, Train Loss: 51.6204, Val Loss: 0.1136\n",
      "Trial: 192, Epoch: 4, Train Loss: 52.1348, Val Loss: 0.1084\n",
      "Trial: 194, Epoch: 3, Train Loss: 53.3312, Val Loss: 0.1108\n",
      "Trial: 187, Epoch: 9, Train Loss: 25.8446, Val Loss: 0.1029\n",
      "Trial: 186, Epoch: 10, Train Loss: 26.2424, Val Loss: 0.1101\n",
      "Trial: 195, Epoch: 1, Train Loss: 54.7570, Val Loss: 0.1097\n",
      "Trial: 188, Epoch: 9, Train Loss: 26.5223, Val Loss: 0.1096\n",
      "Trial: 198, Epoch: 0, Train Loss: 43.0816, Val Loss: 0.1218\n",
      "Trial: 185, Epoch: 8, Train Loss: 53.4359, Val Loss: 0.1083\n",
      "Trial: 171, Epoch: 25, Train Loss: 31.2017, Val Loss: 0.1169\n",
      "Trial: 196, Epoch: 1, Train Loss: 55.6172, Val Loss: 0.1114\n",
      "Trial: 182, Epoch: 10, Train Loss: 52.9867, Val Loss: 0.1090\n",
      "Trial: 197, Epoch: 2, Train Loss: 27.4114, Val Loss: 0.1088\n",
      "Trial: 190, Epoch: 6, Train Loss: 80.6106, Val Loss: 0.1612\n",
      "Trial: 186, Epoch: 11, Train Loss: 25.9834, Val Loss: 0.1127\n",
      "Trial: 187, Epoch: 10, Train Loss: 25.6125, Val Loss: 0.1068\n",
      "Trial: 191, Epoch: 6, Train Loss: 53.3769, Val Loss: 0.1145\n",
      "Trial: 193, Epoch: 4, Train Loss: 53.7857, Val Loss: 0.1140\n",
      "Trial: 188, Epoch: 10, Train Loss: 26.5723, Val Loss: 0.1068\n",
      "Trial: 198, Epoch: 1, Train Loss: 27.7671, Val Loss: 0.1080\n",
      "Trial: 184, Epoch: 10, Train Loss: 51.1557, Val Loss: 0.1118\n",
      "Trial: 192, Epoch: 5, Train Loss: 51.5029, Val Loss: 0.1081\n",
      "Trial: 194, Epoch: 4, Train Loss: 52.0088, Val Loss: 0.1212\n",
      "Trial: 195, Epoch: 2, Train Loss: 53.8476, Val Loss: 0.1135\n",
      "Trial: 171, Epoch: 26, Train Loss: 30.9094, Val Loss: 0.1172\n",
      "Trial: 197, Epoch: 3, Train Loss: 27.0080, Val Loss: 0.1058\n",
      "Trial: 186, Epoch: 12, Train Loss: 25.7552, Val Loss: 0.1105\n",
      "Trial: 185, Epoch: 9, Train Loss: 53.3120, Val Loss: 0.1077\n",
      "Trial: 187, Epoch: 11, Train Loss: 25.6477, Val Loss: 0.1131\n",
      "Trial: 196, Epoch: 2, Train Loss: 54.6275, Val Loss: 0.1112\n",
      "Trial: 182, Epoch: 11, Train Loss: 52.3068, Val Loss: 0.1049\n",
      "Trial: 188, Epoch: 11, Train Loss: 26.5217, Val Loss: 0.1075\n",
      "Trial: 198, Epoch: 2, Train Loss: 27.3720, Val Loss: 0.1150\n",
      "Trial: 190, Epoch: 7, Train Loss: 78.4878, Val Loss: 0.1562\n",
      "Trial: 191, Epoch: 7, Train Loss: 53.1137, Val Loss: 0.1110\n",
      "Trial: 193, Epoch: 5, Train Loss: 53.4914, Val Loss: 0.1057\n",
      "Trial: 171, Epoch: 27, Train Loss: 30.4119, Val Loss: 0.1159\n",
      "Trial: 184, Epoch: 11, Train Loss: 50.5996, Val Loss: 0.1142\n",
      "Early stopping triggered.\n",
      "Trial: 192, Epoch: 6, Train Loss: 51.0896, Val Loss: 0.1162\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:57:21,813] Trial 184 finished with value: 0.1063117199898267 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006945211602617001, 'batch_size': 8, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 199] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.009923906534527505, 'batch_size': 16, 'patience': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 12:57:23,213] Trial 192 finished with value: 0.10618069630210139 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.009761403362619755, 'batch_size': 8, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 194, Epoch: 5, Train Loss: 51.2924, Val Loss: 0.1106\n",
      "Trial: 197, Epoch: 4, Train Loss: 26.7349, Val Loss: 0.1140\n",
      "Trial: 186, Epoch: 13, Train Loss: 25.7421, Val Loss: 0.1130\n",
      "Trial: 195, Epoch: 3, Train Loss: 53.6003, Val Loss: 0.1101\n",
      "Trial: 187, Epoch: 12, Train Loss: 25.4794, Val Loss: 0.1054\n",
      "Trial: 188, Epoch: 12, Train Loss: 26.4445, Val Loss: 0.1090\n",
      "Trial: 198, Epoch: 3, Train Loss: 27.2169, Val Loss: 0.1151\n",
      "Trial: 185, Epoch: 10, Train Loss: 52.9762, Val Loss: 0.1095\n",
      "Trial: 196, Epoch: 3, Train Loss: 54.0314, Val Loss: 0.1038\n",
      "Trial: 171, Epoch: 28, Train Loss: 30.1307, Val Loss: 0.1161\n",
      "Trial: 182, Epoch: 12, Train Loss: 51.4908, Val Loss: 0.1087\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:00:08,694] Trial 182 finished with value: 0.10191330442032895 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005603526647202378, 'batch_size': 8, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 190, Epoch: 8, Train Loss: 76.1963, Val Loss: 0.1541\n",
      "Trial: 199, Epoch: 0, Train Loss: 37.2118, Val Loss: 0.1144\n",
      "Trial: 197, Epoch: 5, Train Loss: 26.5417, Val Loss: 0.1085\n",
      "Trial: 186, Epoch: 14, Train Loss: 25.6603, Val Loss: 0.1096\n",
      "Trial: 191, Epoch: 8, Train Loss: 52.9281, Val Loss: 0.1102\n",
      "Trial: 193, Epoch: 6, Train Loss: 53.2439, Val Loss: 0.1080\n",
      "Trial: 187, Epoch: 13, Train Loss: 25.4375, Val Loss: 0.1069\n",
      "Trial: 188, Epoch: 13, Train Loss: 26.5413, Val Loss: 0.1101\n",
      "Trial: 198, Epoch: 4, Train Loss: 26.8862, Val Loss: 0.1127\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:02:17,797] Trial 198 finished with value: 0.10804785067836443 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003863121003571956, 'batch_size': 16, 'patience': 3}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 194, Epoch: 6, Train Loss: 51.4260, Val Loss: 0.1096\n",
      "Trial: 195, Epoch: 4, Train Loss: 53.3628, Val Loss: 0.1090\n",
      "Trial: 171, Epoch: 29, Train Loss: 29.8355, Val Loss: 0.1163\n",
      "Trial: 185, Epoch: 11, Train Loss: 52.5865, Val Loss: 0.1107\n",
      "Trial: 199, Epoch: 1, Train Loss: 28.0638, Val Loss: 0.1028\n",
      "Trial: 197, Epoch: 6, Train Loss: 26.1258, Val Loss: 0.1204\n",
      "Trial: 186, Epoch: 15, Train Loss: 25.4709, Val Loss: 0.1074\n",
      "Trial: 196, Epoch: 4, Train Loss: 53.7759, Val Loss: 0.1059\n",
      "Trial: 187, Epoch: 14, Train Loss: 25.3992, Val Loss: 0.1123\n",
      "Trial: 190, Epoch: 9, Train Loss: 74.1577, Val Loss: 0.1476\n",
      "Trial: 188, Epoch: 14, Train Loss: 26.2738, Val Loss: 0.1112\n",
      "Trial: 191, Epoch: 9, Train Loss: 52.8692, Val Loss: 0.1093\n",
      "Trial: 193, Epoch: 7, Train Loss: 53.2498, Val Loss: 0.1130\n",
      "Trial: 171, Epoch: 30, Train Loss: 29.7160, Val Loss: 0.1168\n",
      "Trial: 194, Epoch: 7, Train Loss: 51.0186, Val Loss: 0.1073\n",
      "Trial: 195, Epoch: 5, Train Loss: 52.7259, Val Loss: 0.1146\n",
      "Trial: 199, Epoch: 2, Train Loss: 27.3693, Val Loss: 0.1050\n",
      "Trial: 197, Epoch: 7, Train Loss: 25.6964, Val Loss: 0.1158\n",
      "Trial: 186, Epoch: 16, Train Loss: 25.5510, Val Loss: 0.1059\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:06:51,867] Trial 186 finished with value: 0.10173181804517904 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.005883919245001592, 'batch_size': 16, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 187, Epoch: 15, Train Loss: 25.3762, Val Loss: 0.1078\n",
      "Trial: 188, Epoch: 15, Train Loss: 26.3287, Val Loss: 0.1050\n",
      "Trial: 185, Epoch: 12, Train Loss: 52.6678, Val Loss: 0.1073\n",
      "Trial: 196, Epoch: 5, Train Loss: 53.1968, Val Loss: 0.1076\n",
      "Trial: 171, Epoch: 31, Train Loss: 29.1164, Val Loss: 0.1169\n",
      "Trial: 190, Epoch: 10, Train Loss: 72.7853, Val Loss: 0.1435\n",
      "Trial: 191, Epoch: 10, Train Loss: 52.8336, Val Loss: 0.1059\n",
      "Trial: 199, Epoch: 3, Train Loss: 27.1182, Val Loss: 0.1026\n",
      "Trial: 197, Epoch: 8, Train Loss: 25.6844, Val Loss: 0.1125\n",
      "Trial: 193, Epoch: 8, Train Loss: 53.1233, Val Loss: 0.1060\n",
      "Trial: 187, Epoch: 16, Train Loss: 25.3438, Val Loss: 0.1064\n",
      "Trial: 188, Epoch: 16, Train Loss: 26.3553, Val Loss: 0.1059\n",
      "Trial: 195, Epoch: 6, Train Loss: 52.2825, Val Loss: 0.1092\n",
      "Trial: 194, Epoch: 8, Train Loss: 50.7312, Val Loss: 0.1064\n",
      "Trial: 171, Epoch: 32, Train Loss: 28.8451, Val Loss: 0.1196\n",
      "Trial: 185, Epoch: 13, Train Loss: 52.5095, Val Loss: 0.1097\n",
      "Trial: 199, Epoch: 4, Train Loss: 26.9159, Val Loss: 0.1071\n",
      "Trial: 197, Epoch: 9, Train Loss: 25.4901, Val Loss: 0.1167\n",
      "Trial: 196, Epoch: 6, Train Loss: 52.4364, Val Loss: 0.1094\n",
      "Trial: 190, Epoch: 11, Train Loss: 71.0253, Val Loss: 0.1427\n",
      "Trial: 187, Epoch: 17, Train Loss: 25.3129, Val Loss: 0.1041\n",
      "Trial: 188, Epoch: 17, Train Loss: 26.3211, Val Loss: 0.1081\n",
      "Trial: 191, Epoch: 11, Train Loss: 53.0701, Val Loss: 0.1097\n",
      "Trial: 193, Epoch: 9, Train Loss: 52.3554, Val Loss: 0.1057\n",
      "Trial: 171, Epoch: 33, Train Loss: 28.6402, Val Loss: 0.1235\n",
      "Trial: 195, Epoch: 7, Train Loss: 51.2661, Val Loss: 0.1093\n",
      "Trial: 194, Epoch: 9, Train Loss: 50.9098, Val Loss: 0.1133\n",
      "Trial: 199, Epoch: 5, Train Loss: 26.8744, Val Loss: 0.1134\n",
      "Trial: 197, Epoch: 10, Train Loss: 25.3854, Val Loss: 0.1118\n",
      "Trial: 185, Epoch: 14, Train Loss: 52.6906, Val Loss: 0.1077\n",
      "Trial: 187, Epoch: 18, Train Loss: 25.3532, Val Loss: 0.1105\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:15:19,685] Trial 187 finished with value: 0.10293041629095873 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.009975135336231034, 'batch_size': 16, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 188, Epoch: 18, Train Loss: 26.0479, Val Loss: 0.1050\n",
      "Trial: 196, Epoch: 7, Train Loss: 51.5184, Val Loss: 0.1144\n",
      "Trial: 190, Epoch: 12, Train Loss: 70.1391, Val Loss: 0.1418\n",
      "Trial: 171, Epoch: 34, Train Loss: 28.4747, Val Loss: 0.1261\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:16:13,554] Trial 171 finished with value: 0.11593445837497711 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 4.3275817518498327e-05, 'batch_size': 16, 'patience': 7}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 191, Epoch: 12, Train Loss: 52.8384, Val Loss: 0.1089\n",
      "Trial: 199, Epoch: 6, Train Loss: 26.7950, Val Loss: 0.1155\n",
      "Trial: 193, Epoch: 10, Train Loss: 51.6590, Val Loss: 0.1103\n",
      "Early stopping triggered.\n",
      "Trial: 197, Epoch: 11, Train Loss: 25.3480, Val Loss: 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:16:58,735] Trial 193 finished with value: 0.10566786798734625 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006994518750663205, 'batch_size': 8, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 195, Epoch: 8, Train Loss: 50.9247, Val Loss: 0.1069\n",
      "Trial: 194, Epoch: 10, Train Loss: 50.7467, Val Loss: 0.1113\n",
      "Trial: 188, Epoch: 19, Train Loss: 25.8450, Val Loss: 0.1068\n",
      "Trial: 185, Epoch: 15, Train Loss: 52.2285, Val Loss: 0.1086\n",
      "Trial: 196, Epoch: 8, Train Loss: 51.2158, Val Loss: 0.1112\n",
      "Trial: 199, Epoch: 7, Train Loss: 26.6130, Val Loss: 0.1077\n",
      "Trial: 197, Epoch: 12, Train Loss: 25.3107, Val Loss: 0.1260\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:18:53,840] Trial 197 finished with value: 0.10577882304787636 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003884579536437998, 'batch_size': 16, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 190, Epoch: 13, Train Loss: 68.7634, Val Loss: 0.1380\n",
      "Trial: 191, Epoch: 13, Train Loss: 52.6790, Val Loss: 0.1110\n",
      "Trial: 188, Epoch: 20, Train Loss: 25.4705, Val Loss: 0.1118\n",
      "Trial: 195, Epoch: 9, Train Loss: 50.9864, Val Loss: 0.1122\n",
      "Trial: 194, Epoch: 11, Train Loss: 50.5557, Val Loss: 0.1129\n",
      "Trial: 199, Epoch: 8, Train Loss: 26.0567, Val Loss: 0.1120\n",
      "Trial: 185, Epoch: 16, Train Loss: 52.0571, Val Loss: 0.1083\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:20:31,810] Trial 185 finished with value: 0.10732886141964368 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.000585721272202218, 'batch_size': 8, 'patience': 4}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 188, Epoch: 21, Train Loss: 25.4019, Val Loss: 0.1071\n",
      "Trial: 196, Epoch: 9, Train Loss: 50.9724, Val Loss: 0.1136\n",
      "Trial: 190, Epoch: 14, Train Loss: 68.4207, Val Loss: 0.1340\n",
      "Trial: 191, Epoch: 14, Train Loss: 51.6190, Val Loss: 0.1102\n",
      "Trial: 199, Epoch: 9, Train Loss: 25.6261, Val Loss: 0.1078\n",
      "Trial: 195, Epoch: 10, Train Loss: 50.6775, Val Loss: 0.1084\n",
      "Trial: 194, Epoch: 12, Train Loss: 50.7738, Val Loss: 0.1140\n",
      "Trial: 188, Epoch: 22, Train Loss: 25.3501, Val Loss: 0.1124\n",
      "Trial: 196, Epoch: 10, Train Loss: 50.9323, Val Loss: 0.1113\n",
      "Trial: 199, Epoch: 10, Train Loss: 25.5207, Val Loss: 0.1163\n",
      "Trial: 190, Epoch: 15, Train Loss: 67.4278, Val Loss: 0.1339\n",
      "Trial: 191, Epoch: 15, Train Loss: 51.1275, Val Loss: 0.1126\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:23:42,353] Trial 191 finished with value: 0.10587083670396764 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0006442078930374482, 'batch_size': 8, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 188, Epoch: 23, Train Loss: 25.2679, Val Loss: 0.1068\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:23:53,772] Trial 188 finished with value: 0.10495937926073869 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0009452870490662445, 'batch_size': 16, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 195, Epoch: 11, Train Loss: 50.7767, Val Loss: 0.1135\n",
      "Trial: 194, Epoch: 13, Train Loss: 50.3587, Val Loss: 0.1132\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:24:15,998] Trial 194 finished with value: 0.10641404379065297 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.01038320820848288, 'batch_size': 8, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 199, Epoch: 11, Train Loss: 25.3955, Val Loss: 0.1170\n",
      "Trial: 196, Epoch: 11, Train Loss: 50.8291, Val Loss: 0.1115\n",
      "Trial: 190, Epoch: 16, Train Loss: 65.9608, Val Loss: 0.1326\n",
      "Trial: 199, Epoch: 12, Train Loss: 25.4113, Val Loss: 0.1162\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:25:08,146] Trial 199 finished with value: 0.10259126598636309 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.009923906534527505, 'batch_size': 16, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 195, Epoch: 12, Train Loss: 50.5438, Val Loss: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:25:36,214] Trial 196 finished with value: 0.10377317491699667 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.003935136400058372, 'batch_size': 8, 'patience': 9}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 196, Epoch: 12, Train Loss: 50.6155, Val Loss: 0.1075\n",
      "Early stopping triggered.\n",
      "Trial: 190, Epoch: 17, Train Loss: 65.3269, Val Loss: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:25:53,746] Trial 195 finished with value: 0.10694021762920027 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0025710531079060975, 'batch_size': 8, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 195, Epoch: 13, Train Loss: 50.4288, Val Loss: 0.1123\n",
      "Early stopping triggered.\n",
      "Trial: 190, Epoch: 18, Train Loss: 64.6167, Val Loss: 0.1293\n",
      "Trial: 190, Epoch: 19, Train Loss: 64.3469, Val Loss: 0.1283\n",
      "Trial: 190, Epoch: 20, Train Loss: 63.0936, Val Loss: 0.1239\n",
      "Trial: 190, Epoch: 21, Train Loss: 62.5866, Val Loss: 0.1234\n",
      "Trial: 190, Epoch: 22, Train Loss: 62.2937, Val Loss: 0.1235\n",
      "Trial: 190, Epoch: 23, Train Loss: 61.3581, Val Loss: 0.1229\n",
      "Trial: 190, Epoch: 24, Train Loss: 60.6168, Val Loss: 0.1204\n",
      "Trial: 190, Epoch: 25, Train Loss: 60.0044, Val Loss: 0.1208\n",
      "Trial: 190, Epoch: 26, Train Loss: 59.2589, Val Loss: 0.1213\n",
      "Trial: 190, Epoch: 27, Train Loss: 58.5816, Val Loss: 0.1228\n",
      "Trial: 190, Epoch: 28, Train Loss: 58.1245, Val Loss: 0.1197\n",
      "Trial: 190, Epoch: 29, Train Loss: 57.6206, Val Loss: 0.1237\n",
      "Trial: 190, Epoch: 30, Train Loss: 57.0555, Val Loss: 0.1246\n",
      "Trial: 190, Epoch: 31, Train Loss: 56.3912, Val Loss: 0.1266\n",
      "Trial: 190, Epoch: 32, Train Loss: 55.9333, Val Loss: 0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-24 13:28:36,938] Trial 190 finished with value: 0.11966487377130684 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 3.334901367093877e-05, 'batch_size': 8, 'patience': 5}. Best is trial 101 with value: 0.10151587203145027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 190, Epoch: 33, Train Loss: 55.5981, Val Loss: 0.1299\n",
      "Early stopping triggered.\n",
      "Best Trial:\n",
      "FrozenTrial(number=101, state=TrialState.COMPLETE, values=[0.10151587203145027], datetime_start=datetime.datetime(2024, 12, 24, 8, 30, 41, 586558), datetime_complete=datetime.datetime(2024, 12, 24, 8, 59, 50, 470016), params={'hidden_dim': 64, 'latent_dim': 128, 'learning_rate': 0.0030668665466399994, 'batch_size': 16, 'patience': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'hidden_dim': IntDistribution(high=512, log=False, low=64, step=64), 'latent_dim': IntDistribution(high=128, log=False, low=32, step=32), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'batch_size': CategoricalDistribution(choices=(8, 16, 32, 64)), 'patience': IntDistribution(high=10, log=False, low=3, step=1)}, trial_id=101, value=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set GPU if available\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=200, n_jobs=multiprocessing.cpu_count())\n",
    "\n",
    "    print(\"Best Trial:\")\n",
    "    print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
