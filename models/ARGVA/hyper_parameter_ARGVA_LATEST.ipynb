{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import multiprocessing\n",
    "   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv , TransformerConv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "class DeepChemToPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        \"\"\"\n",
    "        Converts a list of PyG `Data` objects into an InMemoryDataset.\n",
    "        \n",
    "        Args:\n",
    "            data_list (list of Data): List of PyG Data objects.\n",
    "            transform (callable, optional): Optional transform applied to each data object.\n",
    "        \"\"\"\n",
    "        super(DeepChemToPyGDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data object at the specified index.\n",
    "        \"\"\"\n",
    "        return super().get(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_30428\\137928901.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load(r'../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n"
     ]
    }
   ],
   "source": [
    "pyg_dataset = torch.load(r'../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n",
    "dataset=pyg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(file_path):\n",
    "#     pyg_dataset = torch.load(r'C:\\Users\\sarab\\OneDrive\\Desktop\\CSIR\\generative_model_compare\\Convertors\\cleaned_frag_pyg_dataset.pth')\n",
    "#     dataset_length = len(pyg_dataset)\n",
    "\n",
    "#     # 80% training, 20% validation split\n",
    "#     train_size = int(0.8 * dataset_length)\n",
    "#     val_size = dataset_length - train_size\n",
    "#     train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "#         pyg_dataset, [train_size, val_size]\n",
    "#     )\n",
    "#     return train_dataset, val_dataset, pyg_dataset[0].num_features, pyg_dataset[0].edge_attr.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = pyg_dataset[0].x.shape[1]  # Should be 134 based on your description\n",
    "edge_features = pyg_dataset[0].edge_attr.shape[1]  # Should be 6 based on your description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class ARGVA(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(ARGVA, self).__init__()\n",
    "        # Initialize with correct input dimensions\n",
    "        self.encoder = VariationalEncoder(node_features, edge_features, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, node_features, edge_features)\n",
    "        self.discriminator = Discriminator(latent_dim)\n",
    "        \n",
    "    def encode(self, x, edge_index, edge_attr, batch=None):\n",
    "        return self.encoder(x, edge_index, edge_attr, batch)\n",
    "\n",
    "    def decode(self, z, edge_index, batch=None):\n",
    "        return self.decoder(z, edge_index, batch)\n",
    "\n",
    "    def discriminate(self, z):\n",
    "        return self.discriminator(z)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return mu + torch.randn_like(std) * std if self.training else mu\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        mu, logvar = self.encode(x, edge_index, edge_attr, batch)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, edge_index, batch) + (mu, logvar)\n",
    "\n",
    "    def generate_multiple_outputs(self, x, edge_index, edge_attr, num_samples=5, temperature=0.5):\n",
    "        mu, logvar = self.encode(x, edge_index, edge_attr)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        \n",
    "        outputs = []\n",
    "        for _ in range(num_samples):\n",
    "            with torch.no_grad():\n",
    "                z = mu + temperature * std * torch.randn_like(std)\n",
    "                x_rec, edge_rec = self.decode(z, edge_index)\n",
    "                outputs.append((\n",
    "                    F.softmax(x_rec/temperature, dim=-1),\n",
    "                    F.softmax(edge_rec/temperature, dim=-1),\n",
    "                    edge_index\n",
    "                ))\n",
    "        return outputs\n",
    "\n",
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        # First GCN layer processes node features\n",
    "        self.conv1 = GCNConv(node_features, hidden_dim)\n",
    "        # Second GCN layer processes combined features\n",
    "        self.conv2 = GCNConv(hidden_dim + edge_features, hidden_dim)\n",
    "        # Final transformation to latent space\n",
    "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        # Process node features first\n",
    "        h = F.relu(self.conv1(x, edge_index))\n",
    "        \n",
    "        # Add edge features to node embeddings\n",
    "        edge_feat = torch.zeros(h.size(0), edge_attr.size(1), device=x.device)\n",
    "        edge_feat.index_add_(0, edge_index[0], edge_attr)\n",
    "        \n",
    "        # Combine node embeddings with edge features\n",
    "        h = torch.cat([h, edge_feat], dim=-1)\n",
    "        \n",
    "        # Second convolution\n",
    "        h = F.relu(self.conv2(h, edge_index))\n",
    "        \n",
    "        # Pool if batch is provided\n",
    "        if batch is not None:\n",
    "            h = global_mean_pool(h, batch)\n",
    "        else:\n",
    "            h = h.mean(dim=0, keepdim=True)\n",
    "            \n",
    "        return self.mu(h), self.logvar(h)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, node_features, edge_features):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.node_out = nn.Linear(latent_dim, node_features)\n",
    "        self.edge_out = nn.Linear(latent_dim * 2, edge_features)\n",
    "        \n",
    "    def forward(self, z, edge_index, batch=None):\n",
    "        z = z[batch] if batch is not None else z.repeat(edge_index.max().item() + 1, 1)\n",
    "        \n",
    "        # Decode nodes\n",
    "        node_pred = self.node_out(z)\n",
    "        \n",
    "        # Decode edges using concatenated node features\n",
    "        edge_input = torch.cat([z[edge_index[0]], z[edge_index[1]]], dim=1)\n",
    "        edge_pred = self.edge_out(edge_input)\n",
    "        \n",
    "        return node_pred, edge_pred\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.out = nn.Linear(latent_dim, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return torch.sigmoid(self.out(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Fixed hyperparameter\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_argva_with_early_stopping(\n",
    "    model, train_dataset, val_dataset, num_epochs, batch_size, lr=1e-4, device='cuda', patience=10\n",
    "):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience//2, verbose=True)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Dynamic loss weights\n",
    "    beta_start = 0.01  # KL weight start\n",
    "    beta_end = 1.0    # KL weight end\n",
    "    adv_weight = 0.1  # Adversarial weight  #0.1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = total_recon_loss = total_kl_loss = total_adv_loss = 0\n",
    "        \n",
    "        # KL annealing\n",
    "        # beta = min(beta_start + (beta_end - beta_start) * epoch / (num_epochs // 2), beta_end)\n",
    "        beta = 0.01  #0.01\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "            )\n",
    "\n",
    "            # Reconstruction loss with edge importance\n",
    "            recon_loss = (\n",
    "                F.mse_loss(reconstructed_x, batch.x) * 1 +\n",
    "                F.mse_loss(reconstructed_edge_attr, batch.edge_attr) * 1\n",
    "            )\n",
    "\n",
    "            # KL divergence\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "            # Adversarial component\n",
    "            z = model.reparameterize(mu, logvar)\n",
    "            real_z = torch.randn_like(z)\n",
    "            real_scores = model.discriminate(real_z)\n",
    "            fake_scores = model.discriminate(z)\n",
    "            adv_loss = -torch.mean(torch.log(real_scores + 1e-8) + torch.log(1 - fake_scores + 1e-8))\n",
    "\n",
    "            # Combined loss\n",
    "            loss = recon_loss + beta * kl_loss + adv_weight * adv_loss\n",
    "\n",
    "            if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_recon_loss += recon_loss.item()\n",
    "                total_kl_loss += kl_loss.item()\n",
    "                total_adv_loss += adv_loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                    batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "                )\n",
    "                val_recon_loss = F.mse_loss(reconstructed_x, batch.x) + F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "                val_kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                val_loss += (val_recon_loss + beta * val_kl_loss).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f} Val: {val_loss:.4f} Beta: {beta:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import optuna\n",
    "import multiprocessing\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 00:57:39,100] A new study created in memory with name: no-name-450ef3e5-106f-4078-ada4-6b592d4de150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_30428\\535849477.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load(r'../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 1] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.04997842549958054, 'batch_size': 64, 'patience': 10}\n",
      "\n",
      "[Trial 5] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.08710140797905021, 'batch_size': 32, 'patience': 7}\n",
      "\n",
      "[Trial 9] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.005555908264553736, 'batch_size': 8, 'patience': 9}\n",
      "\n",
      "[Trial 13] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.09709893341602743, 'batch_size': 8, 'patience': 6}\n",
      "\n",
      "[Trial 15] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.032947189184635385, 'batch_size': 8, 'patience': 9}\n",
      "\n",
      "[Trial 2] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.005216984374571024, 'batch_size': 16, 'patience': 9}\n",
      "\n",
      "[Trial 10] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006518608445872273, 'batch_size': 64, 'patience': 6}\n",
      "\n",
      "[Trial 4] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 9.559326967707409e-05, 'batch_size': 64, 'patience': 5}\n",
      "\n",
      "[Trial 8] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.014057162685988176, 'batch_size': 8, 'patience': 8}\n",
      "\n",
      "[Trial 11] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.03292056245600919, 'batch_size': 32, 'patience': 7}\n",
      "\n",
      "[Trial 3] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.00023746689906228616, 'batch_size': 16, 'patience': 5}\n",
      "\n",
      "[Trial 7] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.0010717712990044857, 'batch_size': 16, 'patience': 9}\n",
      "\n",
      "[Trial 14] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.008724847965881365, 'batch_size': 64, 'patience': 10}\n",
      "\n",
      "[Trial 0] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 4.653557597801828e-05, 'batch_size': 64, 'patience': 4}\n",
      "\n",
      "[Trial 6] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0074380914575929245, 'batch_size': 32, 'patience': 9}\n",
      "\n",
      "[Trial 12] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 1.37598545768513e-05, 'batch_size': 64, 'patience': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60] Loss: 1.1128 Val: 0.3029 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.9070 Val: 0.1393 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 36.2629 Val: 0.1376 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2406 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.0369 Val: 0.2018 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2492 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1007163812471776896.0000 Val: inf Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1977 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.5693 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 1.0763 Val: 0.2875 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.5869 Val: 0.1170 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1494 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1412 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.8055 Val: 0.1578 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1589 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2292 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 1.0474 Val: 0.2736 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.3105 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3549 Val: 0.1232 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1811 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1315 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1184 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.5971 Val: 0.1463 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1407 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1351 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1189 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 1.0118 Val: 0.2607 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.2130 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1219 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1171 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.4081 Val: 0.1347 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1300 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.9890 Val: 0.2485 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1211 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1942 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 2997997937556.3325 Val: 0.1396 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2997 Val: 0.1136 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1165 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1143 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1130 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.2903 Val: 0.1227 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1234 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1648 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1679 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1717 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.9570 Val: 0.2371 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1894 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1971 Val: 0.1186 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1278 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1130 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1095 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.2385 Val: 0.1157 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1192 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1141 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.9363 Val: 0.2263 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1126 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1873 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1107 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1109 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.2148 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1150 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.9049 Val: 0.2158 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1872 Val: 0.1119 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [7/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [5/60] Loss: 0.1096 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1076 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1112 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.2062 Val: 0.1151 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:01:06,504] Trial 4 finished with value: 0.18040551443894703 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 9.559326967707409e-05, 'batch_size': 64, 'patience': 5}. Best is trial 4 with value: 0.18040551443894703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 16] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.04174757255332235, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [8/60] Loss: 0.1118 Val: 0.0938 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:01:09,447] Trial 5 finished with value: inf and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.08710140797905021, 'batch_size': 32, 'patience': 7}. Best is trial 4 with value: 0.18040551443894703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 17] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 1.9616575634979678e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch [5/60] Loss: 0.1128 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1596 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.8832 Val: 0.2060 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1899 Val: 0.1165 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1157 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1066 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1118 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.2016 Val: 0.1155 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1096 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.8507 Val: 0.1966 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1069 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1455 Val: 0.1239 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1129 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1250 Val: 0.1171 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1051 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1102 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.2012 Val: 0.1157 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1083 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1186 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1188 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.8311 Val: 0.1880 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 3.4942 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1046 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1460 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1107 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1981 Val: 0.1155 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [7/60] Loss: 0.1054 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1062 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.8003 Val: 0.1799 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:02:16,670] Trial 0 finished with value: 0.19229017198085785 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 4.653557597801828e-05, 'batch_size': 64, 'patience': 4}. Best is trial 4 with value: 0.18040551443894703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 18] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 2.1473004383391493e-05, 'batch_size': 64, 'patience': 9}\n",
      "Epoch [7/60] Loss: 0.1136 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1860 Val: 0.1155 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1098 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1027 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1129 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1047 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.7774 Val: 0.1727 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1176 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1044 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1026 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1091 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.7548 Val: 0.1662 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1101 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1033 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.0815 Val: 0.2325 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1356 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1110 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1022 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1020 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.7316 Val: 0.1606 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1027 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1040 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.8716 Val: 0.1350 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1828 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 1.0000 Val: 0.1979 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1072 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1518 Val: 0.1861 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1241 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1286 Val: 0.1187 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.7113 Val: 0.1557 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1040 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1009 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1026 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1125 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1171 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1116 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.9222 Val: 0.1699 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1024 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.6916 Val: 0.1516 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1032 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1015 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1027 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1101 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1289 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.8488 Val: 0.1519 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.6688 Val: 0.1479 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1038 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1006 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1101 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1013 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1789 Val: 0.1139 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1022 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.7719 Val: 0.1416 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1057 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.6494 Val: 0.1448 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1044 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1050 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1004 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0992 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.7093 Val: 0.1350 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1087 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.6321 Val: 0.1421 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1041 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1013 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0999 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0979 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1239 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.4142 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.6329 Val: 0.1289 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1054 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1999 Val: 0.1594 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.6096 Val: 0.1396 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1230 Val: 0.1298 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1040 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1007 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1777 Val: 0.1135 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1090 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0981 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.5668 Val: 0.1230 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1100 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1156 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1055 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.5957 Val: 0.1373 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1007 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1036 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1000 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0977 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1054 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.4962 Val: 0.1178 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.5788 Val: 0.1351 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1129 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1042 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1009 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1196 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0975 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1006 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.4295 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.5599 Val: 0.1330 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1056 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1044 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1737 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1000 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0973 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1083 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.3755 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.5424 Val: 0.1310 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1035 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1051 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1010 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0966 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0971 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.3314 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.5236 Val: 0.1289 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.2150 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.3460 Val: 0.3467 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1063 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1039 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1045 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1168 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1292 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0960 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.5025 Val: 0.1269 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0971 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.2982 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0972 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1090 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1168 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1718 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1001 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.4887 Val: 0.1250 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.2695 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0960 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1015 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0971 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1032 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1026 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1005 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.4699 Val: 0.1231 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.2519 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0966 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0958 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0972 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1017 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.4536 Val: 0.1213 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1004 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1138 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.2382 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1041 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0966 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0962 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1694 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.4375 Val: 0.1196 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1003 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.2289 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0971 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1944 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0968 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 1.1159 Val: 0.1673 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1018 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0958 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1042 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.4207 Val: 0.1180 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.0981 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1002 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.2201 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1277 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0965 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.4064 Val: 0.1165 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0957 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0971 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1084 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1122 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1009 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.2145 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1157 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1021 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1055 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0956 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.3917 Val: 0.1151 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1668 Val: 0.1110 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0942 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.2124 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1008 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.3756 Val: 0.1140 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0954 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0970 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1019 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.2097 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0982 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1002 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0966 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0936 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.3613 Val: 0.1129 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0950 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.2078 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1099 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0958 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0935 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0970 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1905 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.3514 Val: 0.1120 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1621 Val: 0.1586 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0972 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0952 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1004 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1630 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.2068 Val: 0.1095 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [35/60] Loss: 0.0971 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1291 Val: 0.1222 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:10:10,270] Trial 18 finished with value: 0.18537329534689587 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 2.1473004383391493e-05, 'batch_size': 64, 'patience': 9}. Best is trial 4 with value: 0.18040551443894703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 19] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.0006945617135233866, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [38/60] Loss: 0.3391 Val: 0.1113 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0937 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0952 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0961 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1085 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0968 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0984 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0979 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.3311 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1153 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1002 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0937 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0951 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1082 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.3203 Val: 0.1101 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0967 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1612 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0936 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0956 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3017 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0982 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0949 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1012 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.3086 Val: 0.1098 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0967 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0950 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0937 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.3022 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0975 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1634 Val: 0.1563 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [13/60] Loss: 0.0978 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1878 Val: 0.1123 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1810 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0979 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0958 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0968 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.2932 Val: 0.1093 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:11:40,317] Trial 13 finished with value: 0.15842104822146794 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.09709893341602743, 'batch_size': 8, 'patience': 6}. Best is trial 13 with value: 0.15842104822146794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 20] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.004672783734927634, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [39/60] Loss: 0.0947 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1070 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0933 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1275 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0968 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1574 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.2857 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0947 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1756 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0979 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0969 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0957 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0932 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1087 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1155 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.2804 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0946 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0929 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0930 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0978 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.2738 Val: 0.1088 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1710 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0942 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0966 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0956 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1054 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0947 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0930 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1876 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.2674 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1541 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0933 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0945 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1860 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.2613 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1668 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0938 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0968 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0955 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0929 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1326 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0946 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.2541 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0977 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1278 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0930 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1043 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0946 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1619 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0943 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.2505 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0936 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0949 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0955 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1071 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1087 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1515 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.2471 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0931 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0934 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0943 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0945 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1578 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0942 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.2416 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0955 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0941 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1166 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0976 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.2373 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1034 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1848 Val: 0.1109 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0945 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0945 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1512 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0939 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1489 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.2344 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0955 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1291 Val: 0.1179 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0922 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0941 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.2309 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0931 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1096 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0944 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0942 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1467 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0955 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.2278 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1088 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1014 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0941 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0972 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1027 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0915 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.2258 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0945 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1464 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0943 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1416 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0941 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0930 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0953 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1065 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.2222 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0916 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0941 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0937 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.2200 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1841 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0914 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0940 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1379 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0929 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0939 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0954 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1301 Val: 0.1164 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.2175 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1020 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0971 Val: 0.0942 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:16:34,950] Trial 12 finished with value: 0.1805521458387375 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 1.37598545768513e-05, 'batch_size': 64, 'patience': 8}. Best is trial 13 with value: 0.15842104822146794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 21] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 1.0575931414591631e-05, 'batch_size': 32, 'patience': 3}\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0929 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1440 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1042 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0937 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0939 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1353 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0953 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1089 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1014 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0940 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0919 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0937 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0938 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1325 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.0794 Val: 0.2399 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0929 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0937 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1009 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1027 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0953 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0917 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0970 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1419 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0938 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0938 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1832 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0927 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0941 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 1.0034 Val: 0.1993 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1303 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0918 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1149 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0956 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0936 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0917 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:18:16,984] Trial 1 finished with value: 0.09010067731142044 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.04997842549958054, 'batch_size': 64, 'patience': 10}. Best is trial 1 with value: 0.09010067731142044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 22] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.00010842907385255791, 'batch_size': 32, 'patience': 3}\n",
      "Epoch [32/60] Loss: 0.0938 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1024 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.9275 Val: 0.1670 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0939 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1281 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0938 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1006 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0969 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0924 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0951 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1399 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1098 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1015 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0937 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0937 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.8529 Val: 0.1482 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0923 Val: 0.0884 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:18:55,161] Trial 10 finished with value: 0.0937556544939677 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006518608445872273, 'batch_size': 64, 'patience': 6}. Best is trial 1 with value: 0.09010067731142044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 23] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.0007779816457270815, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [16/60] Loss: 0.1262 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0927 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.8018 Val: 0.1554 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1014 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0952 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0935 Val: 0.0879 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [58/60] Loss: 0.0926 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.7729 Val: 0.1401 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1829 Val: 0.1101 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:19:27,583] Trial 16 finished with value: 0.0885298083225886 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'learning_rate': 0.04174757255332235, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 24] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 5.676042441475006e-05, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [22/60] Loss: 0.0998 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1247 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.3582 Val: 0.1306 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0968 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1378 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1153 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0950 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.6950 Val: 0.1336 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1003 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0919 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.2196 Val: 0.1199 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1230 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.9971 Val: 0.1707 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0926 Val: 0.0907 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:20:13,184] Trial 14 finished with value: 0.09261286755402882 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.008724847965881365, 'batch_size': 64, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 25] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.00036232217775251067, 'batch_size': 32, 'patience': 3}\n",
      "Epoch [40/60] Loss: 0.0950 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1092 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.8099 Val: 0.1348 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.6130 Val: 0.1261 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1018 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0997 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0918 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1995 Val: 0.1205 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0967 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1216 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1363 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.5926 Val: 0.1162 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1005 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0951 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2226 Val: 0.1113 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.5183 Val: 0.1195 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.3773 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1828 Val: 0.1099 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1947 Val: 0.1199 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3813 Val: 0.1224 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1203 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.2605 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1175 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0989 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.4352 Val: 0.1138 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0952 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1935 Val: 0.1192 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0965 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.2179 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0991 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.2047 Val: 0.1164 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1342 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1188 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.2030 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.3698 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0949 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1092 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1920 Val: 0.1186 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1009 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1984 Val: 0.1146 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1957 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1174 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0988 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.3239 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0994 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1934 Val: 0.1120 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1644 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0946 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1907 Val: 0.1181 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0937 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1331 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0919 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1821 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1936 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1163 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1917 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.2883 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1175 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1896 Val: 0.1175 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0943 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1911 Val: 0.1123 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [5/60] Loss: 0.1918 Val: 0.1126 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0883 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:23:07,432] Trial 24 finished with value: 0.1867367595434189 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 5.676042441475006e-05, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 26] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.012924963480081689, 'batch_size': 32, 'patience': 3}\n",
      "Epoch [14/60] Loss: 0.0992 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0974 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1150 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.2625 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1885 Val: 0.1170 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1314 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0933 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1884 Val: 0.1125 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0945 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0914 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1092 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1007 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1145 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.2443 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1870 Val: 0.1165 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1991 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0994 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1871 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1514 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0941 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1813 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0973 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1130 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.2349 Val: 0.1076 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [27/60] Loss: 0.1300 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1169 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1870 Val: 0.1160 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:24:27,404] Trial 21 finished with value: 0.18268811802069346 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 1.0575931414591631e-05, 'batch_size': 32, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/60] Loss: 0.0935 Val: 0.0929 Beta: 0.0100\n",
      "\n",
      "[Trial 27] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.010258917030078004, 'batch_size': 16, 'patience': 3}\n",
      "Epoch [2/60] Loss: 0.1255 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1846 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0942 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0992 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1122 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1873 Val: 0.1156 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1144 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1820 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0968 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0914 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0942 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1096 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1007 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1287 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1109 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1858 Val: 0.1152 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0935 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1093 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1806 Val: 0.1111 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1756 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0987 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1392 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1807 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0941 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1849 Val: 0.1149 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1105 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1067 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1168 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1781 Val: 0.1111 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0970 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0914 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0940 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1278 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1846 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0938 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1053 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0957 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1101 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1204 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1754 Val: 0.1102 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0941 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1092 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1840 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1012 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1042 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0966 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1089 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1734 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1801 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1302 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1263 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0955 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1826 Val: 0.1142 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0940 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1118 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0937 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1017 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1714 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1179 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1083 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1824 Val: 0.1137 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0941 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1011 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0966 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1697 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0952 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1078 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1075 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1249 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1826 Val: 0.1134 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0934 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1010 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1096 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0941 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1004 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1674 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1068 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1817 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1802 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1236 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0958 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0965 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1006 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0940 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1641 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1060 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1195 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1243 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1063 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1808 Val: 0.1131 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0924 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1003 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0940 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1618 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0957 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1811 Val: 0.1129 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1053 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0913 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1001 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1058 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1090 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0940 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1604 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1004 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1231 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1794 Val: 0.1127 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0923 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1806 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1051 Val: 0.0945 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:30:25,205] Trial 11 finished with value: 0.08863396793603898 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.03292056245600919, 'batch_size': 32, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 28] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.01196142973073135, 'batch_size': 16, 'patience': 3}\n",
      "Epoch [7/60] Loss: 0.1193 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0998 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0958 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0940 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1187 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1572 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1797 Val: 0.1125 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0963 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1008 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1048 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0999 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0938 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1789 Val: 0.1124 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1220 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1556 Val: 0.1035 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:31:15,799] Trial 6 finished with value: 0.09192558005452156 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0074380914575929245, 'batch_size': 32, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 29] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.001075730868489503, 'batch_size': 16, 'patience': 3}\n",
      "Epoch [33/60] Loss: 0.0922 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0943 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1046 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0999 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1636 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1791 Val: 0.1123 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1097 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0958 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1530 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1005 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1005 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1802 Val: 0.1088 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1043 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1154 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0985 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0939 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1782 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1213 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1188 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0923 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1507 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2389 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1154 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0978 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1781 Val: 0.1120 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1042 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0956 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1007 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1487 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0938 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1773 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0986 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1209 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1039 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0923 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1092 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1797 Val: 0.1101 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1090 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1771 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1477 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1001 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1788 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0982 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1134 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0956 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1000 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0939 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1036 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1166 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1762 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1449 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1201 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0982 Val: 0.0936 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [3/60] Loss: 0.1678 Val: 0.1085 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:34:16,826] Trial 26 finished with value: 0.09630630339185396 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.012924963480081689, 'batch_size': 32, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 30] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 0.0009899212697901244, 'batch_size': 16, 'patience': 5}\n",
      "Epoch [36/60] Loss: 0.0922 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1064 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1036 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1763 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0940 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1434 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0998 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0954 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1758 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1032 Val: 0.0945 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [22/60] Loss: 0.1098 Val: 0.1041 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:35:02,003] Trial 19 finished with value: 0.1058363159497579 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.0006945617135233866, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 31] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 0.001588189246390009, 'batch_size': 16, 'patience': 5}\n",
      "Epoch [21/60] Loss: 0.1788 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1184 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1574 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1003 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1419 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1015 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1112 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0925 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0941 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1766 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1179 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2211 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0998 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0954 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1406 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1753 Val: 0.1111 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1486 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1180 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1014 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2075 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0924 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1393 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1702 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1749 Val: 0.1109 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0986 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0951 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1039 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1788 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1002 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1749 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1373 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1386 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1091 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0943 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1105 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1007 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1176 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1604 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1600 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0924 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1742 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0980 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1371 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0949 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1742 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1320 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1008 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1439 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1345 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1169 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1489 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1779 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1034 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0922 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1738 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0981 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1001 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0948 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1072 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0940 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1099 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1341 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1732 Val: 0.1102 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1280 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1317 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1007 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1390 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1174 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0919 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1726 Val: 0.1102 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1327 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0981 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0947 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0940 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1726 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1236 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1777 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1323 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1248 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1031 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1319 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1002 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1167 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1000 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1064 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1104 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1718 Val: 0.1099 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0976 Val: 0.0929 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:40:18,971] Trial 27 finished with value: 0.09432068342963855 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.010258917030078004, 'batch_size': 16, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/60] Loss: 0.0947 Val: 0.0894 Beta: 0.0100\n",
      "\n",
      "[Trial 32] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.0015946456096232935, 'batch_size': 16, 'patience': 5}\n",
      "Epoch [37/60] Loss: 0.1311 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1213 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1719 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1184 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1260 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0997 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1163 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0940 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1308 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1710 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0945 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1779 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2429 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1026 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1293 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1183 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1709 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1147 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1220 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1096 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1002 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1050 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0980 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0937 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1160 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1712 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0921 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1594 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1289 Val: 0.0982 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [46/60] Loss: 0.0946 Val: 0.0894 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:42:12,341] Trial 25 finished with value: 0.1284939942260583 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.00036232217775251067, 'batch_size': 32, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 33] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 0.002474917330215983, 'batch_size': 16, 'patience': 5}\n",
      "Epoch [50/60] Loss: 0.1696 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1167 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0939 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1122 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1183 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0977 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1781 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1162 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1436 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.1692 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1028 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0918 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0942 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1099 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2160 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1040 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0957 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0939 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.1693 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1145 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1156 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1096 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0978 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1318 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.1694 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1159 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1431 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0943 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.1681 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1769 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1134 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1248 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1129 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0979 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1077 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1024 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.1676 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1089 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1273 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1159 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1037 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0954 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0936 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0941 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.1680 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1197 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1117 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0975 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1108 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1061 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.1669 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1188 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0940 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1153 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1766 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0943 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1157 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0917 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.1661 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1023 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1094 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1102 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1128 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.1665 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0971 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1027 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0937 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1092 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1049 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0954 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1122 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.1150 Val: 0.0990 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [51/60] Loss: 0.0941 Val: 0.0890 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:46:49,273] Trial 3 finished with value: 0.11739822775125504 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.00023746689906228616, 'batch_size': 16, 'patience': 5}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/60] Loss: 0.1656 Val: 0.1069 Beta: 0.0100\n",
      "\n",
      "[Trial 34] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 96, 'learning_rate': 0.0022679682793483504, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0925 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:46:53,479] Trial 22 finished with value: 0.16081935067971548 and parameters: {'hidden_dim': 192, 'latent_dim': 32, 'learning_rate': 0.00010842907385255791, 'batch_size': 32, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 35] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 0.002226255085564582, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [6/60] Loss: 0.1093 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0936 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1091 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0969 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1768 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1101 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1082 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1037 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0940 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1099 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1022 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1066 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0918 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1018 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0937 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0953 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1079 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1079 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0969 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1064 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1024 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0939 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1928 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1045 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1891 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0935 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1765 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1071 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1073 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0967 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1095 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1022 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1034 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1058 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0938 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1020 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1017 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0951 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1052 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1307 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1067 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0970 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1297 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1023 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0937 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1762 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0937 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1045 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1012 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1044 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1097 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0917 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0976 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1013 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0968 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1056 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0936 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1010 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1179 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1034 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0936 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0953 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1034 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1006 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1173 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1013 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1747 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0937 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0965 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1024 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1047 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0936 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1089 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1027 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1000 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1001 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0970 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1096 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0935 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1001 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0918 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1018 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0952 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0964 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1046 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0935 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1112 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0971 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1749 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0930 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1022 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0995 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1011 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0918 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1091 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1066 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0961 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0967 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0936 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1042 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0969 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1004 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1008 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1014 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0988 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0950 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1070 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1745 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0965 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0962 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0934 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0929 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1040 Val: 0.0952 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:54:49,480] Trial 7 finished with value: 0.09033403173089027 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.0010717712990044857, 'batch_size': 16, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 36] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.03144594196198228, 'batch_size': 8, 'patience': 10}\n",
      "Epoch [19/60] Loss: 0.1001 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1043 Val: 0.0936 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:54:57,658] Trial 29 finished with value: 0.10141485755642256 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.001075730868489503, 'batch_size': 16, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 37] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.03256296250495541, 'batch_size': 8, 'patience': 10}\n",
      "Epoch [36/60] Loss: 0.1034 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1006 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0983 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0966 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0968 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0929 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0963 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0998 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0995 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0951 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1049 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1748 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0962 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1003 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0980 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1024 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0930 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0916 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0992 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0964 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1032 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1750 Val: 0.1167 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1669 Val: 0.1124 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0953 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0964 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0932 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0996 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0998 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0986 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0975 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0916 Val: 0.0924 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [29/60] Loss: 0.0963 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1031 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0951 Val: 0.0906 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:57:27,892] Trial 2 finished with value: 0.09313068625827631 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.005216984374571024, 'batch_size': 16, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 38] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.0339884673556373, 'batch_size': 8, 'patience': 10}\n",
      "Epoch [36/60] Loss: 0.1743 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1014 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0953 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1211 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0985 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1031 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1235 Val: 0.1229 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0977 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0997 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0960 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0952 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0964 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0927 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0988 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0981 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1025 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1005 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1737 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0953 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0970 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0950 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0994 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0961 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1641 Val: 0.1187 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1235 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0931 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0977 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1025 Val: 0.0955 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 01:59:27,080] Trial 20 finished with value: 0.09156058883915345 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.004672783734927634, 'batch_size': 16, 'patience': 8}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 39] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.034671418844170035, 'batch_size': 32, 'patience': 10}\n",
      "Epoch [3/60] Loss: 0.1189 Val: 0.1111 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0950 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0961 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0961 Val: 0.0941 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [26/60] Loss: 0.0963 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0987 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4301 Val: 0.1168 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0992 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0977 Val: 0.0896 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:00:14,356] Trial 28 finished with value: 0.0950864713639021 and parameters: {'hidden_dim': 512, 'latent_dim': 32, 'learning_rate': 0.01196142973073135, 'batch_size': 16, 'patience': 3}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 40] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.038574885634627874, 'batch_size': 8, 'patience': 5}\n",
      "Epoch [10/60] Loss: 0.0995 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1734 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1012 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0948 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1160 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0945 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1217 Val: 0.1226 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1231 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1025 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1189 Val: 0.1144 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0970 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0960 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1102 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0989 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0946 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1112 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0963 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0995 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0971 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0984 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1728 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1005 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1089 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0960 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0949 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1184 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.5462 Val: 0.1265 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0986 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1231 Val: 0.1180 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0946 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1197 Val: 0.1127 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1020 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1132 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0971 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1107 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0945 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0958 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0991 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0960 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0984 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0967 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1731 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0986 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1100 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0997 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1229 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1494 Val: 0.1320 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0949 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1230 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0944 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1227 Val: 0.1173 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1023 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1114 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0959 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0966 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0979 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1039 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0990 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0944 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0962 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1725 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1054 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0962 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0983 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1205 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0998 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0956 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1200 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1489 Val: 0.1327 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0978 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0950 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1192 Val: 0.1204 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1044 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0944 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1022 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0961 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1051 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0982 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0954 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0942 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0976 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1719 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1053 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0961 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1251 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0961 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0979 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0994 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1233 Val: 0.1177 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1478 Val: 0.1384 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1210 Val: 0.1147 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1063 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1027 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0941 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0954 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0959 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0972 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1064 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0945 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1012 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0940 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1719 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1197 Val: 0.1129 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0961 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0957 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0952 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0981 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0991 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1232 Val: 0.1126 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1013 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1225 Val: 0.1373 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0971 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1325 Val: 0.1267 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1022 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0941 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1011 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0948 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0957 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0953 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1013 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1225 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0968 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1714 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0939 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0964 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0956 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0977 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0991 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1011 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1123 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1253 Val: 0.1142 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1356 Val: 0.1286 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [46/60] Loss: 0.1020 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0923 Val: 0.0895 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:09:28,400] Trial 40 finished with value: 0.12924961870958826 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.038574885634627874, 'batch_size': 8, 'patience': 5}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/60] Loss: 0.0951 Val: 0.0916 Beta: 0.0100\n",
      "\n",
      "[Trial 41] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.03076338678087238, 'batch_size': 32, 'patience': 10}\n",
      "Epoch [36/60] Loss: 0.0938 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1013 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0947 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0971 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0958 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1016 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1252 Val: 0.1159 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1714 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2269 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0938 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0962 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0952 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1016 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1127 Val: 0.1124 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0946 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0983 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1123 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0979 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0967 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1163 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1020 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0922 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1017 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0945 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0939 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1105 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0944 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0946 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0971 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1129 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1714 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0963 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1077 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0935 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0978 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1126 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0962 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1130 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0944 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0984 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1065 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0976 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1021 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0944 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0980 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0947 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0922 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0935 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1059 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0960 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0944 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0974 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1133 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1705 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1050 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0972 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1126 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0946 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0925 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1140 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0942 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0980 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1063 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0960 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0976 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1021 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0946 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0970 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0923 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1058 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0936 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1128 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0974 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0945 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0942 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1070 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1710 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0961 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0936 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1129 Val: 0.1101 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0935 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1133 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1055 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0930 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0984 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0942 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0945 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.1021 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0934 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0975 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0944 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1070 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0911 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0958 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1133 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0935 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0933 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0945 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1013 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1701 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0934 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1131 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0944 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1154 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1010 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0936 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0942 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0927 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0978 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0957 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0934 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0940 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.1022 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0972 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1009 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1133 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0908 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0934 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0934 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0942 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1021 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.1695 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0957 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0933 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1128 Val: 0.1134 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1141 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0925 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1020 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0933 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0913 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0977 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0929 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0941 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.1019 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0942 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0973 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1020 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1136 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0906 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0956 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0909 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0934 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1015 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0941 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.1695 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1125 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0908 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0927 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0942 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1148 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1024 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0934 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0907 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0954 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0976 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0928 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.1017 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0941 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1133 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0977 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0973 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0908 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0940 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0934 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0975 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.1689 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1133 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0940 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0910 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0956 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0928 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1148 Val: 0.1146 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0973 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0907 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0932 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0976 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.1022 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0926 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0938 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0943 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1141 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0977 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0910 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0977 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0953 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0933 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0976 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1133 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.1689 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0903 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0941 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0928 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0942 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1146 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0978 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0902 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0934 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0954 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0978 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.1017 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1132 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0926 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0941 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0902 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0973 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0943 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1130 Val: 0.1128 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0976 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0903 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.1695 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0933 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0928 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0938 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0954 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1137 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0945 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0903 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1135 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.1021 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0938 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0934 Val: 0.0919 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [51/60] Loss: 0.0944 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0943 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0902 Val: 0.0929 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:23:46,173] Trial 33 finished with value: 0.09348297156393529 and parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 0.002474917330215983, 'batch_size': 16, 'patience': 5}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/60] Loss: 0.0941 Val: 0.0888 Beta: 0.0100\n",
      "\n",
      "[Trial 42] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.030212702541102233, 'batch_size': 32, 'patience': 10}\n",
      "Epoch [52/60] Loss: 0.0953 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0971 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1127 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0944 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0931 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0902 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.1681 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0911 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2298 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0939 Val: 0.0887 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [52/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:24:38,371] Trial 32 finished with value: 0.09033011707166831 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.0015946456096232935, 'batch_size': 16, 'patience': 5}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 43] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.030179464972871158, 'batch_size': 32, 'patience': 10}\n",
      "Epoch [19/60] Loss: 0.1148 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0949 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0901 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1122 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1159 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0952 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.1020 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0941 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0903 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0944 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0926 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1112 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4429 Val: 0.1123 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0971 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0941 Val: 0.0910 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [29/60] Loss: 0.0924 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1059 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0903 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0946 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.1681 Val: 0.1048 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:25:43,430] Trial 31 finished with value: 0.09281494108339151 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 0.001588189246390009, 'batch_size': 16, 'patience': 5}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 44] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.030346536341042007, 'batch_size': 32, 'patience': 10}\n",
      "Epoch [4/60] Loss: 0.1081 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1194 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0908 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0954 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0903 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1149 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0944 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1067 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1120 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1065 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.1022 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3767 Val: 0.1209 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0905 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0942 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0948 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1080 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1080 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0924 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0952 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0922 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1208 Val: 0.1163 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1055 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0904 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0947 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0972 Val: 0.0933 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:27:07,231] Trial 39 finished with value: 0.09347308923800786 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.034671418844170035, 'batch_size': 32, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 45] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 96, 'learning_rate': 0.027483105904999087, 'batch_size': 8, 'patience': 4}\n",
      "Epoch [7/60] Loss: 0.1056 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1089 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.1682 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0908 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1150 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0947 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1067 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1057 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1086 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1065 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1101 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0974 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0951 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1066 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0946 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1164 Val: 0.1126 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0940 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0926 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0921 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1091 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1055 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1054 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1108 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0930 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.1668 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0969 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1102 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0950 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1863 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1068 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0908 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1085 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1070 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1061 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1106 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1080 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0973 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1080 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0941 Val: 0.0895 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:29:33,131] Trial 15 finished with value: 0.09168881472168851 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'learning_rate': 0.032947189184635385, 'batch_size': 8, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 46] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.019099922961295604, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [8/60] Loss: 0.1124 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0920 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1063 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1031 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1053 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0951 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0929 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.1667 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1088 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0969 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1014 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1032 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1291 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1910 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0928 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0906 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1054 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1072 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1031 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1009 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1035 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1194 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0951 Val: 0.0945 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [45/60] Loss: 0.0930 Val: 0.0925 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:30:56,872] Trial 30 finished with value: 0.09698071678479513 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'learning_rate': 0.0009899212697901244, 'batch_size': 16, 'patience': 5}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 47] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.021515007546519384, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [30/60] Loss: 0.0940 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1033 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0922 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1012 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1040 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1101 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1047 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0924 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0929 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1038 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.1666 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1011 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1042 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1088 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0967 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1200 Val: 0.1137 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:31:44,257] Trial 17 finished with value: 0.16282704322278 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'learning_rate': 1.9616575634979678e-05, 'batch_size': 8, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60] Loss: 0.1928 Val: 0.1021 Beta: 0.0100\n",
      "\n",
      "[Trial 48] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.021735062287856516, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [47/60] Loss: 0.0928 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1053 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0910 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1068 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1034 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1023 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1043 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1067 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1185 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0928 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1041 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1018 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1052 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1047 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0938 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1958 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0920 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1110 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1054 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0926 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0926 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1040 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1019 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1048 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1059 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1202 Val: 0.0996 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:33:02,439] Trial 8 finished with value: 0.09104498716838219 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.014057162685988176, 'batch_size': 8, 'patience': 8}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 49] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.051842610593253895, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [4/60] Loss: 0.1088 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1240 Val: 0.1139 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0927 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0969 Val: 0.0929 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [28/60] Loss: 0.1055 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1019 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1046 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1069 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1086 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1041 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0907 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1000 Val: 0.0988 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:33:27,254] Trial 23 finished with value: 0.09462782781289406 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.0007779816457270815, 'batch_size': 8, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 50] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.05655005037861559, 'batch_size': 32, 'patience': 4}\n",
      "Epoch [5/60] Loss: 0.1075 Val: 0.0968 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:33:39,874] Trial 9 finished with value: 0.08958216431010671 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.005555908264553736, 'batch_size': 8, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/60] Loss: 0.0924 Val: 0.0923 Beta: 0.0100\n",
      "\n",
      "[Trial 51] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.02279690011074574, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [22/60] Loss: 0.1023 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1052 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.7766 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1061 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1046 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1005 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1058 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0922 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0941 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1052 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0926 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1026 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1077 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.6012 Val: 0.1149 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1049 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.0994 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1169 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1004 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1054 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3907 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1113 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0926 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1020 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1055 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1165 Val: 0.1138 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1052 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1056 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0990 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1149 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1004 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1073 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1062 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1260 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1027 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.0998 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1129 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0991 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1003 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1126 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1007 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1046 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1142 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0922 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0925 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1047 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0940 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1025 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.0998 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0990 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1146 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1003 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1208 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1004 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1001 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1136 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0925 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1023 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1124 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.0997 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0995 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1127 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1053 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1102 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1002 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1009 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1001 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1064 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1095 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0925 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1024 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1001 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1001 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1132 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0997 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1111 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1004 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1007 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1104 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0920 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0979 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0925 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1047 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0998 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0963 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1046 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1007 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1108 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0941 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1004 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1007 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1091 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0978 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0924 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0997 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0958 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1041 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1001 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1124 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1006 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1117 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1005 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1057 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1098 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0976 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1063 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0965 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0924 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0960 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1047 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1007 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0962 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1039 Val: 0.0980 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:38:05,027] Trial 41 finished with value: 0.09284032086531321 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.03076338678087238, 'batch_size': 32, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/60] Loss: 0.1003 Val: 0.0988 Beta: 0.0100\n",
      "\n",
      "[Trial 52] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.060591724092680245, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [9/60] Loss: 0.1111 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0975 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0963 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0963 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0965 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1058 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0922 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1049 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0970 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1043 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1007 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0938 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1035 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0976 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0964 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0957 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 34775.3313 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0968 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1003 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0969 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1051 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1005 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1149 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1054 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1029 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0978 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0963 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0944 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0964 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1245 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1010 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1063 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0966 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1045 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0962 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0980 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1035 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0948 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0968 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1005 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0965 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1370 Val: 0.1457 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1003 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1053 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0922 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0970 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0940 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0979 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1032 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0946 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0943 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0947 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0968 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1014 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1279 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1006 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0965 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1054 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1141 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0979 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0946 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0943 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1040 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0943 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0963 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1009 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1222 Val: 0.1189 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1010 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1068 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0964 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0977 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0946 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0941 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0943 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1038 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0929 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1017 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1006 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1244 Val: 0.1288 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1045 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0921 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0944 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0946 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0942 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0945 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1037 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0923 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0924 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0968 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1013 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1117 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0963 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1051 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1072 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0940 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0945 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0943 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0930 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1049 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0975 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1010 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1089 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0964 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1062 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0943 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0948 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0939 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0936 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0929 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0997 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0969 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1013 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1084 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0927 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1052 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0942 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0922 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0946 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0939 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0936 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0927 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0994 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0977 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0965 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0924 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1093 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0923 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1000 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0941 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0940 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1074 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0939 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0938 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0943 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0972 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0998 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1097 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0944 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1059 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0937 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0938 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0926 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0971 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0940 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0998 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0926 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1052 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1049 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0945 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0938 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0921 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0936 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0928 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0970 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0942 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0999 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0928 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1052 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0923 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0942 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0997 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0936 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0939 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1072 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0912 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0943 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0942 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0999 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0924 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0923 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1058 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0936 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0937 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1059 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0907 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0937 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0940 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0959 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0926 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0937 Val: 0.0914 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [36/60] Loss: 0.1045 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1061 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0937 Val: 0.0909 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:45:52,441] Trial 48 finished with value: 0.09284126237034798 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.021735062287856516, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 53] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.07842045082802288, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [46/60] Loss: 0.0910 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0901 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:45:56,079] Trial 47 finished with value: 0.0920222483575344 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.021515007546519384, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 54] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.049867844295586654, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [27/60] Loss: 0.0943 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0943 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0925 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0923 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0960 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1060 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0998 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0908 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0924 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1070 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0941 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 2244.0982 Val: 0.1863 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0945 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 29.1520 Val: 0.1284 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0926 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0927 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0966 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1060 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1922 Val: 0.1193 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0907 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1333 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1062 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0942 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0942 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0927 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0926 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1532 Val: 0.1210 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1149 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0957 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1046 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1067 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0907 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1272 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0918 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0930 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1127 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0928 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0926 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0924 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0935 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0960 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1146 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0992 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1105 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0908 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1065 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1074 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0928 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0924 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0926 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0926 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1192 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0926 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1088 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0934 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0908 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1290 Val: 0.1442 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1065 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1130 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0928 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0928 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1062 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.2450 Val: 0.1450 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1080 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1049 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0927 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0908 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1016 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0927 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1439 Val: 0.1125 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0920 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0918 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1096 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0928 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0935 Val: 0.0912 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [49/60] Loss: 0.0925 Val: 0.0934 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:49:12,993] Trial 46 finished with value: 0.09233782887458801 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.019099922961295604, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 55] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.06597826196617654, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [39/60] Loss: 0.0991 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1127 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0929 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0909 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1092 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1033 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0928 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0922 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1073 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1080 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0925 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0925 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1033 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0908 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0931 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1097 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1035.4389 Val: 0.1588 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0923 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1028 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1039 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0925 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0923 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1065 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1084 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1668 Val: 0.1239 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1047 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1040 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0912 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1031 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1085 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1205 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0924 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0919 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1035 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0924 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0906 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0990 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1101 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1188 Val: 0.1209 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0929 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1044 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0923 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1025 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0924 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1069 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0923 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1094 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1228 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0990 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0926 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0905 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0922 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0921 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1113 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1149 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1008 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1027 Val: 0.0970 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:51:32,595] Trial 42 finished with value: 0.09318279027938843 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.030212702541102233, 'batch_size': 32, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] Loss: 0.0925 Val: 0.0916 Beta: 0.0100\n",
      "\n",
      "[Trial 56] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.0591713543429676, 'batch_size': 64, 'patience': 6}\n",
      "Epoch [54/60] Loss: 0.0909 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1063 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1051 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0903 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1215 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1048 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1002 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0919 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0931 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0926 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1024 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1042 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.2358 Val: 0.4007 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0905 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1004 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 201.8585 Val: 0.1636 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0903 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0986 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1071 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.2071 Val: 0.1218 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0919 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0925 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1000 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1424 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0923 Val: 0.0916 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [28/60] Loss: 0.0973 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0904 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1071 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1052 Val: 0.0991 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:52:43,627] Trial 50 finished with value: 0.0920035868883133 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.05655005037861559, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 57] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.004224310792635588, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [10/60] Loss: 0.1348 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0905 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0965 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1198 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0924 Val: 0.0890 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:52:55,318] Trial 43 finished with value: 0.09280781174699465 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.030179464972871158, 'batch_size': 32, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 58] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.061690018751405215, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [41/60] Loss: 0.0926 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0920 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1068 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1096 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0953 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0992 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0904 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1168 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1067 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1058 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1039 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1050 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0972 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2439 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1136 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0920 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 129.5858 Val: 0.1304 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1026 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0905 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0976 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1041 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0975 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0919 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1633 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1113 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0992 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1365 Val: 0.1256 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0926 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1009 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1046 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0962 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0919 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1480 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1097 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1185 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0984 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1017 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1011 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1048 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0971 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1384 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1441 Val: 0.1374 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0922 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1140 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0925 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1022 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1056 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0905 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0944 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1309 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1178 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0979 Val: 0.0933 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:54:56,477] Trial 44 finished with value: 0.09336767171820005 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'learning_rate': 0.030346536341042007, 'batch_size': 32, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 59] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.059190473960588866, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [5/60] Loss: 0.1140 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1020 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1045 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0926 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1004 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1060 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0931 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1257 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1215 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0921 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1131 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1029 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0999 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0945 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0930 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1216 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1075 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0984 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1691 Val: 0.1233 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 83.3898 Val: 0.1337 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1023 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1008 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0933 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1028 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1182 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1153 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1012 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1385 Val: 0.1136 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0933 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0991 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1016 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0936 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0923 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1035 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1153 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1091 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1162 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0923 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0979 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1015 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0939 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1028 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1134 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0941 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1105 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1118 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0925 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1045 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0980 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1017 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1057 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0943 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1035 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1113 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1173 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0922 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1151 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0986 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0920 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0981 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0943 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0936 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1039 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0926 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0991 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1355 Val: 0.1293 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1103 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1150 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0984 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0961 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0922 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0935 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1000 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1641 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1081 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1008 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1109 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0943 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0926 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0988 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0982 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0926 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0988 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1125 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1070 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1128 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0993 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0979 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0922 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1007 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1027 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1065 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0938 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1070 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1054 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0991 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1012 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0980 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0996 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0921 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1023 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1051 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1106 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0919 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0987 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [45/60] Loss: 0.0949 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0985 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0943 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1001 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0919 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1035 Val: 0.0966 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 02:59:00,985] Trial 49 finished with value: 0.09169039378563563 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'learning_rate': 0.051842610593253895, 'batch_size': 32, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 60] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.003936428222704068, 'batch_size': 64, 'patience': 6}\n",
      "Epoch [17/60] Loss: 0.1049 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1069 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0967 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0955 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1010 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0919 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1022 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1010 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1039 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1184 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0934 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0957 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0942 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0967 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1041 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0919 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1030 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2507 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1071 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0957 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0919 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1033 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0949 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0937 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1047 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1022 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1699 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1024 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0953 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1004 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0993 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0958 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0916 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0942 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0919 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1021 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1561 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1004 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0919 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0956 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0952 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0977 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0983 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0947 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1016 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1440 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1017 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0954 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0998 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0969 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0952 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1006 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1014 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1363 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1009 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0955 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0935 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1002 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0965 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0949 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1010 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1310 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1007 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0953 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1002 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0979 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0919 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0921 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1047 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0956 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0980 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1251 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0936 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1006 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0955 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0996 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1003 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0946 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0935 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0967 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1212 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0916 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0920 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0946 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1005 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0958 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0968 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0933 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0934 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0922 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1187 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0984 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1000 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0961 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0951 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1008 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0932 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0921 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0922 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1164 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0988 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0959 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0995 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0935 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0952 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0935 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0924 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0922 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1137 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0979 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0959 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0961 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0995 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1043 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0918 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0938 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1116 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0984 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0936 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0958 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1004 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0970 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0989 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0940 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0948 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0924 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1105 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0951 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0918 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0959 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0967 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0986 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0945 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0935 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1086 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0923 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0935 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0955 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1004 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0973 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0917 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0990 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1078 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0925 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0944 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0956 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0946 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0936 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0918 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0945 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1066 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0987 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0924 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0951 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1047 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0954 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0916 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0933 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0920 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0928 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0915 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1061 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0951 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0924 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0987 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1000 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0935 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0950 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0948 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0934 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1051 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0922 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0917 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0953 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0924 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0969 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0953 Val: 0.0922 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:05:54,396] Trial 51 finished with value: 0.08890715589125951 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.02279690011074574, 'batch_size': 32, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] Loss: 0.0933 Val: 0.0907 Beta: 0.0100\n",
      "\n",
      "[Trial 61] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.07237585611160817, 'batch_size': 64, 'patience': 7}\n",
      "Epoch [19/60] Loss: 0.1040 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0917 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0934 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0956 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1000 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0953 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0961 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0934 Val: 0.0905 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:06:17,692] Trial 53 finished with value: 0.09254527489344279 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.07842045082802288, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 62] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.005178259466345686, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [20/60] Loss: 0.1034 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0930 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0926 Val: 0.0905 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:06:31,488] Trial 54 finished with value: 0.09011040031909942 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.049867844295586654, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 63] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.005157669975296654, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [39/60] Loss: 0.0936 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0961 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1007.3524 Val: 0.2127 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0932 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1031 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1048 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0923 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0919 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0938 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1894 Val: 0.1184 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0959 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0917 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1024 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0918 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0949 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1001 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0924 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0919 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0936 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1220 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0961 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1022 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0926 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0915 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0941 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1180 Val: 0.1449 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1021 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0958 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0998 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0923 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0939 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1442 Val: 0.1312 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1011 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0960 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0941 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1242 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1652 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.1048 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1001 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0927 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1622 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0955 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0940 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1204 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0919 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0946 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0996 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0999 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0925 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0915 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0930 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0955 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1201 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0920 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0996 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0926 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0923 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0957 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1116 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0999 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0927 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0992 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0918 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1976 Val: 0.2204 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0956 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0923 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0929 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0990 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0921 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0997 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1204 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1402 Val: 0.1202 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0956 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0922 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0918 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0932 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0990 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1189 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0921 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0948 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:10:28,897] Trial 55 finished with value: 0.09076065570116043 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.06597826196617654, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/60] Loss: 0.1292 Val: 0.1132 Beta: 0.0100\n",
      "\n",
      "[Trial 64] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.004999397284523493, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [48/60] Loss: 0.1003 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0957 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0923 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0916 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0922 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0985 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1137 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0954 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0922 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0981 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0999 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1079 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0915 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0915 Val: 0.0917 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:11:19,546] Trial 52 finished with value: 0.09004842862486839 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.060591724092680245, 'batch_size': 32, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 65] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.005773529759097989, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [53/60] Loss: 0.0925 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0950 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0980 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1060 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0993 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0923 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0947 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0918 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1119 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0977 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1078 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0950 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0915 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1116 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0919 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1000 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0946 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0980 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1081 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0923 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1080 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0945 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1647 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0978 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0915 Val: 0.0917 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:12:40,451] Trial 56 finished with value: 0.09070188899834951 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.0591713543429676, 'batch_size': 64, 'patience': 6}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 66] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.006483912159224152, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [57/60] Loss: 0.0923 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0955 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1081 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0975 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0945 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0924 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1041 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0985 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0974 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0918 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0945 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0920 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1608 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0946 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1097 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1030 Val: 0.1005 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:13:30,551] Trial 35 finished with value: 0.09078973951209493 and parameters: {'hidden_dim': 64, 'latent_dim': 96, 'learning_rate': 0.002226255085564582, 'batch_size': 8, 'patience': 8}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 67] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.0966720571627932, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [40/60] Loss: 0.0974 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0917 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0919 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0945 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0993 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1079 Val: 0.0978 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:13:45,292] Trial 58 finished with value: 0.09086574018001556 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.061690018751405215, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n",
      "\n",
      "[Trial 68] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.004893516589484412, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [22/60] Loss: 0.1042 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0970 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0947 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1033 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1201 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0958 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0971 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0942 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1048 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1601 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0970 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0990 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1042 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0945 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.0027 Val: inf Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0950 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0970 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1173 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1059 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1086 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0943 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0959 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1070 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0965 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1053 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0944 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1651 Val: 0.1048 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:15:44,124] Trial 57 finished with value: 0.09139206657807032 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'learning_rate': 0.004224310792635588, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 69] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.006336401109077662, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [31/60] Loss: 0.0956 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0954 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1014 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1122 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0914 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.0000 Val: inf Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:15:57,527] Trial 59 finished with value: 0.09222044746081035 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.059190473960588866, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 70] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.0065969997998444815, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [29/60] Loss: 0.1000 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0951 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1164 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0993 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1004 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0948 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0952 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1107 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1001 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1084 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0959 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0950 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1068 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1009 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0950 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1198 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0953 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1009 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1101 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0950 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0984 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1635 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1015 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1091 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0948 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1672 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0946 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1019 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0948 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0956 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1071 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0983 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1087 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0949 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1055 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0974 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0926 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1113 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0969 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0948 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1071 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0983 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1185 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0970 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1080 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0947 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0948 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1178 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0974 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0947 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0957 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0970 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1067 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0946 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1080 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1054 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0974 Val: 0.0959 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:20:09,478] Trial 34 finished with value: 0.08939502491545276 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'learning_rate': 0.0022679682793483504, 'batch_size': 8, 'patience': 8}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 71] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.007623391622447656, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [34/60] Loss: 0.0925 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1093 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0944 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0981 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0980 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1071 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0942 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0929 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0987 Val: 0.0963 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:20:48,412] Trial 60 finished with value: 0.09434979905684789 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.003936428222704068, 'batch_size': 64, 'patience': 6}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/60] Loss: 0.1116 Val: 0.1033 Beta: 0.0100\n",
      "\n",
      "[Trial 72] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.018061505448184818, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [7/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1066 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1132 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0984 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0955 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0983 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1010 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1068 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0961 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1053 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.0000 Val: inf Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [5/60] Loss: 0.1073 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0987 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0951 Val: 0.0954 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:22:03,563] Trial 67 finished with value: inf and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.0966720571627932, 'batch_size': 8, 'patience': 8}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 73] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.007259509429056172, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [1/60] Loss: 0.1625 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1058 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0927 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0950 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1065 Val: 0.1013 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:22:22,695] Trial 36 finished with value: 0.09179064258933067 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.03144594196198228, 'batch_size': 8, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 74] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.006325532425102993, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [4/60] Loss: 0.1103 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1114 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0950 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1952 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0954 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0951 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1009 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0925 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1062 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1055 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0952 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0984 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1070 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0947 Val: 0.0947 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:23:38,806] Trial 37 finished with value: 0.09873521634761025 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.03256296250495541, 'batch_size': 8, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 75] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.007998217898011743, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [2/60] Loss: 0.1175 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1062 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0947 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1054 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1635 Val: 0.1162 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1090 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1106 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1624 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0945 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0955 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1214 Val: 0.1208 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0947 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1011 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0927 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1046 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1057 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0949 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1072 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0952 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1116 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1007 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1187 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1063 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0951 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1627 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1088 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1183 Val: 0.1101 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1095 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0954 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0949 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1204 Val: 0.1049 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:25:52,749] Trial 61 finished with value: 0.09464271118243535 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.07237585611160817, 'batch_size': 64, 'patience': 7}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 76] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.006776474656616444, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [38/60] Loss: 0.0925 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1007 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1044 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1050 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1069 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1004 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1113 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1120 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1172 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1061 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1114 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1080 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0953 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1036 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1218 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0927 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1006 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1652 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0997 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1046 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1058 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1003 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1097 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1100 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1134 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1055 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1108 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0954 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1084 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1035 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1198 Val: 0.1180 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:28:52,942] Trial 38 finished with value: 0.09252746547220134 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'learning_rate': 0.0339884673556373, 'batch_size': 8, 'patience': 10}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 77] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.007638170355663797, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [40/60] Loss: 0.0917 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1004 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1192 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0996 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1061 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1053 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2013 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1001 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1103 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1110 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1095 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1059 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1086 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1365 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1074 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1033 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1210 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1003 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1140 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1201 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0993 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1053 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1054 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1142 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1114 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1107 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1001 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1061 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1095 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1085 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1106 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1018 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1031 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1221 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1080 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1003 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1124 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0990 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1051 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1062 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1050 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1104 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1098 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0999 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1056 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1047 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1083 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1099 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1031 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1020 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1205 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1040 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1001 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1117 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0987 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1037 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1051 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1050 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1104 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1082 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0998 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1028 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1058 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1079 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1095 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0916 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1030 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1027 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1018 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1195 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0994 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1101 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0947 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1028 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1054 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1115 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0998 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1083 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1022 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0996 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1056 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1077 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1098 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1022 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1028 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1121 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1017 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0995 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1102 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1023 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0946 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1053 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1107 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1021 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1087 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0996 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0955 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1055 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1081 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1095 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1024 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1027 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1127 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1017 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0996 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1102 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1017 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0944 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0996 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1109 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0975 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1028 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0994 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1021 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1002 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0956 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0972 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1088 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1027 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1127 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0999 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1015 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1102 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0972 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0946 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0994 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1106 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0972 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1030 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1019 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1003 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0957 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0994 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0972 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1039 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1023 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1130 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0995 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1099 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0971 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1013 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0945 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0993 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1105 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0973 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1033 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1020 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0998 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0957 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0991 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0942 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1037 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0936 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1018 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1039 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0997 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1141 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1015 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0943 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0992 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1044 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1029 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1019 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0996 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0956 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0990 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0937 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1035 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1037 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0951 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0980 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1127 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0944 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1012 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0986 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1046 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1027 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1021 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0995 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0953 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0925 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0989 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1036 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1045 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0949 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0973 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1131 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0942 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1008 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0990 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0921 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1037 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1025 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1019 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0993 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0950 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0922 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0984 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0923 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1036 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1040 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0949 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0972 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1137 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0942 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0969 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0985 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0923 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1042 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1028 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1017 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0992 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0919 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0951 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0985 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0917 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1035 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1031 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0947 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0970 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1070 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0942 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0962 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1038 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0987 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1027 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1016 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0992 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0952 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0989 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1034 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0946 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1036 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0940 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0968 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1066 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1037 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0986 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0959 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1020 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1013 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0992 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0951 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0984 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0919 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1029 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0947 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1031 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0942 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0968 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1066 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1037 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0989 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0958 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1010 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1024 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0992 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0949 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0986 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1030 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0948 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0943 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1032 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0967 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1064 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1037 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0982 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0957 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1013 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1022 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0988 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0931 Val: 0.0865 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0914 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0947 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1032 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0942 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0942 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0967 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1024 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1039 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1061 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0986 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1011 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1022 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0957 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0992 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0929 Val: 0.0865 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0944 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1031 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0921 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1036 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0966 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1061 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1032 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0985 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1013 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1019 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0958 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0991 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0929 Val: 0.0865 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0943 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1030 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0944 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0921 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1034 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:57:41,474] Trial 45 finished with value: 0.09072748562242805 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'learning_rate': 0.027483105904999087, 'batch_size': 8, 'patience': 4}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 78] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.014811135569689188, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [27/60] Loss: 0.0966 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1061 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1028 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0941 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1012 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1024 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0955 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0987 Val: 0.0962 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 03:58:19,247] Trial 77 finished with value: 0.09195966819922129 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.007638170355663797, 'batch_size': 32, 'patience': 8}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 79] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.016029782914330375, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [1/60] Loss: 0.2244 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0935 Val: 0.0865 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1229 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1029 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0942 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0945 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1033 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2360 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0964 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1058 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1011 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1025 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0942 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1132 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1024 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1237 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0954 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0948 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1100 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0930 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1157 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1076 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0981 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0943 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1107 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0945 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1034 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0926 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1083 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0967 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1012 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1059 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0942 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1030 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1019 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1081 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0949 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1064 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0954 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1086 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0935 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1064 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1068 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0982 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1035 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0945 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0940 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0924 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1066 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1009 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0965 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1057 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0942 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1020 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1064 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1026 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1050 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0946 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0953 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1062 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1007 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0932 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1014 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1006 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0977 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1035 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0945 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0918 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0942 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1011 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1017 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0941 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0964 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1056 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1018 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1008 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1026 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0945 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1009 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0950 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1009 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0934 Val: 0.0865 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1011 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1009 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0977 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0986 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0943 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0917 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0941 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1007 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1019 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1010 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0941 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0973 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0963 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1008 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1029 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0944 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1019 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1011 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0953 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0932 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1020 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1018 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0983 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1011 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1021 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1015 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0942 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0939 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0973 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1002 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0981 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0943 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0975 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0970 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0952 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0933 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0971 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0975 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0979 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0976 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0918 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0970 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1007 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0977 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0943 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0967 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0938 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0964 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0998 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0969 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0946 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0977 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0974 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0919 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0926 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0971 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0976 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0977 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0970 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0971 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0919 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0918 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1012 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0978 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0965 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0914 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0943 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0962 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1000 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0937 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0980 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0945 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0974 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0934 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0922 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0924 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0973 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0978 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0970 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0935 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1010 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0942 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0911 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0942 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0935 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0996 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0941 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0941 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0971 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0938 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0923 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0939 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0975 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0936 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0970 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0942 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0963 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0963 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0915 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0922 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0937 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0932 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0995 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0940 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0948 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0919 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0975 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0943 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0921 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0927 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0975 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0971 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0926 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0961 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0960 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0920 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0915 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0922 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0941 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0931 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0992 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0943 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0919 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0969 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0922 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0926 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0972 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0920 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0971 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0922 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0960 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0909 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0920 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0959 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0916 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0922 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0932 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0993 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0941 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0918 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0918 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0966 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0922 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0922 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0925 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0973 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0907 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0970 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0922 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0959 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0908 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0961 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0916 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0923 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0933 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0992 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0939 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0924 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0968 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0914 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0975 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0925 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0907 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0925 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0968 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0958 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0908 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0959 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0908 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0913 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0931 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0992 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0941 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0966 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0971 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0926 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0908 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0918 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0955 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0970 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0910 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0960 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0906 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0914 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0919 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0995 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0916 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0972 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0967 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0925 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0958 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0910 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0966 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0958 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0906 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0919 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0916 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0992 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0914 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0970 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0964 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0928 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0956 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0971 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0906 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0907 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0958 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0917 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0907 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0920 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0991 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0922 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0934 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0928 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0966 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0956 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0970 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0904 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0958 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0906 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0916 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0906 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0914 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0992 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0936 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0915 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0954 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0926 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0967 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0968 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0903 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0959 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0905 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:26:37,770] Trial 78 finished with value: 0.09161697775125503 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.014811135569689188, 'batch_size': 32, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 80] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.017973654897907282, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [48/60] Loss: 0.0907 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0908 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0994 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0933 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0922 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0954 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0925 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0968 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0968 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0904 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0959 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0906 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0907 Val: 0.0912 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:28:12,177] Trial 79 finished with value: 0.09001120328903198 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.016029782914330375, 'batch_size': 32, 'patience': 9}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 81] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.018419379797182316, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [1/60] Loss: 0.1838 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0909 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0990 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0932 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2457 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0953 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0923 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0967 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0968 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0959 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0905 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1246 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0905 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0904 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1222 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0910 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1156 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0917 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0996 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0932 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1110 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0951 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0922 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0934 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0965 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1097 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0958 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0906 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0903 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0904 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1191 Val: 0.1137 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1079 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0914 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0988 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0932 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1084 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0921 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0922 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0935 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1070 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0964 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0959 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0906 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0903 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0902 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1183 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1063 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0910 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0934 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0954 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1068 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0924 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1068 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0937 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0960 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0970 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0909 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0906 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0903 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1078 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1199 Val: 0.1165 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0911 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0934 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1066 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0955 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0921 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0913 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1014 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0925 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0934 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0962 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0969 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0906 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1014 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0903 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0904 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1200 Val: 0.1206 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0910 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1012 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0933 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0951 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0919 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0924 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1015 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0925 Val: 0.0864 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0937 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0961 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0901 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [49/60] Loss: 0.0965 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1016 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0904 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1106 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0906 Val: 0.0914 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:37:17,902] Trial 62 finished with value: 0.09046376124024391 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.005178259466345686, 'batch_size': 8, 'patience': 6}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 82] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.015357568193474978, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [56/60] Loss: 0.0909 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1022 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0934 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0949 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0916 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0923 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2264 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1021 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0910 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0934 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0924 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0957 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [2/60] Loss: 0.1256 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1024 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0963 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0902 Val: 0.0912 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:38:42,783] Trial 63 finished with value: 0.090206148118532 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.005157669975296654, 'batch_size': 8, 'patience': 6}. Best is trial 16 with value: 0.0885298083225886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/60] Loss: 0.1108 Val: 0.1020 Beta: 0.0100\n",
      "\n",
      "[Trial 83] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.015403247483316281, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [53/60] Loss: 0.0904 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1146 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0978 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0912 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0950 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0923 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1118 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2235 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0981 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0960 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1104 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1255 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0980 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1124 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0901 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0967 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1065 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0902 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1146 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0981 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1075 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1086 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0949 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0982 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1058 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0867 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1078 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0925 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0925 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1113 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0904 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1059 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1063 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0969 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0905 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0907 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0979 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1062 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1065 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0909 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0947 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0978 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1063 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1059 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0917 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0923 Val: 0.0863 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0923 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0983 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1055 Val: 0.0974 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:43:13,626] Trial 64 finished with value: 0.08691991427365471 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.004999397284523493, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 84] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0025798234904587255, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [9/60] Loss: 0.1006 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1130 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0902 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0969 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0909 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0980 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0903 Val: 0.0914 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1060 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1011 Val: 0.0962 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:43:51,879] Trial 66 finished with value: 0.09226627685442693 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.006483912159224152, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 85] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010283957448726072, 'batch_size': 8, 'patience': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:43:53,797] Trial 69 finished with value: 0.09184018387889661 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.006336401109077662, 'batch_size': 8, 'patience': 6}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 86] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0027278598234446, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [55/60] Loss: 0.0910 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0980 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0947 Val: 0.0869 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1009 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1007 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0922 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0924 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0941 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1009 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1010 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2209 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1116 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0905 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0967 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1793 Val: 0.1023 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:45:08,414] Trial 68 finished with value: 0.09152409315359693 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.004893516589484412, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 87] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0029453400499267735, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [34/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1016 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1011 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1598 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1016 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1012 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0943 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0948 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0913 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1574 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1436 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2169 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0921 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0925 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1014 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1013 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0942 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1334 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1123 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1570 Val: 0.1000 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:46:40,731] Trial 65 finished with value: 0.09105799340901255 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.005773529759097989, 'batch_size': 8, 'patience': 6}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 88] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.003033314912117281, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [16/60] Loss: 0.1015 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1014 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1290 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0928 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1255 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1418 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0909 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1016 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1018 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0940 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1207 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1167 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0947 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0912 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1303 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2276 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0921 Val: 0.0868 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1011 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1014 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0926 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0922 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1173 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1064 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1237 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1567 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1017 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1016 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1153 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1132 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0928 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1186 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1399 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1017 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0977 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0918 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1106 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1134 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1151 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1307 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0948 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1014 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0975 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0921 Val: 0.0914 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:49:21,450] Trial 70 finished with value: 0.0889552605314916 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.0065969997998444815, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 89] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.009767672537855512, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [42/60] Loss: 0.0918 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1091 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1117 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1056 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1235 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1019 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0977 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1073 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1090 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1098 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1184 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0929 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1017 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0976 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1057 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1076 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1152 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1119 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0946 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0972 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0972 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0865 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1065 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1055 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1125 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1057 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0969 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1664 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0975 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0919 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1048 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1095 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0910 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1054 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1037 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0972 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0975 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0928 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0907 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1035 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1078 Val: 0.0932 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:52:11,290] Trial 74 finished with value: 0.09073817332376953 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.006325532425102993, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 90] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0033148607137678345, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [15/60] Loss: 0.1024 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1122 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0972 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0971 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0947 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0924 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0921 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1025 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1064 Val: 0.0921 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:52:43,051] Trial 73 finished with value: 0.0919857814657588 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.007259509429056172, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 91] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.010085465141018978, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [17/60] Loss: 0.1056 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0972 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0977 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1023 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1174 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0921 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1051 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1023 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0970 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1039 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0976 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1017 Val: 0.0919 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:53:27,787] Trial 75 finished with value: 0.0902214622234597 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.007998217898011743, 'batch_size': 8, 'patience': 8}. Best is trial 64 with value: 0.08691991427365471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 92] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.003275753369234194, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [1/60] Loss: 0.2150 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0929 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1046 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0921 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1012 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0975 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0976 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1108 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0924 Val: 0.0862 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1008 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1310 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1731 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1029 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0904 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:54:17,502] Trial 72 finished with value: 0.08646482492194456 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.018061505448184818, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 93] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0029996984321543486, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [1/60] Loss: 0.2183 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1010 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1055 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0972 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0971 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1138 Val: 0.1168 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1186 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1004 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1027 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1586 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0971 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0974 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1008 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1020 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1122 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1019 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1004 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0928 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1419 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0974 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0939 Val: 0.0887 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:55:35,652] Trial 71 finished with value: 0.09158059253412135 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.007623391622447656, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 94] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0030800661816245962, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [19/60] Loss: 0.1000 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1098 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1115 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1015 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1263 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1300 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0971 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0939 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1055 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0977 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1133 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0995 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1075 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1751 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1002 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0912 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1232 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0971 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0939 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0971 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1067 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0991 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1000 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1012 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0968 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0939 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1176 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1065 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0970 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0995 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0987 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1113 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0971 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0866 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0939 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0912 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1142 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1142 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1054 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1721 Val: 0.1028 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:57:49,630] Trial 76 finished with value: 0.08691449144056865 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.006776474656616444, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 95] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.003477575589105216, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [9/60] Loss: 0.1056 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1129 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0993 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0968 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1269 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0987 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0967 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0939 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1112 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1050 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0992 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0971 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0969 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0923 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0987 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1001 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1087 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0913 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1050 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0990 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0973 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1052 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1066 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0979 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0966 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1051 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1053 Val: 0.0980 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 04:59:23,442] Trial 81 finished with value: 0.09102960328261057 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.018419379797182316, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 96] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.003143508721113269, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [4/60] Loss: 0.1101 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1241 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0963 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1122 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0935 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1140 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1051 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1674 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1043 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0983 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0963 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0959 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0932 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0921 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1036 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1037 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1005 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0978 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0958 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0965 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0935 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1043 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1052 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1029 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1051 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0958 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0975 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1064 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1132 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1130 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0932 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0962 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1746 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1033 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1099 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1022 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1214 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0956 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0971 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0921 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0933 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0961 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1042 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1011 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0956 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0921 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0995 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0931 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0971 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1036 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1051 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0963 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0954 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1049 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1007 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1057 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0993 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0946 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1055 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1080 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1259 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0956 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0957 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1060 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1121 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1007 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0991 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0943 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0954 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0922 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0996 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1000 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0988 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1001 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0942 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0954 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0916 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1065 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0991 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0956 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1047 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0993 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1051 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0955 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1051 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1153 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0995 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1051 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1071 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0955 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0943 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0989 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0941 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0994 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0998 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0943 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0954 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0989 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0915 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0987 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0992 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1062 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1050 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0943 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0911 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0954 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1040 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0984 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0954 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1037 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1034 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1055 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0942 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1090 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0910 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0952 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0956 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0976 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0995 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0943 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0940 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0911 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0955 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0950 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1064 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0986 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0977 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0938 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0943 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0916 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0911 Val: 0.0909 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:08:20,426] Trial 82 finished with value: 0.08882466480135917 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.015357568193474978, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 97] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0029601272152669934, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [14/60] Loss: 0.1050 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0958 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0951 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1036 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0976 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1024 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0943 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1023 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1039 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0954 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1067 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0991 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0948 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0939 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0956 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0941 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0954 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1066 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0983 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0948 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0953 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0909 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:10:02,837] Trial 83 finished with value: 0.09141790270805358 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.015403247483316281, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 98] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010435491243756156, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [32/60] Loss: 0.0934 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0941 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1049 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1783 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0939 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1034 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0948 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0953 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1016 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1019 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1034 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0991 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0931 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1055 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0929 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0946 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0950 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1060 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0929 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0942 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0931 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0947 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0937 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0948 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1598 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1269 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1051 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0929 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0983 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0929 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0988 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0936 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1014 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0945 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1019 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0950 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1024 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0928 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1047 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1058 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0948 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0949 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0927 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0930 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0931 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0945 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1144 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1151 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1049 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0943 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0943 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0932 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0986 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0932 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0926 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0981 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1010 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1015 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.0973 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0941 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0932 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0941 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1057 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0928 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1037 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0931 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0932 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0943 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0939 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0928 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0940 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1115 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0932 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1092 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0990 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0933 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0998 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0941 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0940 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0980 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0926 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1004 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0924 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.0977 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1064 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1011 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0941 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0940 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0928 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0929 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1031 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0922 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0940 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0930 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0939 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0986 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0927 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1120 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0941 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1062 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0922 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0997 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0931 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0938 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0941 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0976 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0927 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1002 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0921 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1058 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0928 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0975 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0961 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0938 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0937 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0923 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1031 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0929 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0988 Val: 0.0923 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:18:50,946] Trial 88 finished with value: 0.09199888582030932 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.003033314912117281, 'batch_size': 32, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 99] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.003164112054178065, 'batch_size': 8, 'patience': 9}\n",
      "Epoch [56/60] Loss: 0.0939 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1111 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0940 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0941 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0921 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0923 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1048 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0994 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0937 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0976 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1056 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0942 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0922 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1003 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0973 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0960 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0922 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0937 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0986 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0937 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1027 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1743 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1110 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0935 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0940 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1031 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0938 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0923 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0989 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1055 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0972 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0937 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1000 Val: 0.0936 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:21:44,632] Trial 86 finished with value: 0.09191152701775233 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0027278598234446, 'batch_size': 32, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 100] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010517165499544736, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [45/60] Loss: 0.0936 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0922 Val: 0.0911 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:21:58,316] Trial 87 finished with value: 0.09253073235352834 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0029453400499267735, 'batch_size': 32, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 101] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010485055518345974, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [13/60] Loss: 0.0967 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0983 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0960 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1019 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0935 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1261 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1110 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0919 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1028 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0988 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1059 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0936 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0971 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1001 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0985 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1566 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0969 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0936 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0922 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1581 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0959 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1020 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1146 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0923 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1112 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0932 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0917 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1022 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1058 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0987 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0933 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0968 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0955 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0986 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1150 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0922 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0967 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1152 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0934 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0956 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0923 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1096 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1018 Val: 0.0959 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:25:55,085] Trial 91 finished with value: 0.08898961221178373 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.010085465141018978, 'batch_size': 32, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 102] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.010907357161805676, 'batch_size': 32, 'patience': 9}\n",
      "Epoch [9/60] Loss: 0.1101 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0932 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0920 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1058 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1015 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0988 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0984 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0971 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2170 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0931 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0955 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1130 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1118 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0936 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1286 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0956 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0934 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1065 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1018 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1046 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1165 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1053 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0921 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0967 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0931 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0988 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1113 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0985 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0968 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0956 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0929 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1121 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1103 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1106 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0936 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0957 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1080 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1050 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0928 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1047 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0969 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1006 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0921 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1053 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0965 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0984 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0985 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0926 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0931 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1056 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0954 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1115 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1112 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0936 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0928 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.0999 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0952 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1047 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1039 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0968 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1004 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1004 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0927 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0920 Val: 0.0938 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:31:08,642] Trial 92 finished with value: 0.09459460799892744 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.003275753369234194, 'batch_size': 32, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 103] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.010547628920165277, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [41/60] Loss: 0.0984 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0966 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0986 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1002 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0934 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0955 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1107 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1098 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1000 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2177 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0935 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0951 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1001 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1043 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1304 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1000 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1028 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0966 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0987 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0962 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0987 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1177 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1001 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0935 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0950 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1116 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1099 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1006 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1097 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0934 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1091 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0950 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1004 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0998 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1048 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1027 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0986 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0967 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1060 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0915 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0985 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0958 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1000 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0933 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1070 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0928 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1110 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1000 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1106 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1054 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0934 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0961 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0995 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0926 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1042 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0982 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1047 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1021 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0963 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0912 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0980 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0962 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0961 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1044 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0928 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1045 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0959 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0997 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1100 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0935 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0993 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0959 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1043 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0983 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0997 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0927 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0972 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0963 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0946 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0913 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0963 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0958 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0994 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0933 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0962 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1040 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0990 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0932 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1098 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0935 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0963 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0993 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0983 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0995 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1045 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0928 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0960 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0973 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0995 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0950 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0963 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0914 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0958 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0932 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0963 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0994 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1043 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1109 Val: 0.1098 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0960 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0993 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0984 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0994 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0933 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1041 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0928 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0937 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0971 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0995 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0943 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0955 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0960 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0915 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0931 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0998 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1047 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0929 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0986 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0933 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1104 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0993 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0995 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0933 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0991 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0932 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0926 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0999 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0972 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0946 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0955 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0961 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0934 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0955 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1043 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0929 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0983 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0992 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0933 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1102 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0956 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0986 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0932 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0932 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0929 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0955 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0946 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0971 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0949 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0927 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0958 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0952 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1048 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0983 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0929 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0991 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1037 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0954 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0985 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0931 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0957 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0918 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0945 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0968 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0953 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0960 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0933 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1041 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0940 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0995 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0931 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0928 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1046 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0985 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0935 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0930 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0919 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0944 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0966 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0954 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0928 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0961 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0950 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0931 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0994 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0990 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0924 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0928 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1040 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0980 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0924 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0928 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0917 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0946 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0963 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0952 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0913 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0943 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0991 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0958 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0991 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0927 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0922 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1035 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0980 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0921 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0919 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0947 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0926 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0919 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0944 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0964 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0951 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0922 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0991 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0992 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0958 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0927 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0919 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1039 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0978 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0924 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0919 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0920 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0926 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0944 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0942 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0919 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0951 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0964 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0920 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0989 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0987 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0930 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0959 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0921 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0923 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1035 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0980 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0920 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0924 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0941 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0946 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0948 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0992 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0962 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0924 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0987 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0961 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0921 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0922 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0977 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1037 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0921 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0922 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0941 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0922 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0945 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0921 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0991 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0949 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0921 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0924 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0962 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0984 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0908 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0921 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0959 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0923 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0921 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0978 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0986 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0940 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0922 Val: 0.0893 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 05:56:58,689] Trial 102 finished with value: 0.09014847228924433 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.010907357161805676, 'batch_size': 32, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 104] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.04066776625072988, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0945 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0918 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0946 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0952 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0916 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0982 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0959 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0956 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0921 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0974 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0983 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0943 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0920 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0955 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 403.2979 Val: 0.1249 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0946 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0916 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0949 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0985 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0961 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0932 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0925 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0921 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0978 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0940 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0978 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0917 Val: 0.0906 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:00:06,742] Trial 80 finished with value: 0.09025163275479268 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.017973654897907282, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 105] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.024249534781553114, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [36/60] Loss: 0.0915 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0948 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1293 Val: 0.1147 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0941 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0918 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0915 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0982 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0961 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.9163 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0920 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0975 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1204 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0978 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1133 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0918 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0946 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1376 Val: 0.1303 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0945 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0916 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0916 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0982 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1101 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0958 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0914 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1090 Val: 0.1023 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:02:58,357] Trial 103 finished with value: 0.09146104032794634 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.010547628920165277, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 106] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0018340094111744926, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [40/60] Loss: 0.0921 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0926 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0974 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0974 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1081 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0948 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0916 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1369 Val: 0.1253 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0944 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1085 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0915 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0978 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0960 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0916 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1087 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0977 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1094 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0977 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1875 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0945 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1338 Val: 0.1467 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0926 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1114 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0916 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0908 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1023 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0955 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0975 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1024 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1357 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0975 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0945 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1026 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0916 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1400 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0925 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0979 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0915 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1026 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0959 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0938 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1033 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0923 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0927 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1215 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0973 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0945 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1044 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0926 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1417 Val: 0.1398 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0918 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0977 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0919 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0984 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0915 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0955 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0989 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0938 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0921 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1132 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0973 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0946 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0995 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0928 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1535 Val: 0.1257 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0917 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0979 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0991 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0918 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0958 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0916 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0989 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0936 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0928 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1087 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0992 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0943 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0973 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0927 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1565 Val: 0.1203 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0916 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0949 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0978 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0916 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0953 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0956 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0940 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0922 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0953 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0945 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0926 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1058 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0970 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0927 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0956 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1551 Val: 0.1292 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0915 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0916 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0951 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0908 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0957 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0935 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0926 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0920 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0943 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1040 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0927 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0969 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0919 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0927 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1645 Val: 0.1255 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0946 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0916 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0921 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0954 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0937 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0922 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0945 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0922 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0926 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0972 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1024 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0926 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0923 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1192 Val: 0.1163 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0942 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0925 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0916 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0936 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0954 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0942 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0912 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0968 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1015 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0921 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1200 Val: 0.1163 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0942 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0911 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0917 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0909 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0937 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0953 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0944 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0921 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0912 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0972 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0911 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1002 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0921 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1225 Val: 0.1255 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [39/60] Loss: 0.0912 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0914 Val: 0.0904 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:19:52,354] Trial 104 finished with value: 0.12579511650720565 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.04066776625072988, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 107] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0018940538022155897, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [43/60] Loss: 0.0917 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0939 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0955 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0944 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0910 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0919 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0970 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0996 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0921 Val: 0.0871 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0906 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0915 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0908 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1892 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0909 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0935 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0944 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0955 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0908 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0914 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0931 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0996 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0922 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0907 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0908 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1367 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0937 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0944 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0952 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0909 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0919 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0933 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0908 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0991 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0922 Val: 0.0870 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0916 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0941 Val: 0.0913 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:24:30,768] Trial 85 finished with value: 0.08791619605001282 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010283957448726072, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 108] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.012791434245841829, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0907 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1215 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0937 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0944 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0907 Val: 0.0918 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:25:18,326] Trial 84 finished with value: 0.09433049846346639 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0025798234904587255, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 109] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.009356946228136376, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [40/60] Loss: 0.0933 Val: 0.0874 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:25:20,007] Trial 89 finished with value: 0.08980826254026229 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.009767672537855512, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 110] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.025336065838572067, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [52/60] Loss: 0.0914 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0905 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0931 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0985 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0906 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1580 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1137 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0935 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0906 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0932 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1663 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0913 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0918 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4031 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0906 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0932 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0941 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0982 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0906 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0915 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1171 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1092 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0936 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0905 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0932 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1183 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0906 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1249 Val: 0.1199 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0918 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0941 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0985 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0905 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1137 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1060 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0935 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0905 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0931 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1148 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0906 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1261 Val: 0.1343 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:30:28,123] Trial 105 finished with value: 0.09231914058327675 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.024249534781553114, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 111] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.04606994640301411, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0922 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0934 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0976 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1134 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1044 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0931 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1130 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1222 Val: 0.1332 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0918 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 5820224340.6367 Val: 0.1324 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0931 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0976 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0908 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1147 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1028 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:33:17,049] Trial 90 finished with value: 0.08988906105025475 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0033148607137678345, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 112] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.04302885913543336, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [45/60] Loss: 0.0932 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1121 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1304 Val: 0.1135 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0917 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1362 Val: 0.1183 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0923 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0932 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0977 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1116 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1013 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0922 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 92083.4717 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1125 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1135 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0916 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1375 Val: 0.1134 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:35:33,567] Trial 93 finished with value: 0.09016254522344645 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0029996984321543486, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 113] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.0429226271276371, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [45/60] Loss: 0.0928 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0974 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1125 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0916 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0914 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0920 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1006 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 74.5408 Val: 0.1120 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0921 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1338 Val: 0.1568 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1049 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1190 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1139 Val: 0.1198 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1444 Val: 0.1277 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0923 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0932 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1181 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0976 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1129 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0914 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0919 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1117 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1009 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1311 Val: 0.1249 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0922 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1153 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1057 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1150 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1631 Val: 0.1215 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0922 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1140 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0931 Val: 0.0941 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:39:00,786] Trial 94 finished with value: 0.09140050188959145 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0030800661816245962, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 114] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.012104276395504628, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [22/60] Loss: 0.0972 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1058 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1130 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0921 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0914 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0992 Val: 0.0907 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:39:44,591] Trial 95 finished with value: 0.09140281610879578 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.003477575589105216, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 115] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.013157943886819585, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [8/60] Loss: 0.1177 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2311 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1388 Val: 0.1159 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0923 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1061 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0924 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1680 Val: 0.1278 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1151 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1061 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1275 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0930 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2313 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0973 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1064 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1066 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1157 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1269 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0992 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1067 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1122 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1425 Val: 0.1163 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1160 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0925 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1056 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1071 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1088 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1721 Val: 0.1379 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1173 Val: 0.1166 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1133 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1060 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1071 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0971 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1083 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0901 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1094 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0912 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0906 Val: 0.0894 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:43:05,399] Trial 96 finished with value: 0.09002421455097799 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.003143508721113269, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 116] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.02464792294765577, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [14/60] Loss: 0.1087 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0986 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1058 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1064 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1191 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1054 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0923 Val: 0.0873 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1088 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1060 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1065 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1685 Val: 0.1349 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1175 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0913 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1001 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1034 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1064 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1056 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0969 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0902 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1006 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1041 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1064 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0983 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1177 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1053 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3361 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0919 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1001 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1064 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1037 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1234 Val: 0.1158 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1161 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1047 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1002 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1037 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1061 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0930 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0904 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0912 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1046 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1042 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1004 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0983 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1206 Val: 0.1172 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1005 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0998 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1214 Val: 0.1098 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1043 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1001 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0921 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0916 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1262 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1092 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0997 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1037 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1004 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1010 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0932 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0904 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0996 Val: 0.0946 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:47:58,951] Trial 97 finished with value: 0.09290926768874921 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0029601272152669934, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 117] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.012456451893333676, 'batch_size': 32, 'patience': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:47:59,790] Trial 98 finished with value: 0.09128607070746542 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010435491243756156, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 118] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.025089525598413206, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [23/60] Loss: 0.1046 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1010 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0980 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1212 Val: 0.1120 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0996 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1002 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0999 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1175 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1002 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0916 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0872 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1254 Val: 0.1182 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [1/60] Loss: 0.2208 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.9946 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1111 Val: 0.1051 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:49:05,984] Trial 111 finished with value: 0.11890867440139546 and parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.04606994640301411, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/60] Loss: 0.1004 Val: 0.0951 Beta: 0.0100\n",
      "\n",
      "[Trial 119] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0017291776222730375, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [25/60] Loss: 0.1000 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0913 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1005 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0962 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1268 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1202 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0934 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0996 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0997 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2441 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1152 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0963 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1110 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0978 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1219 Val: 0.1211 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1002 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0997 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0998 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1211 Val: 0.1111 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1735 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1096 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1079 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0921 Val: 0.0872 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [20/60] Loss: 0.0961 Val: 0.0929 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:50:49,312] Trial 99 finished with value: 0.08780727328873482 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.003164112054178065, 'batch_size': 8, 'patience': 9}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 120] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.013003097484713472, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [15/60] Loss: 0.1088 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1007 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0998 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1624 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1071 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1002 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1073 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0911 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0958 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0930 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1002 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0996 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1508 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1074 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1081 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0976 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0962 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1220 Val: 0.1149 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1003 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1000 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1781 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1406 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1053 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0994 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1079 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1184 Val: 0.1280 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0936 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0961 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1085 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1000 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1343 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1052 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1068 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1002 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0906 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1189 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0931 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0964 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0933 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1290 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1002 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1048 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1072 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0941 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1123 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0932 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1254 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0962 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1052 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0998 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1067 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0994 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1132 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0915 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1200 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1217 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0933 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1044 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0962 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0957 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1020 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1094 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0997 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0904 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1188 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0995 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0935 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0961 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1019 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1092 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0955 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0931 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0944 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1162 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1126 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0994 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1017 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0962 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0955 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0934 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0993 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1107 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1217 Val: 0.1104 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1145 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0992 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1031 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0962 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0952 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0925 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1089 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0996 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1119 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0990 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1024 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0963 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0956 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0923 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1027 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0944 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1104 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1131 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0990 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1024 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0953 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0961 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0922 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0992 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1090 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1193 Val: 0.1193 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0995 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1027 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0952 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1026 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0932 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0923 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1089 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0996 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1075 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0990 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1030 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0950 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0926 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0922 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0912 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0943 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1066 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1029 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1128 Val: 0.1148 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0992 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0985 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0949 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0928 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0921 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0991 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1057 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0995 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0981 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0948 Val: 0.0909 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 06:59:43,523] Trial 101 finished with value: 0.0906706215391139 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010485055518345974, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 121] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0018993470075836275, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [35/60] Loss: 0.0930 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1108 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0920 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1028 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1087 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1050 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0997 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0954 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0986 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0950 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0908 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0944 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0920 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1037 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0915 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0958 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0954 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0985 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1128 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0919 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2048 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1034 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0992 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1034 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0956 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0986 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0918 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1119 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0920 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1040 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1540 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0996 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1025 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0956 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0988 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0987 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0944 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0907 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:02:31,482] Trial 100 finished with value: 0.09353823073897041 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.010517165499544736, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 122] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.013432070133679386, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [23/60] Loss: 0.1018 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0956 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0987 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0919 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1062 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0917 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0916 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1356 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0987 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0984 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0920 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0955 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0949 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1014 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1119 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1029 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0992 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1923 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0947 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0920 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0936 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1245 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1009 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0918 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0942 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0989 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0949 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1064 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0935 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1004 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0913 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1176 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1179 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0988 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0914 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0949 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0934 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0996 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0982 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1124 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0950 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1030 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0933 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0952 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0994 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0929 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1137 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1138 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0987 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0949 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1057 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0934 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0991 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0987 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0912 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1099 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1102 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0936 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0985 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0982 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0923 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1129 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0935 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0928 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1026 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0985 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0951 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0919 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1080 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1095 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0924 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1056 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0935 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0981 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0983 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0908 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0923 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0988 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0935 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0978 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1057 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1107 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0928 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0985 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1136 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0974 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1023 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0949 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0924 Val: 0.0907 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:09:52,775] Trial 113 finished with value: 0.08971802443265915 and parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.0429226271276371, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 123] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.012936995313616712, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [37/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1052 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1050 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1098 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0972 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0925 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0981 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0910 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0985 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2285 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0970 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0926 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0931 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1036 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1103 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0928 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1266 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0966 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1065 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1020 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0947 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0982 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0929 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1144 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1049 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0964 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1020 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1032 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1099 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0991 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0982 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0962 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0918 Val: 0.0914 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:12:46,169] Trial 114 finished with value: 0.09251082167029381 and parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.012104276395504628, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 124] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.021810878900737483, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [31/60] Loss: 0.0927 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1092 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0961 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1010 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1031 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0948 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1064 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1020 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1054 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0979 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1050 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0958 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1045 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2622 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0927 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1011 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1036 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0988 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0912 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0907 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0958 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0980 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1055 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0927 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0918 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0926 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:14:55,694] Trial 115 finished with value: 0.09125154738624891 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.013157943886819585, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 125] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0004722248340818844, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [43/60] Loss: 0.0956 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1156 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1045 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0949 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1020 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0918 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1060 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1000 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1035 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1048 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0925 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0980 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1044 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0953 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0925 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0950 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1118 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0988 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0911 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0992 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2638 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1039 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0954 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0930 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0943 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0991 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0952 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0950 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1021 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1118 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1059 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1000 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1790 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0926 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0989 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1039 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0992 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0943 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0949 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0949 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0925 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0991 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1164 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0910 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0918 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0951 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0926 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1728 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0985 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0988 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0923 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0993 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0944 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0949 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0947 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0974 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1058 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0989 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1107 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0954 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0927 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1686 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0979 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0989 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0944 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0943 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0944 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0954 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0924 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0925 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0908 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1046 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0942 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1618 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0956 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0978 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0989 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0943 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0946 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0971 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0944 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0989 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1057 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0954 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0925 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1049 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1561 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0943 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0975 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0955 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0986 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0943 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0943 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0924 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0927 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0909 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0943 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0929 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1490 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1061 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0925 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0917 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0973 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0984 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0943 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0969 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0986 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0926 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0940 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0943 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1056 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0924 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1436 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1061 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0924 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0941 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0944 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0924 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0969 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0945 Val: 0.0941 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:23:17,282] Trial 118 finished with value: 0.09095751742521922 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.025089525598413206, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 126] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0018859539889743806, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0945 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0926 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0910 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0938 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0923 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1383 Val: 0.0949 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:23:48,483] Trial 117 finished with value: 0.0906980832417806 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.012456451893333676, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 127] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0016687349556584621, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [11/60] Loss: 0.1063 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0929 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0985 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0921 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0967 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0939 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0967 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0942 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1059 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0944 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2085 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0926 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1341 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0939 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0945 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1013 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2147 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0968 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0930 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0944 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0944 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0910 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0937 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1580 Val: 0.1008 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:25:26,664] Trial 119 finished with value: 0.09549807608127595 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0017291776222730375, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 128] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.001988642413382156, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [11/60] Loss: 0.1307 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0930 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0986 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0922 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1016 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0965 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1609 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1054 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0962 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0942 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0940 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0929 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1397 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0946 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1277 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2089 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1014 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0925 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1416 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0917 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0909 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0964 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0939 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0941 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1277 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0915 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0984 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0925 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1546 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0963 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1249 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1014 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1309 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1051 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0914 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0964 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0941 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1214 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0939 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0945 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1354 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0914 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1229 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1232 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1015 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0909 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1155 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0914 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0937 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0959 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0941 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0982 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0921 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1251 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0967 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1176 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1206 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0915 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1056 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0972 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1123 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0944 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0937 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0940 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0939 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0914 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0928 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1180 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1138 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1190 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0970 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0909 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0915 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0979 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0923 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1089 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0941 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0941 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0938 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0961 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1145 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0914 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1105 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1006 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1173 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0971 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0941 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0915 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1069 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0939 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0938 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1099 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0914 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1087 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0906 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1157 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0970 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0981 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0923 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1047 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0916 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0963 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0938 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0940 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0938 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1075 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1001 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1060 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0915 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1142 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0969 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0942 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0925 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1034 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0938 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0938 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0916 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0937 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1057 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0907 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1048 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0979 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0924 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0967 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1132 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0909 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0965 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1025 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0936 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0944 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0931 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1041 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0995 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0911 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0944 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1031 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0965 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0923 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1121 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0911 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1014 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0936 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0938 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0907 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1027 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0980 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0909 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0915 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1018 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0969 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1109 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0962 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0909 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1001 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0936 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0923 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0994 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0930 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1015 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0939 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0924 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1009 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0909 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0967 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1095 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0911 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0979 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0997 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0906 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0923 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0935 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0912 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0930 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1011 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1000 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0910 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0961 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0964 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1085 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0991 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0989 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0940 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0908 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0923 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0935 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0931 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0999 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0997 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0909 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1078 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0976 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0908 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0915 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0986 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0910 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0922 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0909 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0932 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0997 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0962 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0988 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0908 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1070 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0991 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0985 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0924 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0911 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0988 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0985 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0982 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0937 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1061 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0914 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0907 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0978 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0922 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0908 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0984 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0929 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0978 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0934 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1056 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0988 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0975 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0923 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0979 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0931 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0979 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0975 Val: 0.0935 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:42:24,687] Trial 123 finished with value: 0.09509791607658068 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.012936995313616712, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 129] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.001973887296966369, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [45/60] Loss: 0.0914 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0934 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0906 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1048 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0969 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0930 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0919 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0915 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0977 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0922 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0975 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2090 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0924 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0991 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1038 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0978 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0967 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0913 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0957 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0915 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0971 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1545 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0907 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0924 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1036 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0930 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0963 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0919 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0904 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0953 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1365 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0965 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0986 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1031 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0976 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0964 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0916 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0918 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0950 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0929 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1249 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0962 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0908 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0923 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1025 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0932 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0963 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0922 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0905 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0950 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1179 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0946 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0962 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0942 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1020 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0912 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0957 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0921 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0904 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1138 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0948 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0958 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:48:11,324] Trial 106 finished with value: 0.0912467495170461 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.0018340094111744926, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 130] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.004161545057220602, 'batch_size': 16, 'patience': 8}\n",
      "Epoch [37/60] Loss: 0.0926 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0930 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1015 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0921 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0955 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0920 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0904 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1099 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0951 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0948 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0955 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0943 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0924 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0912 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1845 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1010 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0955 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0921 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1081 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:49:47,298] Trial 120 finished with value: 0.08933289150396982 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.013003097484713472, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 131] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.008600532644457896, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [26/60] Loss: 0.0949 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0925 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0955 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0929 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0928 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1329 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1006 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0952 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1052 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0943 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0941 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0946 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0951 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1767 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0910 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1198 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0924 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0922 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0999 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0951 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1039 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0902 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0946 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0930 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0952 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1224 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1127 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0909 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0996 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0939 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0941 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0950 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1026 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0902 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0943 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0948 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1115 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1088 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0992 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0950 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1015 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0902 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0930 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0943 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0924 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0949 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1061 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1098 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0936 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0943 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0990 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0948 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1007 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0902 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0943 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0924 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1041 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1070 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0948 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0919 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0921 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0985 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0945 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0997 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0928 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0939 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0926 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1030 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1056 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0948 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0939 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0942 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0991 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0946 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0983 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0939 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1022 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1053 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0944 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0930 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0983 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0943 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0981 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0901 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0938 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1021 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0924 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1049 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0941 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0944 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0983 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0946 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0976 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0932 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1015 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0925 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0941 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1056 Val: 0.0994 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 07:58:35,487] Trial 121 finished with value: 0.09098500224451224 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0018993470075836275, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 132] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.023241888608139645, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0930 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0975 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0944 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0975 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0938 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0903 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1013 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0945 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.0995 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0943 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2027 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0920 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0972 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0940 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0973 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0902 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1010 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0940 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1002 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1122 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0914 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0939 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0970 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0941 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0970 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0903 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1004 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0923 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:01:19,197] Trial 122 finished with value: 0.09305259163180987 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.013432070133679386, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 133] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008692947210840948, 'batch_size': 16, 'patience': 7}\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0939 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1002 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1111 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0921 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0920 Val: 0.0891 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:01:42,854] Trial 107 finished with value: 0.08882221626509137 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.0018940538022155897, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 134] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008649286585656396, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [21/60] Loss: 0.0968 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0942 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0969 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1001 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0930 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0940 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0998 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1123 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1672 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0938 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0907 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0966 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0941 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0965 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0993 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1097 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0922 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0997 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1197 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0918 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1483 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0966 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0940 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0965 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0995 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1107 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0928 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0996 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1111 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0917 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0964 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0939 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0962 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1002 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1101 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1135 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0928 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0921 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0922 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0992 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1064 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0917 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0958 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0962 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1111 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0995 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0918 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0929 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0922 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0918 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0909 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1049 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0955 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0920 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1093 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0957 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1134 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0959 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0993 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0927 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0921 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1047 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0956 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0920 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0953 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1112 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0919 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0996 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0954 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0918 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0927 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1033 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0955 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1076 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [60/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:08:15,700] Trial 124 finished with value: 0.08972112871706486 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.021810878900737483, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 135] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0043453436658094915, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [28/60] Loss: 0.0955 Val: 0.0947 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:08:25,460] Trial 108 finished with value: 0.09147112691352348 and parameters: {'hidden_dim': 448, 'latent_dim': 96, 'learning_rate': 0.012791434245841829, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 136] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.0013487448893697374, 'batch_size': 16, 'patience': 6}\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1104 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0989 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0920 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0955 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1035 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0927 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0917 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0953 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0951 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0919 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1040 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2209 Val: 0.1088 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0988 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0918 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1072 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0953 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1024 Val: 0.1006 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:09:42,797] Trial 109 finished with value: 0.09045770235297058 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.009356946228136376, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 137] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.00423468069402342, 'batch_size': 16, 'patience': 6}\n",
      "Epoch [47/60] Loss: 0.0927 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0952 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1648 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0951 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1042 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0923 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1644 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0920 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0991 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0952 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1027 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0925 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0956 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1873 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0921 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0929 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1044 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1068 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1494 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0993 Val: 0.0949 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:11:27,431] Trial 110 finished with value: 0.08805266698869336 and parameters: {'hidden_dim': 512, 'latent_dim': 128, 'learning_rate': 0.025336065838572067, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 138] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004445456314763027, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [11/60] Loss: 0.0979 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0952 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0917 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1317 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0953 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1194 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1050 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0928 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1364 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0924 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0948 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0977 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0950 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1178 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0952 Val: 0.0942 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:12:34,090] Trial 125 finished with value: 0.09286482023696105 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0004722248340818844, 'batch_size': 16, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 139] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004049337619934675, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [58/60] Loss: 0.0922 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1067 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1048 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0929 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1280 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0945 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1096 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1654 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0977 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1115 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0917 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0947 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1005 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1218 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0912 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0925 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0949 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1071 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1056 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0919 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0982 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0916 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0921 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0948 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1640 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1007 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1169 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0928 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1192 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0949 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1065 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1055 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0976 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0952 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1008 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0912 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1136 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0928 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1061 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0947 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0920 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1039 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0948 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1181 Val: 0.0979 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:16:00,431] Trial 112 finished with value: 0.0911951952872156 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.04302885913543336, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 140] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004338792912326107, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0950 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1001 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1096 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1115 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1047 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0950 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1028 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0947 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0948 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0999 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1009 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1087 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0932 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0924 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1094 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1018 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0946 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1644 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0914 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0921 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0958 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1059 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0945 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1030 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1069 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0927 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0916 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0923 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1012 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0945 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1002 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0913 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0960 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0920 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0943 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1057 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1063 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0922 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1192 Val: 0.0962 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:19:13,820] Trial 126 finished with value: 0.09250690564513206 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0018859539889743806, 'batch_size': 16, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 141] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004057232553973238, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [11/60] Loss: 0.1008 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0949 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1049 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0960 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0912 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0947 Val: 0.0931 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:19:40,206] Trial 127 finished with value: 0.09275286619861921 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.0016687349556584621, 'batch_size': 16, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 142] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.017719994589337113, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [7/60] Loss: 0.1028 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1044 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0925 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0924 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1004 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1008 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0948 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0960 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0914 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0919 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0942 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1040 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1109 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1032 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0925 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1035 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1686 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1003 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0947 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0959 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1021 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0945 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1566 Val: 0.1095 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:21:29,973] Trial 128 finished with value: 0.09317694542308648 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.001988642413382156, 'batch_size': 16, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 143] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.01860505345525922, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [15/60] Loss: 0.1021 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1003 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0926 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1008 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0946 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0959 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1034 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1065 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0923 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1010 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1200 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1031 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0918 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0927 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0959 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0945 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1015 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0938 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1155 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0997 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0920 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1003 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1570 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0916 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0919 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0957 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1022 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0935 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0945 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1043 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1106 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0920 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1027 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1000 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0918 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1140 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1007 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0959 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0936 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0947 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1001 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1153 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0994 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0916 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0917 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1033 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1016 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0936 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0959 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0915 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1068 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0945 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1018 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0922 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1127 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0989 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0967 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1001 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0937 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0959 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1157 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0932 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0914 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1036 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1015 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0983 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1042 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0917 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0956 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1016 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0931 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1123 Val: 0.1101 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0967 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0996 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0969 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1147 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0915 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0934 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0931 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1016 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.0968 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1038 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0965 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0910 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1012 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0916 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0932 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1126 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0929 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0963 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0995 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1135 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0915 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0963 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0932 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0930 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1021 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0968 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1025 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0916 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1016 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0962 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1055 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0932 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:30:18,000] Trial 116 finished with value: 0.09195799198972077 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'learning_rate': 0.02464792294765577, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 144] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008188783713852333, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [24/60] Loss: 0.0933 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0931 Val: 0.0939 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:30:24,736] Trial 129 finished with value: 0.09417160128553709 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.001973887296966369, 'batch_size': 16, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 145] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004308342176384906, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [19/60] Loss: 0.0999 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0964 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1162 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0959 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1012 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0934 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0968 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0931 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1013 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1009 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1063 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0930 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0914 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0959 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0996 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1149 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0968 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0931 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0932 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1550 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1695 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.0969 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0957 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0968 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1009 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0935 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1016 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1059 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0996 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1145 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0965 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0956 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1152 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1211 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0933 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0931 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0971 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1006 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0964 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0917 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0954 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1057 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1009 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0954 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1074 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0959 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1091 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1104 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0913 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0949 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0923 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0929 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0966 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1004 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0966 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1062 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1009 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0951 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0925 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0933 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0957 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1075 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0961 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1065 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1070 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0918 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0970 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0950 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0924 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1009 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0958 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1007 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1009 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0952 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1077 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0946 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0923 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0930 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0927 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1048 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0958 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1067 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0967 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0910 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0915 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1004 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0944 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0961 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0923 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0929 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1008 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1006 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0954 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1083 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1034 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0940 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1075 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0920 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0960 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0928 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0966 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1000 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0960 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0911 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1005 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1012 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0941 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0921 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0931 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0952 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1071 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1032 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0916 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1001 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0932 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0912 Val: 0.0920 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:41:17,182] Trial 130 finished with value: 0.09215210701028506 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.004161545057220602, 'batch_size': 16, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 146] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'learning_rate': 0.01844420966532996, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [51/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0922 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0961 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0942 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0931 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0999 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0958 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1001 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1005 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0929 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0919 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0932 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0929 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1082 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1026 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1006 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0935 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0967 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0927 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0921 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0928 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1580 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0998 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0940 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1000 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0956 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0963 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0929 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0928 Val: 0.0900 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [15/60] Loss: 0.1080 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0911 Val: 0.0919 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:43:50,430] Trial 132 finished with value: 0.0903985025982062 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.023241888608139645, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 147] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.019185691794483605, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [49/60] Loss: 0.0927 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0921 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0938 Val: 0.0917 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:43:56,784] Trial 131 finished with value: 0.0927049845457077 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'learning_rate': 0.008600532644457896, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 148] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.01785270529873516, 'batch_size': 8, 'patience': 6}\n",
      "Epoch [9/60] Loss: 0.1014 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1004 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0935 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0965 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1152 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0993 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0928 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0922 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1000 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0933 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0939 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0963 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0931 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1022 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0928 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0919 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1973 Val: 0.1239 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1017 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0938 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1008 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0936 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1867 Val: 0.1134 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0962 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1142 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0992 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0997 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0933 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0925 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0962 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0911 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [44/60] Loss: 0.0937 Val: 0.0916 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:46:32,690] Trial 137 finished with value: 0.0920003334681193 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.00423468069402342, 'batch_size': 16, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 149] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0189218549507881, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [17/60] Loss: 0.1020 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0934 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1205 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1011 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1230 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0938 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0924 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1001 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0938 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1141 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0935 Val: 0.0916 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [19/60] Loss: 0.0995 Val: 0.0959 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:47:32,615] Trial 136 finished with value: 0.09324420057237148 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'learning_rate': 0.0013487448893697374, 'batch_size': 16, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 150] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.018483976899452827, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [19/60] Loss: 0.0996 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0938 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0964 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0924 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1016 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0933 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1969 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1212 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0968 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1202 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0938 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0999 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0934 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1126 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0994 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0997 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0938 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2018 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0962 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1018 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0933 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0925 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1190 Val: 0.1152 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1192 Val: 0.1238 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0970 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1182 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0960 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1133 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0935 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0953 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0924 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0996 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1189 Val: 0.1143 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0934 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0960 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1013 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0935 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1194 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1205 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0923 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0942 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0966 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1198 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1148 Val: 0.1129 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0962 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0952 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0937 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0998 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1186 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0922 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0937 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0963 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1011 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0931 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1210 Val: 0.1101 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1198 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0923 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0969 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1214 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1129 Val: 0.1083 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 08:53:01,644] Trial 133 finished with value: 0.09430144553383192 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008692947210840948, 'batch_size': 16, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 151] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.016984207830410332, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [23/60] Loss: 0.0952 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0957 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0935 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0999 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1167 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0935 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0938 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0968 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0931 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1200 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1201 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0940 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1143 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1184 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0967 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0955 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0958 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0937 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0954 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1780 Val: 0.1139 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1191 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0936 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0937 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0972 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1104 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1213 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0939 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1069 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1192 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0965 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0953 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0957 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0934 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0954 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1203 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1191 Val: 0.1131 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0938 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0963 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0923 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1109 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1208 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0940 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1072 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0953 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1114 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0964 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0957 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0951 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0934 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1205 Val: 0.1124 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1197 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0963 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0934 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1127 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0923 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1110 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1070 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0953 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1111 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0961 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0955 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0956 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0927 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1101 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1177 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0964 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0936 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0929 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1123 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0925 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1118 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1072 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0941 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0931 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1114 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0959 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0952 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0936 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1109 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0927 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1197 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0962 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0941 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0926 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1130 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0922 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1139 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1069 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0940 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0932 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1114 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0958 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0949 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1122 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0931 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0925 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1213 Val: 0.1104 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0963 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0939 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0927 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1127 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0926 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1131 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1022 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0940 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0933 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1118 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0950 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0963 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1135 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0934 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0928 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1096 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0961 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0941 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1138 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0927 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1136 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0925 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1014 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0941 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0934 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1119 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0952 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0961 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1110 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0937 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0924 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1098 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0961 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0929 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1132 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0927 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1068 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0922 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1012 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0939 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0934 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0953 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1125 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1057 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0937 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0933 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1110 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0959 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1122 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0931 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1065 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0921 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1008 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0937 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0928 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0950 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1121 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1062 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0934 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1118 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0927 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0961 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1073 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1063 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0922 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1009 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0928 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0930 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1130 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1058 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0937 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0927 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1125 Val: 0.1088 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0925 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1070 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0930 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1065 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0928 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0922 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1009 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0936 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0933 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0927 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1049 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1117 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0940 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0963 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0927 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1059 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0927 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1067 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0929 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1059 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0925 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0962 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1049 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1057 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0963 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0925 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1053 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1063 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1060 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0924 Val: 0.0926 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0961 Val: 0.0922 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:12:47,542] Trial 139 finished with value: 0.09340556407300364 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004049337619934675, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 152] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.005883822518355162, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [37/60] Loss: 0.0929 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0937 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0933 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1050 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1058 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0930 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0959 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0927 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1053 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0923 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1063 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1057 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0932 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0960 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0939 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0931 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1048 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1621 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1056 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0932 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0963 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1047 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0927 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1066 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0925 Val: 0.0926 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [22/60] Loss: 0.1060 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:15:24,332] Trial 135 finished with value: 0.09323472911570252 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.0043453436658094915, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 153] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.018383855024734688, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [50/60] Loss: 0.0920 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0959 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0933 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0938 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0933 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1051 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1197 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1051 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0962 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0931 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1055 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1059 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0926 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1055 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0959 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0930 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0936 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1928 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0921 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0998 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1133 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1052 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0963 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0933 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1060 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1046 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0925 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1056 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0918 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0957 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0934 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0935 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1231 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0920 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0994 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1101 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1050 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0965 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0932 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1059 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1045 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1008 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0926 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0960 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0922 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0924 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0938 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1217 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0923 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0994 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1096 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1051 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0931 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1061 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1001 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1043 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0927 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0929 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0957 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0922 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0926 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0930 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1188 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0985 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1083 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1047 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0936 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0934 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1057 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0999 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0998 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0924 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0926 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0960 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0918 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0928 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0925 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1201 Val: 0.1128 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0984 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1076 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0943 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1045 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1010 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0997 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0994 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0928 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0927 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0959 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0924 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0919 Val: 0.0923 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [47/60] Loss: 0.0930 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0984 Val: 0.0944 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:24:24,094] Trial 134 finished with value: 0.09290689389620509 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008649286585656396, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 154] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.01931711172457005, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [6/60] Loss: 0.1213 Val: 0.1167 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1080 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0938 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1046 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1004 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0902 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [29/60] Loss: 0.0992 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0988 Val: 0.0927 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:25:20,025] Trial 145 finished with value: 0.09091988991664238 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004308342176384906, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 155] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.015386324251721312, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [37/60] Loss: 0.0922 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0925 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0932 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0930 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0987 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0923 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1114 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1090 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2071 Val: 0.1095 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0940 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1001 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1001 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0993 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0986 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0925 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0926 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0933 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0925 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0929 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1852 Val: 0.1113 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0983 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0924 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1112 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1071 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1191 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0932 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0993 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0998 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0993 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0988 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0936 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0927 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0931 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1182 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0942 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1118 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1018 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1177 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0929 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0991 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0997 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0992 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0984 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0935 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0930 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0925 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0928 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1165 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0943 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1134 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1019 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0933 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1167 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0990 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0997 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0988 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0935 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0984 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0928 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0924 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0928 Val: 0.0911 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [4/60] Loss: 0.1197 Val: 0.1102 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0941 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0918 Val: 0.0927 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:31:34,818] Trial 140 finished with value: 0.09150195509946647 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004338792912326107, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 156] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.016980293257444254, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [11/60] Loss: 0.1123 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0933 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1019 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1217 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0996 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0988 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0989 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0923 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0981 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0925 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0924 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0940 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1242 Val: 0.1235 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1067 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0933 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1786 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1016 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1208 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0994 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0985 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0945 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0927 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0984 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0925 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0927 Val: 0.0901 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0940 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0920 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1145 Val: 0.1139 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:34:18,500] Trial 138 finished with value: 0.09062890576965668 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004445456314763027, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 157] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.016021582680955257, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [51/60] Loss: 0.0934 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1066 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1189 Val: 0.1099 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1019 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1099 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0997 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0987 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0949 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0926 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0923 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0982 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0939 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0923 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0920 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1162 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1185 Val: 0.1099 Beta: 0.0100Epoch [1/60] Loss: 0.1854 Val: 0.1072 Beta: 0.0100\n",
      "\n",
      "Epoch [52/60] Loss: 0.0931 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1061 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1010 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1108 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0994 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0942 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0947 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0931 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0922 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0983 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0923 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0920 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1083 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1181 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0928 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1201 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1058 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1013 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1114 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0995 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0948 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0943 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0927 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0923 Val: 0.0921 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [31/60] Loss: 0.0982 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0913 Val: 0.0906 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:38:30,405] Trial 141 finished with value: 0.09276853385968369 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.004057232553973238, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/60] Loss: 0.0920 Val: 0.0927 Beta: 0.0100\n",
      "\n",
      "[Trial 158] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.01718065610535565, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [46/60] Loss: 0.0920 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1086 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1205 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0929 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1157 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1055 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0968 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1121 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0993 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0944 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0943 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0927 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0980 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0921 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1104 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1849 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1097 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0929 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1161 Val: 0.1197 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1055 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0966 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0994 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1133 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0943 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0939 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0922 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0915 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0979 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0919 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0920 Val: 0.0921 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [11/60] Loss: 0.1100 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1183 Val: 0.1170 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1096 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0925 Val: 0.0891 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:41:42,554] Trial 144 finished with value: 0.09284949506155583 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.008188783713852333, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 159] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006035698080621992, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [5/60] Loss: 0.1169 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1061 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0951 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0964 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1069 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0946 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0938 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0925 Val: 0.0910 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:42:33,117] Trial 146 finished with value: 0.09136505446889821 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'learning_rate': 0.01844420966532996, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 160] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.0012121282557090497, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0921 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0944 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1183 Val: 0.1147 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1103 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1109 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0929 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1196 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0953 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1055 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0960 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1062 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0942 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1680 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0941 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0909 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0918 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0944 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2066 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1171 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1048 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1116 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0928 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1089 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0951 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1054 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0961 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0945 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1069 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1203 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0940 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0908 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0917 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0939 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1487 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1175 Val: 0.1091 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:45:47,498] Trial 142 finished with value: 0.09296856056742307 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.017719994589337113, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 161] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.03439932289003644, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [10/60] Loss: 0.1111 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1042 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0931 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1097 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0948 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0945 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1060 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0927 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1119 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1061 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0939 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0908 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1312 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0941 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1183 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1112 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0930 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1042 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3861 Val: 0.1215 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 09:47:33,239] Trial 143 finished with value: 0.08997379356071729 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'learning_rate': 0.01860505345525922, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/60] Loss: 0.1108 Val: 0.0991 Beta: 0.0100\n",
      "\n",
      "[Trial 162] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.005503381291566656, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [43/60] Loss: 0.0948 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0942 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0928 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1111 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1006 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1055 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0916 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0909 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2094 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1210 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1177 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0940 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1118 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1423 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1037 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1321 Val: 0.1228 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1104 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0948 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0942 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1270 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0928 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1091 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1004 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1064 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0916 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1190 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0909 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1147 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1180 Val: 0.1153 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0939 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1142 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1118 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1034 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1297 Val: 0.1253 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0946 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1107 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1099 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0941 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0928 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1089 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0999 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1006 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1077 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0909 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1103 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1181 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1059 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0937 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1116 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1319 Val: 0.1197 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1030 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1051 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0947 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1108 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0940 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0929 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1087 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1003 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0998 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1036 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0910 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1029 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1074 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1104 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0939 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1122 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1311 Val: 0.1244 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1028 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1032 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0947 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1114 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0939 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1023 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0930 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1082 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0998 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0996 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0917 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0910 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1014 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1048 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1107 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1058 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0939 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1019 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1313 Val: 0.1216 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1032 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0950 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0943 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1054 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1016 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0928 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1084 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0998 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0994 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0910 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1007 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1029 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1106 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1053 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0971 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0939 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1327 Val: 0.1409 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1026 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0950 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0942 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1048 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0970 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0915 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0997 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1024 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0991 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0907 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0966 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1018 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1124 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1056 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0964 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0937 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1361 Val: 0.1286 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0947 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1034 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0942 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1045 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0965 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0914 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0991 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1022 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0992 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0904 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0966 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1005 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1116 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1048 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0967 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1197 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0918 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0947 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1031 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0918 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0964 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1050 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0915 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0993 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1020 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0989 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0904 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0942 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0918 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.0996 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1115 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1045 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0938 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1207 Val: 0.1136 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0948 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1034 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0938 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1044 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0918 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0950 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1027 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0905 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0990 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0918 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1116 Val: 0.1088 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.0989 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1049 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0939 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1204 Val: 0.1139 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0918 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0948 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1028 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0940 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1042 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0950 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0915 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0905 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1020 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0991 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0939 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0910 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1052 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0984 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1043 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1215 Val: 0.1163 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0949 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0918 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0984 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0930 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1044 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0948 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0904 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0919 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1019 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0987 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1048 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.0978 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1047 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1215 Val: 0.1156 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0926 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0918 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0920 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0983 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0930 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1040 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0905 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0947 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0914 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1019 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0988 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1048 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0908 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0948 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1048 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0931 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1131 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0923 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0919 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0919 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0976 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0993 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0904 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0944 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0913 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1017 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0929 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1049 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0988 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0948 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0994 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1129 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0924 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0912 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0909 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0930 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0973 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0989 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0904 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0945 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0928 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1013 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1043 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0988 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0946 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0994 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1127 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0932 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0926 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0911 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0929 Val: 0.0908 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:09:04,043] Trial 147 finished with value: 0.08942645838280686 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.019185691794483605, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 163] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006618797052231805, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [30/60] Loss: 0.0975 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0985 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0906 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0947 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0912 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0996 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1014 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0946 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0988 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0987 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2040 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1120 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0924 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1369 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0975 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0980 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1227 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0944 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0986 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1013 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0944 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1153 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0909 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0950 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0987 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1127 Val: 0.1088 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:11:22,539] Trial 148 finished with value: 0.09031178479810723 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.01785270529873516, 'batch_size': 8, 'patience': 6}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 164] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006389687913879325, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [51/60] Loss: 0.0926 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1117 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0923 Val: 0.0876 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:11:53,810] Trial 149 finished with value: 0.0880220470120426 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0189218549507881, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 165] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0371992320152522, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [52/60] Loss: 0.0924 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1075 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0972 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0982 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0904 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2061 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0981 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0944 Val: 0.0906 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:12:24,375] Trial 150 finished with value: 0.09068944280137535 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.018483976899452827, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/60] Loss: 0.0922 Val: 0.0907 Beta: 0.0100\n",
      "\n",
      "[Trial 166] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0012944394971590807, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [41/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1055 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1014 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0943 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0985 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1400 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0950 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.2712 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1121 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1047 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1255 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1216 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2622 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1037 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0923 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0968 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1170 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1167 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1729 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1023 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0980 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0924 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0945 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0912 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1012 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1133 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1143 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0942 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0982 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1647 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0948 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1023 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1126 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1102 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1166 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1550 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1027 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0924 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0913 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1086 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1111 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0968 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1461 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0978 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1016 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0979 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0922 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0940 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1116 Val: 0.1030 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1068 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0912 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1387 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1012 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0983 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0940 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0975 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0945 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1123 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0922 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1131 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1050 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1335 Val: 0.0954 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:15:59,601] Trial 162 finished with value: 0.09198691472411155 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.005503381291566656, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 167] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03384430291038931, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [15/60] Loss: 0.0970 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1154 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1032 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1294 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0912 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0969 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0968 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0977 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0976 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1308 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1035 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1258 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0940 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0912 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0980 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0969 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0967 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0937 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1119 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0945 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1059 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1033 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1233 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0965 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1059 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1204 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1021 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4573 Val: 0.1161 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0943 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0970 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0977 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1059 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0940 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1179 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1018 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0942 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0941 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0981 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0938 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0965 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1065 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1123 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1161 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1017 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0946 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0938 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1068 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1144 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1020 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1355 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0939 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0969 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1020 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1124 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0938 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0974 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1025 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0940 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0941 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0981 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1025 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0936 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1113 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0960 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1131 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0969 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0944 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0939 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1021 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1094 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0968 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1319 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0943 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1025 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1083 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0911 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0969 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0932 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0971 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0977 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0940 Val: 0.0937 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:21:13,430] Trial 151 finished with value: 0.08898769857502785 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.016984207830410332, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 168] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.035971432153597466, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [35/60] Loss: 0.0980 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1026 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0942 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1076 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0912 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0935 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1121 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0964 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0968 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0930 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0945 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1028 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1065 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0967 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1260 Val: 0.1175 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0927 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1030 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1058 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0935 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0945 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0968 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0927 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0976 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1030 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0978 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1051 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0942 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0934 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1118 Val: 0.1099 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0910 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0944 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0959 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4461 Val: 0.1182 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0926 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0988 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0947 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1042 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0940 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1313 Val: 0.1248 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0926 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0989 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1037 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0932 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0943 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0924 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0930 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0976 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0992 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1024 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0981 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0917 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1063 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0935 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0946 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0909 Val: 0.0888 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [33/60] Loss: 0.0927 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1338 Val: 0.1314 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0958 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0993 Val: 0.0925 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:24:38,239] Trial 152 finished with value: 0.08910735540029381 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.005883822518355162, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 169] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030263743102610045, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [26/60] Loss: 0.1020 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0944 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0936 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0927 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1312 Val: 0.1173 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0988 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1018 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0934 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0927 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0936 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0948 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0974 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1015 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0935 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1061 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0918 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0923 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0932 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0933 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1260 Val: 0.1179 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0948 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0957 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1014 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0943 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0922 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0934 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1150 Val: 0.1102 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3719 Val: 0.1099 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0951 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1010 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0933 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0922 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0932 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0952 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0932 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0937 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1004 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0941 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0922 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1051 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0934 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0932 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0953 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1396 Val: 0.1350 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0958 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1005 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0923 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0919 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0948 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1166 Val: 0.1123 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1231 Val: 0.1255 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1000 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0921 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0932 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0935 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0948 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0935 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0940 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1000 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0943 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0922 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1053 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0948 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0931 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1359 Val: 0.1469 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0957 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1000 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0945 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0920 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1177 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1239 Val: 0.1385 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0999 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0945 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0930 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0933 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0996 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0939 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0938 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0921 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1051 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0948 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0930 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0931 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1301 Val: 0.1173 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0996 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0919 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0944 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0929 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0924 Val: 0.0876 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1188 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1386 Val: 0.1195 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0994 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0921 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0910 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0948 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0929 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0935 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0921 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0941 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0994 Val: 0.0927 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [39/60] Loss: 0.0939 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0945 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0999 Val: 0.0963 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:31:34,507] Trial 166 finished with value: 0.10020078842838605 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0012944394971590807, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 170] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03645499650301181, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [42/60] Loss: 0.0929 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0929 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0921 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1468 Val: 0.1230 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0920 Val: 0.0934 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [34/60] Loss: 0.0958 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0945 Val: 0.0892 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:32:00,613] Trial 163 finished with value: 0.09469611023863157 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006618797052231805, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 171] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.033171001503288, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [43/60] Loss: 0.0930 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1179 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0922 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1248 Val: 0.1444 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0946 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0910 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0936 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0932 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0946 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0998 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0938 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0928 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0911 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.5696 Val: 0.1223 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0942 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1352 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0959 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0928 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1110 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0922 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1138 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4563 Val: 0.1186 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0942 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0911 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0928 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0924 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0938 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0931 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0989 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0919 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1299 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1485 Val: 0.1198 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0956 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1114 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1326 Val: 0.1185 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0919 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1144 Val: 0.1104 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0911 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0993 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0932 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0935 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0929 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0928 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0921 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1316 Val: 0.1251 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1339 Val: 0.1287 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0960 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1116 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0921 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1244 Val: 0.1307 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1163 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0912 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0914 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0989 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0932 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0936 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0926 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1323 Val: 0.1207 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0911 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1368 Val: 0.1165 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0958 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1117 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1337 Val: 0.1161 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1175 Val: 0.1074 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0914 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0926 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0985 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0914 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0930 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0939 Val: 0.0886 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0925 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0929 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1332 Val: 0.1207 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1383 Val: 0.1202 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0961 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0926 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1115 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1322 Val: 0.1345 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0913 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1165 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0914 Val: 0.0884 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:39:50,189] Trial 165 finished with value: 0.08895570362607638 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.0371992320152522, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/60] Loss: 0.0927 Val: 0.0893 Beta: 0.0100\n",
      "\n",
      "[Trial 172] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030580437971503567, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [48/60] Loss: 0.0917 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0981 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0926 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0937 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0927 Val: 0.0894 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:40:26,940] Trial 164 finished with value: 0.09076834246516227 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006389687913879325, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 173] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03528351365427988, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [6/60] Loss: 0.1358 Val: 0.1196 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.6227 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1204 Val: 0.1127 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1110 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0956 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1296 Val: 0.1208 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0912 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1201 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1189 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.0068 Val: 0.1145 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1121 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0989 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1205 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0930 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1147 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1121 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1141 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1111 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1200 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0925 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1361 Val: 0.1294 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1117 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0904 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1191 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0875 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1119 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1132 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0980 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1137 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1039 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0916 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1168 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1117 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0909 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1122 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1043 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1291 Val: 0.1270 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1213 Val: 0.1144 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0929 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0904 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1101 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1102 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0874 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1047 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:44:20,645] Trial 153 finished with value: 0.08783993898194377 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.018383855024734688, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 174] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.031997805671428604, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [41/60] Loss: 0.0979 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1124 Val: 0.1210 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1054 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0919 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1167 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1183 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0908 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1054 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1055 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1163 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1226 Val: 0.1158 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0928 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0904 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1041 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1052 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1103 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1046 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0980 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1064 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3994 Val: 0.1250 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0917 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0921 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1202 Val: 0.1156 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1047 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1012 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1053 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1173 Val: 0.1148 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0906 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1244 Val: 0.1125 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1051 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0926 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1013 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1107 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1054 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0941 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1015 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1301 Val: 0.1113 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1199 Val: 0.1152 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1057 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0917 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0908 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1019 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0909 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1047 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1176 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0905 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1012 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1223 Val: 0.1155 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0928 Val: 0.0885 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1017 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1107 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1015 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1021 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0941 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1315 Val: 0.1140 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1015 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1114 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0919 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1020 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0912 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1042 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0907 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1195 Val: 0.1127 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0901 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1018 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1023 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1136 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0913 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1108 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1018 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0909 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1024 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0938 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.0968 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0976 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1118 Val: 0.1089 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1315 Val: 0.1321 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0919 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1040 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0907 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1186 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0987 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0977 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0903 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1135 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0914 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1104 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0975 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0979 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0937 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0981 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0975 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1119 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0918 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1260 Val: 0.1151 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1044 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0978 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1113 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0903 Val: 0.0913 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:52:44,183] Trial 154 finished with value: 0.08988811313605108 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.01931711172457005, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 175] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03622565544752858, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [21/60] Loss: 0.1136 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0914 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0943 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0943 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1108 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0942 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0939 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0933 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1119 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0919 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1340 Val: 0.1362 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0909 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0942 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1041 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0944 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1113 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0905 Val: 0.0913 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:53:58,650] Trial 155 finished with value: 0.09110239304664756 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.015386324251721312, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 176] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.035611403856664156, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [22/60] Loss: 0.1129 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0917 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0938 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0939 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1112 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4564 Val: 0.1137 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0938 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0943 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.1358 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0941 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1127 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0915 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1148 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0914 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0942 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1217 Val: 0.1125 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0940 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1038 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0904 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1113 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0939 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1134 Val: 0.1111 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1136 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0915 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0919 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0908 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1108 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0939 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1273 Val: 0.1151 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0942 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1112 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0914 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1124 Val: 0.1077 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0914 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0938 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1105 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1157 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0916 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1039 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0903 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1113 Val: 0.1062 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0939 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1139 Val: 0.1134 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0914 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1125 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1114 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0914 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1270 Val: 0.1212 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0939 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1128 Val: 0.1049 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 10:57:41,249] Trial 156 finished with value: 0.08986411681946586 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.016980293257444254, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 177] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03286165707229693, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [36/60] Loss: 0.0915 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1121 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0938 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1128 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0915 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0915 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0914 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1177 Val: 0.1093 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1036 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0903 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1119 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.5214 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0938 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1176 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0914 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1125 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1180 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0915 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0924 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1102 Val: 0.1063 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1050 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1322 Val: 0.1332 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1146 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1048 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1056 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0911 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1198 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1036 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0900 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1108 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1058 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1052 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1126 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1122 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1053 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0918 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1104 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1351 Val: 0.1425 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0908 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1109 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0920 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1056 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1051 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0915 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1101 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0902 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0877 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0990 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1194 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1049 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0923 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1063 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0909 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1041 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0917 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1066 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0916 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0919 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1124 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1107 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1165 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0909 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1043 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1081 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1048 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0910 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1035 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0902 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0986 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0877 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [21/60] Loss: 0.1050 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1073 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1108 Val: 0.1032 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:03:02,174] Trial 157 finished with value: 0.08808625558344256 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.016021582680955257, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 178] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.035542434110768545, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [11/60] Loss: 0.1045 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1022 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1118 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1054 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1100 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1156 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0917 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1016 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1052 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1047 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0915 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0903 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0982 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1025 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1044 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1111 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1056 Val: 0.1008 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:04:26,379] Trial 158 finished with value: 0.09198485252236117 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.01718065610535565, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 179] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03605488433680859, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [50/60] Loss: 0.0908 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1021 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0918 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4928 Val: 0.1146 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1005 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1131 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0906 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1049 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1166 Val: 0.1138 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1021 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1011 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1048 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0916 Val: 0.0884 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1029 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0982 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1038 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1008 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1117 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0906 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1022 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4474 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1012 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1322 Val: 0.1173 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1121 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1043 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1191 Val: 0.1154 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1025 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1009 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0906 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1042 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0915 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0979 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0980 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1041 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1011 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0906 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1107 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0983 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1307 Val: 0.1156 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1018 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0908 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1324 Val: 0.1550 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0883 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0913 Val: 0.0879 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:08:00,195] Trial 172 finished with value: 0.08871301536758741 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030580437971503567, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/60] Loss: 0.1067 Val: 0.1010 Beta: 0.0100\n",
      "\n",
      "[Trial 180] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03707670472611138, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [29/60] Loss: 0.1042 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0978 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1211 Val: 0.1153 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1015 Val: 0.0984 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0905 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1042 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0984 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0913 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1014 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0975 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1037 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0907 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.1271 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1114 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0979 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1358 Val: 0.1163 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0967 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0909 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1235 Val: 0.1135 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0906 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1285 Val: 0.1181 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:09:24,331] Trial 173 finished with value: 0.09167560736338297 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03528351365427988, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 181] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.028787893394800444, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1057 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0978 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1033 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0976 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1116 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1161 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1044 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0976 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0972 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0888 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0977 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1147 Val: 0.1149 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1037 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.5823 Val: 0.1107 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:10:18,636] Trial 160 finished with value: 0.08933327234342318 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.0012121282557090497, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 182] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.027714936126829542, 'batch_size': 32, 'patience': 7}\n",
      "Epoch [17/60] Loss: 0.1117 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0939 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0973 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1320 Val: 0.1185 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1155 Val: 0.1150 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1229 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0909 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1332 Val: 0.1224 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0938 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0971 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0907 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1057 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1177 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1038 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.4345 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1124 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1141 Val: 0.1019 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:11:16,117] Trial 159 finished with value: 0.08867881844649796 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.006035698080621992, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 183] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030206473863533437, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [27/60] Loss: 0.0991 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0941 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0934 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1131 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1195 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0976 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1096 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1038 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0932 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0938 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1126 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1099 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1140 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1353 Val: 0.1632 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1103 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0910 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1154 Val: 0.1161 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0935 Val: 0.0924 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:12:26,723] Trial 161 finished with value: 0.09136936494282313 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'learning_rate': 0.03439932289003644, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 184] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030609019131521687, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [38/60] Loss: 0.0940 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1136 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1122 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1059 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1131 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1034 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1117 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0991 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0936 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1202 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0936 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1133 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1100 Val: 0.1021 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0977 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3176 Val: 0.1274 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1041 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0934 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1151 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0937 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1095 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1036 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1117 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1160 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1179 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0930 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1029 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1170 Val: 0.1423 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0936 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1031 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1056 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1033 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1116 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2983 Val: 0.1228 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1084 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0934 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1036 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0985 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0935 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1034 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0976 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1297 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1036 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1058 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0931 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1034 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0934 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1044 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1170 Val: 0.1102 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1111 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1066 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0932 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1039 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0935 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1196 Val: 0.1116 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1044 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1051 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1032 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1267 Val: 0.1133 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1067 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0931 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1036 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1123 Val: 0.1056 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0936 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0984 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1047 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0972 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0988 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1265 Val: 0.1094 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1071 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0930 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1046 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0917 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.0997 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1184 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1051 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1070 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0932 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1041 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0912 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1001 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1188 Val: 0.1171 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1029 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0929 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1048 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1051 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1031 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1304 Val: 0.1182 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1128 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0983 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1005 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0975 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1025 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0930 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1051 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0983 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1279 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1002 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1192 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1029 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1003 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0930 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1047 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0912 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0999 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1199 Val: 0.1217 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1030 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1006 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0930 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1226 Val: 0.1147 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1032 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1046 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1125 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1005 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0975 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1032 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0929 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1010 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0973 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0980 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1280 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1001 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1035 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1206 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0930 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1006 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1044 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0913 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1010 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1033 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1211 Val: 0.1219 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0912 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1009 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1271 Val: 0.1165 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1033 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1049 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0963 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1118 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0980 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1035 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0911 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1010 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0974 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0979 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0915 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1279 Val: 0.1132 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0965 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1034 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0909 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1013 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1116 Val: 0.1055 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0908 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1043 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0965 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1040 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0910 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1009 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1199 Val: 0.1180 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0906 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1319 Val: 0.1149 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0983 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0962 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1045 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0979 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1125 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0989 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0910 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1008 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0972 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0978 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0906 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0965 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1272 Val: 0.1154 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0994 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0910 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1010 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1126 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0905 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0931 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1038 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0996 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0909 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1008 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1115 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0906 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1282 Val: 0.1189 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:23:09,538] Trial 176 finished with value: 0.0913924366235733 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.035611403856664156, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 185] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.028395726396999492, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [28/60] Loss: 0.0929 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0982 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0990 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0998 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0910 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0980 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1009 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1065 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0936 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0976 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0932 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0991 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0910 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1011 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1304 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1122 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0931 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0988 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0905 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1040 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0967 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1121 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1148 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0989 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0933 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0904 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0977 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0971 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0979 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0997 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1058 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0940 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3453 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0976 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0989 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0932 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0906 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0969 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1152 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1122 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0988 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0916 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0904 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0966 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1037 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1116 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0948 Val: 0.0887 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1159 Val: 0.1263 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0914 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0904 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0968 Val: 0.0920 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:26:13,320] Trial 177 finished with value: 0.09186577126383781 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03286165707229693, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/60] Loss: 0.0979 Val: 0.0923 Beta: 0.0100\n",
      "\n",
      "[Trial 186] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02583689901128139, 'batch_size': 8, 'patience': 7}\n",
      "Epoch [37/60] Loss: 0.0978 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0990 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1056 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0933 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1291 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0952 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0978 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0913 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0965 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1178 Val: 0.1070 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1123 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0949 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0913 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0967 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1035 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0950 Val: 0.0889 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1119 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0915 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0963 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1178 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0981 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0975 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0992 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1051 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0949 Val: 0.0890 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0938 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1269 Val: 0.1232 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0972 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2588 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0932 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0914 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1136 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0927 Val: 0.0882 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1183 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0910 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0920 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1035 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0930 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0910 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1117 Val: 0.1079 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1195 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0974 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0974 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0921 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0985 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1049 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0935 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0931 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1221 Val: 0.1197 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0971 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1400 Val: 0.1325 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0910 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0921 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1125 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0932 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1200 Val: 0.1151 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0922 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1038 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0932 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1191 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1124 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0936 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0923 Val: 0.0881 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0970 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0918 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0932 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0989 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1045 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1283 Val: 0.1336 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0976 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1227 Val: 0.1170 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0923 Val: 0.0880 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1121 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0914 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1200 Val: 0.1109 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0917 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0915 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1031 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0912 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1183 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1126 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0937 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0972 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0916 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0934 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1249 Val: 0.1138 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0985 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1045 Val: 0.0999 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0971 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1293 Val: 0.1181 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0915 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0915 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1067 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0910 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1182 Val: 0.1137 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0914 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0916 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0986 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1103 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0917 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1117 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0936 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0913 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0974 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0933 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1245 Val: 0.1119 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0910 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0972 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1050 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0985 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0917 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1297 Val: 0.1187 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1063 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0916 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1112 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0915 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1108 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0983 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1118 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0935 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0971 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0932 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1133 Val: 0.1122 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0879 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0974 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1049 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0982 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1132 Val: 0.1057 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1057 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0878 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1112 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0911 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0915 Val: 0.0878 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:36:15,790] Trial 180 finished with value: 0.08828577821453412 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03707670472611138, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 187] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.026511377116777222, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [16/60] Loss: 0.1112 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0983 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1106 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0937 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0970 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0930 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1135 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0971 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1047 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0939 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1146 Val: 0.1117 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1056 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0911 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1119 Val: 0.1012 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1105 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0912 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0980 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0933 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1115 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0911 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2596 Val: 0.1110 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1140 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0969 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0970 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0910 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1049 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0947 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1164 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1055 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0909 Val: 0.0909 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:38:37,483] Trial 181 finished with value: 0.09155256822705268 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.028787893394800444, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 188] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.026861274442503552, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [60/60] Loss: 0.0911 Val: 0.0895 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:38:48,319] Trial 182 finished with value: 0.08986878891785939 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.027714936126829542, 'batch_size': 32, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 189] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02312061456029855, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [18/60] Loss: 0.1105 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1100 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0933 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0977 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1119 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1232 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0910 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1150 Val: 0.1064 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0972 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0932 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1043 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0940 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1177 Val: 0.1085 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1051 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1111 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3007 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2331 Val: 0.1160 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1100 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0933 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1124 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0976 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1225 Val: 0.1121 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0916 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1158 Val: 0.1092 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0936 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0967 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1044 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0941 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1051 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1162 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1115 Val: 0.1007 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1249 Val: 0.1157 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1222 Val: 0.1134 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1108 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0935 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1117 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1257 Val: 0.1197 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0976 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0912 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1158 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0934 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0971 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1044 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0939 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1054 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1182 Val: 0.1150 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1242 Val: 0.1174 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1109 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1214 Val: 0.1183 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1103 Val: 0.1072 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0933 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1241 Val: 0.1177 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1123 Val: 0.1256 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0974 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0914 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1173 Val: 0.1181 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0934 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0972 Val: 0.0912 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:44:00,030] Trial 167 finished with value: 0.0914341389444195 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03384430291038931, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 190] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.023786809583528287, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [34/60] Loss: 0.1049 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0939 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1050 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1101 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1250 Val: 0.1187 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1111 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1233 Val: 0.1127 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1101 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0930 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1272 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1056 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0975 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1158 Val: 0.1224 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0933 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0971 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1045 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1047 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0937 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1101 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2241 Val: 0.1114 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1220 Val: 0.1175 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1217 Val: 0.1161 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1106 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1100 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0910 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1269 Val: 0.1159 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1052 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1093 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0932 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0975 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0969 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1045 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1049 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0940 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1230 Val: 0.1162 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1098 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1251 Val: 0.1160 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1269 Val: 0.1197 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1116 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1099 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0907 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1246 Val: 0.1156 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1047 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1087 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0931 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0971 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0933 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0997 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1049 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1226 Val: 0.1149 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0938 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1097 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1236 Val: 0.1150 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1105 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1132 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1109 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1293 Val: 0.1213 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1082 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1048 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0931 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0974 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0935 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1050 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0989 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1233 Val: 0.1098 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0938 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1100 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1239 Val: 0.1189 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1107 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1138 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1106 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1270 Val: 0.1205 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1085 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0932 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1048 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0937 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0935 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0998 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0991 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1234 Val: 0.1123 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0937 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1099 Val: 0.1035 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:51:41,732] Trial 168 finished with value: 0.09084880176712484 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.035971432153597466, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 191] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02461254135668886, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [9/60] Loss: 0.1246 Val: 0.1136 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1100 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0913 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1155 Val: 0.1158 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1104 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1297 Val: 0.1153 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1084 Val: 0.1032 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0932 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1044 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0936 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0934 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0996 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0988 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1219 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1098 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1127 Val: 0.1083 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1101 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2395 Val: 0.1124 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0903 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1152 Val: 0.1120 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1105 Val: 0.1005 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1150 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1088 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0929 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1049 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0935 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0933 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0989 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1260 Val: 0.1265 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0986 Val: 0.0947 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:54:15,443] Trial 169 finished with value: 0.08962340349284541 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030263743102610045, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 192] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.022908919364288884, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [21/60] Loss: 0.1097 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1130 Val: 0.1141 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1096 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1228 Val: 0.1125 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0904 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1165 Val: 0.1250 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1161 Val: 0.1091 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1104 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1092 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0934 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0998 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0933 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0991 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1266 Val: 0.1262 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0982 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1092 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.1481 Val: 0.1090 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1130 Val: 0.1113 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1104 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1232 Val: 0.1206 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0905 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1194 Val: 0.1080 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1158 Val: 0.1110 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1106 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0933 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1084 Val: 0.1026 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0989 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0986 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0936 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1266 Val: 0.1268 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0983 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1097 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1149 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1143 Val: 0.1098 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1100 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1210 Val: 0.1169 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1153 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1165 Val: 0.1115 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1119 Val: 0.1019 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0931 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1086 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0983 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0987 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0932 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1140 Val: 0.1066 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0982 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1131 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1096 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1145 Val: 0.1105 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1110 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0904 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1244 Val: 0.1146 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1171 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0930 Val: 0.0915 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:59:25,229] Trial 170 finished with value: 0.09195196462654266 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03645499650301181, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/60] Loss: 0.1090 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1083 Val: 0.1031 Beta: 0.0100\n",
      "\n",
      "[Trial 193] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.05081090624375041, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [32/60] Loss: 0.1111 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0985 Val: 0.0957 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 11:59:36,960] Trial 171 finished with value: 0.09181810780858793 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.033171001503288, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 194] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02225508218201987, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [38/60] Loss: 0.0986 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0932 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1146 Val: 0.1130 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0982 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1121 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1039 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1138 Val: 0.1107 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1095 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1180 Val: 0.1128 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1250 Val: 0.1156 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1082 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1087 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1106 Val: 0.1017 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0984 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0984 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.6365 Val: 0.1113 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1162 Val: 0.1110 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2170 Val: 0.1146 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0935 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0981 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1115 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1034 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1077 Val: 0.1038 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1045 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1102 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1115 Val: 0.1086 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1081 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1086 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1053 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0979 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1279 Val: 0.1192 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0983 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1145 Val: 0.1136 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1221 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0932 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0978 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1125 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1032 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1075 Val: 0.1045 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1043 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1099 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1124 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1027 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1094 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1044 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1232 Val: 0.1135 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0980 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0982 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1208 Val: 0.1217 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1150 Val: 0.1082 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0934 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0977 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1128 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1027 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1074 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1037 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1094 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1024 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1149 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1087 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1210 Val: 0.1108 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1043 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0978 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0981 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1217 Val: 0.1123 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1162 Val: 0.1126 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0934 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0981 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1130 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1025 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1035 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1075 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1093 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1019 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1165 Val: 0.1087 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1210 Val: 0.1103 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1083 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0982 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1040 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0979 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1229 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1088 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0933 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0979 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1126 Val: 0.1042 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1027 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1030 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1075 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1095 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1019 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1142 Val: 0.1098 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1251 Val: 0.1140 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1031 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0984 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1036 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0978 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1233 Val: 0.1078 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1087 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0933 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0981 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1058 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1023 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1035 Val: 0.0995 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1069 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1092 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1018 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1353 Val: 0.1198 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1148 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0980 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1025 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0977 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1040 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1223 Val: 0.1112 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1081 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0933 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1063 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0981 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1033 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1023 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1071 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1091 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1016 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1330 Val: 0.1150 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1160 Val: 0.1084 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0983 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1022 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0975 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1038 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1236 Val: 0.1203 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1088 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1060 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0942 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0935 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1027 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1069 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1023 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1091 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1012 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1622 Val: 0.1310 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1084 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0985 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1016 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0971 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1259 Val: 0.1184 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1075 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1041 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1064 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0942 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1030 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1014 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1022 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1091 Val: 0.1014 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1014 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1429 Val: 0.1244 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0983 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1082 Val: 0.1043 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1017 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1240 Val: 0.1162 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0972 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1077 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1038 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1055 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0941 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0911 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1028 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1011 Val: 0.0984 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:14:48,827] Trial 174 finished with value: 0.08966565232316986 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.031997805671428604, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 195] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.023914510778901134, 'batch_size': 8, 'patience': 8}\n",
      "Epoch [35/60] Loss: 0.0976 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1090 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1011 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1256 Val: 0.1189 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0983 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1084 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1141 Val: 0.1054 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1026 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1015 Val: 0.0997 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0937 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1034 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1061 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0936 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1025 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1010 Val: 0.0982 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0975 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1091 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1015 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1259 Val: 0.1202 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.2278 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0981 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1082 Val: 0.1034 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1147 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1025 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0942 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1015 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1034 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1057 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0938 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1026 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1004 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1038 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0972 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1267 Val: 0.1175 Beta: 0.0100\n",
      "Early stopping triggered\n",
      "Epoch [36/60] Loss: 0.1010 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1134 Val: 0.1107 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:18:09,140] Trial 193 finished with value: 0.11837581995905948 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.05081090624375041, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 196] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.027247734535667926, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [51/60] Loss: 0.0943 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1138 Val: 0.1065 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1075 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1021 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0937 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1017 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1030 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1054 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.5203 Val: 0.1106 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0938 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1029 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1003 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1032 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0969 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1010 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1208 Val: 0.1053 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1121 Val: 0.1049 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0943 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1161 Val: 0.1047 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1123 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1016 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1084 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0935 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1014 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1034 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1058 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1122 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0938 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1028 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1002 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1025 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1116 Val: 0.1096 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0965 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0962 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1123 Val: 0.1069 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0940 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1138 Val: 0.1040 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1154 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1008 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1078 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0934 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1011 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0987 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1088 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1058 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0938 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1028 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1082 Val: 0.1041 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1000 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1024 Val: 0.0958 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:22:08,815] Trial 175 finished with value: 0.09194930545797869 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03622565544752858, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 197] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.022246279126166505, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [40/60] Loss: 0.0966 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0966 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0944 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1032 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1122 Val: 0.1048 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1171 Val: 0.1161 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1008 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1074 Val: 0.1046 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0933 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1022 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.3033 Val: 0.1076 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1010 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0983 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1053 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1039 Val: 0.1016 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1216 Val: 0.1029 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1025 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0997 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1025 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0962 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0966 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1033 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1171 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0942 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1123 Val: 0.1050 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1149 Val: 0.1039 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1007 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1044 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1074 Val: 0.1044 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1101 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0935 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1013 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0980 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1055 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1040 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1084 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0980 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0998 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1020 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0958 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0964 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1042 Val: 0.1006 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1076 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0938 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1135 Val: 0.1073 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1146 Val: 0.1059 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1006 Val: 0.0964 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.0999 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1078 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1082 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0934 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1011 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1059 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0980 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1071 Val: 0.1002 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.0999 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0977 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0999 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1022 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1078 Val: 0.1052 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1003 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0959 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0965 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0941 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1123 Val: 0.1100 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1155 Val: 0.1061 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1097 Val: 0.1024 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0998 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1007 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0934 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1080 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1011 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1057 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1075 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1001 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0979 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0972 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0997 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1020 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1079 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1008 Val: 0.0978 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0956 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0963 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1022 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0999 Val: 0.0967 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1155 Val: 0.1075 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1005 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1131 Val: 0.1081 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0933 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1072 Val: 0.1035 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1018 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1000 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1060 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1009 Val: 0.0993 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0977 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0971 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0954 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1022 Val: 0.0988 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1006 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1018 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0955 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0963 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0915 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1023 Val: 0.0979 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1007 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1146 Val: 0.1097 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0955 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1136 Val: 0.1118 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0910 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1024 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1004 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1031 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1063 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1013 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0975 Val: 0.0902 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0973 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1004 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1027 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0954 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1017 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0954 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0965 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0918 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1008 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1028 Val: 0.0995 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:31:25,669] Trial 179 finished with value: 0.08983347067186813 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.03605488433680859, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/60] Loss: 0.1154 Val: 0.1059 Beta: 0.0100\n",
      "\n",
      "[Trial 198] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.023611716917454784, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [33/60] Loss: 0.0962 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1058 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0960 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1030 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0909 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1018 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1008 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0967 Val: 0.0951 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:32:00,388] Trial 178 finished with value: 0.09241105099560834 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.035542434110768545, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 199] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.02633615339333913, 'batch_size': 32, 'patience': 8}\n",
      "Epoch [54/60] Loss: 0.0972 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0967 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0969 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1033 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 0.6751 Val: 0.1051 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0951 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1019 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0956 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0967 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0962 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.0987 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1184 Val: 0.1008 Beta: 0.0100\n",
      "Epoch [1/60] Loss: 1.5400 Val: 0.1067 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1087 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0958 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1058 Val: 0.1009 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0962 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1116 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0986 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [2/60] Loss: 0.1223 Val: 0.1037 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1019 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1003 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0965 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0964 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0976 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1095 Val: 0.0989 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0991 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0973 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [3/60] Loss: 0.1157 Val: 0.1036 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0951 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1018 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0955 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0960 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1092 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0989 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0963 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [4/60] Loss: 0.1118 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1080 Val: 0.1023 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0958 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0962 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1123 Val: 0.1003 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0989 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1054 Val: 0.1028 Beta: 0.0100\n",
      "Epoch [5/60] Loss: 0.1132 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1005 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1013 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0930 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0958 Val: 0.0948 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1093 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0992 Val: 0.0960 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0975 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0968 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [6/60] Loss: 0.1116 Val: 0.1033 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1019 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0949 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0956 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0923 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1077 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0993 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [7/60] Loss: 0.1126 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0961 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1082 Val: 0.1025 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0955 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0927 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1107 Val: 0.1068 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0946 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [8/60] Loss: 0.1119 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1062 Val: 0.1010 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1005 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1013 Val: 0.0986 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0927 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1035 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0958 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0952 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [9/60] Loss: 0.1110 Val: 0.0985 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0970 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0973 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0975 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0946 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0927 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1035 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0956 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0948 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [10/60] Loss: 0.1094 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0963 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0932 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1037 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1075 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0952 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0949 Val: 0.0929 Beta: 0.0100\n",
      "Epoch [11/60] Loss: 0.1115 Val: 0.1027 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1052 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1004 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0927 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1035 Val: 0.0963 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1010 Val: 0.0990 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0948 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0959 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [12/60] Loss: 0.1122 Val: 0.1015 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0966 Val: 0.0928 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0973 Val: 0.0903 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0970 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0946 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0914 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1034 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0957 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0950 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [13/60] Loss: 0.1176 Val: 0.1020 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0962 Val: 0.0927 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0911 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1038 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1078 Val: 0.1013 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0952 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0922 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [14/60] Loss: 0.1100 Val: 0.1071 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0910 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1056 Val: 0.1058 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1005 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1044 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1007 Val: 0.0970 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0917 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [15/60] Loss: 0.1047 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0958 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0971 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0910 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0970 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0948 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0973 Val: 0.0905 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1001 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0924 Val: 0.0913 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:40:07,503] Trial 184 finished with value: 0.0937070690658914 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030609019131521687, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [16/60] Loss: 0.1045 Val: 0.0958 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0913 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0963 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.0993 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1074 Val: 0.1031 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0954 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1050 Val: 0.0998 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0911 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1006 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.0999 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [17/60] Loss: 0.1049 Val: 0.1004 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0918 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1009 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1049 Val: 0.0954 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0956 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0911 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0966 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0947 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0975 Val: 0.0904 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.0998 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0923 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0917 Val: 0.0915 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:41:39,603] Trial 183 finished with value: 0.09071834914448883 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.030206473863533437, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/60] Loss: 0.1052 Val: 0.0966 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0911 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0960 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1002 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1080 Val: 0.0994 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0951 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0920 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1054 Val: 0.0969 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0911 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1000 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1001 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [18/60] Loss: 0.1058 Val: 0.1060 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0921 Val: 0.0917 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1008 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1049 Val: 0.0959 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0911 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0955 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0964 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0944 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0998 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0921 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0921 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0912 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1054 Val: 0.0965 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.0997 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1072 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0952 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0919 Val: 0.0916 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0913 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.1055 Val: 0.0961 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1003 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1002 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0918 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [19/60] Loss: 0.1053 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1004 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0912 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1012 Val: 0.0944 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0954 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0963 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0944 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0956 Val: 0.0906 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0911 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0924 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0914 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.1009 Val: 0.0930 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.1077 Val: 0.0987 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0963 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0949 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0909 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0933 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0916 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.1010 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1003 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0909 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0963 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0908 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [20/60] Loss: 0.1054 Val: 0.1022 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1009 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.1010 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0966 Val: 0.0911 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0956 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0945 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0910 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.0961 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0925 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.1016 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.1073 Val: 0.0992 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0909 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0954 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0959 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0927 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0921 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:46:04,946] Trial 196 finished with value: 0.09248450075586637 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.027247734535667926, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/60] Loss: 0.1009 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0970 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0908 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0958 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [21/60] Loss: 0.1048 Val: 0.1018 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1006 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.1009 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0963 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0955 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0948 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0907 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0922 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0930 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0972 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.1072 Val: 0.0991 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0907 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0951 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0925 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0930 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0970 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0968 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0905 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0926 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [22/60] Loss: 0.1050 Val: 0.1011 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0960 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0961 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0968 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0943 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0907 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0957 Val: 0.0943 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0921 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0929 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0969 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.1075 Val: 0.1001 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0907 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0950 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0927 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0927 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0974 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0971 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0906 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0929 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [23/60] Loss: 0.0999 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0965 Val: 0.0941 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0963 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0969 Val: 0.0900 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0918 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0906 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0922 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0955 Val: 0.0945 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0929 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.1076 Val: 0.0996 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.0967 Val: 0.0899 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0950 Val: 0.0920 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0917 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0969 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0908 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0968 Val: 0.0901 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:49:57,855] Trial 197 finished with value: 0.0919363650182883 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.022246279126166505, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/60] Loss: 0.0916 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0957 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [24/60] Loss: 0.1004 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0964 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0916 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0967 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0922 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0954 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0918 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.1070 Val: 0.1000 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0952 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0967 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0915 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0928 Val: 0.0907 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0973 Val: 0.0923 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:50:57,807] Trial 185 finished with value: 0.09104419083279722 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.028395726396999492, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/60] Loss: 0.0964 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0916 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0962 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0954 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [25/60] Loss: 0.0998 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0916 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0923 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0967 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0919 Val: 0.0923 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:51:28,029] Trial 186 finished with value: 0.09166335258163325 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02583689901128139, 'batch_size': 8, 'patience': 7}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/60] Loss: 0.0916 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [37/60] Loss: 0.1018 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0952 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0962 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0915 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0970 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0965 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0912 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0962 Val: 0.0915 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0956 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0916 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [26/60] Loss: 0.0999 Val: 0.0977 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0966 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0921 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0914 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.1019 Val: 0.0947 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0950 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0962 Val: 0.0898 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0962 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0963 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0958 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0918 Val: 0.0925 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0955 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [27/60] Loss: 0.0997 Val: 0.0980 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0966 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0923 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.1010 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0952 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0963 Val: 0.0901 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0957 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0962 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0963 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0916 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0953 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [28/60] Loss: 0.0995 Val: 0.0973 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0959 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0922 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.1011 Val: 0.0942 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0952 Val: 0.0921 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0915 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0963 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0956 Val: 0.0912 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0912 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0960 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0962 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0905 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0952 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0912 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [29/60] Loss: 0.1001 Val: 0.0976 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0964 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0924 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.1006 Val: 0.0940 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0919 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0912 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0964 Val: 0.0896 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0961 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0931 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0961 Val: 0.0891 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0904 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0952 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0966 Val: 0.0897 Beta: 0.0100\n",
      "Epoch [30/60] Loss: 0.0993 Val: 0.0974 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.1008 Val: 0.0946 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0921 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0958 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0963 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0914 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0933 Val: 0.0895 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0960 Val: 0.0893 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0913 Val: 0.0892 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0905 Val: 0.0922 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:56:41,900] Trial 198 finished with value: 0.08962549890081088 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.023611716917454784, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/60] Loss: 0.0953 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0963 Val: 0.0894 Beta: 0.0100\n",
      "Epoch [31/60] Loss: 0.0995 Val: 0.0968 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.1003 Val: 0.0938 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:56:57,654] Trial 199 finished with value: 0.08999090989430746 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'learning_rate': 0.02633615339333913, 'batch_size': 32, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/60] Loss: 0.0921 Val: 0.0923 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0925 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.0960 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0931 Val: 0.0893 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:57:22,871] Trial 187 finished with value: 0.08955849397207509 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.026511377116777222, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/60] Loss: 0.0907 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0952 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [32/60] Loss: 0.0995 Val: 0.0972 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.1003 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0922 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0921 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0963 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0906 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0953 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.1005 Val: 0.0938 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0922 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0961 Val: 0.0914 Beta: 0.0100\n",
      "Epoch [33/60] Loss: 0.0995 Val: 0.0983 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0921 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0907 Val: 0.0922 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:58:32,955] Trial 189 finished with value: 0.09246479494481527 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02312061456029855, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/60] Loss: 0.0950 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0954 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.1003 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0924 Val: 0.0908 Beta: 0.0100\n",
      "Epoch [34/60] Loss: 0.0995 Val: 0.0975 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0954 Val: 0.0913 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0952 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [47/60] Loss: 0.1003 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0924 Val: 0.0909 Beta: 0.0100\n",
      "Epoch [35/60] Loss: 0.0996 Val: 0.0981 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0922 Val: 0.0922 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:59:24,134] Trial 188 finished with value: 0.09243791400134063 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.026861274442503552, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/60] Loss: 0.0953 Val: 0.0913 Beta: 0.0100\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:59:36,323] Trial 192 finished with value: 0.09220284746349358 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'learning_rate': 0.022908919364288884, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/60] Loss: 0.0952 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.1004 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0921 Val: 0.0910 Beta: 0.0100\n",
      "Epoch [36/60] Loss: 0.0993 Val: 0.0971 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.1004 Val: 0.0936 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0951 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0921 Val: 0.0909 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:00:01,990] Trial 190 finished with value: 0.09115711608979882 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.023786809583528287, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] Loss: 0.0963 Val: 0.0957 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.1001 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0952 Val: 0.0933 Beta: 0.0100\n",
      "Epoch [38/60] Loss: 0.0959 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.1004 Val: 0.0935 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0950 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [39/60] Loss: 0.0964 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.1001 Val: 0.0931 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0953 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [40/60] Loss: 0.0959 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.1004 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0920 Val: 0.0919 Beta: 0.0100\n",
      "Epoch [41/60] Loss: 0.0962 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.1000 Val: 0.0926 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0921 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [42/60] Loss: 0.0962 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.1001 Val: 0.0924 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0923 Val: 0.0918 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.1003 Val: 0.0934 Beta: 0.0100\n",
      "Epoch [43/60] Loss: 0.0964 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0920 Val: 0.0919 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:01:45,264] Trial 191 finished with value: 0.0921138382571585 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02461254135668886, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/60] Loss: 0.1000 Val: 0.0939 Beta: 0.0100\n",
      "Epoch [44/60] Loss: 0.0963 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.1003 Val: 0.0937 Beta: 0.0100\n",
      "Epoch [45/60] Loss: 0.0963 Val: 0.0956 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.1000 Val: 0.0932 Beta: 0.0100\n",
      "Epoch [46/60] Loss: 0.0966 Val: 0.0962 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.1006 Val: 0.0933 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:02:18,555] Trial 194 finished with value: 0.09356996730095198 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'learning_rate': 0.02225508218201987, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/60] Loss: 0.0963 Val: 0.0955 Beta: 0.0100\n",
      "Epoch [48/60] Loss: 0.0947 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [49/60] Loss: 0.0953 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [50/60] Loss: 0.0952 Val: 0.0952 Beta: 0.0100\n",
      "Epoch [51/60] Loss: 0.0951 Val: 0.0953 Beta: 0.0100\n",
      "Epoch [52/60] Loss: 0.0949 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [53/60] Loss: 0.0949 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [54/60] Loss: 0.0950 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [55/60] Loss: 0.0947 Val: 0.0949 Beta: 0.0100\n",
      "Epoch [56/60] Loss: 0.0945 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [57/60] Loss: 0.0944 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [58/60] Loss: 0.0944 Val: 0.0951 Beta: 0.0100\n",
      "Epoch [59/60] Loss: 0.0947 Val: 0.0950 Beta: 0.0100\n",
      "Epoch [60/60] Loss: 0.0945 Val: 0.0950 Beta: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:03:36,256] Trial 195 finished with value: 0.09562067678119957 and parameters: {'hidden_dim': 448, 'latent_dim': 32, 'learning_rate': 0.023914510778901134, 'batch_size': 8, 'patience': 8}. Best is trial 72 with value: 0.08646482492194456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Trial Number: 72\n",
      "Best Parameters: {'hidden_dim': 384, 'latent_dim': 128, 'learning_rate': 0.018061505448184818, 'batch_size': 8, 'patience': 8}\n",
      "Best Value (Objective): 0.08646482492194456\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    pyg_dataset = torch.load(r'../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n",
    "    node_features = pyg_dataset[0].x.size(1)\n",
    "    edge_features = pyg_dataset[0].edge_attr.size(1)\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512, step=64)\n",
    "    latent_dim = trial.suggest_int(\"latent_dim\", 32, 128, step=32)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10)\n",
    "    adv_weight = 0.1\n",
    "    print(f\"\\n[Trial {trial.number}] Starting with parameters: {trial.params}\")\n",
    "    # Initialize model\n",
    "    \n",
    "    model = ARGVA(node_features, edge_features, hidden_dim, latent_dim)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_ratio = 0.8\n",
    "    valid_ratio = 0.2\n",
    "    beta = 0.01 \n",
    "    \n",
    "    train_ratio = 0.8\n",
    "    num_train = int(len(pyg_dataset) * train_ratio)\n",
    "    num_valid = len(pyg_dataset) - num_train\n",
    "    train_dataset, valid_dataset = random_split(pyg_dataset, [num_train, num_valid])\n",
    "\n",
    "    # Model initialization\n",
    "    \n",
    "    # Train and validate model\n",
    "    trained_model = train_argva_with_early_stopping(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=valid_dataset,\n",
    "        num_epochs=60,  # Adjust based on requirements\n",
    "        batch_size=batch_size,\n",
    "        lr=learning_rate,\n",
    "        device=device,\n",
    "        patience=patience\n",
    "    )\n",
    "        \n",
    "\n",
    "    # Create DataLoader for training dataset\n",
    "    train_loader = PyGDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create DataLoader for validation dataset\n",
    "    val_loader = PyGDataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # Validation loss as the optimization target\n",
    "    # trained_model = train_argva_with_early_stopping(\n",
    "    #     model=model,\n",
    "    #     train_dataset=train_dataset,\n",
    "    #     val_dataset=valid_dataset,\n",
    "    #     num_epochs=60,  # Adjust based on requirements\n",
    "    #     batch_size=batch_size,\n",
    "    #     lr=learning_rate,\n",
    "    #     device=device,\n",
    "    #     patience=patience,\n",
    "    #     adv_weight=adv_weight  # Pass adversarial weight to the training function\n",
    "    # )\n",
    "\n",
    "    # Validation loss as the optimization target\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            reconstructed_x, reconstructed_edge_attr, mu, logvar = model(\n",
    "                batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "            )\n",
    "            val_recon_loss = F.mse_loss(reconstructed_x, batch.x) + F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "            val_kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            z = trained_model.reparameterize(mu, logvar)\n",
    "            real_z = torch.randn_like(z)\n",
    "            real_scores = trained_model.discriminate(real_z)\n",
    "            fake_scores = trained_model.discriminate(z)\n",
    "            adv_loss = -torch.mean(torch.log(real_scores + 1e-8) + torch.log(1 - fake_scores + 1e-8))\n",
    "\n",
    "            val_loss += (val_recon_loss + beta *val_kl_loss + adv_weight * adv_loss).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    return val_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create Optuna study\n",
    "    \n",
    "    num_jobs = min(cpu_count(), 27)  # Use up to 4 cores or fewer if limited\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=200, n_jobs=num_jobs)\n",
    "\n",
    "    # Output the best parameters along with the trial number\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"\\nBest Trial Number: {best_trial.number}\")\n",
    "    print(\"Best Parameters:\", best_trial.params)\n",
    "    print(\"Best Value (Objective):\", best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
