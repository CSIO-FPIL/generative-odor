{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "class DeepChemToPyGDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        \"\"\"\n",
    "        Converts a list of PyG `Data` objects into an InMemoryDataset.\n",
    "        \n",
    "        Args:\n",
    "            data_list (list of Data): List of PyG Data objects.\n",
    "            transform (callable, optional): Optional transform applied to each data object.\n",
    "        \"\"\"\n",
    "        super(DeepChemToPyGDataset, self).__init__('.', transform, None, None)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data object at the specified index.\n",
    "        \"\"\"\n",
    "        return super().get(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "class ARGA(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim, dropout=0.2):\n",
    "        super(ARGA, self).__init__()\n",
    "        self.encoder = Encoder(node_features, edge_features, hidden_dim, latent_dim, dropout)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, node_features, edge_features)\n",
    "        self.discriminator = Discriminator(latent_dim, hidden_dim)\n",
    "        \n",
    "    def encode(self, x, edge_index, edge_attr, batch=None):\n",
    "        return self.encoder(x, edge_index, edge_attr, batch)\n",
    "\n",
    "    def decode(self, z, edge_index, batch=None):\n",
    "        return self.decoder(z, edge_index, batch)\n",
    "\n",
    "    def discriminate(self, z):\n",
    "        return self.discriminator(z)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        z, mu = self.encode(x, edge_index, edge_attr, batch)\n",
    "        reconstructed_x, reconstructed_edge_attr = self.decode(z, edge_index, batch)\n",
    "        return reconstructed_x, reconstructed_edge_attr, z\n",
    "\n",
    "    def generate_multiple_outputs(self, x, edge_index, edge_attr, batch=None, num_samples=5, variator=0.1):\n",
    "        outputs = []\n",
    "        with torch.no_grad():\n",
    "            z, mu = self.encode(x, edge_index, edge_attr, batch)\n",
    "            for _ in range(num_samples):\n",
    "                epsilon = torch.randn_like(mu) * variator\n",
    "                z_new = mu + epsilon\n",
    "                reconstructed_x, reconstructed_edge_attr = self.decode(z_new, edge_index, batch)\n",
    "                outputs.append((reconstructed_x, reconstructed_edge_attr, edge_index))\n",
    "        return outputs\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, latent_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.edge_encoder = nn.Linear(edge_features, hidden_dim)\n",
    "        self.conv1 = SAGEConv(node_features + hidden_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        edge_attr = torch.clamp(edge_attr, -5, 5)\n",
    "        edge_attr = F.relu(self.edge_encoder(edge_attr))\n",
    "        edge_attr = self.dropout(edge_attr)\n",
    "        \n",
    "        edge_attr_expanded = torch.zeros((x.size(0), edge_attr.size(1)), device=x.device)\n",
    "        edge_attr_expanded[edge_index[0]] = edge_attr\n",
    "        \n",
    "        x = torch.cat([x, edge_attr_expanded], dim=1)\n",
    "        x = torch.clamp(x, -5, 5)\n",
    "        \n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h1 = self.layer_norm1(h1)\n",
    "        h1 = F.relu(h1)\n",
    "        h1 = self.dropout(h1)\n",
    "        \n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h2 = self.layer_norm2(h2)\n",
    "        h2 = F.relu(h2)\n",
    "        h2 = self.dropout(h2)\n",
    "        \n",
    "        if batch is not None:\n",
    "            h2 = global_mean_pool(h2, batch)\n",
    "        \n",
    "        mu = self.fc_mu(h2)\n",
    "        log_var = self.fc_var(h2)\n",
    "        log_var = torch.clamp(log_var, -10, 2)\n",
    "        \n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        return z, mu\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, node_features, edge_features):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.node_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, node_features)\n",
    "        )\n",
    "        \n",
    "        self.edge_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, edge_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, edge_index, batch=None):\n",
    "        if batch is not None:\n",
    "            z = z[batch]\n",
    "        \n",
    "        reconstructed_x = self.node_decoder(z)\n",
    "        \n",
    "        row, col = edge_index\n",
    "        edge_h = torch.cat([z[row], z[col]], dim=1)\n",
    "        reconstructed_edge_attr = self.edge_decoder(edge_h)\n",
    "        \n",
    "        return reconstructed_x, reconstructed_edge_attr\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "def train_arga_with_early_stopping(model, train_loader, val_loader, num_epochs, lr=0.0001, device='cuda', patience=10):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            reconstructed_x, reconstructed_edge_attr, z = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            \n",
    "            recon_loss = F.mse_loss(reconstructed_x, batch.x) + F.mse_loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "          \n",
    "            real_z = torch.randn_like(z)\n",
    "            real_scores = model.discriminate(real_z)\n",
    "            fake_scores = model.discriminate(z)\n",
    "            \n",
    "            adv_loss = -torch.mean(torch.log(torch.clamp(fake_scores, 1e-6, 1.0)) + \n",
    "                                 torch.log(torch.clamp(1 - real_scores, 1e-6, 1.0)))\n",
    "            \n",
    "            loss = recon_loss + 1 * adv_loss\n",
    "            \n",
    "            if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                reconstructed_x, reconstructed_edge_attr, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                val_loss += (F.mse_loss(reconstructed_x, batch.x) + \n",
    "                           F.mse_loss(reconstructed_edge_attr, batch.edge_attr)).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\miniconda3\\envs\\ENV4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:10:14,546] A new study created in memory with name: no-name-1fc3b48d-ab78-4b60-9d34-6eae675e279a\n",
      "C:\\Users\\sarab\\AppData\\Local\\Temp\\ipykernel_25536\\533947880.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pyg_dataset = torch.load('../../data/curated dataset/frag_pyg_dataset.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 1] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0005670950504210985, 'batch_size': 16, 'patience': 4}\n",
      "[Trial 0] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 64, 'lr': 0.04448765643911486, 'batch_size': 64, 'patience': 10}\n",
      "\n",
      "\n",
      "[Trial 2] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.001368526281729318, 'batch_size': 8, 'patience': 8}\n",
      "\n",
      "[Trial 3] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 32, 'lr': 1.9255673577850748e-05, 'batch_size': 64, 'patience': 10}\n",
      "\n",
      "[Trial 4] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 96, 'lr': 0.0013606265013507803, 'batch_size': 64, 'patience': 4}\n",
      "\n",
      "[Trial 5] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 2.2632688109496862e-05, 'batch_size': 16, 'patience': 6}\n",
      "\n",
      "[Trial 6] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0011861753762190549, 'batch_size': 8, 'patience': 6}\n",
      "\n",
      "[Trial 8] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.0014828801561934703, 'batch_size': 64, 'patience': 5}\n",
      "\n",
      "[Trial 7] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.01591669379645929, 'batch_size': 8, 'patience': 10}\n",
      "\n",
      "[Trial 10] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'lr': 0.0013213739986966879, 'batch_size': 32, 'patience': 10}\n",
      "\n",
      "[Trial 11] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'lr': 0.021237796971271747, 'batch_size': 8, 'patience': 10}\n",
      "\n",
      "[Trial 9] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 32, 'lr': 0.029282186806683874, 'batch_size': 64, 'patience': 8}\n",
      "\n",
      "[Trial 12] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.001148154498740274, 'batch_size': 64, 'patience': 3}\n",
      "\n",
      "[Trial 14] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 96, 'lr': 3.970813749735035e-05, 'batch_size': 64, 'patience': 10}\n",
      "\n",
      "[Trial 13] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 32, 'lr': 0.00011544666457474547, 'batch_size': 32, 'patience': 4}\n",
      "\n",
      "[Trial 15] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.014548620875315334, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 1/60, Loss: 0.3644, Val Loss: 0.0929\n",
      "Epoch 1/60, Loss: 1.5229, Val Loss: 0.2709\n",
      "Epoch 1/60, Loss: 1.1231, Val Loss: 0.1287\n",
      "Epoch 1/60, Loss: 0.2615, Val Loss: 0.0923\n",
      "Epoch 1/60, Loss: 1.2213, Val Loss: 0.2047\n",
      "Epoch 1/60, Loss: 0.2665, Val Loss: 0.0944\n",
      "Epoch 1/60, Loss: 6.7942, Val Loss: 0.1274\n",
      "Epoch 1/60, Loss: 0.3091, Val Loss: 0.0929\n",
      "Epoch 1/60, Loss: 0.6941, Val Loss: 0.1022\n",
      "Epoch 2/60, Loss: 0.1005, Val Loss: 0.0915\n",
      "Epoch 2/60, Loss: 1.0601, Val Loss: 0.1805\n",
      "Epoch 2/60, Loss: 0.1288, Val Loss: 0.1299\n",
      "Epoch 2/60, Loss: 0.7419, Val Loss: 0.1385\n",
      "Epoch 2/60, Loss: 0.0924, Val Loss: 0.0908\n",
      "Epoch 2/60, Loss: 0.0931, Val Loss: 0.0906\n",
      "Epoch 2/60, Loss: 0.1262, Val Loss: 0.1273\n",
      "Epoch 1/60, Loss: 1.0934, Val Loss: 0.1834\n",
      "Epoch 3/60, Loss: 0.0938, Val Loss: 0.0897\n",
      "Epoch 3/60, Loss: 0.8689, Val Loss: 0.1470\n",
      "Epoch 2/60, Loss: 0.0990, Val Loss: 0.0896\n",
      "Epoch 1/60, Loss: 0.2604, Val Loss: 0.0943\n",
      "Epoch 3/60, Loss: 0.1278, Val Loss: 0.1257\n",
      "Epoch 3/60, Loss: 0.5507, Val Loss: 0.1148\n",
      "Epoch 3/60, Loss: 0.0907, Val Loss: 0.0890\n",
      "Epoch 3/60, Loss: 0.0901, Val Loss: 0.0901\n",
      "Epoch 2/60, Loss: 0.2048, Val Loss: 0.0926\n",
      "Epoch 3/60, Loss: 0.1262, Val Loss: 0.1267\n",
      "Epoch 4/60, Loss: 0.0914, Val Loss: 0.0896\n",
      "Epoch 4/60, Loss: 0.7542, Val Loss: 0.1301\n",
      "Epoch 4/60, Loss: 0.1265, Val Loss: 0.1246\n",
      "Epoch 4/60, Loss: 0.4219, Val Loss: 0.1049\n",
      "Epoch 4/60, Loss: 0.0899, Val Loss: 0.0886\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0896\n",
      "Epoch 4/60, Loss: 0.3054, Val Loss: 0.1302\n",
      "Epoch 3/60, Loss: 0.0931, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0904, Val Loss: 0.0895\n",
      "Epoch 5/60, Loss: 0.6614, Val Loss: 0.1186\n",
      "Epoch 3/60, Loss: 0.1334, Val Loss: 0.0915\n",
      "Epoch 5/60, Loss: 0.1271, Val Loss: 0.1268\n",
      "Epoch 5/60, Loss: 0.3278, Val Loss: 0.0993\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0885\n",
      "Epoch 1/60, Loss: 0.1340, Val Loss: 0.0882\n",
      "Epoch 5/60, Loss: 0.0892, Val Loss: 0.0896\n",
      "Epoch 1/60, Loss: 0.1758, Val Loss: 0.1268\n",
      "Epoch 1/60, Loss: 0.1526, Val Loss: 0.1268\n",
      "Epoch 5/60, Loss: 0.1543, Val Loss: 0.1265\n",
      "Epoch 1/60, Loss: 0.1360, Val Loss: 0.0902\n",
      "Epoch 2/60, Loss: 0.6008, Val Loss: 0.1329\n",
      "Epoch 1/60, Loss: 0.1950, Val Loss: 0.1279\n",
      "Epoch 6/60, Loss: 0.0900, Val Loss: 0.0894\n",
      "Epoch 6/60, Loss: 0.5837, Val Loss: 0.1120\n",
      "Epoch 2/60, Loss: 0.0932, Val Loss: 0.0927\n",
      "Epoch 4/60, Loss: 0.0912, Val Loss: 0.0878\n",
      "Epoch 6/60, Loss: 0.1715, Val Loss: 0.1249\n",
      "Epoch 6/60, Loss: 0.2620, Val Loss: 0.0969\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0887\n",
      "Epoch 6/60, Loss: 0.0892, Val Loss: 0.0898\n",
      "Epoch 6/60, Loss: 0.1229, Val Loss: 0.1042\n",
      "Epoch 4/60, Loss: 0.1136, Val Loss: 0.0907\n",
      "Epoch 7/60, Loss: 0.0896, Val Loss: 0.0892\n",
      "Epoch 7/60, Loss: 0.5206, Val Loss: 0.1079\n",
      "Epoch 7/60, Loss: 0.1266, Val Loss: 0.1246\n",
      "Epoch 7/60, Loss: 0.2207, Val Loss: 0.0956\n",
      "Epoch 7/60, Loss: 0.0893, Val Loss: 0.0883\n",
      "Epoch 7/60, Loss: 0.0891, Val Loss: 0.0895\n",
      "Epoch 7/60, Loss: 0.1026, Val Loss: 0.1030\n",
      "Epoch 5/60, Loss: 0.0904, Val Loss: 0.0877\n",
      "Epoch 8/60, Loss: 0.0894, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.4639, Val Loss: 0.1044\n",
      "Epoch 8/60, Loss: 0.1261, Val Loss: 0.1249\n",
      "Epoch 5/60, Loss: 0.1041, Val Loss: 0.0904\n",
      "Epoch 8/60, Loss: 0.1953, Val Loss: 0.0948\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 3/60, Loss: 0.4322, Val Loss: 0.1124\n",
      "Epoch 8/60, Loss: 0.1052, Val Loss: 0.1062\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0892\n",
      "Epoch 9/60, Loss: 0.4231, Val Loss: 0.1015\n",
      "Epoch 3/60, Loss: 0.0898, Val Loss: 0.0925\n",
      "Epoch 6/60, Loss: 0.0900, Val Loss: 0.0876\n",
      "Epoch 9/60, Loss: 0.1264, Val Loss: 0.1244\n",
      "Epoch 9/60, Loss: 0.1752, Val Loss: 0.0942\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 9/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 9/60, Loss: 0.1125, Val Loss: 0.1087\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 10/60, Loss: 0.3792, Val Loss: 0.0995\n",
      "Epoch 6/60, Loss: 0.0993, Val Loss: 0.0900\n",
      "Epoch 10/60, Loss: 0.1264, Val Loss: 0.1270\n",
      "Epoch 10/60, Loss: 0.1609, Val Loss: 0.0937\n",
      "Epoch 10/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0876\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0896\n",
      "Epoch 10/60, Loss: 0.1012, Val Loss: 0.1005\n",
      "Epoch 2/60, Loss: 0.0898, Val Loss: 0.0876\n",
      "Epoch 2/60, Loss: 0.1049, Val Loss: 0.0917\n",
      "Epoch 2/60, Loss: 0.1260, Val Loss: 0.1269\n",
      "Epoch 11/60, Loss: 0.3398, Val Loss: 0.0977\n",
      "Epoch 2/60, Loss: 0.0894, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.1238, Val Loss: 0.1027\n",
      "Epoch 4/60, Loss: 0.3317, Val Loss: 0.1046\n",
      "Epoch 11/60, Loss: 0.1518, Val Loss: 0.0933\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 12/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Early stopping triggered\n",
      "Epoch 7/60, Loss: 0.0967, Val Loss: 0.0900\n",
      "[Trial 12] Validation Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0894\n",
      "Epoch 2/60, Loss: 0.1396, Val Loss: 0.1262\n",
      "Epoch 11/60, Loss: 0.0997, Val Loss: 0.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:17:29,750] Trial 12 finished with value: 0.08921072880427043 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.001148154498740274, 'batch_size': 64, 'patience': 3}. Best is trial 12 with value: 0.08921072880427043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 16] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 96, 'lr': 0.035810794129719443, 'batch_size': 64, 'patience': 4}\n",
      "Epoch 12/60, Loss: 0.3119, Val Loss: 0.0966\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0924\n",
      "Epoch 8/60, Loss: 0.0896, Val Loss: 0.0877\n",
      "Epoch 12/60, Loss: 0.1094, Val Loss: 0.0945\n",
      "Epoch 12/60, Loss: 0.1423, Val Loss: 0.0930\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0884\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0997, Val Loss: 0.1006\n",
      "Epoch 13/60, Loss: 0.2802, Val Loss: 0.0956\n",
      "Epoch 13/60, Loss: 0.0929, Val Loss: 0.0910\n",
      "Epoch 8/60, Loss: 0.0946, Val Loss: 0.0899\n",
      "Epoch 1/60, Loss: 0.3524, Val Loss: 0.1272\n",
      "Epoch 9/60, Loss: 0.0896, Val Loss: 0.0878\n",
      "Epoch 13/60, Loss: 0.1361, Val Loss: 0.0926\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0884\n",
      "Epoch 14/60, Loss: 0.2556, Val Loss: 0.0950\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0996, Val Loss: 0.1009\n",
      "Epoch 5/60, Loss: 0.2678, Val Loss: 0.1007\n",
      "Epoch 14/60, Loss: 0.0912, Val Loss: 0.0904\n",
      "Epoch 2/60, Loss: 0.1273, Val Loss: 0.1254\n",
      "Epoch 14/60, Loss: 0.1303, Val Loss: 0.0923\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 15/60, Loss: 0.2387, Val Loss: 0.0945\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 14/60, Loss: 0.0999, Val Loss: 0.0997\n",
      "Epoch 9/60, Loss: 0.0934, Val Loss: 0.0899\n",
      "Epoch 5/60, Loss: 0.0887, Val Loss: 0.0921\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0876\n",
      "Epoch 3/60, Loss: 0.1264, Val Loss: 0.1259\n",
      "Epoch 15/60, Loss: 0.0905, Val Loss: 0.0895\n",
      "Epoch 16/60, Loss: 0.2229, Val Loss: 0.0942\n",
      "Epoch 15/60, Loss: 0.1257, Val Loss: 0.0920\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.1455, Val Loss: 0.1085\n",
      "Epoch 4/60, Loss: 0.1264, Val Loss: 0.1251\n",
      "Epoch 3/60, Loss: 0.0893, Val Loss: 0.0876\n",
      "Epoch 3/60, Loss: 0.0914, Val Loss: 0.0893\n",
      "Epoch 16/60, Loss: 0.0899, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.1464, Val Loss: 0.1268\n",
      "Epoch 11/60, Loss: 0.0893, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.0923, Val Loss: 0.0898\n",
      "Epoch 17/60, Loss: 0.2099, Val Loss: 0.0939\n",
      "Epoch 3/60, Loss: 0.0890, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0879\n",
      "Epoch 16/60, Loss: 0.1215, Val Loss: 0.0918\n",
      "Epoch 5/60, Loss: 0.1263, Val Loss: 0.1252\n",
      "Epoch 16/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 6/60, Loss: 0.2285, Val Loss: 0.0971\n",
      "Epoch 16/60, Loss: 0.1436, Val Loss: 0.1012\n",
      "Epoch 17/60, Loss: 0.0894, Val Loss: 0.0890\n",
      "Epoch 18/60, Loss: 0.1985, Val Loss: 0.0937\n",
      "Epoch 6/60, Loss: 0.1260, Val Loss: 0.1250\n",
      "Epoch 3/60, Loss: 0.1130, Val Loss: 0.0931\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0878\n",
      "Epoch 17/60, Loss: 0.1177, Val Loss: 0.0915\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 6/60, Loss: 0.0880, Val Loss: 0.0921\n",
      "Epoch 12/60, Loss: 0.0893, Val Loss: 0.0873\n",
      "Epoch 17/60, Loss: 0.1057, Val Loss: 0.1040\n",
      "Epoch 11/60, Loss: 0.0917, Val Loss: 0.0898\n",
      "Epoch 18/60, Loss: 0.0894, Val Loss: 0.0894\n",
      "Epoch 7/60, Loss: 0.1267, Val Loss: 0.1238\n",
      "Epoch 19/60, Loss: 0.1876, Val Loss: 0.0934\n",
      "Epoch 18/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 18/60, Loss: 0.1153, Val Loss: 0.0913\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0893, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.1008, Val Loss: 0.1008\n",
      "Epoch 8/60, Loss: 0.1065, Val Loss: 0.0979\n",
      "Epoch 20/60, Loss: 0.1808, Val Loss: 0.0932\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0873\n",
      "Epoch 7/60, Loss: 0.1987, Val Loss: 0.0932\n",
      "Epoch 12/60, Loss: 0.0913, Val Loss: 0.0897\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0877\n",
      "Epoch 19/60, Loss: 0.1129, Val Loss: 0.0912\n",
      "Epoch 20/60, Loss: 0.0892, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0895\n",
      "Epoch 9/60, Loss: 0.1565, Val Loss: 0.0999\n",
      "Epoch 19/60, Loss: 0.0999, Val Loss: 0.1014\n",
      "Epoch 21/60, Loss: 0.1709, Val Loss: 0.0931\n",
      "Epoch 20/60, Loss: 0.1108, Val Loss: 0.0911\n",
      "Epoch 20/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.1006, Val Loss: 0.0988\n",
      "Epoch 14/60, Loss: 0.0891, Val Loss: 0.0872\n",
      "Epoch 21/60, Loss: 0.0895, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0880, Val Loss: 0.0919\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0889\n",
      "Epoch 22/60, Loss: 0.1647, Val Loss: 0.0929\n",
      "Epoch 20/60, Loss: 0.1036, Val Loss: 0.1009\n",
      "Epoch 13/60, Loss: 0.0908, Val Loss: 0.0897\n",
      "Epoch 4/60, Loss: 0.0993, Val Loss: 0.0900\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0873\n",
      "Epoch 11/60, Loss: 0.1004, Val Loss: 0.0986\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 21/60, Loss: 0.1085, Val Loss: 0.0910\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0887\n",
      "Epoch 23/60, Loss: 0.1602, Val Loss: 0.0927\n",
      "Epoch 4/60, Loss: 0.1257, Val Loss: 0.1262\n",
      "Epoch 21/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 15/60, Loss: 0.0889, Val Loss: 0.0871\n",
      "Epoch 12/60, Loss: 0.1005, Val Loss: 0.0989\n",
      "Early stopping triggered\n",
      "[Trial 16] Validation Loss: 0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:23:54,038] Trial 16 finished with value: 0.09885171006123225 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'lr': 0.035810794129719443, 'batch_size': 64, 'patience': 4}. Best is trial 12 with value: 0.08921072880427043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 17] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'lr': 0.0003058132771533535, 'batch_size': 64, 'patience': 10}\n",
      "Epoch 21/60, Loss: 0.0999, Val Loss: 0.1004\n",
      "Epoch 4/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "Epoch 8/60, Loss: 0.1768, Val Loss: 0.0914\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.1071, Val Loss: 0.0910\n",
      "Epoch 23/60, Loss: 0.0893, Val Loss: 0.0886\n",
      "Epoch 24/60, Loss: 0.1540, Val Loss: 0.0926\n",
      "Epoch 14/60, Loss: 0.0905, Val Loss: 0.0896\n",
      "Epoch 1/60, Loss: 0.6651, Val Loss: 0.1010\n",
      "Epoch 22/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 22/60, Loss: 0.0998, Val Loss: 0.1003\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0874\n",
      "Epoch 25/60, Loss: 0.1491, Val Loss: 0.0925\n",
      "Epoch 24/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.1057, Val Loss: 0.0908\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 8/60, Loss: 0.0879, Val Loss: 0.0918\n",
      "Epoch 2/60, Loss: 0.1760, Val Loss: 0.0913\n",
      "Epoch 4/60, Loss: 0.0925, Val Loss: 0.0928\n",
      "Epoch 26/60, Loss: 0.1436, Val Loss: 0.0924\n",
      "Epoch 15/60, Loss: 0.0900, Val Loss: 0.0897\n",
      "Epoch 23/60, Loss: 0.0997, Val Loss: 0.1006\n",
      "Epoch 23/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 25/60, Loss: 0.0919, Val Loss: 0.1169\n",
      "Epoch 24/60, Loss: 0.1043, Val Loss: 0.0908\n",
      "Epoch 3/60, Loss: 0.1227, Val Loss: 0.0902\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 17/60, Loss: 0.0889, Val Loss: 0.0871\n",
      "Epoch 9/60, Loss: 0.1603, Val Loss: 0.0906\n",
      "Epoch 27/60, Loss: 0.1408, Val Loss: 0.0923\n",
      "Epoch 4/60, Loss: 0.1078, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0928, Val Loss: 0.0892\n",
      "Epoch 24/60, Loss: 0.1003, Val Loss: 0.1003\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:27:00,042] Trial 0 finished with value: 0.10023667166630428 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'lr': 0.04448765643911486, 'batch_size': 64, 'patience': 10}. Best is trial 12 with value: 0.08921072880427043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Validation Loss: 0.1002\n",
      "\n",
      "[Trial 18] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 64, 'lr': 0.0005113013699407474, 'batch_size': 8, 'patience': 3}\n",
      "Epoch 25/60, Loss: 0.1031, Val Loss: 0.0908\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 16/60, Loss: 0.0898, Val Loss: 0.0896\n",
      "Epoch 28/60, Loss: 0.1373, Val Loss: 0.0922\n",
      "Epoch 18/60, Loss: 0.0888, Val Loss: 0.0871\n",
      "Epoch 5/60, Loss: 0.0924, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.1011, Val Loss: 0.0888\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0872\n",
      "Epoch 27/60, Loss: 0.0893, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.1021, Val Loss: 0.0908\n",
      "Epoch 29/60, Loss: 0.1345, Val Loss: 0.0921\n",
      "Epoch 9/60, Loss: 0.0880, Val Loss: 0.0919\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.0974, Val Loss: 0.0887\n",
      "Epoch 25/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0896, Val Loss: 0.0895\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0870\n",
      "Epoch 5/60, Loss: 0.0886, Val Loss: 0.0893\n",
      "Epoch 28/60, Loss: 0.1008, Val Loss: 0.1251\n",
      "Epoch 30/60, Loss: 0.1321, Val Loss: 0.0920\n",
      "Epoch 5/60, Loss: 0.1274, Val Loss: 0.1262\n",
      "Epoch 10/60, Loss: 0.1487, Val Loss: 0.0900\n",
      "Epoch 27/60, Loss: 0.1009, Val Loss: 0.0907\n",
      "Epoch 7/60, Loss: 0.0952, Val Loss: 0.0886\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 31/60, Loss: 0.1295, Val Loss: 0.0919\n",
      "Epoch 26/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 29/60, Loss: 0.1221, Val Loss: 0.0908\n",
      "Epoch 8/60, Loss: 0.0937, Val Loss: 0.0887\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0870\n",
      "Epoch 28/60, Loss: 0.1001, Val Loss: 0.0907\n",
      "Epoch 18/60, Loss: 0.0893, Val Loss: 0.0894\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.1258, Val Loss: 0.0918\n",
      "Epoch 9/60, Loss: 0.0928, Val Loss: 0.0886\n",
      "Epoch 30/60, Loss: 0.0913, Val Loss: 0.0903\n",
      "Epoch 10/60, Loss: 0.0877, Val Loss: 0.0916\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 29/60, Loss: 0.0993, Val Loss: 0.0906\n",
      "Epoch 33/60, Loss: 0.1235, Val Loss: 0.0917\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0868\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 11/60, Loss: 0.1385, Val Loss: 0.0895\n",
      "Epoch 10/60, Loss: 0.0921, Val Loss: 0.0885\n",
      "Epoch 19/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 31/60, Loss: 0.0909, Val Loss: 0.0903\n",
      "Early stopping triggered\n",
      "Epoch 5/60, Loss: 0.0902, Val Loss: 0.0912\n",
      "Epoch 34/60, Loss: 0.1218, Val Loss: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:31:29,698] Trial 9 finished with value: 0.0903423547744751 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'lr': 0.029282186806683874, 'batch_size': 64, 'patience': 8}. Best is trial 12 with value: 0.08921072880427043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 9] Validation Loss: 0.0903\n",
      "\n",
      "[Trial 19] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0031132657036024958, 'batch_size': 64, 'patience': 10}\n",
      "Epoch 30/60, Loss: 0.0985, Val Loss: 0.0906\n",
      "Epoch 11/60, Loss: 0.0915, Val Loss: 0.0884\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 6/60, Loss: 0.0909, Val Loss: 0.0890\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0872\n",
      "Epoch 35/60, Loss: 0.1199, Val Loss: 0.0914\n",
      "Epoch 1/60, Loss: 0.1376, Val Loss: 0.0904\n",
      "Epoch 1/60, Loss: 0.2610, Val Loss: 0.1013\n",
      "Epoch 12/60, Loss: 0.0911, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0979, Val Loss: 0.0906\n",
      "Epoch 20/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 36/60, Loss: 0.1188, Val Loss: 0.0913\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 2/60, Loss: 0.0948, Val Loss: 0.0905\n",
      "Epoch 6/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 13/60, Loss: 0.0906, Val Loss: 0.0884\n",
      "Epoch 11/60, Loss: 0.0874, Val Loss: 0.0916\n",
      "Epoch 12/60, Loss: 0.1307, Val Loss: 0.0891\n",
      "Epoch 32/60, Loss: 0.0972, Val Loss: 0.0906\n",
      "Epoch 6/60, Loss: 0.1259, Val Loss: 0.1271\n",
      "Epoch 37/60, Loss: 0.1164, Val Loss: 0.0912\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:33:31,852] Trial 8 finished with value: 0.08740770320097606 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.0014828801561934703, 'batch_size': 64, 'patience': 5}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 8] Validation Loss: 0.0874\n",
      "\n",
      "[Trial 20] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'lr': 0.010064749839787277, 'batch_size': 16, 'patience': 3}\n",
      "Epoch 3/60, Loss: 0.0909, Val Loss: 0.0890\n",
      "Epoch 14/60, Loss: 0.0905, Val Loss: 0.0883\n",
      "Epoch 21/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 33/60, Loss: 0.0967, Val Loss: 0.0905\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 38/60, Loss: 0.1149, Val Loss: 0.0911\n",
      "Epoch 4/60, Loss: 0.0898, Val Loss: 0.0887\n",
      "Epoch 15/60, Loss: 0.0902, Val Loss: 0.0882\n",
      "Epoch 34/60, Loss: 0.0962, Val Loss: 0.0905\n",
      "Epoch 39/60, Loss: 0.1136, Val Loss: 0.0910\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0886\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 16/60, Loss: 0.0900, Val Loss: 0.0881\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 13/60, Loss: 0.1248, Val Loss: 0.0889\n",
      "Epoch 40/60, Loss: 0.1118, Val Loss: 0.0909\n",
      "Epoch 12/60, Loss: 0.0873, Val Loss: 0.0914\n",
      "Epoch 35/60, Loss: 0.0957, Val Loss: 0.0905\n",
      "Epoch 6/60, Loss: 0.0893, Val Loss: 0.0886\n",
      "Epoch 1/60, Loss: 0.1380, Val Loss: 0.0905\n",
      "Epoch 17/60, Loss: 0.0897, Val Loss: 0.0882\n",
      "Epoch 7/60, Loss: 0.0902, Val Loss: 0.0890\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 41/60, Loss: 0.1104, Val Loss: 0.0909\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 36/60, Loss: 0.0954, Val Loss: 0.0905\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 18/60, Loss: 0.0896, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0914\n",
      "Epoch 2/60, Loss: 0.0895, Val Loss: 0.0898\n",
      "Epoch 42/60, Loss: 0.1093, Val Loss: 0.0908\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 19/60, Loss: 0.0894, Val Loss: 0.0881\n",
      "Epoch 37/60, Loss: 0.0950, Val Loss: 0.0905\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 14/60, Loss: 0.1188, Val Loss: 0.0886\n",
      "Epoch 27/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 2/60, Loss: 0.0900, Val Loss: 0.0891\n",
      "Epoch 43/60, Loss: 0.1087, Val Loss: 0.0907\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0893\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 20/60, Loss: 0.0893, Val Loss: 0.0880\n",
      "Epoch 13/60, Loss: 0.0874, Val Loss: 0.0914\n",
      "Epoch 38/60, Loss: 0.0946, Val Loss: 0.0905\n",
      "Epoch 7/60, Loss: 0.1258, Val Loss: 0.1265\n",
      "Epoch 44/60, Loss: 0.1070, Val Loss: 0.0907\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0886\n",
      "Epoch 21/60, Loss: 0.0893, Val Loss: 0.0882\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 39/60, Loss: 0.0942, Val Loss: 0.0904\n",
      "Epoch 45/60, Loss: 0.1062, Val Loss: 0.0906\n",
      "Epoch 25/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0891, Val Loss: 0.0878\n",
      "Epoch 3/60, Loss: 0.0893, Val Loss: 0.0888\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 40/60, Loss: 0.0939, Val Loss: 0.0904\n",
      "Epoch 15/60, Loss: 0.1147, Val Loss: 0.0884\n",
      "Epoch 46/60, Loss: 0.1052, Val Loss: 0.0906\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "Epoch 23/60, Loss: 0.0889, Val Loss: 0.0878\n",
      "Epoch 8/60, Loss: 0.0901, Val Loss: 0.0887\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0891\n",
      "Epoch 41/60, Loss: 0.0936, Val Loss: 0.0905\n",
      "Epoch 14/60, Loss: 0.0873, Val Loss: 0.0914\n",
      "Epoch 47/60, Loss: 0.1043, Val Loss: 0.0906\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0879\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0884\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0877\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 30/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 48/60, Loss: 0.1039, Val Loss: 0.0906\n",
      "Epoch 42/60, Loss: 0.0934, Val Loss: 0.0904\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0890\n",
      "Epoch 3/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 16/60, Loss: 0.1118, Val Loss: 0.0880\n",
      "Epoch 27/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 7/60, Loss: 0.0998, Val Loss: 0.0994\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 8/60, Loss: 0.0882, Val Loss: 0.0888\n",
      "Epoch 49/60, Loss: 0.1032, Val Loss: 0.0905\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 43/60, Loss: 0.0931, Val Loss: 0.0904\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 50/60, Loss: 0.1024, Val Loss: 0.0905\n",
      "Epoch 16/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 27/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 44/60, Loss: 0.0928, Val Loss: 0.0904\n",
      "Epoch 8/60, Loss: 0.1261, Val Loss: 0.1267\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.0874, Val Loss: 0.0913\n",
      "Epoch 28/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 51/60, Loss: 0.1018, Val Loss: 0.0904\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 45/60, Loss: 0.0925, Val Loss: 0.0904\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 17/60, Loss: 0.1085, Val Loss: 0.0879\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 52/60, Loss: 0.1012, Val Loss: 0.0905\n",
      "Epoch 29/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 9/60, Loss: 0.0903, Val Loss: 0.0885\n",
      "Epoch 46/60, Loss: 0.0923, Val Loss: 0.0903\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0870\n",
      "Epoch 53/60, Loss: 0.1005, Val Loss: 0.0904\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0886\n",
      "Epoch 47/60, Loss: 0.0922, Val Loss: 0.0903\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0878\n",
      "Epoch 16/60, Loss: 0.0873, Val Loss: 0.0914\n",
      "Epoch 54/60, Loss: 0.1001, Val Loss: 0.0904\n",
      "Epoch 34/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 48/60, Loss: 0.0920, Val Loss: 0.0903\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 18/60, Loss: 0.1060, Val Loss: 0.0876\n",
      "Epoch 55/60, Loss: 0.0992, Val Loss: 0.0904\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 49/60, Loss: 0.0918, Val Loss: 0.0904\n",
      "Epoch 35/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 42/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 56/60, Loss: 0.0992, Val Loss: 0.0903\n",
      "Epoch 4/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 7/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 8/60, Loss: 0.0904, Val Loss: 0.0909\n",
      "Epoch 33/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 9/60, Loss: 0.1448, Val Loss: 0.1287\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 57/60, Loss: 0.0986, Val Loss: 0.0904\n",
      "Epoch 50/60, Loss: 0.0917, Val Loss: 0.0903\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 17/60, Loss: 0.0875, Val Loss: 0.0913\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.0944, Val Loss: 0.0907\n",
      "Epoch 58/60, Loss: 0.0979, Val Loss: 0.0903\n",
      "Epoch 19/60, Loss: 0.1037, Val Loss: 0.0874\n",
      "Epoch 51/60, Loss: 0.0915, Val Loss: 0.0903\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 59/60, Loss: 0.0976, Val Loss: 0.0903\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0869\n",
      "Epoch 52/60, Loss: 0.0913, Val Loss: 0.0903\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 60/60, Loss: 0.0972, Val Loss: 0.0903\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:47:10,140] Trial 3 finished with value: 0.09026619742314021 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'lr': 1.9255673577850748e-05, 'batch_size': 64, 'patience': 10}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 3] Validation Loss: 0.0903\n",
      "\n",
      "[Trial 21] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 5.4927223583845344e-05, 'batch_size': 64, 'patience': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:47:13,854] Trial 4 finished with value: 0.08846540848414103 and parameters: {'hidden_dim': 512, 'latent_dim': 96, 'lr': 0.0013606265013507803, 'batch_size': 64, 'patience': 4}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 4] Validation Loss: 0.0885\n",
      "\n",
      "[Trial 22] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.0002338506066403989, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 53/60, Loss: 0.0912, Val Loss: 0.0904\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 18/60, Loss: 0.0869, Val Loss: 0.0915\n",
      "Epoch 1/60, Loss: 1.2661, Val Loss: 0.2173\n",
      "Epoch 20/60, Loss: 0.1018, Val Loss: 0.0872\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0897\n",
      "Early stopping triggered\n",
      "Epoch 54/60, Loss: 0.0911, Val Loss: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:48:05,800] Trial 20 finished with value: 0.0897860304142038 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'lr': 0.010064749839787277, 'batch_size': 16, 'patience': 3}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 20] Validation Loss: 0.0898\n",
      "\n",
      "[Trial 23] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 128, 'lr': 0.006695624206951987, 'batch_size': 16, 'patience': 8}\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.0882, Val Loss: 0.0887\n",
      "Epoch 38/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 0.7727, Val Loss: 0.1445\n",
      "Epoch 55/60, Loss: 0.0909, Val Loss: 0.0904\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.5702, Val Loss: 0.1157\n",
      "Epoch 10/60, Loss: 0.1275, Val Loss: 0.1299\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0931, Val Loss: 0.0888\n",
      "Epoch 5/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 56/60, Loss: 0.0909, Val Loss: 0.0903\n",
      "Epoch 30/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 9/60, Loss: 0.0898, Val Loss: 0.0903\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.4365, Val Loss: 0.1063\n",
      "Epoch 21/60, Loss: 0.1002, Val Loss: 0.0870\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 19/60, Loss: 0.0872, Val Loss: 0.0914\n",
      "Early stopping triggered\n",
      "Epoch 57/60, Loss: 0.0907, Val Loss: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:49:59,347] Trial 1 finished with value: 0.09142223820090294 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0005670950504210985, 'batch_size': 16, 'patience': 4}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 1] Validation Loss: 0.0914\n",
      "\n",
      "[Trial 24] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 128, 'lr': 0.015815275738838633, 'batch_size': 64, 'patience': 7}\n",
      "Epoch 31/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 5/60, Loss: 0.3451, Val Loss: 0.0994\n",
      "Epoch 1/60, Loss: 0.1411, Val Loss: 0.0970\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 0.2607, Val Loss: 0.1236\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 58/60, Loss: 0.0906, Val Loss: 0.0903\n",
      "Epoch 6/60, Loss: 0.2773, Val Loss: 0.0957\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 0.1060, Val Loss: 0.0990\n",
      "Epoch 7/60, Loss: 0.2353, Val Loss: 0.0941\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 59/60, Loss: 0.0905, Val Loss: 0.0903\n",
      "Epoch 43/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0987, Val Loss: 0.0868\n",
      "Epoch 3/60, Loss: 0.0970, Val Loss: 0.0937\n",
      "Epoch 1/60, Loss: 0.2300, Val Loss: 0.0891\n",
      "Epoch 42/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 8/60, Loss: 0.2087, Val Loss: 0.0933\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 60/60, Loss: 0.0904, Val Loss: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:51:54,417] Trial 14 finished with value: 0.09023251136144002 and parameters: {'hidden_dim': 384, 'latent_dim': 96, 'lr': 3.970813749735035e-05, 'batch_size': 64, 'patience': 10}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 14] Validation Loss: 0.0902\n",
      "\n",
      "[Trial 25] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.00021234195192368455, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 11/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.0936, Val Loss: 0.0923\n",
      "Epoch 2/60, Loss: 0.0906, Val Loss: 0.0893\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 9/60, Loss: 0.1892, Val Loss: 0.0927\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 43/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 5/60, Loss: 0.0932, Val Loss: 0.0916\n",
      "Epoch 12/60, Loss: 0.0929, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.1739, Val Loss: 0.0923\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 11/60, Loss: 0.1297, Val Loss: 0.1267\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Early stopping triggered\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 6/60, Loss: 0.0927, Val Loss: 0.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:52:56,827] Trial 13 finished with value: 0.08892363707224528 and parameters: {'hidden_dim': 384, 'latent_dim': 32, 'lr': 0.00011544666457474547, 'batch_size': 32, 'patience': 4}. Best is trial 8 with value: 0.08740770320097606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 13] Validation Loss: 0.0889\n",
      "\n",
      "[Trial 26] Starting with parameters: {'hidden_dim': 512, 'latent_dim': 64, 'lr': 0.0015929863382772756, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 1/60, Loss: 0.4029, Val Loss: 0.0928\n",
      "Epoch 23/60, Loss: 0.0974, Val Loss: 0.0867\n",
      "Epoch 11/60, Loss: 0.1622, Val Loss: 0.0918\n",
      "Epoch 44/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 7/60, Loss: 0.0917, Val Loss: 0.0896\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 6/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.0946, Val Loss: 0.0913\n",
      "Epoch 12/60, Loss: 0.1514, Val Loss: 0.0916\n",
      "Epoch 3/60, Loss: 0.0893, Val Loss: 0.0925\n",
      "Epoch 8/60, Loss: 0.0906, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0870\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 2/60, Loss: 0.1157, Val Loss: 0.0903\n",
      "Epoch 13/60, Loss: 0.1436, Val Loss: 0.0912\n",
      "Epoch 9/60, Loss: 0.0901, Val Loss: 0.0885\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.0896, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.1365, Val Loss: 0.0908\n",
      "Epoch 24/60, Loss: 0.0962, Val Loss: 0.0866\n",
      "Epoch 46/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.0998, Val Loss: 0.0898\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 11/60, Loss: 0.0895, Val Loss: 0.0883\n",
      "Epoch 2/60, Loss: 0.0938, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.1309, Val Loss: 0.0906\n",
      "Epoch 12/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 4/60, Loss: 0.0895, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0905, Val Loss: 0.0903\n",
      "Epoch 12/60, Loss: 0.0894, Val Loss: 0.0883\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 41/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 47/60, Loss: 0.0899, Val Loss: 0.0868\n",
      "Epoch 16/60, Loss: 0.1265, Val Loss: 0.0904\n",
      "Epoch 13/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.0949, Val Loss: 0.0895\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 12/60, Loss: 0.1259, Val Loss: 0.1262\n",
      "Epoch 42/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 17/60, Loss: 0.1227, Val Loss: 0.0901\n",
      "Epoch 14/60, Loss: 0.0895, Val Loss: 0.0889\n",
      "Epoch 25/60, Loss: 0.0955, Val Loss: 0.0866\n",
      "Epoch 48/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Early stopping triggered\n",
      "[Trial 10] Validation Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 10:56:39,426] Trial 10 finished with value: 0.08669025426109632 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'lr': 0.0013213739986966879, 'batch_size': 32, 'patience': 10}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 27] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004213876686795246, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 1/60, Loss: 0.1178, Val Loss: 0.0887\n",
      "Epoch 52/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 18/60, Loss: 0.1193, Val Loss: 0.0899\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 15/60, Loss: 0.0894, Val Loss: 0.0881\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0868\n",
      "Epoch 5/60, Loss: 0.0926, Val Loss: 0.0894\n",
      "Epoch 5/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 19/60, Loss: 0.1161, Val Loss: 0.0899\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 7/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 16/60, Loss: 0.0893, Val Loss: 0.0881\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 11/60, Loss: 0.0908, Val Loss: 0.0905\n",
      "Epoch 1/60, Loss: 0.2493, Val Loss: 0.0966\n",
      "Epoch 20/60, Loss: 0.1134, Val Loss: 0.0896\n",
      "Epoch 17/60, Loss: 0.0893, Val Loss: 0.0883\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 26/60, Loss: 0.0948, Val Loss: 0.0865\n",
      "Epoch 6/60, Loss: 0.0915, Val Loss: 0.0892\n",
      "Epoch 18/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 2/60, Loss: 0.0935, Val Loss: 0.0912\n",
      "Epoch 21/60, Loss: 0.1114, Val Loss: 0.0895\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 14/60, Loss: 0.0899, Val Loss: 0.0891\n",
      "Epoch 19/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 3/60, Loss: 0.0910, Val Loss: 0.0887\n",
      "Epoch 22/60, Loss: 0.1093, Val Loss: 0.0895\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0886\n",
      "Epoch 3/60, Loss: 0.0904, Val Loss: 0.0896\n",
      "Epoch 56/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 20/60, Loss: 0.0894, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0908, Val Loss: 0.0893\n",
      "Epoch 23/60, Loss: 0.1073, Val Loss: 0.0894\n",
      "Epoch 21/60, Loss: 0.0892, Val Loss: 0.0881\n",
      "Epoch 57/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 48/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 4/60, Loss: 0.0895, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.1269, Val Loss: 0.1282\n",
      "Epoch 27/60, Loss: 0.0940, Val Loss: 0.0865\n",
      "Epoch 24/60, Loss: 0.1059, Val Loss: 0.0894\n",
      "Epoch 22/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 8/60, Loss: 0.0902, Val Loss: 0.0892\n",
      "Epoch 49/60, Loss: 0.0948, Val Loss: 0.0886\n",
      "Epoch 2/60, Loss: 0.0897, Val Loss: 0.0893\n",
      "Epoch 25/60, Loss: 0.1045, Val Loss: 0.0893\n",
      "Epoch 14/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Epoch 5/60, Loss: 0.0893, Val Loss: 0.0894\n",
      "Epoch 23/60, Loss: 0.0893, Val Loss: 0.0883\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 50/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 26/60, Loss: 0.1035, Val Loss: 0.0892\n",
      "Epoch 24/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 7/60, Loss: 0.0896, Val Loss: 0.0891\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0898\n",
      "Epoch 9/60, Loss: 0.0900, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 25/60, Loss: 0.0891, Val Loss: 0.0880\n",
      "Epoch 60/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 27/60, Loss: 0.1023, Val Loss: 0.0892\n",
      "Epoch 51/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "[Trial 17] Validation Loss: 0.0874\n",
      "Epoch 28/60, Loss: 0.0936, Val Loss: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:01:25,230] Trial 17 finished with value: 0.08742160151402155 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'lr': 0.0003058132771533535, 'batch_size': 64, 'patience': 10}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 28] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004499697894454544, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 12/60, Loss: 0.0897, Val Loss: 0.0904\n",
      "Epoch 15/60, Loss: 0.0940, Val Loss: 0.0937\n",
      "Epoch 26/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0894\n",
      "Epoch 28/60, Loss: 0.1014, Val Loss: 0.0892\n",
      "Epoch 52/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 14/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 27/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 10/60, Loss: 0.0895, Val Loss: 0.0893\n",
      "Epoch 1/60, Loss: 0.2362, Val Loss: 0.0973\n",
      "Epoch 29/60, Loss: 0.1004, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0882\n",
      "Epoch 53/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 8/60, Loss: 0.0889, Val Loss: 0.0895\n",
      "Epoch 28/60, Loss: 0.1490, Val Loss: 0.0935\n",
      "Epoch 8/60, Loss: 0.0894, Val Loss: 0.0890\n",
      "Epoch 30/60, Loss: 0.0997, Val Loss: 0.0891\n",
      "Epoch 2/60, Loss: 0.0938, Val Loss: 0.0908\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 29/60, Loss: 0.0929, Val Loss: 0.0864\n",
      "Epoch 14/60, Loss: 0.1260, Val Loss: 0.1270\n",
      "Epoch 29/60, Loss: 0.0923, Val Loss: 0.0899\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.0893, Val Loss: 0.0891\n",
      "Epoch 31/60, Loss: 0.0989, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0918, Val Loss: 0.0872\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Early stopping triggered\n",
      "[Trial 19] Validation Loss: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:03:20,977] Trial 19 finished with value: 0.08756206234296163 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0031132657036024958, 'batch_size': 64, 'patience': 10}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 29] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004286451374752511, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 30/60, Loss: 0.0917, Val Loss: 0.0900\n",
      "Epoch 3/60, Loss: 0.0903, Val Loss: 0.0899\n",
      "Epoch 32/60, Loss: 0.0983, Val Loss: 0.0890\n",
      "Epoch 3/60, Loss: 0.0892, Val Loss: 0.0881\n",
      "Epoch 10/60, Loss: 0.0887, Val Loss: 0.0895\n",
      "Epoch 31/60, Loss: 0.0911, Val Loss: 0.0895\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0889\n",
      "Epoch 33/60, Loss: 0.0977, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.0895, Val Loss: 0.0894\n",
      "Epoch 1/60, Loss: 0.2457, Val Loss: 0.0963\n",
      "Epoch 32/60, Loss: 0.0904, Val Loss: 0.0888\n",
      "Early stopping triggered\n",
      "[Trial 24] Validation Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:04:08,999] Trial 24 finished with value: 0.08882988741000493 and parameters: {'hidden_dim': 64, 'latent_dim': 128, 'lr': 0.015815275738838633, 'batch_size': 64, 'patience': 7}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 30] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002299211997085747, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 30/60, Loss: 0.0925, Val Loss: 0.0863\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 34/60, Loss: 0.0969, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0923, Val Loss: 0.0895\n",
      "Epoch 5/60, Loss: 0.0892, Val Loss: 0.0894\n",
      "Epoch 9/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 2/60, Loss: 0.0950, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0887\n",
      "Epoch 35/60, Loss: 0.0965, Val Loss: 0.0890\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 1/60, Loss: 0.2182, Val Loss: 0.0900\n",
      "Epoch 13/60, Loss: 0.0898, Val Loss: 0.0911\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 6/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 36/60, Loss: 0.0961, Val Loss: 0.0890\n",
      "Epoch 3/60, Loss: 0.0910, Val Loss: 0.0875\n",
      "Epoch 5/60, Loss: 0.0894, Val Loss: 0.0879\n",
      "Epoch 31/60, Loss: 0.0922, Val Loss: 0.0863\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 2/60, Loss: 0.0934, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0887\n",
      "Epoch 37/60, Loss: 0.0957, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0893\n",
      "Epoch 10/60, Loss: 0.0947, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0868\n",
      "Epoch 15/60, Loss: 0.1257, Val Loss: 0.1265\n",
      "Epoch 4/60, Loss: 0.0900, Val Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0953, Val Loss: 0.0889\n",
      "Epoch 14/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 3/60, Loss: 0.0909, Val Loss: 0.0876\n",
      "Epoch 39/60, Loss: 0.0948, Val Loss: 0.0889\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0886\n",
      "Epoch 5/60, Loss: 0.0898, Val Loss: 0.0874\n",
      "Epoch 4/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0946, Val Loss: 0.0889\n",
      "Epoch 32/60, Loss: 0.0918, Val Loss: 0.0862\n",
      "Epoch 4/60, Loss: 0.0901, Val Loss: 0.0873\n",
      "Epoch 17/60, Loss: 0.0907, Val Loss: 0.0894\n",
      "Epoch 6/60, Loss: 0.0899, Val Loss: 0.0873\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0889\n",
      "Epoch 41/60, Loss: 0.0943, Val Loss: 0.0889\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.0899, Val Loss: 0.0875\n",
      "Epoch 42/60, Loss: 0.0939, Val Loss: 0.0888\n",
      "Epoch 10/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0896, Val Loss: 0.0876\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 43/60, Loss: 0.0937, Val Loss: 0.0888\n",
      "Epoch 17/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0884\n",
      "Epoch 33/60, Loss: 0.0915, Val Loss: 0.0862\n",
      "Epoch 14/60, Loss: 0.0942, Val Loss: 0.0904\n",
      "Epoch 6/60, Loss: 0.0896, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0879\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0872\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 44/60, Loss: 0.0933, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Early stopping triggered\n",
      "Epoch 16/60, Loss: 0.1266, Val Loss: 0.1277\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "[Trial 27] Validation Loss: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:08:49,064] Trial 27 finished with value: 0.08905857180555661 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004213876686795246, 'batch_size': 32, 'patience': 6}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 31] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00013483477928033966, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 45/60, Loss: 0.0932, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0871\n",
      "Epoch 9/60, Loss: 0.0895, Val Loss: 0.0873\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 46/60, Loss: 0.0928, Val Loss: 0.0888\n",
      "Epoch 18/60, Loss: 0.0926, Val Loss: 0.0892\n",
      "Epoch 34/60, Loss: 0.0913, Val Loss: 0.0862\n",
      "Epoch 5/60, Loss: 0.0888, Val Loss: 0.0882\n",
      "Epoch 10/60, Loss: 0.0894, Val Loss: 0.0872\n",
      "Epoch 8/60, Loss: 0.0894, Val Loss: 0.0872\n",
      "Epoch 47/60, Loss: 0.0927, Val Loss: 0.0887\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 48/60, Loss: 0.0925, Val Loss: 0.0888\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0884\n",
      "Epoch 11/60, Loss: 0.0894, Val Loss: 0.0873\n",
      "Epoch 13/60, Loss: 0.1069, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 9/60, Loss: 0.0893, Val Loss: 0.0871\n",
      "Epoch 49/60, Loss: 0.0923, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 12/60, Loss: 0.0892, Val Loss: 0.0873\n",
      "Epoch 50/60, Loss: 0.0922, Val Loss: 0.0888\n",
      "Epoch 35/60, Loss: 0.0911, Val Loss: 0.0862\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0871\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 1/60, Loss: 0.4539, Val Loss: 0.0936\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 51/60, Loss: 0.0919, Val Loss: 0.0887\n",
      "Epoch 7/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 15/60, Loss: 0.0966, Val Loss: 0.0926\n",
      "Early stopping triggered\n",
      "Epoch 13/60, Loss: 0.0892, Val Loss: 0.0869\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 11/60, Loss: 0.0892, Val Loss: 0.0869\n",
      "Epoch 17/60, Loss: 0.1361, Val Loss: 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:12:03,105] Trial 15 finished with value: 0.0925650886259973 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.014548620875315334, 'batch_size': 8, 'patience': 6}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 15] Validation Loss: 0.0926\n",
      "\n",
      "[Trial 32] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00015911148108685322, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 52/60, Loss: 0.0917, Val Loss: 0.0888\n",
      "Epoch 14/60, Loss: 0.0895, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0958, Val Loss: 0.0905\n",
      "Early stopping triggered\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0869\n",
      "Epoch 53/60, Loss: 0.0917, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0889\n",
      "[Trial 7] Validation Loss: 0.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:12:38,276] Trial 7 finished with value: 0.09051591651514172 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.01591669379645929, 'batch_size': 8, 'patience': 10}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 33] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00019782024226935616, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 36/60, Loss: 0.0909, Val Loss: 0.0862\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0868\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 54/60, Loss: 0.0915, Val Loss: 0.0887\n",
      "Epoch 1/60, Loss: 0.7018, Val Loss: 0.1061\n",
      "Epoch 15/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0888\n",
      "Epoch 55/60, Loss: 0.0913, Val Loss: 0.0887\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 1/60, Loss: 0.6691, Val Loss: 0.1034\n",
      "Epoch 2/60, Loss: 0.2430, Val Loss: 0.0932\n",
      "Epoch 2/60, Loss: 0.1190, Val Loss: 0.0911\n",
      "Epoch 56/60, Loss: 0.0912, Val Loss: 0.0887\n",
      "Epoch 15/60, Loss: 0.0892, Val Loss: 0.0888\n",
      "Epoch 16/60, Loss: 0.0890, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 37/60, Loss: 0.0906, Val Loss: 0.0861\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0866\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 57/60, Loss: 0.0911, Val Loss: 0.0887\n",
      "Epoch 12/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 2/60, Loss: 0.2076, Val Loss: 0.0924\n",
      "Epoch 3/60, Loss: 0.1594, Val Loss: 0.0906\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0868\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 58/60, Loss: 0.0910, Val Loss: 0.0887\n",
      "Epoch 8/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0866\n",
      "Epoch 18/60, Loss: 0.1259, Val Loss: 0.1281\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 59/60, Loss: 0.0909, Val Loss: 0.0886\n",
      "Epoch 3/60, Loss: 0.1390, Val Loss: 0.0906\n",
      "Epoch 18/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 4/60, Loss: 0.1291, Val Loss: 0.0898\n",
      "Epoch 16/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 38/60, Loss: 0.0905, Val Loss: 0.0861\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0864\n",
      "Epoch 60/60, Loss: 0.0908, Val Loss: 0.0887\n",
      "[Trial 21] Validation Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:15:38,283] Trial 21 finished with value: 0.08868166108926137 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 5.4927223583845344e-05, 'batch_size': 64, 'patience': 10}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 34] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0002282369341933327, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0869\n",
      "Epoch 4/60, Loss: 0.1173, Val Loss: 0.0896\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.1144, Val Loss: 0.0890\n",
      "Epoch 3/60, Loss: 0.0989, Val Loss: 0.0899\n",
      "Epoch 17/60, Loss: 0.0888, Val Loss: 0.0865\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 1/60, Loss: 0.6521, Val Loss: 0.1025\n",
      "Epoch 20/60, Loss: 0.0890, Val Loss: 0.0868\n",
      "Epoch 24/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 5/60, Loss: 0.1067, Val Loss: 0.0888\n",
      "Epoch 6/60, Loss: 0.1070, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.0886, Val Loss: 0.0865\n",
      "Epoch 39/60, Loss: 0.0903, Val Loss: 0.0862\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 2/60, Loss: 0.1934, Val Loss: 0.0928\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 6/60, Loss: 0.1011, Val Loss: 0.0883\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0864\n",
      "Epoch 13/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.1020, Val Loss: 0.0880\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.1310, Val Loss: 0.0909\n",
      "Epoch 19/60, Loss: 0.1290, Val Loss: 0.1269\n",
      "Epoch 40/60, Loss: 0.0901, Val Loss: 0.0861\n",
      "Epoch 7/60, Loss: 0.0977, Val Loss: 0.0880\n",
      "Epoch 23/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 20/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 4/60, Loss: 0.0936, Val Loss: 0.0896\n",
      "Epoch 27/60, Loss: 0.0921, Val Loss: 0.0897\n",
      "Early stopping triggered\n",
      "Epoch 8/60, Loss: 0.0987, Val Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:18:32,096] Trial 28 finished with value: 0.08968388537565868 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004499697894454544, 'batch_size': 32, 'patience': 6}. Best is trial 10 with value: 0.08669025426109632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 28] Validation Loss: 0.0897\n",
      "\n",
      "[Trial 35] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0002635824298475761, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0894\n",
      "Epoch 4/60, Loss: 0.1117, Val Loss: 0.0897\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 21/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 8/60, Loss: 0.0958, Val Loss: 0.0882\n",
      "Epoch 9/60, Loss: 0.0967, Val Loss: 0.0875\n",
      "Epoch 8/60, Loss: 0.0885, Val Loss: 0.0877\n",
      "Epoch 1/60, Loss: 0.6352, Val Loss: 0.1024\n",
      "Epoch 5/60, Loss: 0.1032, Val Loss: 0.0889\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 25/60, Loss: 0.0889, Val Loss: 0.0866\n",
      "Epoch 41/60, Loss: 0.0899, Val Loss: 0.0861\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 9/60, Loss: 0.0942, Val Loss: 0.0878\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0952, Val Loss: 0.0876\n",
      "Epoch 2/60, Loss: 0.1735, Val Loss: 0.0937\n",
      "Epoch 6/60, Loss: 0.0986, Val Loss: 0.0886\n",
      "Epoch 5/60, Loss: 0.0915, Val Loss: 0.0895\n",
      "Epoch 26/60, Loss: 0.0890, Val Loss: 0.0868\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0863\n",
      "Epoch 10/60, Loss: 0.0931, Val Loss: 0.0877\n",
      "Epoch 11/60, Loss: 0.0942, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.1209, Val Loss: 0.0922\n",
      "Epoch 14/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0959, Val Loss: 0.0884\n",
      "Epoch 27/60, Loss: 0.0889, Val Loss: 0.0866\n",
      "Epoch 28/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 42/60, Loss: 0.0900, Val Loss: 0.0860\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 24/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 20/60, Loss: 0.1264, Val Loss: 0.1266\n",
      "Epoch 11/60, Loss: 0.0925, Val Loss: 0.0878\n",
      "Epoch 4/60, Loss: 0.1057, Val Loss: 0.0911\n",
      "Epoch 12/60, Loss: 0.0932, Val Loss: 0.0873\n",
      "Epoch 8/60, Loss: 0.0942, Val Loss: 0.0884\n",
      "Epoch 28/60, Loss: 0.0888, Val Loss: 0.0866\n",
      "Epoch 20/60, Loss: 0.0918, Val Loss: 0.0923\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 6/60, Loss: 0.0905, Val Loss: 0.0895\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 12/60, Loss: 0.0919, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.0992, Val Loss: 0.0908\n",
      "Epoch 29/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 9/60, Loss: 0.0932, Val Loss: 0.0883\n",
      "Epoch 13/60, Loss: 0.0925, Val Loss: 0.0872\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 43/60, Loss: 0.0902, Val Loss: 0.0860\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 26/60, Loss: 0.0885, Val Loss: 0.0864\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0885\n",
      "Epoch 30/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 6/60, Loss: 0.0956, Val Loss: 0.0904\n",
      "Epoch 13/60, Loss: 0.0916, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.0922, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.0921, Val Loss: 0.0873\n",
      "Epoch 30/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 21/60, Loss: 0.0898, Val Loss: 0.0887\n",
      "Epoch 31/60, Loss: 0.0888, Val Loss: 0.0868\n",
      "Epoch 7/60, Loss: 0.0938, Val Loss: 0.0903\n",
      "Epoch 11/60, Loss: 0.0918, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.0912, Val Loss: 0.0875\n",
      "Epoch 44/60, Loss: 0.0896, Val Loss: 0.0860\n",
      "Epoch 15/60, Loss: 0.0917, Val Loss: 0.0872\n",
      "Epoch 15/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 11/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 32/60, Loss: 0.0889, Val Loss: 0.0866\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0893\n",
      "Epoch 21/60, Loss: 0.1261, Val Loss: 0.1263\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 8/60, Loss: 0.0924, Val Loss: 0.0904\n",
      "Epoch 12/60, Loss: 0.0912, Val Loss: 0.0881\n",
      "Epoch 15/60, Loss: 0.0909, Val Loss: 0.0875\n",
      "Epoch 16/60, Loss: 0.0914, Val Loss: 0.0873\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 33/60, Loss: 0.0888, Val Loss: 0.0866\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:25:12,297] Trial 29 finished with value: 0.08664216424028079 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004286451374752511, 'batch_size': 32, 'patience': 6}. Best is trial 29 with value: 0.08664216424028079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 29] Validation Loss: 0.0866\n",
      "\n",
      "[Trial 36] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0003293464467013183, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 22/60, Loss: 0.0895, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0908, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.0917, Val Loss: 0.0906\n",
      "Epoch 45/60, Loss: 0.0898, Val Loss: 0.0860\n",
      "Epoch 16/60, Loss: 0.0905, Val Loss: 0.0875\n",
      "Epoch 17/60, Loss: 0.0910, Val Loss: 0.0872\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 1/60, Loss: 0.6999, Val Loss: 0.1037\n",
      "Epoch 22/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 10/60, Loss: 0.0911, Val Loss: 0.0902\n",
      "Epoch 14/60, Loss: 0.0905, Val Loss: 0.0881\n",
      "Epoch 10/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 17/60, Loss: 0.0904, Val Loss: 0.0875\n",
      "Epoch 18/60, Loss: 0.0908, Val Loss: 0.0874\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 2/60, Loss: 0.1976, Val Loss: 0.0948\n",
      "Epoch 11/60, Loss: 0.0905, Val Loss: 0.0903\n",
      "Epoch 15/60, Loss: 0.0901, Val Loss: 0.0881\n",
      "Epoch 8/60, Loss: 0.0894, Val Loss: 0.0893\n",
      "Epoch 46/60, Loss: 0.0900, Val Loss: 0.0860\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0892, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.0902, Val Loss: 0.0874\n",
      "Epoch 19/60, Loss: 0.0907, Val Loss: 0.0872\n",
      "Epoch 3/60, Loss: 0.1296, Val Loss: 0.0928\n",
      "Epoch 32/60, Loss: 0.0903, Val Loss: 0.0863\n",
      "Epoch 12/60, Loss: 0.0901, Val Loss: 0.0901\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 16/60, Loss: 0.0876, Val Loss: 0.0887\n",
      "Epoch 16/60, Loss: 0.0901, Val Loss: 0.0880\n",
      "Epoch 22/60, Loss: 0.1305, Val Loss: 0.1273\n",
      "Early stopping triggered\n",
      "[Trial 11] Validation Loss: 0.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:27:54,323] Trial 11 finished with value: 0.1273106701672077 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'lr': 0.021237796971271747, 'batch_size': 8, 'patience': 10}. Best is trial 29 with value: 0.08664216424028079.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 37] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00030388497061919047, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 19/60, Loss: 0.0902, Val Loss: 0.0874\n",
      "Epoch 20/60, Loss: 0.0904, Val Loss: 0.0871\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 4/60, Loss: 0.1095, Val Loss: 0.0920\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 33/60, Loss: 0.0886, Val Loss: 0.0862\n",
      "Epoch 13/60, Loss: 0.0898, Val Loss: 0.0901\n",
      "Epoch 47/60, Loss: 0.0895, Val Loss: 0.0860\n",
      "Epoch 17/60, Loss: 0.0899, Val Loss: 0.0880\n",
      "Epoch 24/60, Loss: 0.0892, Val Loss: 0.0887\n",
      "Epoch 1/60, Loss: 0.7564, Val Loss: 0.1044\n",
      "Epoch 20/60, Loss: 0.0898, Val Loss: 0.0875\n",
      "Epoch 21/60, Loss: 0.0903, Val Loss: 0.0870\n",
      "Epoch 5/60, Loss: 0.1015, Val Loss: 0.0912\n",
      "Epoch 34/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:29:10,112] Trial 30 finished with value: 0.08619186456004778 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002299211997085747, 'batch_size': 32, 'patience': 6}. Best is trial 30 with value: 0.08619186456004778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 30] Validation Loss: 0.0862\n",
      "\n",
      "[Trial 38] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0004372379839293407, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 14/60, Loss: 0.0897, Val Loss: 0.0900\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 18/60, Loss: 0.0898, Val Loss: 0.0879\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0891\n",
      "Epoch 2/60, Loss: 0.2228, Val Loss: 0.0929\n",
      "Epoch 11/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 21/60, Loss: 0.0898, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.0972, Val Loss: 0.0911\n",
      "Epoch 22/60, Loss: 0.0902, Val Loss: 0.0870\n",
      "Epoch 1/60, Loss: 0.6375, Val Loss: 0.1005\n",
      "Epoch 48/60, Loss: 0.0896, Val Loss: 0.0860\n",
      "Epoch 15/60, Loss: 0.0895, Val Loss: 0.0902\n",
      "Epoch 19/60, Loss: 0.0897, Val Loss: 0.0879\n",
      "Epoch 3/60, Loss: 0.1386, Val Loss: 0.0917\n",
      "Epoch 22/60, Loss: 0.0897, Val Loss: 0.0874\n",
      "Epoch 25/60, Loss: 0.0930, Val Loss: 0.0889\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 7/60, Loss: 0.0947, Val Loss: 0.0908\n",
      "Epoch 2/60, Loss: 0.1630, Val Loss: 0.0925\n",
      "Epoch 23/60, Loss: 0.0900, Val Loss: 0.0869\n",
      "Epoch 16/60, Loss: 0.0894, Val Loss: 0.0900\n",
      "Epoch 20/60, Loss: 0.0895, Val Loss: 0.0878\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 17/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Early stopping triggered\n",
      "Epoch 4/60, Loss: 0.1146, Val Loss: 0.0904\n",
      "Epoch 23/60, Loss: 0.0897, Val Loss: 0.0872\n",
      "Epoch 3/60, Loss: 0.1147, Val Loss: 0.0916\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Epoch 8/60, Loss: 0.0929, Val Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:31:23,542] Trial 18 finished with value: 0.08863114370033146 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'lr': 0.0005113013699407474, 'batch_size': 8, 'patience': 3}. Best is trial 30 with value: 0.08619186456004778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 18] Validation Loss: 0.0886\n",
      "\n",
      "[Trial 39] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002753494253356034, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 24/60, Loss: 0.0898, Val Loss: 0.0870\n",
      "Epoch 49/60, Loss: 0.0894, Val Loss: 0.0859\n",
      "Epoch 17/60, Loss: 0.0892, Val Loss: 0.0901\n",
      "Epoch 21/60, Loss: 0.0894, Val Loss: 0.0878\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.1020, Val Loss: 0.0907\n",
      "Epoch 5/60, Loss: 0.1047, Val Loss: 0.0898\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0890\n",
      "Epoch 9/60, Loss: 0.0922, Val Loss: 0.0905\n",
      "Epoch 24/60, Loss: 0.0894, Val Loss: 0.0872\n",
      "Epoch 26/60, Loss: 0.0893, Val Loss: 0.0888\n",
      "Epoch 1/60, Loss: 0.2274, Val Loss: 0.0910\n",
      "Epoch 25/60, Loss: 0.0896, Val Loss: 0.0868\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 24/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0892, Val Loss: 0.0877\n",
      "Epoch 5/60, Loss: 0.0969, Val Loss: 0.0903\n",
      "Epoch 6/60, Loss: 0.0996, Val Loss: 0.0891\n",
      "Epoch 10/60, Loss: 0.0915, Val Loss: 0.0908\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 25/60, Loss: 0.0893, Val Loss: 0.0872\n",
      "Epoch 50/60, Loss: 0.0896, Val Loss: 0.0860\n",
      "Epoch 2/60, Loss: 0.0926, Val Loss: 0.0887\n",
      "Epoch 26/60, Loss: 0.0895, Val Loss: 0.0868\n",
      "Epoch 19/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 6/60, Loss: 0.0939, Val Loss: 0.0900\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0876\n",
      "Epoch 11/60, Loss: 0.0907, Val Loss: 0.0905\n",
      "Epoch 7/60, Loss: 0.0965, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0926, Val Loss: 0.0901\n",
      "Epoch 3/60, Loss: 0.0902, Val Loss: 0.0884\n",
      "Epoch 26/60, Loss: 0.0892, Val Loss: 0.0870\n",
      "Epoch 27/60, Loss: 0.0894, Val Loss: 0.0886\n",
      "Epoch 27/60, Loss: 0.0895, Val Loss: 0.0867\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0876\n",
      "Epoch 12/60, Loss: 0.0904, Val Loss: 0.0905\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0866\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 8/60, Loss: 0.0915, Val Loss: 0.0898\n",
      "Epoch 8/60, Loss: 0.0946, Val Loss: 0.0887\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0882\n",
      "Epoch 51/60, Loss: 0.0899, Val Loss: 0.0859\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 27/60, Loss: 0.0892, Val Loss: 0.0871\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0897\n",
      "Epoch 28/60, Loss: 0.0895, Val Loss: 0.0868\n",
      "Epoch 9/60, Loss: 0.0908, Val Loss: 0.0897\n",
      "Epoch 25/60, Loss: 0.0891, Val Loss: 0.0876\n",
      "Epoch 13/60, Loss: 0.0900, Val Loss: 0.0904\n",
      "Epoch 9/60, Loss: 0.0931, Val Loss: 0.0889\n",
      "Epoch 40/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 5/60, Loss: 0.0894, Val Loss: 0.0881\n",
      "Epoch 10/60, Loss: 0.0903, Val Loss: 0.0897\n",
      "Epoch 28/60, Loss: 0.0891, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0897\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.0894, Val Loss: 0.0868\n",
      "Epoch 28/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 26/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 14/60, Loss: 0.0899, Val Loss: 0.0904\n",
      "Epoch 11/60, Loss: 0.0899, Val Loss: 0.0896\n",
      "Epoch 10/60, Loss: 0.0924, Val Loss: 0.0887\n",
      "Epoch 52/60, Loss: 0.0895, Val Loss: 0.0859\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 29/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 12/60, Loss: 0.0898, Val Loss: 0.0897\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 30/60, Loss: 0.0892, Val Loss: 0.0866\n",
      "Epoch 15/60, Loss: 0.0896, Val Loss: 0.0904\n",
      "Epoch 27/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 11/60, Loss: 0.0917, Val Loss: 0.0887\n",
      "Epoch 13/60, Loss: 0.0897, Val Loss: 0.0896\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0880\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 24/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 12/60, Loss: 0.0884, Val Loss: 0.0888\n",
      "Epoch 30/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 31/60, Loss: 0.0892, Val Loss: 0.0866\n",
      "Epoch 16/60, Loss: 0.0895, Val Loss: 0.0903\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 29/60, Loss: 0.0890, Val Loss: 0.0890\n",
      "Epoch 12/60, Loss: 0.0911, Val Loss: 0.0886\n",
      "Epoch 14/60, Loss: 0.0895, Val Loss: 0.0895\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0880\n",
      "Epoch 53/60, Loss: 0.0894, Val Loss: 0.0859\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0897\n",
      "Epoch 15/60, Loss: 0.0892, Val Loss: 0.0895\n",
      "Epoch 31/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 17/60, Loss: 0.0892, Val Loss: 0.0904\n",
      "Epoch 32/60, Loss: 0.0892, Val Loss: 0.0865\n",
      "Epoch 29/60, Loss: 0.0886, Val Loss: 0.0874\n",
      "Epoch 13/60, Loss: 0.0907, Val Loss: 0.0885\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0880\n",
      "Epoch 16/60, Loss: 0.0891, Val Loss: 0.0895\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 18/60, Loss: 0.0892, Val Loss: 0.0904\n",
      "Epoch 32/60, Loss: 0.0888, Val Loss: 0.0868\n",
      "Epoch 30/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 33/60, Loss: 0.0891, Val Loss: 0.0865\n",
      "Epoch 14/60, Loss: 0.0904, Val Loss: 0.0885\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0895\n",
      "Epoch 30/60, Loss: 0.0891, Val Loss: 0.0888\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0879\n",
      "Epoch 54/60, Loss: 0.0895, Val Loss: 0.0858\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 18/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0903\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0887\n",
      "Epoch 33/60, Loss: 0.0888, Val Loss: 0.0868\n",
      "Epoch 34/60, Loss: 0.0888, Val Loss: 0.0864\n",
      "Epoch 15/60, Loss: 0.0903, Val Loss: 0.0885\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0876\n",
      "Epoch 19/60, Loss: 0.0888, Val Loss: 0.0894\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 20/60, Loss: 0.0890, Val Loss: 0.0903\n",
      "Epoch 32/60, Loss: 0.0886, Val Loss: 0.0874\n",
      "Epoch 16/60, Loss: 0.0900, Val Loss: 0.0884\n",
      "Epoch 35/60, Loss: 0.0889, Val Loss: 0.0865\n",
      "Epoch 14/60, Loss: 0.0912, Val Loss: 0.0906\n",
      "Epoch 34/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 55/60, Loss: 0.0892, Val Loss: 0.0859\n",
      "Epoch 31/60, Loss: 0.0897, Val Loss: 0.0890\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 21/60, Loss: 0.0889, Val Loss: 0.0904\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0886, Val Loss: 0.0874\n",
      "Epoch 17/60, Loss: 0.0898, Val Loss: 0.0885\n",
      "Epoch 36/60, Loss: 0.0890, Val Loss: 0.0865\n",
      "Epoch 35/60, Loss: 0.0887, Val Loss: 0.0867\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0897, Val Loss: 0.0883\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0875\n",
      "Epoch 37/60, Loss: 0.0888, Val Loss: 0.0863\n",
      "Epoch 14/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 36/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 56/60, Loss: 0.0894, Val Loss: 0.0858\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0892\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0894\n",
      "Epoch 32/60, Loss: 0.0892, Val Loss: 0.0891\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0901\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 19/60, Loss: 0.0895, Val Loss: 0.0883\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0889, Val Loss: 0.0864\n",
      "Epoch 37/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 29/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0894\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0900\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 36/60, Loss: 0.0885, Val Loss: 0.0872\n",
      "Epoch 20/60, Loss: 0.0895, Val Loss: 0.0884\n",
      "Epoch 16/60, Loss: 0.0887, Val Loss: 0.0875\n",
      "Epoch 57/60, Loss: 0.0892, Val Loss: 0.0858\n",
      "Epoch 39/60, Loss: 0.0887, Val Loss: 0.0863\n",
      "Epoch 38/60, Loss: 0.0886, Val Loss: 0.0867\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0900\n",
      "Epoch 15/60, Loss: 0.0889, Val Loss: 0.0876\n",
      "Epoch 33/60, Loss: 0.0890, Val Loss: 0.0887\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0893, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0887, Val Loss: 0.0863\n",
      "Epoch 15/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 39/60, Loss: 0.0886, Val Loss: 0.0867\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0900\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 28/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 38/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 58/60, Loss: 0.0893, Val Loss: 0.0857\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 22/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0881\n",
      "Epoch 41/60, Loss: 0.0887, Val Loss: 0.0862\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0899\n",
      "Epoch 40/60, Loss: 0.0886, Val Loss: 0.0866\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 34/60, Loss: 0.0888, Val Loss: 0.0893\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0900\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 41/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 59/60, Loss: 0.0893, Val Loss: 0.0858\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0899\n",
      "Epoch 43/60, Loss: 0.0886, Val Loss: 0.0863\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0867\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 35/60, Loss: 0.0889, Val Loss: 0.0888\n",
      "Early stopping triggered\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 25/60, Loss: 0.0889, Val Loss: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:50:13,426] Trial 23 finished with value: 0.08879333001871904 and parameters: {'hidden_dim': 192, 'latent_dim': 128, 'lr': 0.006695624206951987, 'batch_size': 16, 'patience': 8}. Best is trial 30 with value: 0.08619186456004778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 23] Validation Loss: 0.0888\n",
      "\n",
      "[Trial 40] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0025945388795526247, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0899\n",
      "Epoch 18/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 44/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 60/60, Loss: 0.0894, Val Loss: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:50:57,811] Trial 5 finished with value: 0.08564341689149539 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 2.2632688109496862e-05, 'batch_size': 16, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5] Validation Loss: 0.0856\n",
      "\n",
      "[Trial 41] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.1294508616387914e-05, 'batch_size': 32, 'patience': 7}\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 26/60, Loss: 0.0887, Val Loss: 0.0881\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0898\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 1/60, Loss: 0.2333, Val Loss: 0.0897\n",
      "Epoch 39/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 45/60, Loss: 0.0886, Val Loss: 0.0862\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 44/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "Epoch 1/60, Loss: 1.7088, Val Loss: 0.3547\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0898\n",
      "Epoch 2/60, Loss: 0.0934, Val Loss: 0.0885\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 46/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 45/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0872\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0897\n",
      "Epoch 2/60, Loss: 1.3223, Val Loss: 0.2688\n",
      "Epoch 3/60, Loss: 0.0911, Val Loss: 0.0870\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 47/60, Loss: 0.0886, Val Loss: 0.0862\n",
      "Epoch 46/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0897\n",
      "Epoch 4/60, Loss: 0.0902, Val Loss: 0.0867\n",
      "Epoch 3/60, Loss: 1.1254, Val Loss: 0.2243\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 54/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 19/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 48/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 47/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0896\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 5/60, Loss: 0.0898, Val Loss: 0.0865\n",
      "Epoch 4/60, Loss: 0.9942, Val Loss: 0.1892\n",
      "Epoch 30/60, Loss: 0.0886, Val Loss: 0.0879\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 49/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 48/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 18/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Early stopping triggered\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.0897, Val Loss: 0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:55:37,958] Trial 25 finished with value: 0.08817502657572428 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.00021234195192368455, 'batch_size': 32, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 25] Validation Loss: 0.0882\n",
      "\n",
      "[Trial 42] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.09525278719068223, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 5/60, Loss: 0.8895, Val Loss: 0.1683\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 40/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 50/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0864\n",
      "Epoch 28/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 49/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 6/60, Loss: 0.8132, Val Loss: 0.1543\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0864\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 51/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 29/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 0.7944, Val Loss: 0.1283\n",
      "Epoch 7/60, Loss: 0.7384, Val Loss: 0.1414\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Early stopping triggered\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0864\n",
      "Epoch 47/60, Loss: 0.0876, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 39/60, Loss: 0.0877, Val Loss: 0.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 11:57:57,633] Trial 6 finished with value: 0.08837757830818495 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0011861753762190549, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 6] Validation Loss: 0.0884\n",
      "\n",
      "[Trial 43] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.0505109963833127e-05, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 52/60, Loss: 0.0886, Val Loss: 0.0862\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 8/60, Loss: 0.6860, Val Loss: 0.1321\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 51/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 19/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0871\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0862\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 2/60, Loss: 0.1309, Val Loss: 0.1285\n",
      "Epoch 53/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 31/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 9/60, Loss: 0.6359, Val Loss: 0.1255\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0895\n",
      "Epoch 1/60, Loss: 1.5204, Val Loss: 0.2872\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 10/60, Loss: 0.5748, Val Loss: 0.1200\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 54/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 53/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 3/60, Loss: 0.1268, Val Loss: 0.1280\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 12/60, Loss: 0.0893, Val Loss: 0.0862\n",
      "Epoch 42/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.5414, Val Loss: 0.1156\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 55/60, Loss: 0.0883, Val Loss: 0.0862\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 2/60, Loss: 1.0289, Val Loss: 0.2006\n",
      "Epoch 13/60, Loss: 0.0890, Val Loss: 0.0861\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 51/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 12/60, Loss: 0.5022, Val Loss: 0.1130\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0873\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 4/60, Loss: 0.1539, Val Loss: 0.1284\n",
      "Epoch 56/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 34/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0858\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.4682, Val Loss: 0.1099\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 57/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 3/60, Loss: 0.8233, Val Loss: 0.1624\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 56/60, Loss: 0.0883, Val Loss: 0.0865\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0859\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.1773, Val Loss: 0.1302\n",
      "Epoch 14/60, Loss: 0.4282, Val Loss: 0.1074\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 36/60, Loss: 0.0914, Val Loss: 0.0915\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 19/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 58/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 16/60, Loss: 0.0890, Val Loss: 0.0860\n",
      "Epoch 57/60, Loss: 0.0883, Val Loss: 0.0865\n",
      "Epoch 46/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 54/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.4044, Val Loss: 0.1059\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 21/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 37/60, Loss: 0.0894, Val Loss: 0.0876\n",
      "Epoch 4/60, Loss: 0.6939, Val Loss: 0.1445\n",
      "Epoch 57/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 59/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 6/60, Loss: 0.1525, Val Loss: 0.1278\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 17/60, Loss: 0.0889, Val Loss: 0.0858\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 58/60, Loss: 0.0882, Val Loss: 0.0865\n",
      "Epoch 55/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.3769, Val Loss: 0.1037\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 38/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 60/60, Loss: 0.0884, Val Loss: 0.0861\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0859\n",
      "[Trial 32] Validation Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:05:01,195] Trial 32 finished with value: 0.08612179582317671 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00015911148108685322, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 44] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.2539480751152271e-05, 'batch_size': 16, 'patience': 8}\n",
      "Epoch 56/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0865\n",
      "Epoch 17/60, Loss: 0.3536, Val Loss: 0.1019\n",
      "Epoch 43/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 5/60, Loss: 0.5956, Val Loss: 0.1310\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 57/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 7/60, Loss: 0.1655, Val Loss: 0.1301\n",
      "Epoch 59/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0858\n",
      "Epoch 57/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 60/60, Loss: 0.0882, Val Loss: 0.0865\n",
      "Epoch 18/60, Loss: 0.3283, Val Loss: 0.1008\n",
      "[Trial 33] Validation Loss: 0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:06:04,228] Trial 33 finished with value: 0.0865263357758522 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00019782024226935616, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 45] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0815025779906469, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 58/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 22/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "[Trial 34] Validation Loss: 0.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:06:30,359] Trial 34 finished with value: 0.08710792486866316 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0002282369341933327, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 46] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.1423556899358826e-05, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0857\n",
      "Epoch 58/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 1.4978, Val Loss: 0.2605\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 19/60, Loss: 0.3124, Val Loss: 0.0995\n",
      "Epoch 6/60, Loss: 0.5153, Val Loss: 0.1220\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Early stopping triggered\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 8/60, Loss: 0.1467, Val Loss: 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:07:05,277] Trial 39 finished with value: 0.0872475897272428 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002753494253356034, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 39] Validation Loss: 0.0872\n",
      "\n",
      "[Trial 47] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.00120965405112e-05, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 60/60, Loss: 0.0876, Val Loss: 0.0887\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:07:17,104] Trial 38 finished with value: 0.08865037883321444 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0004372379839293407, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 38] Validation Loss: 0.0887\n",
      "\n",
      "[Trial 48] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.6576653656943163e-05, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 20/60, Loss: 0.2948, Val Loss: 0.0981\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 1/60, Loss: 0.6206, Val Loss: 0.1246\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0857\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 60/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 1/60, Loss: 1.6095, Val Loss: 0.3059\n",
      "Epoch 2/60, Loss: 0.9669, Val Loss: 0.1868\n",
      "[Trial 35] Validation Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:08:06,422] Trial 35 finished with value: 0.08917199199398358 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0002635824298475761, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 49] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.0557893689005761e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 7/60, Loss: 0.4549, Val Loss: 0.1134\n",
      "Epoch 21/60, Loss: 0.2778, Val Loss: 0.0972\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 1.3916, Val Loss: 0.2388\n",
      "Epoch 9/60, Loss: 0.1283, Val Loss: 0.1283\n",
      "Epoch 53/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 1/60, Loss: 1.5910, Val Loss: 0.3148\n",
      "Epoch 23/60, Loss: 0.0888, Val Loss: 0.0856\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.2640, Val Loss: 0.0969\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 2/60, Loss: 0.1268, Val Loss: 0.1372\n",
      "Epoch 2/60, Loss: 1.0784, Val Loss: 0.2085\n",
      "Epoch 54/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 8/60, Loss: 0.4021, Val Loss: 0.1083\n",
      "Epoch 3/60, Loss: 0.7448, Val Loss: 0.1489\n",
      "Epoch 24/60, Loss: 0.0888, Val Loss: 0.0858\n",
      "Epoch 2/60, Loss: 0.8703, Val Loss: 0.1615\n",
      "Epoch 23/60, Loss: 0.2529, Val Loss: 0.0963\n",
      "Epoch 1/60, Loss: 1.4723, Val Loss: 0.2972\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.1266, Val Loss: 0.1310\n",
      "Epoch 2/60, Loss: 1.1528, Val Loss: 0.2238\n",
      "Epoch 55/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 24/60, Loss: 0.2414, Val Loss: 0.0960\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 3/60, Loss: 0.2920, Val Loss: 0.1248\n",
      "Epoch 3/60, Loss: 0.8463, Val Loss: 0.1641\n",
      "Epoch 3/60, Loss: 0.6563, Val Loss: 0.1321\n",
      "Epoch 21/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.3529, Val Loss: 0.1055\n",
      "Epoch 4/60, Loss: 0.6169, Val Loss: 0.1300\n",
      "Epoch 56/60, Loss: 0.0875, Val Loss: 0.0896\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0871\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0856\n",
      "Epoch 2/60, Loss: 1.0360, Val Loss: 0.2069\n",
      "Epoch 25/60, Loss: 0.2323, Val Loss: 0.0958\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 11/60, Loss: 0.1279, Val Loss: 0.1303\n",
      "Epoch 3/60, Loss: 0.9461, Val Loss: 0.1741\n",
      "Epoch 57/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 4/60, Loss: 0.5275, Val Loss: 0.1147\n",
      "Epoch 27/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 26/60, Loss: 0.2220, Val Loss: 0.0954\n",
      "Epoch 4/60, Loss: 0.7030, Val Loss: 0.1435\n",
      "Epoch 4/60, Loss: 0.2061, Val Loss: 0.1249\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.3152, Val Loss: 0.1027\n",
      "Epoch 5/60, Loss: 0.5251, Val Loss: 0.1177\n",
      "Epoch 58/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 3/60, Loss: 0.8316, Val Loss: 0.1655\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0856\n",
      "Epoch 27/60, Loss: 0.2136, Val Loss: 0.0951\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 4/60, Loss: 0.7999, Val Loss: 0.1527\n",
      "Epoch 12/60, Loss: 0.1493, Val Loss: 0.1295\n",
      "Epoch 5/60, Loss: 0.4318, Val Loss: 0.1064\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 5/60, Loss: 0.5952, Val Loss: 0.1284\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 28/60, Loss: 0.2062, Val Loss: 0.0947\n",
      "Epoch 29/60, Loss: 0.0888, Val Loss: 0.0858\n",
      "Epoch 5/60, Loss: 0.1270, Val Loss: 0.1271\n",
      "Epoch 11/60, Loss: 0.2839, Val Loss: 0.1004\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 6/60, Loss: 0.4467, Val Loss: 0.1098\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 4/60, Loss: 0.7001, Val Loss: 0.1421\n",
      "Epoch 60/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "[Trial 36] Validation Loss: 0.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:13:35,643] Trial 36 finished with value: 0.0894794762134552 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0003293464467013183, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 50] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.1870418679160136e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 25/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 6/60, Loss: 0.3567, Val Loss: 0.1013\n",
      "Epoch 29/60, Loss: 0.1991, Val Loss: 0.0945\n",
      "Epoch 30/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 5/60, Loss: 0.6974, Val Loss: 0.1371\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 22/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Early stopping triggered\n",
      "Epoch 13/60, Loss: 0.2376, Val Loss: 0.1286\n",
      "Early stopping triggered\n",
      "[Trial 42] Validation Loss: 0.1286\n",
      "Epoch 6/60, Loss: 0.5112, Val Loss: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:14:07,854] Trial 42 finished with value: 0.12862211304406326 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.09525278719068223, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 51] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.6669200250467567e-05, 'batch_size': 16, 'patience': 9}\n",
      "[Trial 26] Validation Loss: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:14:11,320] Trial 26 finished with value: 0.0875785367252926 and parameters: {'hidden_dim': 512, 'latent_dim': 64, 'lr': 0.0015929863382772756, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 52] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.1219347413493853e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 12/60, Loss: 0.2601, Val Loss: 0.0981\n",
      "Epoch 30/60, Loss: 0.1926, Val Loss: 0.0944\n",
      "Epoch 31/60, Loss: 0.0888, Val Loss: 0.0857\n",
      "Epoch 6/60, Loss: 0.1273, Val Loss: 0.1262\n",
      "Epoch 7/60, Loss: 0.3840, Val Loss: 0.1051\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 5/60, Loss: 0.6092, Val Loss: 0.1285\n",
      "Epoch 7/60, Loss: 0.2988, Val Loss: 0.0982\n",
      "Epoch 6/60, Loss: 0.6106, Val Loss: 0.1259\n",
      "Epoch 31/60, Loss: 0.1852, Val Loss: 0.0941\n",
      "Epoch 1/60, Loss: 1.4928, Val Loss: 0.2739\n",
      "Epoch 32/60, Loss: 0.0886, Val Loss: 0.0855\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 7/60, Loss: 0.4452, Val Loss: 0.1111\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 26/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 13/60, Loss: 0.2406, Val Loss: 0.0965\n",
      "Epoch 1/60, Loss: 1.1984, Val Loss: 0.1905\n",
      "Epoch 1/60, Loss: 1.4049, Val Loss: 0.2772\n",
      "Epoch 32/60, Loss: 0.1801, Val Loss: 0.0939\n",
      "Epoch 8/60, Loss: 0.3324, Val Loss: 0.1012\n",
      "Epoch 6/60, Loss: 0.5286, Val Loss: 0.1176\n",
      "Epoch 33/60, Loss: 0.0886, Val Loss: 0.0857\n",
      "Epoch 7/60, Loss: 0.1270, Val Loss: 0.1276\n",
      "Epoch 58/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 8/60, Loss: 0.2580, Val Loss: 0.0963\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 7/60, Loss: 0.5361, Val Loss: 0.1163\n",
      "Epoch 2/60, Loss: 1.0522, Val Loss: 0.1861\n",
      "Epoch 33/60, Loss: 0.1754, Val Loss: 0.0938\n",
      "Epoch 8/60, Loss: 0.3896, Val Loss: 0.1061\n",
      "Epoch 34/60, Loss: 0.0915, Val Loss: 0.0862\n",
      "Epoch 59/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 14/60, Loss: 0.2209, Val Loss: 0.0955\n",
      "Epoch 2/60, Loss: 0.9603, Val Loss: 0.1994\n",
      "Epoch 2/60, Loss: 0.6328, Val Loss: 0.1294\n",
      "Epoch 7/60, Loss: 0.4671, Val Loss: 0.1129\n",
      "Epoch 9/60, Loss: 0.2953, Val Loss: 0.0985\n",
      "Epoch 34/60, Loss: 0.1684, Val Loss: 0.0936\n",
      "Epoch 60/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 35/60, Loss: 0.0888, Val Loss: 0.0856\n",
      "[Trial 37] Validation Loss: 0.0876\n",
      "Epoch 8/60, Loss: 0.1283, Val Loss: 0.1265\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:17:18,461] Trial 37 finished with value: 0.08759380206465721 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00030388497061919047, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60, Loss: 0.2290, Val Loss: 0.0950\n",
      "\n",
      "[Trial 53] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.0613529251193415e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 8/60, Loss: 0.4779, Val Loss: 0.1111\n",
      "[Trial 45] Validation Loss: 0.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:17:26,292] Trial 45 finished with value: 0.12652819839616616 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0815025779906469, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 54] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 1.2575610775385682e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 3/60, Loss: 0.8526, Val Loss: 0.1482\n",
      "Epoch 9/60, Loss: 0.3383, Val Loss: 0.1029\n",
      "Epoch 35/60, Loss: 0.1648, Val Loss: 0.0934\n",
      "Epoch 27/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 36/60, Loss: 0.0888, Val Loss: 0.0856\n",
      "Epoch 15/60, Loss: 0.2062, Val Loss: 0.0948\n",
      "Epoch 40/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Early stopping triggered\n",
      "Epoch 3/60, Loss: 0.7615, Val Loss: 0.1613\n",
      "Epoch 3/60, Loss: 0.4359, Val Loss: 0.1095\n",
      "Epoch 8/60, Loss: 0.4093, Val Loss: 0.1084\n",
      "[Trial 2] Validation Loss: 0.0867\n",
      "Epoch 10/60, Loss: 0.2632, Val Loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:18:14,993] Trial 2 finished with value: 0.08672841542089979 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.001368526281729318, 'batch_size': 8, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 55] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.301992263984231e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 36/60, Loss: 0.1605, Val Loss: 0.0932\n",
      "Epoch 10/60, Loss: 0.2067, Val Loss: 0.0944\n",
      "Epoch 9/60, Loss: 0.4226, Val Loss: 0.1069\n",
      "Epoch 37/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 4/60, Loss: 0.7135, Val Loss: 0.1289\n",
      "Epoch 10/60, Loss: 0.2997, Val Loss: 0.1002\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 1/60, Loss: 1.2862, Val Loss: 0.2132\n",
      "Epoch 37/60, Loss: 0.1566, Val Loss: 0.0932\n",
      "Epoch 1/60, Loss: 1.3791, Val Loss: 0.2250\n",
      "Epoch 16/60, Loss: 0.1958, Val Loss: 0.0944\n",
      "Epoch 4/60, Loss: 0.6388, Val Loss: 0.1403\n",
      "Epoch 4/60, Loss: 0.3218, Val Loss: 0.1020\n",
      "Epoch 38/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 9/60, Loss: 0.3647, Val Loss: 0.1051\n",
      "Epoch 11/60, Loss: 0.2372, Val Loss: 0.0962\n",
      "Epoch 38/60, Loss: 0.1526, Val Loss: 0.0929\n",
      "Epoch 11/60, Loss: 0.1879, Val Loss: 0.0938\n",
      "Epoch 10/60, Loss: 0.3798, Val Loss: 0.1036\n",
      "Epoch 1/60, Loss: 1.5756, Val Loss: 0.2846\n",
      "Epoch 11/60, Loss: 0.2736, Val Loss: 0.0980\n",
      "Epoch 5/60, Loss: 0.6119, Val Loss: 0.1163\n",
      "Epoch 2/60, Loss: 0.7858, Val Loss: 0.1467\n",
      "Epoch 39/60, Loss: 0.0886, Val Loss: 0.0856\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 2/60, Loss: 0.9112, Val Loss: 0.1560\n",
      "Epoch 39/60, Loss: 0.1485, Val Loss: 0.0928\n",
      "Epoch 17/60, Loss: 0.1826, Val Loss: 0.0938\n",
      "Epoch 5/60, Loss: 0.5389, Val Loss: 0.1262\n",
      "Epoch 5/60, Loss: 0.2515, Val Loss: 0.0970\n",
      "Epoch 10/60, Loss: 0.3223, Val Loss: 0.1023\n",
      "Epoch 12/60, Loss: 0.2182, Val Loss: 0.0954\n",
      "Epoch 40/60, Loss: 0.0891, Val Loss: 0.0857\n",
      "Early stopping triggered\n",
      "[Trial 40] Validation Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:20:52,545] Trial 40 finished with value: 0.08567992374300956 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0025945388795526247, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60, Loss: 0.1734, Val Loss: 0.0933\n",
      "\n",
      "[Trial 56] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.4338641397271748e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 11/60, Loss: 0.3409, Val Loss: 0.1011\n",
      "Epoch 2/60, Loss: 1.0893, Val Loss: 0.1952\n",
      "Epoch 40/60, Loss: 0.1458, Val Loss: 0.0927\n",
      "Epoch 12/60, Loss: 0.2454, Val Loss: 0.0962\n",
      "Epoch 6/60, Loss: 0.5310, Val Loss: 0.1093\n",
      "Epoch 3/60, Loss: 0.5831, Val Loss: 0.1219\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 3/60, Loss: 0.7081, Val Loss: 0.1268\n",
      "Epoch 18/60, Loss: 0.1730, Val Loss: 0.0933\n",
      "Epoch 41/60, Loss: 0.1428, Val Loss: 0.0927\n",
      "Epoch 6/60, Loss: 0.4722, Val Loss: 0.1165\n",
      "Epoch 11/60, Loss: 0.2907, Val Loss: 0.0999\n",
      "Epoch 6/60, Loss: 0.2099, Val Loss: 0.0953\n",
      "Epoch 13/60, Loss: 0.2014, Val Loss: 0.0949\n",
      "Epoch 13/60, Loss: 0.1618, Val Loss: 0.0928\n",
      "Epoch 3/60, Loss: 0.8763, Val Loss: 0.1543\n",
      "Epoch 12/60, Loss: 0.3058, Val Loss: 0.0983\n",
      "Epoch 13/60, Loss: 0.2288, Val Loss: 0.0949\n",
      "Epoch 42/60, Loss: 0.1394, Val Loss: 0.0924\n",
      "Epoch 7/60, Loss: 0.4610, Val Loss: 0.1048\n",
      "Epoch 4/60, Loss: 0.4448, Val Loss: 0.1088\n",
      "Epoch 29/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 1/60, Loss: 1.4418, Val Loss: 0.2426\n",
      "Epoch 4/60, Loss: 0.5664, Val Loss: 0.1121\n",
      "Epoch 19/60, Loss: 0.1652, Val Loss: 0.0929\n",
      "Epoch 7/60, Loss: 0.4071, Val Loss: 0.1106\n",
      "Epoch 12/60, Loss: 0.2648, Val Loss: 0.0978\n",
      "Epoch 43/60, Loss: 0.1366, Val Loss: 0.0924\n",
      "Epoch 7/60, Loss: 0.1818, Val Loss: 0.0944\n",
      "Epoch 14/60, Loss: 0.1877, Val Loss: 0.0944\n",
      "Epoch 14/60, Loss: 0.1523, Val Loss: 0.0924\n",
      "Epoch 4/60, Loss: 0.7254, Val Loss: 0.1353\n",
      "Epoch 13/60, Loss: 0.2807, Val Loss: 0.0963\n",
      "Epoch 14/60, Loss: 0.2114, Val Loss: 0.0943\n",
      "Epoch 5/60, Loss: 0.3486, Val Loss: 0.1019\n",
      "Epoch 8/60, Loss: 0.4085, Val Loss: 0.1019\n",
      "Epoch 44/60, Loss: 0.1344, Val Loss: 0.0922\n",
      "Epoch 2/60, Loss: 1.0039, Val Loss: 0.1704\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0872\n",
      "Epoch 5/60, Loss: 0.4677, Val Loss: 0.1047\n",
      "Epoch 20/60, Loss: 0.1572, Val Loss: 0.0926\n",
      "Epoch 8/60, Loss: 0.3561, Val Loss: 0.1064\n",
      "Epoch 13/60, Loss: 0.2421, Val Loss: 0.0967\n",
      "Epoch 8/60, Loss: 0.1601, Val Loss: 0.0936\n",
      "Epoch 45/60, Loss: 0.1311, Val Loss: 0.0921\n",
      "Epoch 15/60, Loss: 0.1774, Val Loss: 0.0939\n",
      "Epoch 5/60, Loss: 0.6060, Val Loss: 0.1211\n",
      "Epoch 15/60, Loss: 0.1432, Val Loss: 0.0921\n",
      "Epoch 14/60, Loss: 0.2578, Val Loss: 0.0949\n",
      "Epoch 15/60, Loss: 0.1969, Val Loss: 0.0937\n",
      "Epoch 30/60, Loss: 0.0875, Val Loss: 0.0884\n",
      "Epoch 6/60, Loss: 0.2809, Val Loss: 0.0980\n",
      "Epoch 9/60, Loss: 0.3546, Val Loss: 0.0983\n",
      "Epoch 3/60, Loss: 0.8133, Val Loss: 0.1401\n",
      "Epoch 46/60, Loss: 0.1285, Val Loss: 0.0920\n",
      "Epoch 6/60, Loss: 0.3836, Val Loss: 0.0990\n",
      "Epoch 21/60, Loss: 0.1502, Val Loss: 0.0922\n",
      "Epoch 9/60, Loss: 0.3153, Val Loss: 0.1025\n",
      "Epoch 14/60, Loss: 0.2256, Val Loss: 0.0962\n",
      "Epoch 9/60, Loss: 0.1469, Val Loss: 0.0930\n",
      "Epoch 16/60, Loss: 0.1661, Val Loss: 0.0937\n",
      "Epoch 47/60, Loss: 0.1268, Val Loss: 0.0919\n",
      "Epoch 6/60, Loss: 0.5180, Val Loss: 0.1110\n",
      "Epoch 16/60, Loss: 0.1360, Val Loss: 0.0919\n",
      "Epoch 15/60, Loss: 0.2370, Val Loss: 0.0942\n",
      "Epoch 16/60, Loss: 0.1853, Val Loss: 0.0932\n",
      "Epoch 7/60, Loss: 0.2371, Val Loss: 0.0964\n",
      "Epoch 10/60, Loss: 0.3129, Val Loss: 0.0954\n",
      "Epoch 4/60, Loss: 0.6595, Val Loss: 0.1211\n",
      "Epoch 48/60, Loss: 0.1247, Val Loss: 0.0917\n",
      "Epoch 7/60, Loss: 0.3202, Val Loss: 0.0961\n",
      "Epoch 22/60, Loss: 0.1441, Val Loss: 0.0921\n",
      "Epoch 30/60, Loss: 0.0899, Val Loss: 0.0871\n",
      "Epoch 10/60, Loss: 0.2817, Val Loss: 0.1003\n",
      "Epoch 15/60, Loss: 0.2096, Val Loss: 0.0954\n",
      "Epoch 10/60, Loss: 0.1357, Val Loss: 0.0926\n",
      "Epoch 17/60, Loss: 0.1579, Val Loss: 0.0932\n",
      "Epoch 7/60, Loss: 0.4491, Val Loss: 0.1055\n",
      "Epoch 17/60, Loss: 0.1300, Val Loss: 0.0915\n",
      "Epoch 17/60, Loss: 0.1742, Val Loss: 0.0927\n",
      "Epoch 16/60, Loss: 0.2214, Val Loss: 0.0936\n",
      "Epoch 49/60, Loss: 0.1222, Val Loss: 0.0916\n",
      "Epoch 31/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 8/60, Loss: 0.2072, Val Loss: 0.0953\n",
      "Epoch 11/60, Loss: 0.2796, Val Loss: 0.0937\n",
      "Epoch 5/60, Loss: 0.5509, Val Loss: 0.1086\n",
      "Epoch 50/60, Loss: 0.1206, Val Loss: 0.0915\n",
      "Epoch 23/60, Loss: 0.1389, Val Loss: 0.0918\n",
      "Epoch 16/60, Loss: 0.1973, Val Loss: 0.0947\n",
      "Epoch 8/60, Loss: 0.2732, Val Loss: 0.0943\n",
      "Epoch 11/60, Loss: 0.2526, Val Loss: 0.0986\n",
      "Epoch 11/60, Loss: 0.1273, Val Loss: 0.0923\n",
      "Epoch 18/60, Loss: 0.1492, Val Loss: 0.0930\n",
      "Epoch 8/60, Loss: 0.3861, Val Loss: 0.1009\n",
      "Epoch 18/60, Loss: 0.1650, Val Loss: 0.0923\n",
      "Epoch 18/60, Loss: 0.1246, Val Loss: 0.0913\n",
      "Epoch 17/60, Loss: 0.2076, Val Loss: 0.0930\n",
      "Epoch 9/60, Loss: 0.1861, Val Loss: 0.0945\n",
      "Epoch 51/60, Loss: 0.1192, Val Loss: 0.0914\n",
      "Epoch 12/60, Loss: 0.2555, Val Loss: 0.0928\n",
      "Epoch 6/60, Loss: 0.4673, Val Loss: 0.1023\n",
      "Epoch 17/60, Loss: 0.1862, Val Loss: 0.0943\n",
      "Epoch 12/60, Loss: 0.2343, Val Loss: 0.0976\n",
      "Epoch 24/60, Loss: 0.1338, Val Loss: 0.0916\n",
      "Epoch 9/60, Loss: 0.2378, Val Loss: 0.0934\n",
      "Epoch 52/60, Loss: 0.1173, Val Loss: 0.0913\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0872\n",
      "Epoch 12/60, Loss: 0.1204, Val Loss: 0.0918\n",
      "Epoch 9/60, Loss: 0.3392, Val Loss: 0.0983\n",
      "Epoch 19/60, Loss: 0.1425, Val Loss: 0.0926\n",
      "Epoch 19/60, Loss: 0.1565, Val Loss: 0.0920\n",
      "Epoch 19/60, Loss: 0.1201, Val Loss: 0.0910\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.1962, Val Loss: 0.0926\n",
      "Epoch 10/60, Loss: 0.1685, Val Loss: 0.0940\n",
      "Epoch 13/60, Loss: 0.2332, Val Loss: 0.0922\n",
      "Epoch 53/60, Loss: 0.1160, Val Loss: 0.0912\n",
      "Epoch 7/60, Loss: 0.3934, Val Loss: 0.0976\n",
      "Epoch 18/60, Loss: 0.1760, Val Loss: 0.0942\n",
      "Epoch 13/60, Loss: 0.2154, Val Loss: 0.0968\n",
      "Epoch 25/60, Loss: 0.1292, Val Loss: 0.0914\n",
      "Epoch 10/60, Loss: 0.2132, Val Loss: 0.0925\n",
      "Epoch 54/60, Loss: 0.1141, Val Loss: 0.0910\n",
      "Epoch 13/60, Loss: 0.1156, Val Loss: 0.0916\n",
      "Epoch 10/60, Loss: 0.2976, Val Loss: 0.0958\n",
      "Epoch 20/60, Loss: 0.1366, Val Loss: 0.0923\n",
      "Epoch 20/60, Loss: 0.1492, Val Loss: 0.0917\n",
      "Epoch 20/60, Loss: 0.1159, Val Loss: 0.0907\n",
      "Epoch 19/60, Loss: 0.1861, Val Loss: 0.0922\n",
      "Epoch 11/60, Loss: 0.1557, Val Loss: 0.0934\n",
      "Epoch 14/60, Loss: 0.2165, Val Loss: 0.0917\n",
      "Epoch 8/60, Loss: 0.3320, Val Loss: 0.0946\n",
      "Epoch 55/60, Loss: 0.1127, Val Loss: 0.0910\n",
      "Epoch 19/60, Loss: 0.1681, Val Loss: 0.0937\n",
      "Epoch 14/60, Loss: 0.2017, Val Loss: 0.0963\n",
      "Epoch 26/60, Loss: 0.1255, Val Loss: 0.0912\n",
      "Epoch 11/60, Loss: 0.1939, Val Loss: 0.0918\n",
      "Epoch 11/60, Loss: 0.2641, Val Loss: 0.0947\n",
      "Epoch 14/60, Loss: 0.1113, Val Loss: 0.0912\n",
      "Epoch 56/60, Loss: 0.1115, Val Loss: 0.0909\n",
      "Epoch 21/60, Loss: 0.1315, Val Loss: 0.0921\n",
      "Epoch 21/60, Loss: 0.1438, Val Loss: 0.0914\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0871\n",
      "Epoch 21/60, Loss: 0.1124, Val Loss: 0.0904\n",
      "Epoch 20/60, Loss: 0.1754, Val Loss: 0.0919\n",
      "Epoch 12/60, Loss: 0.1437, Val Loss: 0.0930\n",
      "Epoch 15/60, Loss: 0.2019, Val Loss: 0.0912\n",
      "Epoch 9/60, Loss: 0.2897, Val Loss: 0.0929\n",
      "Epoch 57/60, Loss: 0.1100, Val Loss: 0.0908\n",
      "Epoch 20/60, Loss: 0.1585, Val Loss: 0.0935\n",
      "Epoch 15/60, Loss: 0.1895, Val Loss: 0.0958\n",
      "Epoch 27/60, Loss: 0.1216, Val Loss: 0.0909\n",
      "Epoch 12/60, Loss: 0.1782, Val Loss: 0.0913\n",
      "Epoch 12/60, Loss: 0.2397, Val Loss: 0.0938\n",
      "Epoch 15/60, Loss: 0.1077, Val Loss: 0.0909\n",
      "Epoch 22/60, Loss: 0.1375, Val Loss: 0.0910\n",
      "Epoch 22/60, Loss: 0.1268, Val Loss: 0.0919\n",
      "Epoch 22/60, Loss: 0.1098, Val Loss: 0.0903\n",
      "Epoch 21/60, Loss: 0.1674, Val Loss: 0.0916\n",
      "Epoch 58/60, Loss: 0.1091, Val Loss: 0.0908\n",
      "Epoch 13/60, Loss: 0.1360, Val Loss: 0.0926\n",
      "Epoch 16/60, Loss: 0.1870, Val Loss: 0.0913\n",
      "Epoch 10/60, Loss: 0.2544, Val Loss: 0.0919\n",
      "Epoch 59/60, Loss: 0.1080, Val Loss: 0.0907\n",
      "Epoch 21/60, Loss: 0.1529, Val Loss: 0.0931\n",
      "Epoch 16/60, Loss: 0.1774, Val Loss: 0.0954\n",
      "Epoch 28/60, Loss: 0.1189, Val Loss: 0.0907\n",
      "Epoch 13/60, Loss: 0.1671, Val Loss: 0.0910\n",
      "Epoch 13/60, Loss: 0.2216, Val Loss: 0.0933\n",
      "Epoch 23/60, Loss: 0.1328, Val Loss: 0.0907\n",
      "Epoch 34/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 16/60, Loss: 0.1044, Val Loss: 0.0906\n",
      "Epoch 23/60, Loss: 0.1232, Val Loss: 0.0916\n",
      "Epoch 23/60, Loss: 0.1071, Val Loss: 0.0900\n",
      "Epoch 14/60, Loss: 0.1296, Val Loss: 0.0922\n",
      "Epoch 22/60, Loss: 0.1581, Val Loss: 0.0914\n",
      "Epoch 60/60, Loss: 0.1071, Val Loss: 0.0907\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0871\n",
      "[Trial 41] Validation Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 12:34:21,439] Trial 41 finished with value: 0.09068256864945094 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.1294508616387914e-05, 'batch_size': 32, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 57] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 0.00011561945744604013, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 17/60, Loss: 0.1756, Val Loss: 0.0906\n",
      "Epoch 11/60, Loss: 0.2284, Val Loss: 0.0913\n",
      "Epoch 22/60, Loss: 0.1453, Val Loss: 0.0929\n",
      "Epoch 17/60, Loss: 0.1681, Val Loss: 0.0951\n",
      "Epoch 29/60, Loss: 0.1157, Val Loss: 0.0904\n",
      "Epoch 14/60, Loss: 0.1562, Val Loss: 0.0905\n",
      "Epoch 14/60, Loss: 0.2031, Val Loss: 0.0926\n",
      "Epoch 24/60, Loss: 0.1280, Val Loss: 0.0905\n",
      "Epoch 17/60, Loss: 0.1022, Val Loss: 0.0905\n",
      "Epoch 24/60, Loss: 0.1191, Val Loss: 0.0914\n",
      "Epoch 24/60, Loss: 0.1052, Val Loss: 0.0899\n",
      "Epoch 15/60, Loss: 0.1225, Val Loss: 0.0919\n",
      "Epoch 23/60, Loss: 0.1522, Val Loss: 0.0911\n",
      "Epoch 18/60, Loss: 0.1670, Val Loss: 0.0903\n",
      "Epoch 12/60, Loss: 0.2080, Val Loss: 0.0906\n",
      "Epoch 1/60, Loss: 0.6133, Val Loss: 0.0939\n",
      "Epoch 23/60, Loss: 0.1398, Val Loss: 0.0926\n",
      "Epoch 18/60, Loss: 0.1597, Val Loss: 0.0948\n",
      "Epoch 30/60, Loss: 0.1128, Val Loss: 0.0904\n",
      "Epoch 15/60, Loss: 0.1892, Val Loss: 0.0923\n",
      "Epoch 15/60, Loss: 0.1471, Val Loss: 0.0902\n",
      "Epoch 35/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.1244, Val Loss: 0.0903\n",
      "Epoch 18/60, Loss: 0.1002, Val Loss: 0.0903\n",
      "Epoch 25/60, Loss: 0.1153, Val Loss: 0.0912\n",
      "Epoch 16/60, Loss: 0.1177, Val Loss: 0.0917\n",
      "Epoch 25/60, Loss: 0.1033, Val Loss: 0.0898\n",
      "Epoch 24/60, Loss: 0.1473, Val Loss: 0.0908\n",
      "Epoch 19/60, Loss: 0.1583, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 13/60, Loss: 0.1918, Val Loss: 0.0903\n",
      "Epoch 2/60, Loss: 0.1643, Val Loss: 0.0890\n",
      "Epoch 24/60, Loss: 0.1353, Val Loss: 0.0924\n",
      "Epoch 19/60, Loss: 0.1526, Val Loss: 0.0945\n",
      "Epoch 31/60, Loss: 0.1108, Val Loss: 0.0903\n",
      "Epoch 16/60, Loss: 0.1761, Val Loss: 0.0919\n",
      "Epoch 26/60, Loss: 0.1205, Val Loss: 0.0900\n",
      "Epoch 16/60, Loss: 0.1406, Val Loss: 0.0898\n",
      "Epoch 19/60, Loss: 0.0986, Val Loss: 0.0902\n",
      "Epoch 17/60, Loss: 0.1139, Val Loss: 0.0914\n",
      "Epoch 26/60, Loss: 0.1127, Val Loss: 0.0910\n",
      "Epoch 26/60, Loss: 0.1012, Val Loss: 0.0897\n",
      "Epoch 25/60, Loss: 0.1408, Val Loss: 0.0906\n",
      "Epoch 20/60, Loss: 0.1500, Val Loss: 0.0898\n",
      "Epoch 14/60, Loss: 0.1771, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.1180, Val Loss: 0.0879\n",
      "Epoch 25/60, Loss: 0.1304, Val Loss: 0.0922\n",
      "Epoch 20/60, Loss: 0.1457, Val Loss: 0.0942\n",
      "Epoch 32/60, Loss: 0.1085, Val Loss: 0.0902\n",
      "Epoch 17/60, Loss: 0.1661, Val Loss: 0.0916\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 27/60, Loss: 0.1164, Val Loss: 0.0898\n",
      "Epoch 17/60, Loss: 0.1331, Val Loss: 0.0896\n",
      "Epoch 18/60, Loss: 0.1104, Val Loss: 0.0912\n",
      "Epoch 20/60, Loss: 0.0973, Val Loss: 0.0903\n",
      "Epoch 27/60, Loss: 0.1100, Val Loss: 0.0909\n",
      "Epoch 27/60, Loss: 0.1001, Val Loss: 0.0897\n",
      "Epoch 26/60, Loss: 0.1360, Val Loss: 0.0904\n",
      "Epoch 21/60, Loss: 0.1435, Val Loss: 0.0896\n",
      "Epoch 15/60, Loss: 0.1663, Val Loss: 0.0895\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 26/60, Loss: 0.1267, Val Loss: 0.0920\n",
      "Epoch 4/60, Loss: 0.1042, Val Loss: 0.0873\n",
      "Epoch 21/60, Loss: 0.1405, Val Loss: 0.0939\n",
      "Epoch 18/60, Loss: 0.1564, Val Loss: 0.0912\n",
      "Epoch 33/60, Loss: 0.1066, Val Loss: 0.0900\n",
      "Epoch 28/60, Loss: 0.1137, Val Loss: 0.0897\n",
      "Epoch 18/60, Loss: 0.1281, Val Loss: 0.0893\n",
      "Epoch 19/60, Loss: 0.1073, Val Loss: 0.0911\n",
      "Epoch 21/60, Loss: 0.0961, Val Loss: 0.0902\n",
      "Epoch 28/60, Loss: 0.1079, Val Loss: 0.0908\n",
      "Epoch 28/60, Loss: 0.0988, Val Loss: 0.0897\n",
      "Epoch 27/60, Loss: 0.1313, Val Loss: 0.0901\n",
      "Epoch 22/60, Loss: 0.1384, Val Loss: 0.0893\n",
      "Epoch 16/60, Loss: 0.1572, Val Loss: 0.0891\n",
      "Epoch 27/60, Loss: 0.1231, Val Loss: 0.0918\n",
      "Epoch 5/60, Loss: 0.0987, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.1344, Val Loss: 0.0937\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 19/60, Loss: 0.1484, Val Loss: 0.0910\n",
      "Epoch 34/60, Loss: 0.1047, Val Loss: 0.0899\n",
      "Epoch 29/60, Loss: 0.1113, Val Loss: 0.0896\n",
      "Epoch 20/60, Loss: 0.1050, Val Loss: 0.0910\n",
      "Epoch 19/60, Loss: 0.1232, Val Loss: 0.0891\n",
      "Epoch 22/60, Loss: 0.0951, Val Loss: 0.0900\n",
      "Epoch 29/60, Loss: 0.0975, Val Loss: 0.0895\n",
      "Epoch 29/60, Loss: 0.1059, Val Loss: 0.0907\n",
      "Epoch 28/60, Loss: 0.1272, Val Loss: 0.0898\n",
      "Epoch 23/60, Loss: 0.1327, Val Loss: 0.0891\n",
      "Epoch 17/60, Loss: 0.1492, Val Loss: 0.0888\n",
      "Epoch 28/60, Loss: 0.1191, Val Loss: 0.0916\n",
      "Epoch 6/60, Loss: 0.0953, Val Loss: 0.0874\n",
      "Epoch 23/60, Loss: 0.1301, Val Loss: 0.0935\n",
      "Epoch 20/60, Loss: 0.1413, Val Loss: 0.0907\n",
      "Epoch 30/60, Loss: 0.1090, Val Loss: 0.0894\n",
      "Epoch 35/60, Loss: 0.1031, Val Loss: 0.0898\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 21/60, Loss: 0.1027, Val Loss: 0.0909\n",
      "Epoch 20/60, Loss: 0.1195, Val Loss: 0.0889\n",
      "Epoch 23/60, Loss: 0.0943, Val Loss: 0.0900\n",
      "Epoch 30/60, Loss: 0.0968, Val Loss: 0.0895\n",
      "Epoch 29/60, Loss: 0.1243, Val Loss: 0.0897\n",
      "Epoch 30/60, Loss: 0.1039, Val Loss: 0.0907\n",
      "Epoch 24/60, Loss: 0.1281, Val Loss: 0.0889\n",
      "Epoch 18/60, Loss: 0.1412, Val Loss: 0.0885\n",
      "Epoch 29/60, Loss: 0.1158, Val Loss: 0.0914\n",
      "Epoch 7/60, Loss: 0.0938, Val Loss: 0.0868\n",
      "Epoch 38/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.1261, Val Loss: 0.0932\n",
      "Epoch 21/60, Loss: 0.1359, Val Loss: 0.0903\n",
      "Epoch 31/60, Loss: 0.1071, Val Loss: 0.0893\n",
      "Epoch 36/60, Loss: 0.1019, Val Loss: 0.0898\n",
      "Epoch 22/60, Loss: 0.1011, Val Loss: 0.0908\n",
      "Epoch 21/60, Loss: 0.1157, Val Loss: 0.0888\n",
      "Epoch 30/60, Loss: 0.1201, Val Loss: 0.0895\n",
      "Epoch 31/60, Loss: 0.0956, Val Loss: 0.0894\n",
      "Epoch 24/60, Loss: 0.0934, Val Loss: 0.0900\n",
      "Epoch 31/60, Loss: 0.1026, Val Loss: 0.0906\n",
      "Epoch 25/60, Loss: 0.1242, Val Loss: 0.0886\n",
      "Epoch 19/60, Loss: 0.1349, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.1138, Val Loss: 0.0912\n",
      "Epoch 8/60, Loss: 0.0926, Val Loss: 0.0869\n",
      "Epoch 25/60, Loss: 0.1221, Val Loss: 0.0930\n",
      "Epoch 22/60, Loss: 0.1306, Val Loss: 0.0900\n",
      "Epoch 32/60, Loss: 0.1055, Val Loss: 0.0894\n",
      "Epoch 37/60, Loss: 0.1006, Val Loss: 0.0897\n",
      "Epoch 23/60, Loss: 0.0993, Val Loss: 0.0907\n",
      "Epoch 22/60, Loss: 0.1124, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 31/60, Loss: 0.1171, Val Loss: 0.0893\n",
      "Epoch 32/60, Loss: 0.0946, Val Loss: 0.0895\n",
      "Epoch 25/60, Loss: 0.0926, Val Loss: 0.0899\n",
      "Epoch 32/60, Loss: 0.1010, Val Loss: 0.0905\n",
      "Epoch 26/60, Loss: 0.1203, Val Loss: 0.0885\n",
      "Epoch 20/60, Loss: 0.1294, Val Loss: 0.0879\n",
      "Epoch 31/60, Loss: 0.1112, Val Loss: 0.0911\n",
      "Epoch 9/60, Loss: 0.0917, Val Loss: 0.0869\n",
      "Epoch 39/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 23/60, Loss: 0.1257, Val Loss: 0.0899\n",
      "Epoch 26/60, Loss: 0.1185, Val Loss: 0.0928\n",
      "Epoch 33/60, Loss: 0.1037, Val Loss: 0.0892\n",
      "Epoch 38/60, Loss: 0.0993, Val Loss: 0.0896\n",
      "Epoch 24/60, Loss: 0.0981, Val Loss: 0.0906\n",
      "Epoch 23/60, Loss: 0.1099, Val Loss: 0.0886\n",
      "Epoch 32/60, Loss: 0.1145, Val Loss: 0.0891\n",
      "Epoch 33/60, Loss: 0.0939, Val Loss: 0.0894\n",
      "Epoch 26/60, Loss: 0.0923, Val Loss: 0.0899\n",
      "Epoch 33/60, Loss: 0.0992, Val Loss: 0.0904\n",
      "Epoch 27/60, Loss: 0.1169, Val Loss: 0.0884\n",
      "Epoch 21/60, Loss: 0.1249, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.1087, Val Loss: 0.0909\n",
      "Epoch 10/60, Loss: 0.0912, Val Loss: 0.0871\n",
      "Epoch 24/60, Loss: 0.1213, Val Loss: 0.0896\n",
      "Epoch 27/60, Loss: 0.1159, Val Loss: 0.0926\n",
      "Epoch 34/60, Loss: 0.1023, Val Loss: 0.0891\n",
      "Epoch 39/60, Loss: 0.0985, Val Loss: 0.0896\n",
      "Epoch 25/60, Loss: 0.0969, Val Loss: 0.0906\n",
      "Epoch 33/60, Loss: 0.1119, Val Loss: 0.0890\n",
      "Epoch 34/60, Loss: 0.0935, Val Loss: 0.0893\n",
      "Epoch 24/60, Loss: 0.1074, Val Loss: 0.0884\n",
      "Epoch 27/60, Loss: 0.0917, Val Loss: 0.0899\n",
      "Epoch 34/60, Loss: 0.0984, Val Loss: 0.0904\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0870\n",
      "Epoch 28/60, Loss: 0.1140, Val Loss: 0.0882\n",
      "Epoch 22/60, Loss: 0.1203, Val Loss: 0.0875\n",
      "Epoch 33/60, Loss: 0.1071, Val Loss: 0.0908\n",
      "Epoch 40/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 11/60, Loss: 0.0907, Val Loss: 0.0867\n",
      "Epoch 25/60, Loss: 0.1182, Val Loss: 0.0893\n",
      "Epoch 35/60, Loss: 0.1008, Val Loss: 0.0891\n",
      "Epoch 28/60, Loss: 0.1124, Val Loss: 0.0924\n",
      "Epoch 40/60, Loss: 0.0977, Val Loss: 0.0896\n",
      "Epoch 26/60, Loss: 0.0956, Val Loss: 0.0905\n",
      "Epoch 34/60, Loss: 0.1100, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0930, Val Loss: 0.0894\n",
      "Epoch 25/60, Loss: 0.1053, Val Loss: 0.0883\n",
      "Epoch 28/60, Loss: 0.0915, Val Loss: 0.0899\n",
      "Epoch 35/60, Loss: 0.0975, Val Loss: 0.0904\n",
      "Epoch 29/60, Loss: 0.1115, Val Loss: 0.0881\n",
      "Epoch 23/60, Loss: 0.1166, Val Loss: 0.0872\n",
      "Epoch 34/60, Loss: 0.1050, Val Loss: 0.0907\n",
      "Epoch 12/60, Loss: 0.0904, Val Loss: 0.0869\n",
      "Epoch 26/60, Loss: 0.1148, Val Loss: 0.0892\n",
      "Epoch 36/60, Loss: 0.0995, Val Loss: 0.0890\n",
      "Epoch 29/60, Loss: 0.1101, Val Loss: 0.0922\n",
      "Epoch 27/60, Loss: 0.0951, Val Loss: 0.0905\n",
      "Epoch 41/60, Loss: 0.0965, Val Loss: 0.0895\n",
      "Epoch 35/60, Loss: 0.1078, Val Loss: 0.0889\n",
      "Epoch 36/60, Loss: 0.0924, Val Loss: 0.0893\n",
      "Epoch 26/60, Loss: 0.1034, Val Loss: 0.0883\n",
      "Epoch 29/60, Loss: 0.0908, Val Loss: 0.0898\n",
      "Epoch 36/60, Loss: 0.0965, Val Loss: 0.0903\n",
      "Epoch 30/60, Loss: 0.1089, Val Loss: 0.0880\n",
      "Epoch 24/60, Loss: 0.1142, Val Loss: 0.0871\n",
      "Epoch 35/60, Loss: 0.1035, Val Loss: 0.0906\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0871\n",
      "Epoch 27/60, Loss: 0.1122, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0904, Val Loss: 0.0866\n",
      "Epoch 37/60, Loss: 0.0985, Val Loss: 0.0890\n",
      "Epoch 30/60, Loss: 0.1082, Val Loss: 0.0920\n",
      "Epoch 28/60, Loss: 0.0942, Val Loss: 0.0905\n",
      "Epoch 42/60, Loss: 0.0960, Val Loss: 0.0895\n",
      "Epoch 36/60, Loss: 0.1060, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0924, Val Loss: 0.0893\n",
      "Epoch 27/60, Loss: 0.1019, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0906, Val Loss: 0.0897\n",
      "Epoch 37/60, Loss: 0.0955, Val Loss: 0.0903\n",
      "Epoch 31/60, Loss: 0.1074, Val Loss: 0.0881\n",
      "Epoch 25/60, Loss: 0.1109, Val Loss: 0.0870\n",
      "Epoch 36/60, Loss: 0.1023, Val Loss: 0.0905\n",
      "Epoch 28/60, Loss: 0.1095, Val Loss: 0.0890\n",
      "Epoch 38/60, Loss: 0.0975, Val Loss: 0.0889\n",
      "Epoch 14/60, Loss: 0.0901, Val Loss: 0.0865\n",
      "Epoch 31/60, Loss: 0.1061, Val Loss: 0.0919\n",
      "Epoch 29/60, Loss: 0.0932, Val Loss: 0.0904\n",
      "Epoch 43/60, Loss: 0.0951, Val Loss: 0.0895\n",
      "Epoch 37/60, Loss: 0.1045, Val Loss: 0.0887\n",
      "Epoch 38/60, Loss: 0.0918, Val Loss: 0.0892\n",
      "Epoch 28/60, Loss: 0.1001, Val Loss: 0.0881\n",
      "Epoch 31/60, Loss: 0.0902, Val Loss: 0.0897\n",
      "Epoch 38/60, Loss: 0.0950, Val Loss: 0.0903\n",
      "Epoch 32/60, Loss: 0.1051, Val Loss: 0.0879\n",
      "Epoch 26/60, Loss: 0.1087, Val Loss: 0.0868\n",
      "Epoch 42/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 37/60, Loss: 0.1006, Val Loss: 0.0905\n",
      "Epoch 29/60, Loss: 0.1072, Val Loss: 0.0889\n",
      "Epoch 39/60, Loss: 0.0966, Val Loss: 0.0889\n",
      "Epoch 15/60, Loss: 0.0897, Val Loss: 0.0867\n",
      "Epoch 32/60, Loss: 0.1042, Val Loss: 0.0918\n",
      "Epoch 30/60, Loss: 0.0931, Val Loss: 0.0903\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0871\n",
      "Epoch 44/60, Loss: 0.0946, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.1029, Val Loss: 0.0887\n",
      "Epoch 39/60, Loss: 0.0912, Val Loss: 0.0893\n",
      "Epoch 32/60, Loss: 0.0901, Val Loss: 0.0897\n",
      "Epoch 29/60, Loss: 0.0990, Val Loss: 0.0881\n",
      "Epoch 39/60, Loss: 0.0941, Val Loss: 0.0902\n",
      "Epoch 33/60, Loss: 0.1036, Val Loss: 0.0879\n",
      "Epoch 27/60, Loss: 0.1066, Val Loss: 0.0868\n",
      "Epoch 38/60, Loss: 0.0997, Val Loss: 0.0905\n",
      "Epoch 30/60, Loss: 0.1053, Val Loss: 0.0888\n",
      "Epoch 40/60, Loss: 0.0959, Val Loss: 0.0888\n",
      "Epoch 33/60, Loss: 0.1025, Val Loss: 0.0917\n",
      "Epoch 16/60, Loss: 0.0897, Val Loss: 0.0863\n",
      "Epoch 31/60, Loss: 0.0923, Val Loss: 0.0903\n",
      "Epoch 45/60, Loss: 0.0941, Val Loss: 0.0894\n",
      "Epoch 39/60, Loss: 0.1016, Val Loss: 0.0886\n",
      "Epoch 40/60, Loss: 0.0912, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0898, Val Loss: 0.0897\n",
      "Epoch 30/60, Loss: 0.0982, Val Loss: 0.0881\n",
      "Epoch 40/60, Loss: 0.0936, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.1018, Val Loss: 0.0878\n",
      "Epoch 43/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 28/60, Loss: 0.1045, Val Loss: 0.0867\n",
      "Epoch 39/60, Loss: 0.0984, Val Loss: 0.0904\n",
      "Epoch 31/60, Loss: 0.1034, Val Loss: 0.0887\n",
      "Epoch 41/60, Loss: 0.0951, Val Loss: 0.0888\n",
      "Epoch 34/60, Loss: 0.1008, Val Loss: 0.0916\n",
      "Epoch 17/60, Loss: 0.0894, Val Loss: 0.0862\n",
      "Epoch 32/60, Loss: 0.0917, Val Loss: 0.0903\n",
      "Epoch 46/60, Loss: 0.0934, Val Loss: 0.0894\n",
      "Epoch 40/60, Loss: 0.1006, Val Loss: 0.0886\n",
      "Epoch 41/60, Loss: 0.0906, Val Loss: 0.0893\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0870\n",
      "Epoch 41/60, Loss: 0.0930, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.0896, Val Loss: 0.0897\n",
      "Epoch 31/60, Loss: 0.0969, Val Loss: 0.0880\n",
      "Epoch 35/60, Loss: 0.1005, Val Loss: 0.0878\n",
      "Epoch 29/60, Loss: 0.1027, Val Loss: 0.0866\n",
      "Epoch 40/60, Loss: 0.0976, Val Loss: 0.0903\n",
      "Epoch 42/60, Loss: 0.0947, Val Loss: 0.0888\n",
      "Epoch 32/60, Loss: 0.1021, Val Loss: 0.0887\n",
      "Epoch 35/60, Loss: 0.0999, Val Loss: 0.0915\n",
      "Epoch 33/60, Loss: 0.0916, Val Loss: 0.0902\n",
      "Epoch 47/60, Loss: 0.0930, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0892, Val Loss: 0.0864\n",
      "Epoch 41/60, Loss: 0.0993, Val Loss: 0.0885\n",
      "Epoch 42/60, Loss: 0.0906, Val Loss: 0.0891\n",
      "Epoch 42/60, Loss: 0.0928, Val Loss: 0.0902\n",
      "Epoch 35/60, Loss: 0.0896, Val Loss: 0.0897\n",
      "Epoch 32/60, Loss: 0.0961, Val Loss: 0.0880\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 36/60, Loss: 0.0995, Val Loss: 0.0877\n",
      "Epoch 41/60, Loss: 0.0964, Val Loss: 0.0903\n",
      "Epoch 30/60, Loss: 0.1014, Val Loss: 0.0866\n",
      "Epoch 43/60, Loss: 0.0941, Val Loss: 0.0888\n",
      "Epoch 33/60, Loss: 0.1002, Val Loss: 0.0886\n",
      "Epoch 36/60, Loss: 0.0987, Val Loss: 0.0915\n",
      "Epoch 34/60, Loss: 0.0913, Val Loss: 0.0902\n",
      "Epoch 48/60, Loss: 0.0927, Val Loss: 0.0894\n",
      "Epoch 42/60, Loss: 0.0987, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0902, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0893, Val Loss: 0.0864\n",
      "Epoch 43/60, Loss: 0.0921, Val Loss: 0.0901\n",
      "Epoch 36/60, Loss: 0.0894, Val Loss: 0.0897\n",
      "Epoch 33/60, Loss: 0.0953, Val Loss: 0.0879\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 42/60, Loss: 0.0959, Val Loss: 0.0903\n",
      "Epoch 37/60, Loss: 0.0983, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.1001, Val Loss: 0.0865\n",
      "Epoch 44/60, Loss: 0.0936, Val Loss: 0.0887\n",
      "Epoch 34/60, Loss: 0.0995, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0979, Val Loss: 0.0914\n",
      "Epoch 35/60, Loss: 0.0908, Val Loss: 0.0902\n",
      "Epoch 49/60, Loss: 0.0923, Val Loss: 0.0893\n",
      "Epoch 44/60, Loss: 0.0901, Val Loss: 0.0892\n",
      "Epoch 43/60, Loss: 0.0976, Val Loss: 0.0884\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0861\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 44/60, Loss: 0.0920, Val Loss: 0.0901\n",
      "Epoch 37/60, Loss: 0.0894, Val Loss: 0.0897\n",
      "Epoch 34/60, Loss: 0.0947, Val Loss: 0.0879\n",
      "Epoch 43/60, Loss: 0.0951, Val Loss: 0.0902\n",
      "Epoch 38/60, Loss: 0.0977, Val Loss: 0.0877\n",
      "Epoch 32/60, Loss: 0.0986, Val Loss: 0.0865\n",
      "Epoch 45/60, Loss: 0.0930, Val Loss: 0.0887\n",
      "Epoch 35/60, Loss: 0.0981, Val Loss: 0.0885\n",
      "Epoch 38/60, Loss: 0.0967, Val Loss: 0.0914\n",
      "Epoch 36/60, Loss: 0.0905, Val Loss: 0.0902\n",
      "Epoch 50/60, Loss: 0.0917, Val Loss: 0.0893\n",
      "Epoch 45/60, Loss: 0.0901, Val Loss: 0.0892\n",
      "Epoch 44/60, Loss: 0.0968, Val Loss: 0.0884\n",
      "Epoch 45/60, Loss: 0.0917, Val Loss: 0.0901\n",
      "Epoch 38/60, Loss: 0.0890, Val Loss: 0.0896\n",
      "Epoch 21/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 35/60, Loss: 0.0942, Val Loss: 0.0879\n",
      "Epoch 44/60, Loss: 0.0945, Val Loss: 0.0902\n",
      "Epoch 39/60, Loss: 0.0967, Val Loss: 0.0876\n",
      "Epoch 46/60, Loss: 0.0926, Val Loss: 0.0887\n",
      "Epoch 33/60, Loss: 0.0980, Val Loss: 0.0865\n",
      "Epoch 36/60, Loss: 0.0972, Val Loss: 0.0885\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0870\n",
      "Epoch 39/60, Loss: 0.0960, Val Loss: 0.0913\n",
      "Epoch 37/60, Loss: 0.0900, Val Loss: 0.0901\n",
      "Epoch 51/60, Loss: 0.0917, Val Loss: 0.0893\n",
      "Epoch 46/60, Loss: 0.0897, Val Loss: 0.0891\n",
      "Epoch 45/60, Loss: 0.0962, Val Loss: 0.0884\n",
      "Epoch 46/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 46/60, Loss: 0.0909, Val Loss: 0.0901\n",
      "Epoch 39/60, Loss: 0.0892, Val Loss: 0.0896\n",
      "Epoch 45/60, Loss: 0.0939, Val Loss: 0.0902\n",
      "Epoch 36/60, Loss: 0.0937, Val Loss: 0.0879\n",
      "Epoch 47/60, Loss: 0.0925, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0963, Val Loss: 0.0885\n",
      "Epoch 40/60, Loss: 0.0959, Val Loss: 0.0875\n",
      "Epoch 34/60, Loss: 0.0969, Val Loss: 0.0864\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0861\n",
      "Epoch 38/60, Loss: 0.0901, Val Loss: 0.0901\n",
      "Epoch 40/60, Loss: 0.0949, Val Loss: 0.0913\n",
      "Epoch 47/60, Loss: 0.0897, Val Loss: 0.0891\n",
      "Epoch 52/60, Loss: 0.0912, Val Loss: 0.0893\n",
      "Epoch 46/60, Loss: 0.0952, Val Loss: 0.0883\n",
      "Epoch 47/60, Loss: 0.0907, Val Loss: 0.0900\n",
      "Epoch 46/60, Loss: 0.0936, Val Loss: 0.0902\n",
      "Epoch 40/60, Loss: 0.0891, Val Loss: 0.0895\n",
      "Epoch 48/60, Loss: 0.0919, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0930, Val Loss: 0.0879\n",
      "Epoch 38/60, Loss: 0.0957, Val Loss: 0.0884\n",
      "Epoch 35/60, Loss: 0.0962, Val Loss: 0.0864\n",
      "Epoch 41/60, Loss: 0.0952, Val Loss: 0.0875\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0860\n",
      "Epoch 39/60, Loss: 0.0901, Val Loss: 0.0901\n",
      "Epoch 41/60, Loss: 0.0946, Val Loss: 0.0912\n",
      "Epoch 48/60, Loss: 0.0898, Val Loss: 0.0891\n",
      "Epoch 53/60, Loss: 0.0912, Val Loss: 0.0893\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 47/60, Loss: 0.0946, Val Loss: 0.0883\n",
      "Epoch 47/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 47/60, Loss: 0.0931, Val Loss: 0.0901\n",
      "Epoch 49/60, Loss: 0.0917, Val Loss: 0.0886\n",
      "Epoch 48/60, Loss: 0.0909, Val Loss: 0.0900\n",
      "Epoch 41/60, Loss: 0.0887, Val Loss: 0.0895\n",
      "Epoch 39/60, Loss: 0.0947, Val Loss: 0.0884\n",
      "Epoch 38/60, Loss: 0.0927, Val Loss: 0.0878\n",
      "Epoch 36/60, Loss: 0.0954, Val Loss: 0.0863\n",
      "Epoch 42/60, Loss: 0.0944, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0898, Val Loss: 0.0901\n",
      "Epoch 42/60, Loss: 0.0936, Val Loss: 0.0912\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0860\n",
      "Epoch 49/60, Loss: 0.0896, Val Loss: 0.0891\n",
      "Epoch 54/60, Loss: 0.0909, Val Loss: 0.0892\n",
      "Epoch 48/60, Loss: 0.0943, Val Loss: 0.0883\n",
      "Epoch 50/60, Loss: 0.0914, Val Loss: 0.0886\n",
      "Epoch 48/60, Loss: 0.0924, Val Loss: 0.0901\n",
      "Epoch 49/60, Loss: 0.0907, Val Loss: 0.0900\n",
      "Epoch 40/60, Loss: 0.0943, Val Loss: 0.0884\n",
      "Epoch 42/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 37/60, Loss: 0.0947, Val Loss: 0.0863\n",
      "Epoch 43/60, Loss: 0.0943, Val Loss: 0.0875\n",
      "Epoch 39/60, Loss: 0.0924, Val Loss: 0.0878\n",
      "Epoch 41/60, Loss: 0.0899, Val Loss: 0.0901\n",
      "Epoch 43/60, Loss: 0.0934, Val Loss: 0.0912\n",
      "Epoch 50/60, Loss: 0.0892, Val Loss: 0.0890\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0859\n",
      "Epoch 55/60, Loss: 0.0907, Val Loss: 0.0892\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 49/60, Loss: 0.0937, Val Loss: 0.0882\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 51/60, Loss: 0.0911, Val Loss: 0.0887\n",
      "Epoch 49/60, Loss: 0.0922, Val Loss: 0.0901\n",
      "Epoch 41/60, Loss: 0.0935, Val Loss: 0.0883\n",
      "Epoch 50/60, Loss: 0.0902, Val Loss: 0.0900\n",
      "Epoch 38/60, Loss: 0.0942, Val Loss: 0.0862\n",
      "Epoch 44/60, Loss: 0.0937, Val Loss: 0.0875\n",
      "Epoch 43/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 40/60, Loss: 0.0920, Val Loss: 0.0878\n",
      "Epoch 42/60, Loss: 0.0895, Val Loss: 0.0901\n",
      "Epoch 44/60, Loss: 0.0929, Val Loss: 0.0911\n",
      "Epoch 51/60, Loss: 0.0895, Val Loss: 0.0891\n",
      "Epoch 56/60, Loss: 0.0907, Val Loss: 0.0892\n",
      "Epoch 50/60, Loss: 0.0932, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0885, Val Loss: 0.0859\n",
      "Epoch 52/60, Loss: 0.0909, Val Loss: 0.0886\n",
      "Epoch 50/60, Loss: 0.0917, Val Loss: 0.0901\n",
      "Epoch 42/60, Loss: 0.0933, Val Loss: 0.0883\n",
      "Epoch 51/60, Loss: 0.0900, Val Loss: 0.0900\n",
      "Epoch 39/60, Loss: 0.0936, Val Loss: 0.0863\n",
      "Epoch 45/60, Loss: 0.0929, Val Loss: 0.0874\n",
      "Epoch 41/60, Loss: 0.0915, Val Loss: 0.0878\n",
      "Epoch 43/60, Loss: 0.0894, Val Loss: 0.0901\n",
      "Epoch 44/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 45/60, Loss: 0.0925, Val Loss: 0.0911\n",
      "Epoch 49/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 52/60, Loss: 0.0890, Val Loss: 0.0891\n",
      "Epoch 57/60, Loss: 0.0904, Val Loss: 0.0892\n",
      "Epoch 51/60, Loss: 0.0930, Val Loss: 0.0882\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0859\n",
      "Epoch 53/60, Loss: 0.0908, Val Loss: 0.0886\n",
      "Epoch 51/60, Loss: 0.0917, Val Loss: 0.0900\n",
      "Epoch 43/60, Loss: 0.0926, Val Loss: 0.0883\n",
      "Epoch 52/60, Loss: 0.0899, Val Loss: 0.0900\n",
      "Epoch 46/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 46/60, Loss: 0.0927, Val Loss: 0.0874\n",
      "Epoch 40/60, Loss: 0.0934, Val Loss: 0.0862\n",
      "Epoch 42/60, Loss: 0.0912, Val Loss: 0.0877\n",
      "Epoch 44/60, Loss: 0.0891, Val Loss: 0.0902\n",
      "Epoch 46/60, Loss: 0.0920, Val Loss: 0.0911\n",
      "Epoch 45/60, Loss: 0.0889, Val Loss: 0.0895\n",
      "Epoch 53/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 52/60, Loss: 0.0926, Val Loss: 0.0882\n",
      "Epoch 58/60, Loss: 0.0901, Val Loss: 0.0892\n",
      "Epoch 54/60, Loss: 0.0906, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0910, Val Loss: 0.0900\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0860\n",
      "Epoch 44/60, Loss: 0.0924, Val Loss: 0.0883\n",
      "Epoch 53/60, Loss: 0.0899, Val Loss: 0.0899\n",
      "Epoch 47/60, Loss: 0.0925, Val Loss: 0.0874\n",
      "Epoch 41/60, Loss: 0.0931, Val Loss: 0.0862\n",
      "Epoch 45/60, Loss: 0.0890, Val Loss: 0.0900\n",
      "Epoch 43/60, Loss: 0.0911, Val Loss: 0.0877\n",
      "Epoch 47/60, Loss: 0.0917, Val Loss: 0.0911\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 46/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 54/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 53/60, Loss: 0.0922, Val Loss: 0.0881\n",
      "Epoch 59/60, Loss: 0.0899, Val Loss: 0.0892\n",
      "Epoch 55/60, Loss: 0.0903, Val Loss: 0.0886\n",
      "Epoch 53/60, Loss: 0.0909, Val Loss: 0.0900\n",
      "Epoch 45/60, Loss: 0.0920, Val Loss: 0.0883\n",
      "Epoch 29/60, Loss: 0.0886, Val Loss: 0.0858\n",
      "Epoch 54/60, Loss: 0.0895, Val Loss: 0.0899\n",
      "Epoch 48/60, Loss: 0.0919, Val Loss: 0.0873\n",
      "Epoch 42/60, Loss: 0.0923, Val Loss: 0.0862\n",
      "Epoch 46/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "Epoch 44/60, Loss: 0.0910, Val Loss: 0.0878\n",
      "Epoch 48/60, Loss: 0.0911, Val Loss: 0.0911\n",
      "Epoch 47/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 55/60, Loss: 0.0890, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0886, Val Loss: 0.0894\n",
      "Epoch 54/60, Loss: 0.0919, Val Loss: 0.0881\n",
      "Epoch 60/60, Loss: 0.0897, Val Loss: 0.0892\n",
      "[Trial 43] Validation Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:12:14,799] Trial 43 finished with value: 0.08917253178854784 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.0505109963833127e-05, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 58] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 96, 'lr': 0.00010402287832023142, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 56/60, Loss: 0.0902, Val Loss: 0.0886\n",
      "Epoch 54/60, Loss: 0.0906, Val Loss: 0.0900\n",
      "Epoch 46/60, Loss: 0.0916, Val Loss: 0.0883\n",
      "Epoch 55/60, Loss: 0.0896, Val Loss: 0.0900\n",
      "Epoch 30/60, Loss: 0.0887, Val Loss: 0.0858\n",
      "Epoch 49/60, Loss: 0.0918, Val Loss: 0.0874\n",
      "Epoch 43/60, Loss: 0.0922, Val Loss: 0.0862\n",
      "Epoch 47/60, Loss: 0.0890, Val Loss: 0.0900\n",
      "Epoch 49/60, Loss: 0.0910, Val Loss: 0.0910\n",
      "Epoch 51/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 45/60, Loss: 0.0907, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 1.1898, Val Loss: 0.1500\n",
      "Epoch 56/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 55/60, Loss: 0.0917, Val Loss: 0.0881\n",
      "Epoch 48/60, Loss: 0.0886, Val Loss: 0.0893\n",
      "Epoch 57/60, Loss: 0.0899, Val Loss: 0.0886\n",
      "Epoch 55/60, Loss: 0.0906, Val Loss: 0.0899\n",
      "Epoch 47/60, Loss: 0.0913, Val Loss: 0.0883\n",
      "Epoch 2/60, Loss: 0.6126, Val Loss: 0.1073\n",
      "Epoch 56/60, Loss: 0.0893, Val Loss: 0.0900\n",
      "Epoch 48/60, Loss: 0.0890, Val Loss: 0.0900\n",
      "Epoch 44/60, Loss: 0.0917, Val Loss: 0.0862\n",
      "Epoch 50/60, Loss: 0.0912, Val Loss: 0.0874\n",
      "Epoch 50/60, Loss: 0.0907, Val Loss: 0.0910\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0858\n",
      "Epoch 46/60, Loss: 0.0903, Val Loss: 0.0877\n",
      "Epoch 3/60, Loss: 0.3810, Val Loss: 0.0972\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0870\n",
      "Epoch 56/60, Loss: 0.0912, Val Loss: 0.0881\n",
      "Epoch 58/60, Loss: 0.0901, Val Loss: 0.0885\n",
      "Epoch 57/60, Loss: 0.0888, Val Loss: 0.0890\n",
      "Epoch 49/60, Loss: 0.0884, Val Loss: 0.0893\n",
      "Epoch 56/60, Loss: 0.0902, Val Loss: 0.0900\n",
      "Epoch 48/60, Loss: 0.0911, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.2631, Val Loss: 0.0930\n",
      "Epoch 57/60, Loss: 0.0893, Val Loss: 0.0899\n",
      "Epoch 52/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 49/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 51/60, Loss: 0.0911, Val Loss: 0.0873\n",
      "Epoch 45/60, Loss: 0.0913, Val Loss: 0.0861\n",
      "Epoch 51/60, Loss: 0.0905, Val Loss: 0.0910\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0859\n",
      "Epoch 47/60, Loss: 0.0902, Val Loss: 0.0877\n",
      "Epoch 5/60, Loss: 0.2025, Val Loss: 0.0920\n",
      "Epoch 59/60, Loss: 0.0899, Val Loss: 0.0886\n",
      "Epoch 57/60, Loss: 0.0912, Val Loss: 0.0881\n",
      "Epoch 58/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 50/60, Loss: 0.0883, Val Loss: 0.0892\n",
      "Epoch 57/60, Loss: 0.0900, Val Loss: 0.0900\n",
      "Epoch 49/60, Loss: 0.0909, Val Loss: 0.0882\n",
      "Epoch 6/60, Loss: 0.1689, Val Loss: 0.0909\n",
      "Epoch 58/60, Loss: 0.0893, Val Loss: 0.0899\n",
      "Epoch 52/60, Loss: 0.0908, Val Loss: 0.0872\n",
      "Epoch 52/60, Loss: 0.0904, Val Loss: 0.0910\n",
      "Epoch 46/60, Loss: 0.0914, Val Loss: 0.0862\n",
      "Epoch 50/60, Loss: 0.0888, Val Loss: 0.0900\n",
      "Epoch 48/60, Loss: 0.0900, Val Loss: 0.0877\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0857\n",
      "Epoch 60/60, Loss: 0.0899, Val Loss: 0.0886\n",
      "Epoch 58/60, Loss: 0.0908, Val Loss: 0.0881\n",
      "[Trial 46] Validation Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:16:58,283] Trial 46 finished with value: 0.08854262555638949 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.1423556899358826e-05, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 59] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 0.00012771811589784742, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 7/60, Loss: 0.1477, Val Loss: 0.0903\n",
      "Epoch 59/60, Loss: 0.0887, Val Loss: 0.0889\n",
      "Epoch 58/60, Loss: 0.0900, Val Loss: 0.0899\n",
      "Epoch 50/60, Loss: 0.0906, Val Loss: 0.0882\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 51/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 53/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 59/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 8/60, Loss: 0.1330, Val Loss: 0.0899\n",
      "Epoch 53/60, Loss: 0.0909, Val Loss: 0.0873\n",
      "Epoch 53/60, Loss: 0.0898, Val Loss: 0.0909\n",
      "Epoch 47/60, Loss: 0.0912, Val Loss: 0.0861\n",
      "Epoch 51/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 1/60, Loss: 0.7124, Val Loss: 0.1117\n",
      "Epoch 49/60, Loss: 0.0900, Val Loss: 0.0877\n",
      "Epoch 34/60, Loss: 0.0886, Val Loss: 0.0858\n",
      "Epoch 59/60, Loss: 0.0907, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.1234, Val Loss: 0.0894\n",
      "Epoch 59/60, Loss: 0.0898, Val Loss: 0.0900\n",
      "Epoch 60/60, Loss: 0.0889, Val Loss: 0.0889\n",
      "Epoch 51/60, Loss: 0.0903, Val Loss: 0.0881\n",
      "[Trial 48] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:18:29,621] Trial 48 finished with value: 0.08891931536297003 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.6576653656943163e-05, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60, Loss: 0.2401, Val Loss: 0.0955\n",
      "\n",
      "[Trial 60] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 96, 'lr': 0.0007565545382795885, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 52/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 60/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 54/60, Loss: 0.0907, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0899, Val Loss: 0.0910\n",
      "[Trial 44] Validation Loss: 0.0899\n",
      "Epoch 48/60, Loss: 0.0909, Val Loss: 0.0861\n",
      "Epoch 10/60, Loss: 0.1165, Val Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:18:59,933] Trial 44 finished with value: 0.08991183446099361 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.2539480751152271e-05, 'batch_size': 16, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 61] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.000716115827994906, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 52/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 3/60, Loss: 0.1532, Val Loss: 0.0937\n",
      "Epoch 50/60, Loss: 0.0897, Val Loss: 0.0876\n",
      "Epoch 60/60, Loss: 0.0905, Val Loss: 0.0881\n",
      "Epoch 1/60, Loss: 0.2640, Val Loss: 0.0920\n",
      "[Trial 47] Validation Loss: 0.0881\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:19:30,388] Trial 47 finished with value: 0.08806669948001702 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 1.00120965405112e-05, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 62] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0001238995766825796, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 60/60, Loss: 0.0897, Val Loss: 0.0899\n",
      "Epoch 52/60, Loss: 0.0904, Val Loss: 0.0882\n",
      "[Trial 49] Validation Loss: 0.0899\n",
      "Epoch 11/60, Loss: 0.1115, Val Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:19:42,329] Trial 49 finished with value: 0.08989892651637395 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.0557893689005761e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 63] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'lr': 0.0007902025636598139, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 54/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 53/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.1253, Val Loss: 0.0927\n",
      "Epoch 1/60, Loss: 0.3523, Val Loss: 0.0921\n",
      "Epoch 50/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 2/60, Loss: 0.0944, Val Loss: 0.0904\n",
      "Epoch 55/60, Loss: 0.0896, Val Loss: 0.0910\n",
      "Epoch 55/60, Loss: 0.0907, Val Loss: 0.0872\n",
      "Epoch 49/60, Loss: 0.0906, Val Loss: 0.0861\n",
      "Epoch 12/60, Loss: 0.1079, Val Loss: 0.0884\n",
      "Epoch 53/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 1/60, Loss: 0.7841, Val Loss: 0.1095\n",
      "Epoch 51/60, Loss: 0.0899, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.1123, Val Loss: 0.0924\n",
      "Epoch 2/60, Loss: 0.0990, Val Loss: 0.0897\n",
      "Epoch 1/60, Loss: 0.2578, Val Loss: 0.0920\n",
      "Epoch 53/60, Loss: 0.0902, Val Loss: 0.0881\n",
      "Epoch 3/60, Loss: 0.0909, Val Loss: 0.0900\n",
      "Epoch 36/60, Loss: 0.0886, Val Loss: 0.0858\n",
      "Epoch 13/60, Loss: 0.1043, Val Loss: 0.0881\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0892\n",
      "Epoch 6/60, Loss: 0.1054, Val Loss: 0.0914\n",
      "Epoch 2/60, Loss: 0.2744, Val Loss: 0.0952\n",
      "Epoch 3/60, Loss: 0.0927, Val Loss: 0.0888\n",
      "Epoch 2/60, Loss: 0.0947, Val Loss: 0.0905\n",
      "Epoch 56/60, Loss: 0.0894, Val Loss: 0.0909\n",
      "Epoch 50/60, Loss: 0.0908, Val Loss: 0.0861\n",
      "Epoch 56/60, Loss: 0.0904, Val Loss: 0.0872\n",
      "Epoch 4/60, Loss: 0.0898, Val Loss: 0.0900\n",
      "Epoch 14/60, Loss: 0.1022, Val Loss: 0.0879\n",
      "Epoch 54/60, Loss: 0.0889, Val Loss: 0.0899\n",
      "Epoch 52/60, Loss: 0.0896, Val Loss: 0.0876\n",
      "Epoch 7/60, Loss: 0.1007, Val Loss: 0.0911\n",
      "Epoch 3/60, Loss: 0.1648, Val Loss: 0.0929\n",
      "Epoch 3/60, Loss: 0.0911, Val Loss: 0.0900\n",
      "Epoch 4/60, Loss: 0.0910, Val Loss: 0.0888\n",
      "Epoch 54/60, Loss: 0.0899, Val Loss: 0.0882\n",
      "Epoch 55/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 5/60, Loss: 0.0893, Val Loss: 0.0900\n",
      "Epoch 37/60, Loss: 0.0887, Val Loss: 0.0858\n",
      "Epoch 15/60, Loss: 0.1001, Val Loss: 0.0878\n",
      "Epoch 55/60, Loss: 0.0883, Val Loss: 0.0892\n",
      "Epoch 8/60, Loss: 0.0976, Val Loss: 0.0909\n",
      "Epoch 4/60, Loss: 0.1303, Val Loss: 0.0920\n",
      "Epoch 51/60, Loss: 0.0905, Val Loss: 0.0860\n",
      "Epoch 57/60, Loss: 0.0896, Val Loss: 0.0909\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0870\n",
      "Epoch 4/60, Loss: 0.0899, Val Loss: 0.0899\n",
      "Epoch 57/60, Loss: 0.0903, Val Loss: 0.0873\n",
      "Epoch 5/60, Loss: 0.0903, Val Loss: 0.0892\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0898\n",
      "Epoch 55/60, Loss: 0.0889, Val Loss: 0.0899\n",
      "Epoch 16/60, Loss: 0.0986, Val Loss: 0.0877\n",
      "Epoch 53/60, Loss: 0.0895, Val Loss: 0.0877\n",
      "Epoch 9/60, Loss: 0.0958, Val Loss: 0.0909\n",
      "Epoch 55/60, Loss: 0.0899, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.1144, Val Loss: 0.0913\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0900\n",
      "Epoch 6/60, Loss: 0.0899, Val Loss: 0.0885\n",
      "Epoch 38/60, Loss: 0.0885, Val Loss: 0.0857\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 17/60, Loss: 0.0973, Val Loss: 0.0876\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 52/60, Loss: 0.0906, Val Loss: 0.0861\n",
      "Epoch 58/60, Loss: 0.0893, Val Loss: 0.0909\n",
      "Epoch 10/60, Loss: 0.0944, Val Loss: 0.0907\n",
      "Epoch 58/60, Loss: 0.0902, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.1068, Val Loss: 0.0909\n",
      "Epoch 6/60, Loss: 0.0892, Val Loss: 0.0899\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0886\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0895\n",
      "Epoch 56/60, Loss: 0.0884, Val Loss: 0.0899\n",
      "Epoch 54/60, Loss: 0.0896, Val Loss: 0.0877\n",
      "Epoch 18/60, Loss: 0.0964, Val Loss: 0.0876\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 56/60, Loss: 0.0897, Val Loss: 0.0881\n",
      "Epoch 11/60, Loss: 0.0932, Val Loss: 0.0906\n",
      "Epoch 7/60, Loss: 0.1018, Val Loss: 0.0905\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0897\n",
      "Epoch 8/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0896\n",
      "Epoch 19/60, Loss: 0.0954, Val Loss: 0.0875\n",
      "Epoch 53/60, Loss: 0.0904, Val Loss: 0.0861\n",
      "Epoch 59/60, Loss: 0.0890, Val Loss: 0.0909\n",
      "Epoch 57/60, Loss: 0.0883, Val Loss: 0.0892\n",
      "Epoch 59/60, Loss: 0.0899, Val Loss: 0.0872\n",
      "Epoch 12/60, Loss: 0.0923, Val Loss: 0.0906\n",
      "Epoch 8/60, Loss: 0.0989, Val Loss: 0.0904\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 52/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0883\n",
      "Epoch 57/60, Loss: 0.0885, Val Loss: 0.0898\n",
      "Epoch 55/60, Loss: 0.0894, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 20/60, Loss: 0.0947, Val Loss: 0.0875\n",
      "Epoch 57/60, Loss: 0.0897, Val Loss: 0.0881\n",
      "Epoch 13/60, Loss: 0.0918, Val Loss: 0.0905\n",
      "Epoch 9/60, Loss: 0.0963, Val Loss: 0.0902\n",
      "Epoch 9/60, Loss: 0.0888, Val Loss: 0.0896\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 40/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 54/60, Loss: 0.0902, Val Loss: 0.0861\n",
      "Epoch 60/60, Loss: 0.0891, Val Loss: 0.0909\n",
      "Epoch 21/60, Loss: 0.0940, Val Loss: 0.0875\n",
      "Epoch 11/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "[Trial 52] Validation Loss: 0.0909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:26:42,183] Trial 52 finished with value: 0.09091595734159151 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.1219347413493853e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 64] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0001197966165019995, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 60/60, Loss: 0.0899, Val Loss: 0.0872\n",
      "Epoch 58/60, Loss: 0.0882, Val Loss: 0.0891\n",
      "[Trial 50] Validation Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:26:49,467] Trial 50 finished with value: 0.08719302304089069 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.1870418679160136e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 65] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.000832295763593712, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 14/60, Loss: 0.0913, Val Loss: 0.0904\n",
      "Epoch 10/60, Loss: 0.0948, Val Loss: 0.0902\n",
      "Epoch 57/60, Loss: 0.0875, Val Loss: 0.0884\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0895\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 56/60, Loss: 0.0893, Val Loss: 0.0876\n",
      "Epoch 58/60, Loss: 0.0884, Val Loss: 0.0898\n",
      "Epoch 58/60, Loss: 0.0896, Val Loss: 0.0881\n",
      "Epoch 22/60, Loss: 0.0937, Val Loss: 0.0874\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0893\n",
      "Epoch 1/60, Loss: 0.9318, Val Loss: 0.1083\n",
      "Epoch 15/60, Loss: 0.0908, Val Loss: 0.0905\n",
      "Epoch 1/60, Loss: 0.2988, Val Loss: 0.0932\n",
      "Epoch 11/60, Loss: 0.0936, Val Loss: 0.0901\n",
      "Epoch 11/60, Loss: 0.0884, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 55/60, Loss: 0.0901, Val Loss: 0.0860\n",
      "Epoch 41/60, Loss: 0.0884, Val Loss: 0.0857\n",
      "Epoch 23/60, Loss: 0.0931, Val Loss: 0.0874\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0892\n",
      "Epoch 2/60, Loss: 0.3341, Val Loss: 0.0927\n",
      "Epoch 16/60, Loss: 0.0905, Val Loss: 0.0906\n",
      "Epoch 2/60, Loss: 0.0961, Val Loss: 0.0913\n",
      "Epoch 12/60, Loss: 0.0928, Val Loss: 0.0901\n",
      "Epoch 59/60, Loss: 0.0896, Val Loss: 0.0881\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 57/60, Loss: 0.0894, Val Loss: 0.0876\n",
      "Epoch 59/60, Loss: 0.0883, Val Loss: 0.0898\n",
      "Epoch 24/60, Loss: 0.0927, Val Loss: 0.0874\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 13/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 3/60, Loss: 0.1830, Val Loss: 0.0907\n",
      "Epoch 17/60, Loss: 0.0903, Val Loss: 0.0904\n",
      "Epoch 3/60, Loss: 0.0912, Val Loss: 0.0904\n",
      "Epoch 13/60, Loss: 0.0922, Val Loss: 0.0900\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 56/60, Loss: 0.0901, Val Loss: 0.0860\n",
      "Epoch 25/60, Loss: 0.0925, Val Loss: 0.0873\n",
      "Epoch 58/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0857\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0879, Val Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:30:08,659] Trial 51 finished with value: 0.08914359485109648 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.6669200250467567e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 51] Validation Loss: 0.0891\n",
      "\n",
      "[Trial 66] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.00010183556995112552, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 4/60, Loss: 0.1400, Val Loss: 0.0898\n",
      "Epoch 18/60, Loss: 0.0900, Val Loss: 0.0904\n",
      "Epoch 4/60, Loss: 0.0900, Val Loss: 0.0902\n",
      "Epoch 60/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 14/60, Loss: 0.0917, Val Loss: 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:30:28,464] Trial 55 finished with value: 0.08807083815336228 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.301992263984231e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 55] Validation Loss: 0.0881\n",
      "\n",
      "[Trial 67] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.0007830819550148285, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 58/60, Loss: 0.0893, Val Loss: 0.0875\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0897\n",
      "Epoch 14/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0920, Val Loss: 0.0873\n",
      "[Trial 53] Validation Loss: 0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:30:40,373] Trial 53 finished with value: 0.08974832507471243 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.0613529251193415e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 68] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 9.938570286846068e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 1/60, Loss: 1.4580, Val Loss: 0.2042\n",
      "Epoch 5/60, Loss: 0.1207, Val Loss: 0.0888\n",
      "Epoch 19/60, Loss: 0.0899, Val Loss: 0.0904\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0902\n",
      "Epoch 57/60, Loss: 0.0899, Val Loss: 0.0860\n",
      "Epoch 15/60, Loss: 0.0910, Val Loss: 0.0899\n",
      "Epoch 1/60, Loss: 0.6276, Val Loss: 0.1258\n",
      "Epoch 27/60, Loss: 0.0917, Val Loss: 0.0874\n",
      "Epoch 15/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 1.4907, Val Loss: 0.2144\n",
      "Epoch 2/60, Loss: 0.8893, Val Loss: 0.1420\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0890\n",
      "Epoch 2/60, Loss: 0.1683, Val Loss: 0.0993\n",
      "Epoch 6/60, Loss: 0.1108, Val Loss: 0.0884\n",
      "Epoch 20/60, Loss: 0.0896, Val Loss: 0.0904\n",
      "Epoch 6/60, Loss: 0.0893, Val Loss: 0.0904\n",
      "Epoch 59/60, Loss: 0.0891, Val Loss: 0.0875\n",
      "Epoch 16/60, Loss: 0.0909, Val Loss: 0.0899\n",
      "Epoch 2/60, Loss: 0.9615, Val Loss: 0.1517\n",
      "Epoch 28/60, Loss: 0.0915, Val Loss: 0.0872\n",
      "Epoch 3/60, Loss: 0.6495, Val Loss: 0.1269\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 3/60, Loss: 0.1133, Val Loss: 0.0924\n",
      "Epoch 59/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 18/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 7/60, Loss: 0.1047, Val Loss: 0.0884\n",
      "Epoch 3/60, Loss: 0.7118, Val Loss: 0.1346\n",
      "Epoch 58/60, Loss: 0.0899, Val Loss: 0.0860\n",
      "Epoch 21/60, Loss: 0.0895, Val Loss: 0.0904\n",
      "Epoch 7/60, Loss: 0.0891, Val Loss: 0.0902\n",
      "Epoch 4/60, Loss: 0.4974, Val Loss: 0.1155\n",
      "Epoch 17/60, Loss: 0.0905, Val Loss: 0.0900\n",
      "Epoch 29/60, Loss: 0.0913, Val Loss: 0.0872\n",
      "Epoch 4/60, Loss: 0.1010, Val Loss: 0.0911\n",
      "Epoch 17/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 44/60, Loss: 0.0887, Val Loss: 0.0857\n",
      "Epoch 4/60, Loss: 0.5496, Val Loss: 0.1289\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.1009, Val Loss: 0.0880\n",
      "Epoch 5/60, Loss: 0.3914, Val Loss: 0.1068\n",
      "Epoch 5/60, Loss: 0.0963, Val Loss: 0.0901\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 60/60, Loss: 0.0891, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0892, Val Loss: 0.0906\n",
      "Epoch 30/60, Loss: 0.0911, Val Loss: 0.0872\n",
      "Epoch 18/60, Loss: 0.0904, Val Loss: 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:33:45,086] Trial 54 finished with value: 0.08750862057010332 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 1.2575610775385682e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 54] Validation Loss: 0.0875\n",
      "\n",
      "[Trial 69] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.0008442769348301436, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 5/60, Loss: 0.4288, Val Loss: 0.1250\n",
      "Epoch 18/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 6/60, Loss: 0.3176, Val Loss: 0.1034\n",
      "Epoch 6/60, Loss: 0.0938, Val Loss: 0.0896\n",
      "Epoch 19/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 9/60, Loss: 0.0984, Val Loss: 0.0879\n",
      "Epoch 59/60, Loss: 0.0899, Val Loss: 0.0860\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0899\n",
      "Epoch 23/60, Loss: 0.0892, Val Loss: 0.0903\n",
      "Epoch 1/60, Loss: 0.6070, Val Loss: 0.1076\n",
      "Epoch 31/60, Loss: 0.0909, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.3488, Val Loss: 0.1177\n",
      "Epoch 19/60, Loss: 0.0901, Val Loss: 0.0899\n",
      "Epoch 7/60, Loss: 0.0924, Val Loss: 0.0895\n",
      "Epoch 7/60, Loss: 0.2608, Val Loss: 0.1015\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 45/60, Loss: 0.0884, Val Loss: 0.0856\n",
      "Epoch 10/60, Loss: 0.0965, Val Loss: 0.0878\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 2/60, Loss: 0.1520, Val Loss: 0.0989\n",
      "Epoch 60/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 7/60, Loss: 0.2864, Val Loss: 0.1074\n",
      "Epoch 10/60, Loss: 0.0885, Val Loss: 0.0898\n",
      "Epoch 8/60, Loss: 0.0915, Val Loss: 0.0895\n",
      "Epoch 32/60, Loss: 0.0908, Val Loss: 0.0872\n",
      "Epoch 24/60, Loss: 0.0891, Val Loss: 0.0902\n",
      "[Trial 31] Validation Loss: 0.0883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:35:16,803] Trial 31 finished with value: 0.08826221115887165 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00013483477928033966, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 70] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.000651709835410296, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 20/60, Loss: 0.0897, Val Loss: 0.0898\n",
      "Epoch 8/60, Loss: 0.2256, Val Loss: 0.0997\n",
      "Epoch 3/60, Loss: 0.1106, Val Loss: 0.0910\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 60/60, Loss: 0.0900, Val Loss: 0.0860\n",
      "Epoch 8/60, Loss: 0.2394, Val Loss: 0.1031\n",
      "Epoch 11/60, Loss: 0.0951, Val Loss: 0.0877\n",
      "Epoch 9/60, Loss: 0.0910, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "[Trial 56] Validation Loss: 0.0860\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:35:57,318] Trial 56 finished with value: 0.08597237008313338 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 1.4338641397271748e-05, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 71] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 32, 'lr': 0.0008596724037215931, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 0.6068, Val Loss: 0.1130\n",
      "Epoch 11/60, Loss: 0.0883, Val Loss: 0.0899\n",
      "Epoch 33/60, Loss: 0.0906, Val Loss: 0.0872\n",
      "Epoch 9/60, Loss: 0.1954, Val Loss: 0.0968\n",
      "Epoch 25/60, Loss: 0.0889, Val Loss: 0.0901\n",
      "Epoch 21/60, Loss: 0.0898, Val Loss: 0.0898\n",
      "Epoch 4/60, Loss: 0.0995, Val Loss: 0.0901\n",
      "Epoch 9/60, Loss: 0.2103, Val Loss: 0.1018\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0858\n",
      "Epoch 10/60, Loss: 0.0906, Val Loss: 0.0892\n",
      "Epoch 21/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 2/60, Loss: 0.1769, Val Loss: 0.1005\n",
      "Epoch 12/60, Loss: 0.0942, Val Loss: 0.0878\n",
      "Epoch 10/60, Loss: 0.1719, Val Loss: 0.0948\n",
      "Epoch 5/60, Loss: 0.0955, Val Loss: 0.0892\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 34/60, Loss: 0.0904, Val Loss: 0.0872\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0901\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 1/60, Loss: 0.2552, Val Loss: 0.0909\n",
      "Epoch 22/60, Loss: 0.0896, Val Loss: 0.0897\n",
      "Epoch 10/60, Loss: 0.1841, Val Loss: 0.1006\n",
      "Epoch 11/60, Loss: 0.0902, Val Loss: 0.0890\n",
      "Epoch 6/60, Loss: 0.0931, Val Loss: 0.0888\n",
      "Epoch 3/60, Loss: 0.1196, Val Loss: 0.0951\n",
      "Epoch 11/60, Loss: 0.1562, Val Loss: 0.0938\n",
      "Epoch 22/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 13/60, Loss: 0.0934, Val Loss: 0.0878\n",
      "Epoch 23/60, Loss: 0.0894, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0904, Val Loss: 0.0872\n",
      "Epoch 24/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.1673, Val Loss: 0.0992\n",
      "Epoch 27/60, Loss: 0.0887, Val Loss: 0.0901\n",
      "Epoch 7/60, Loss: 0.0919, Val Loss: 0.0885\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 2/60, Loss: 0.0942, Val Loss: 0.0886\n",
      "Epoch 12/60, Loss: 0.0900, Val Loss: 0.0893\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 4/60, Loss: 0.1040, Val Loss: 0.0939\n",
      "Epoch 12/60, Loss: 0.1438, Val Loss: 0.0932\n",
      "Epoch 24/60, Loss: 0.0892, Val Loss: 0.0897\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 14/60, Loss: 0.0926, Val Loss: 0.0876\n",
      "Epoch 8/60, Loss: 0.0911, Val Loss: 0.0885\n",
      "Epoch 12/60, Loss: 0.1547, Val Loss: 0.0971\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 36/60, Loss: 0.0903, Val Loss: 0.0872\n",
      "Epoch 5/60, Loss: 0.0979, Val Loss: 0.0934\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0898, Val Loss: 0.0889\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0900\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0896\n",
      "Epoch 3/60, Loss: 0.0910, Val Loss: 0.0883\n",
      "Epoch 13/60, Loss: 0.1358, Val Loss: 0.0929\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 25/60, Loss: 0.0891, Val Loss: 0.0896\n",
      "Epoch 6/60, Loss: 0.0950, Val Loss: 0.0929\n",
      "Epoch 13/60, Loss: 0.1429, Val Loss: 0.0939\n",
      "Epoch 9/60, Loss: 0.0907, Val Loss: 0.0884\n",
      "Epoch 15/60, Loss: 0.0921, Val Loss: 0.0876\n",
      "Epoch 14/60, Loss: 0.0897, Val Loss: 0.0891\n",
      "Epoch 37/60, Loss: 0.0901, Val Loss: 0.0872\n",
      "Epoch 26/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 24/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 7/60, Loss: 0.0932, Val Loss: 0.0927\n",
      "Epoch 14/60, Loss: 0.1276, Val Loss: 0.0926\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0901\n",
      "Epoch 26/60, Loss: 0.0890, Val Loss: 0.0895\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0895\n",
      "Epoch 4/60, Loss: 0.0902, Val Loss: 0.0882\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0871\n",
      "Epoch 10/60, Loss: 0.0903, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 14/60, Loss: 0.1339, Val Loss: 0.0925\n",
      "Epoch 8/60, Loss: 0.0919, Val Loss: 0.0924\n",
      "Epoch 15/60, Loss: 0.0895, Val Loss: 0.0890\n",
      "Epoch 48/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 16/60, Loss: 0.0918, Val Loss: 0.0876\n",
      "Epoch 38/60, Loss: 0.0901, Val Loss: 0.0872\n",
      "Epoch 15/60, Loss: 0.1227, Val Loss: 0.0922\n",
      "Epoch 9/60, Loss: 0.0911, Val Loss: 0.0922\n",
      "Epoch 27/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 27/60, Loss: 0.0889, Val Loss: 0.0895\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 11/60, Loss: 0.0902, Val Loss: 0.0884\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0901\n",
      "Epoch 15/60, Loss: 0.1266, Val Loss: 0.0918\n",
      "Epoch 5/60, Loss: 0.0898, Val Loss: 0.0883\n",
      "Epoch 16/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0894, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.0905, Val Loss: 0.0921\n",
      "Epoch 16/60, Loss: 0.1174, Val Loss: 0.0919\n",
      "Epoch 39/60, Loss: 0.0900, Val Loss: 0.0871\n",
      "Epoch 17/60, Loss: 0.0913, Val Loss: 0.0875\n",
      "Epoch 12/60, Loss: 0.0899, Val Loss: 0.0883\n",
      "Epoch 16/60, Loss: 0.1210, Val Loss: 0.0913\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0895\n",
      "Epoch 17/60, Loss: 0.0893, Val Loss: 0.0889\n",
      "Epoch 6/60, Loss: 0.0896, Val Loss: 0.0884\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0899\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 17/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.0901, Val Loss: 0.0920\n",
      "Epoch 17/60, Loss: 0.1134, Val Loss: 0.0918\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 13/60, Loss: 0.0897, Val Loss: 0.0883\n",
      "Epoch 40/60, Loss: 0.0900, Val Loss: 0.0872\n",
      "Epoch 17/60, Loss: 0.1169, Val Loss: 0.0909\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 18/60, Loss: 0.0911, Val Loss: 0.0876\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 18/60, Loss: 0.0893, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0897, Val Loss: 0.0921\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0895\n",
      "Epoch 18/60, Loss: 0.1106, Val Loss: 0.0915\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 18/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0899\n",
      "Epoch 27/60, Loss: 0.0875, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.1132, Val Loss: 0.0905\n",
      "Epoch 14/60, Loss: 0.0896, Val Loss: 0.0882\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 19/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 41/60, Loss: 0.0900, Val Loss: 0.0872\n",
      "Epoch 30/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 13/60, Loss: 0.0895, Val Loss: 0.0918\n",
      "Epoch 19/60, Loss: 0.0908, Val Loss: 0.0875\n",
      "Epoch 19/60, Loss: 0.1080, Val Loss: 0.0913\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0895\n",
      "Epoch 15/60, Loss: 0.0895, Val Loss: 0.0882\n",
      "Epoch 19/60, Loss: 0.1105, Val Loss: 0.0902\n",
      "Epoch 20/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0877\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 14/60, Loss: 0.0893, Val Loss: 0.0919\n",
      "Epoch 28/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 42/60, Loss: 0.0898, Val Loss: 0.0871\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 20/60, Loss: 0.1059, Val Loss: 0.0913\n",
      "Epoch 57/60, Loss: 0.0877, Val Loss: 0.0870\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0857\n",
      "Epoch 20/60, Loss: 0.0906, Val Loss: 0.0874\n",
      "Epoch 16/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0891, Val Loss: 0.0888\n",
      "Epoch 20/60, Loss: 0.1078, Val Loss: 0.0900\n",
      "Epoch 15/60, Loss: 0.0891, Val Loss: 0.0918\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0894\n",
      "Epoch 9/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 21/60, Loss: 0.1039, Val Loss: 0.0911\n",
      "Epoch 34/60, Loss: 0.0883, Val Loss: 0.0898\n",
      "Epoch 43/60, Loss: 0.0897, Val Loss: 0.0871\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 17/60, Loss: 0.0895, Val Loss: 0.0882\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 16/60, Loss: 0.0890, Val Loss: 0.0918\n",
      "Epoch 22/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 21/60, Loss: 0.1061, Val Loss: 0.0896\n",
      "Epoch 21/60, Loss: 0.0904, Val Loss: 0.0873\n",
      "Epoch 17/60, Loss: 0.0887, Val Loss: 0.0918\n",
      "Epoch 22/60, Loss: 0.1023, Val Loss: 0.0910\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0893, Val Loss: 0.0882\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0889\n",
      "Epoch 22/60, Loss: 0.1036, Val Loss: 0.0894\n",
      "Epoch 44/60, Loss: 0.0897, Val Loss: 0.0871\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0898\n",
      "Epoch 30/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 18/60, Loss: 0.0887, Val Loss: 0.0917\n",
      "Epoch 51/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 22/60, Loss: 0.0902, Val Loss: 0.0872\n",
      "Epoch 23/60, Loss: 0.1011, Val Loss: 0.0908\n",
      "Epoch 19/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0888\n",
      "Epoch 23/60, Loss: 0.1020, Val Loss: 0.0892\n",
      "Epoch 34/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0893\n",
      "Epoch 45/60, Loss: 0.0897, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0917\n",
      "Epoch 36/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 24/60, Loss: 0.0997, Val Loss: 0.0907\n",
      "Epoch 31/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 20/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0899, Val Loss: 0.0872\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0888\n",
      "Epoch 24/60, Loss: 0.1009, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0917\n",
      "Epoch 46/60, Loss: 0.0897, Val Loss: 0.0871\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 25/60, Loss: 0.0986, Val Loss: 0.0906\n",
      "Epoch 23/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0888\n",
      "Epoch 21/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 25/60, Loss: 0.0995, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0881, Val Loss: 0.0898\n",
      "Epoch 52/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 24/60, Loss: 0.0898, Val Loss: 0.0872\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0887\n",
      "Early stopping triggered\n",
      "[Trial 63] Validation Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:47:41,316] Trial 63 finished with value: 0.08873625795046489 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'lr': 0.0007902025636598139, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 72] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 32, 'lr': 5.687210714100786e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 21/60, Loss: 0.0885, Val Loss: 0.0917\n",
      "Epoch 26/60, Loss: 0.0978, Val Loss: 0.0906\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0870\n",
      "Epoch 47/60, Loss: 0.0895, Val Loss: 0.0870\n",
      "Epoch 22/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 27/60, Loss: 0.0890, Val Loss: 0.0888\n",
      "Epoch 26/60, Loss: 0.0985, Val Loss: 0.0887\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 24/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0917\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0897\n",
      "Epoch 25/60, Loss: 0.0897, Val Loss: 0.0872\n",
      "Epoch 37/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 27/60, Loss: 0.0969, Val Loss: 0.0905\n",
      "Epoch 1/60, Loss: 1.3345, Val Loss: 0.1873\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0880\n",
      "Epoch 27/60, Loss: 0.0974, Val Loss: 0.0886\n",
      "Epoch 28/60, Loss: 0.0888, Val Loss: 0.0886\n",
      "Epoch 48/60, Loss: 0.0895, Val Loss: 0.0870\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0916\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 28/60, Loss: 0.0961, Val Loss: 0.0904\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 2/60, Loss: 0.8601, Val Loss: 0.1401\n",
      "Epoch 53/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0896, Val Loss: 0.0871\n",
      "Epoch 28/60, Loss: 0.0967, Val Loss: 0.0885\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0896\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 24/60, Loss: 0.0885, Val Loss: 0.0916\n",
      "Epoch 49/60, Loss: 0.0895, Val Loss: 0.0870\n",
      "Epoch 29/60, Loss: 0.0956, Val Loss: 0.0903\n",
      "Epoch 25/60, Loss: 0.0889, Val Loss: 0.0879\n",
      "Epoch 37/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0961, Val Loss: 0.0884\n",
      "Epoch 3/60, Loss: 0.6459, Val Loss: 0.1255\n",
      "Epoch 15/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 27/60, Loss: 0.0894, Val Loss: 0.0871\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0896\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0918\n",
      "Epoch 39/60, Loss: 0.0875, Val Loss: 0.0888\n",
      "Epoch 30/60, Loss: 0.0950, Val Loss: 0.0901\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0879\n",
      "Epoch 50/60, Loss: 0.0894, Val Loss: 0.0870\n",
      "Epoch 30/60, Loss: 0.0954, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0917\n",
      "Epoch 4/60, Loss: 0.4966, Val Loss: 0.1105\n",
      "Epoch 27/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 28/60, Loss: 0.0893, Val Loss: 0.0871\n",
      "Epoch 31/60, Loss: 0.0942, Val Loss: 0.0901\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Early stopping triggered\n",
      "Epoch 16/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0896\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "[Trial 57] Validation Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:51:24,557] Trial 57 finished with value: 0.08565590536842743 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 0.00011561945744604013, 'batch_size': 16, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 73] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 7.198406973830452e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 31/60, Loss: 0.0950, Val Loss: 0.0883\n",
      "Epoch 32/60, Loss: 0.0886, Val Loss: 0.0885\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 51/60, Loss: 0.0893, Val Loss: 0.0869\n",
      "Epoch 27/60, Loss: 0.0883, Val Loss: 0.0916\n",
      "Epoch 5/60, Loss: 0.3890, Val Loss: 0.1054\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 32/60, Loss: 0.0939, Val Loss: 0.0900\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 32/60, Loss: 0.0944, Val Loss: 0.0883\n",
      "Epoch 29/60, Loss: 0.0892, Val Loss: 0.0870\n",
      "Epoch 33/60, Loss: 0.0885, Val Loss: 0.0885\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0915\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 1/60, Loss: 1.0464, Val Loss: 0.1301\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 52/60, Loss: 0.0893, Val Loss: 0.0869\n",
      "Epoch 41/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 6/60, Loss: 0.3148, Val Loss: 0.1033\n",
      "Epoch 33/60, Loss: 0.0934, Val Loss: 0.0899\n",
      "Epoch 29/60, Loss: 0.0888, Val Loss: 0.0878\n",
      "Epoch 33/60, Loss: 0.0939, Val Loss: 0.0883\n",
      "Epoch 34/60, Loss: 0.0886, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0915\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 30/60, Loss: 0.0890, Val Loss: 0.0871\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 53/60, Loss: 0.0892, Val Loss: 0.0868\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 0.4906, Val Loss: 0.1008\n",
      "Epoch 7/60, Loss: 0.2618, Val Loss: 0.1014\n",
      "Epoch 34/60, Loss: 0.0931, Val Loss: 0.0899\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 34/60, Loss: 0.0936, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0888, Val Loss: 0.0878\n",
      "Epoch 35/60, Loss: 0.0886, Val Loss: 0.0884\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0914\n",
      "Epoch 30/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 31/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 35/60, Loss: 0.0927, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0933, Val Loss: 0.0881\n",
      "Epoch 36/60, Loss: 0.0887, Val Loss: 0.0884\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 54/60, Loss: 0.0891, Val Loss: 0.0869\n",
      "Epoch 8/60, Loss: 0.2262, Val Loss: 0.0992\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 3/60, Loss: 0.2836, Val Loss: 0.0939\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0914\n",
      "Epoch 43/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 31/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 36/60, Loss: 0.0927, Val Loss: 0.0881\n",
      "Epoch 36/60, Loss: 0.0923, Val Loss: 0.0898\n",
      "Epoch 37/60, Loss: 0.0885, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 32/60, Loss: 0.0890, Val Loss: 0.0869\n",
      "Epoch 9/60, Loss: 0.1992, Val Loss: 0.0965\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 55/60, Loss: 0.0890, Val Loss: 0.0868\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0913\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 4/60, Loss: 0.1971, Val Loss: 0.0924\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 37/60, Loss: 0.0925, Val Loss: 0.0881\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 38/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 33/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 37/60, Loss: 0.0921, Val Loss: 0.0897\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 10/60, Loss: 0.1773, Val Loss: 0.0948\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0913\n",
      "Epoch 33/60, Loss: 0.0890, Val Loss: 0.0869\n",
      "Epoch 56/60, Loss: 0.0891, Val Loss: 0.0867\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 38/60, Loss: 0.0923, Val Loss: 0.0880\n",
      "Epoch 5/60, Loss: 0.1599, Val Loss: 0.0913\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 34/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 38/60, Loss: 0.0919, Val Loss: 0.0896\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0871\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:56:20,821] Trial 22 finished with value: 0.08708507415528098 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.0002338506066403989, 'batch_size': 8, 'patience': 10}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 22] Validation Loss: 0.0871\n",
      "\n",
      "[Trial 74] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 4.028660222497338e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0913\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.1624, Val Loss: 0.0941\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Early stopping triggered\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:56:31,608] Trial 65 finished with value: 0.08923321614662806 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.000832295763593712, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 65] Validation Loss: 0.0892\n",
      "\n",
      "[Trial 75] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 96, 'lr': 6.696492767998545e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 39/60, Loss: 0.0920, Val Loss: 0.0880\n",
      "Epoch 57/60, Loss: 0.0891, Val Loss: 0.0868\n",
      "Epoch 34/60, Loss: 0.0889, Val Loss: 0.0869\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0883\n",
      "Epoch 35/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 39/60, Loss: 0.0917, Val Loss: 0.0896\n",
      "Epoch 6/60, Loss: 0.1397, Val Loss: 0.0906\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0912\n",
      "Epoch 12/60, Loss: 0.1503, Val Loss: 0.0936\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 40/60, Loss: 0.0918, Val Loss: 0.0880\n",
      "Epoch 1/60, Loss: 1.1849, Val Loss: 0.1662\n",
      "Epoch 36/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 41/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 58/60, Loss: 0.0890, Val Loss: 0.0867\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 1/60, Loss: 1.2049, Val Loss: 0.1768\n",
      "Epoch 40/60, Loss: 0.0914, Val Loss: 0.0896\n",
      "Epoch 22/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 35/60, Loss: 0.0887, Val Loss: 0.0869\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0912\n",
      "Epoch 7/60, Loss: 0.1268, Val Loss: 0.0900\n",
      "Epoch 13/60, Loss: 0.1405, Val Loss: 0.0933\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 41/60, Loss: 0.0915, Val Loss: 0.0880\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 42/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 44/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 41/60, Loss: 0.0913, Val Loss: 0.0895\n",
      "Epoch 2/60, Loss: 0.6517, Val Loss: 0.1271\n",
      "Epoch 2/60, Loss: 0.6816, Val Loss: 0.1209\n",
      "Epoch 59/60, Loss: 0.0890, Val Loss: 0.0867\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0912\n",
      "Epoch 36/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 42/60, Loss: 0.0914, Val Loss: 0.0879\n",
      "Epoch 8/60, Loss: 0.1180, Val Loss: 0.0897\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 14/60, Loss: 0.1324, Val Loss: 0.0930\n",
      "Epoch 38/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 49/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 42/60, Loss: 0.0909, Val Loss: 0.0895\n",
      "Epoch 3/60, Loss: 0.4624, Val Loss: 0.1075\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0911\n",
      "Epoch 60/60, Loss: 0.0890, Val Loss: 0.0867\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.4734, Val Loss: 0.1069\n",
      "[Trial 58] Validation Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 13:59:05,314] Trial 58 finished with value: 0.08668840005993843 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'lr': 0.00010402287832023142, 'batch_size': 32, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 76] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 5.1254233548958216e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 43/60, Loss: 0.0913, Val Loss: 0.0879\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 37/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 15/60, Loss: 0.1268, Val Loss: 0.0926\n",
      "Epoch 44/60, Loss: 0.0883, Val Loss: 0.0882\n",
      "Epoch 9/60, Loss: 0.1115, Val Loss: 0.0894\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 48/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 43/60, Loss: 0.0909, Val Loss: 0.0895\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 39/60, Loss: 0.0877, Val Loss: 0.0911\n",
      "Epoch 4/60, Loss: 0.3449, Val Loss: 0.1013\n",
      "Epoch 44/60, Loss: 0.0911, Val Loss: 0.0879\n",
      "Epoch 4/60, Loss: 0.3402, Val Loss: 0.0982\n",
      "Epoch 40/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 1/60, Loss: 0.9854, Val Loss: 0.1547\n",
      "Epoch 16/60, Loss: 0.1212, Val Loss: 0.0923\n",
      "Epoch 38/60, Loss: 0.0886, Val Loss: 0.0868\n",
      "Epoch 44/60, Loss: 0.0907, Val Loss: 0.0894\n",
      "Epoch 10/60, Loss: 0.1076, Val Loss: 0.0897\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0911\n",
      "Epoch 45/60, Loss: 0.0909, Val Loss: 0.0879\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 5/60, Loss: 0.2771, Val Loss: 0.0971\n",
      "Epoch 51/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 41/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.2563, Val Loss: 0.0947\n",
      "Epoch 17/60, Loss: 0.1177, Val Loss: 0.0921\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 45/60, Loss: 0.0905, Val Loss: 0.0894\n",
      "Epoch 2/60, Loss: 0.4524, Val Loss: 0.1117\n",
      "Epoch 41/60, Loss: 0.0876, Val Loss: 0.0910\n",
      "Epoch 11/60, Loss: 0.1040, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.0886, Val Loss: 0.0869\n",
      "Epoch 46/60, Loss: 0.0907, Val Loss: 0.0878\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 42/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 6/60, Loss: 0.2290, Val Loss: 0.0941\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 18/60, Loss: 0.1142, Val Loss: 0.0918\n",
      "Epoch 46/60, Loss: 0.0905, Val Loss: 0.0894\n",
      "Epoch 6/60, Loss: 0.2112, Val Loss: 0.0935\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0910\n",
      "Epoch 3/60, Loss: 0.2918, Val Loss: 0.1005\n",
      "Epoch 47/60, Loss: 0.0907, Val Loss: 0.0879\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 12/60, Loss: 0.1016, Val Loss: 0.0891\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 7/60, Loss: 0.1990, Val Loss: 0.0929\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0903, Val Loss: 0.0894\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0910\n",
      "Epoch 19/60, Loss: 0.1111, Val Loss: 0.0917\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 48/60, Loss: 0.0906, Val Loss: 0.0878\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 7/60, Loss: 0.1838, Val Loss: 0.0927\n",
      "Epoch 51/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.2162, Val Loss: 0.0959\n",
      "Epoch 44/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 49/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 13/60, Loss: 0.0996, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.1750, Val Loss: 0.0921\n",
      "Epoch 41/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 44/60, Loss: 0.0875, Val Loss: 0.0911\n",
      "Epoch 48/60, Loss: 0.0901, Val Loss: 0.0893\n",
      "Epoch 51/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 20/60, Loss: 0.1086, Val Loss: 0.0915\n",
      "Epoch 49/60, Loss: 0.0905, Val Loss: 0.0878\n",
      "Epoch 54/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.1631, Val Loss: 0.0920\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.1767, Val Loss: 0.0948\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.1581, Val Loss: 0.0914\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0910\n",
      "Epoch 14/60, Loss: 0.0980, Val Loss: 0.0890\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 49/60, Loss: 0.0901, Val Loss: 0.0894\n",
      "Epoch 50/60, Loss: 0.0903, Val Loss: 0.0878\n",
      "Epoch 21/60, Loss: 0.1064, Val Loss: 0.0913\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0867\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 55/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 9/60, Loss: 0.1491, Val Loss: 0.0914\n",
      "Epoch 6/60, Loss: 0.1552, Val Loss: 0.0938\n",
      "Epoch 46/60, Loss: 0.0875, Val Loss: 0.0910\n",
      "Epoch 50/60, Loss: 0.0898, Val Loss: 0.0893\n",
      "Epoch 51/60, Loss: 0.0903, Val Loss: 0.0878\n",
      "Epoch 10/60, Loss: 0.1451, Val Loss: 0.0910\n",
      "Epoch 15/60, Loss: 0.0968, Val Loss: 0.0889\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 22/60, Loss: 0.1046, Val Loss: 0.0911\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 53/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Early stopping triggered\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "[Trial 60] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:04:41,284] Trial 60 finished with value: 0.08888425106803576 and parameters: {'hidden_dim': 320, 'latent_dim': 96, 'lr': 0.0007565545382795885, 'batch_size': 32, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60, Loss: 0.0885, Val Loss: 0.0867\n",
      "\n",
      "[Trial 77] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 5.376875364548665e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0875, Val Loss: 0.0910\n",
      "Epoch 56/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 52/60, Loss: 0.0902, Val Loss: 0.0878\n",
      "Epoch 7/60, Loss: 0.1400, Val Loss: 0.0929\n",
      "Epoch 10/60, Loss: 0.1386, Val Loss: 0.0911\n",
      "Epoch 51/60, Loss: 0.0899, Val Loss: 0.0893\n",
      "Epoch 11/60, Loss: 0.1364, Val Loss: 0.0906\n",
      "Epoch 23/60, Loss: 0.1031, Val Loss: 0.0909\n",
      "Epoch 16/60, Loss: 0.0957, Val Loss: 0.0889\n",
      "Epoch 48/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 53/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 52/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 48/60, Loss: 0.0874, Val Loss: 0.0909\n",
      "Epoch 44/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 8/60, Loss: 0.1298, Val Loss: 0.0926\n",
      "Epoch 1/60, Loss: 1.0737, Val Loss: 0.1502\n",
      "Epoch 53/60, Loss: 0.0900, Val Loss: 0.0878\n",
      "Epoch 54/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 52/60, Loss: 0.0898, Val Loss: 0.0893\n",
      "Epoch 11/60, Loss: 0.1305, Val Loss: 0.0907\n",
      "Epoch 12/60, Loss: 0.1286, Val Loss: 0.0901\n",
      "Epoch 57/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 24/60, Loss: 0.1013, Val Loss: 0.0908\n",
      "Epoch 49/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Early stopping triggered\n",
      "[Trial 67] Validation Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:06:04,660] Trial 67 finished with value: 0.08805979589621225 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.0007830819550148285, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 78] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 4.749241855750065e-05, 'batch_size': 32, 'patience': 5}\n",
      "Epoch 17/60, Loss: 0.0948, Val Loss: 0.0888\n",
      "Epoch 49/60, Loss: 0.0875, Val Loss: 0.0910\n",
      "Epoch 9/60, Loss: 0.1222, Val Loss: 0.0920\n",
      "Epoch 54/60, Loss: 0.0901, Val Loss: 0.0878\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 53/60, Loss: 0.0897, Val Loss: 0.0893\n",
      "Epoch 45/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 2/60, Loss: 0.5607, Val Loss: 0.1093\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 13/60, Loss: 0.1228, Val Loss: 0.0898\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 12/60, Loss: 0.1248, Val Loss: 0.0903\n",
      "Epoch 25/60, Loss: 0.1002, Val Loss: 0.0906\n",
      "Epoch 58/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 50/60, Loss: 0.0875, Val Loss: 0.0909\n",
      "Epoch 18/60, Loss: 0.0941, Val Loss: 0.0888\n",
      "Epoch 55/60, Loss: 0.0898, Val Loss: 0.0878\n",
      "Epoch 54/60, Loss: 0.0897, Val Loss: 0.0892\n",
      "Epoch 1/60, Loss: 1.0774, Val Loss: 0.1616\n",
      "Epoch 10/60, Loss: 0.1164, Val Loss: 0.0916\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.3545, Val Loss: 0.0971\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 51/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Early stopping triggered\n",
      "Epoch 46/60, Loss: 0.0885, Val Loss: 0.0867\n",
      "Epoch 14/60, Loss: 0.1174, Val Loss: 0.0895\n",
      "[Trial 69] Validation Loss: 0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:07:21,690] Trial 69 finished with value: 0.08744708274801573 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.0008442769348301436, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 79] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 6.585730619223292e-05, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 26/60, Loss: 0.0989, Val Loss: 0.0905\n",
      "Epoch 13/60, Loss: 0.1186, Val Loss: 0.0900\n",
      "Epoch 51/60, Loss: 0.0874, Val Loss: 0.0909\n",
      "Epoch 56/60, Loss: 0.0898, Val Loss: 0.0877\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 19/60, Loss: 0.0935, Val Loss: 0.0889\n",
      "Epoch 55/60, Loss: 0.0896, Val Loss: 0.0893\n",
      "Epoch 2/60, Loss: 0.5353, Val Loss: 0.1149\n",
      "Epoch 11/60, Loss: 0.1120, Val Loss: 0.0913\n",
      "Epoch 4/60, Loss: 0.2457, Val Loss: 0.0935\n",
      "Epoch 15/60, Loss: 0.1133, Val Loss: 0.0893\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 27/60, Loss: 0.0979, Val Loss: 0.0904\n",
      "Epoch 52/60, Loss: 0.0874, Val Loss: 0.0909\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 57/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 57/60, Loss: 0.0898, Val Loss: 0.0877\n",
      "Epoch 1/60, Loss: 1.0419, Val Loss: 0.1423\n",
      "Epoch 14/60, Loss: 0.1150, Val Loss: 0.0898\n",
      "Epoch 56/60, Loss: 0.0894, Val Loss: 0.0892\n",
      "Epoch 60/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "[Trial 59] Validation Loss: 0.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:08:31,968] Trial 59 finished with value: 0.08945996264616649 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 0.00012771811589784742, 'batch_size': 32, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 80] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 6.01384511505037e-05, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 20/60, Loss: 0.0929, Val Loss: 0.0887\n",
      "Epoch 3/60, Loss: 0.3504, Val Loss: 0.1022\n",
      "Epoch 12/60, Loss: 0.1082, Val Loss: 0.0912\n",
      "Epoch 53/60, Loss: 0.0875, Val Loss: 0.0909\n",
      "Epoch 16/60, Loss: 0.1105, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.1933, Val Loss: 0.0923\n",
      "Epoch 28/60, Loss: 0.0972, Val Loss: 0.0903\n",
      "Epoch 58/60, Loss: 0.0898, Val Loss: 0.0877\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0874\n",
      "Epoch 57/60, Loss: 0.0894, Val Loss: 0.0892\n",
      "Epoch 48/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 58/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.4767, Val Loss: 0.1077\n",
      "Epoch 15/60, Loss: 0.1114, Val Loss: 0.0896\n",
      "Epoch 21/60, Loss: 0.0926, Val Loss: 0.0887\n",
      "Epoch 4/60, Loss: 0.2538, Val Loss: 0.0955\n",
      "Epoch 1/60, Loss: 1.3171, Val Loss: 0.2058\n",
      "Epoch 54/60, Loss: 0.0874, Val Loss: 0.0910\n",
      "Epoch 13/60, Loss: 0.1057, Val Loss: 0.0908\n",
      "Epoch 59/60, Loss: 0.0897, Val Loss: 0.0877\n",
      "Epoch 29/60, Loss: 0.0965, Val Loss: 0.0903\n",
      "Epoch 17/60, Loss: 0.1078, Val Loss: 0.0888\n",
      "Epoch 6/60, Loss: 0.1638, Val Loss: 0.0914\n",
      "Epoch 58/60, Loss: 0.0894, Val Loss: 0.0892\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.2822, Val Loss: 0.0977\n",
      "Epoch 49/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 16/60, Loss: 0.1083, Val Loss: 0.0896\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 55/60, Loss: 0.0874, Val Loss: 0.0909\n",
      "Epoch 2/60, Loss: 0.7964, Val Loss: 0.1399\n",
      "Epoch 5/60, Loss: 0.2031, Val Loss: 0.0936\n",
      "Epoch 22/60, Loss: 0.0922, Val Loss: 0.0887\n",
      "Epoch 60/60, Loss: 0.0897, Val Loss: 0.0877\n",
      "[Trial 68] Validation Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:10:23,287] Trial 68 finished with value: 0.08770630608002344 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 9.938570286846068e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 81] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.288048041953943e-05, 'batch_size': 32, 'patience': 8}\n",
      "Epoch 14/60, Loss: 0.1034, Val Loss: 0.0906\n",
      "Epoch 30/60, Loss: 0.0955, Val Loss: 0.0902\n",
      "Epoch 18/60, Loss: 0.1054, Val Loss: 0.0887\n",
      "Epoch 59/60, Loss: 0.0894, Val Loss: 0.0892\n",
      "Epoch 7/60, Loss: 0.1467, Val Loss: 0.0907\n",
      "Epoch 56/60, Loss: 0.0873, Val Loss: 0.0909\n",
      "Epoch 4/60, Loss: 0.2013, Val Loss: 0.0953\n",
      "Epoch 17/60, Loss: 0.1060, Val Loss: 0.0894\n",
      "Epoch 58/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.5747, Val Loss: 0.1147\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 60/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 6/60, Loss: 0.1740, Val Loss: 0.0925\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "[Trial 62] Validation Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:11:03,545] Trial 62 finished with value: 0.08900896633664766 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0001238995766825796, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 82] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 4.814986678449057e-05, 'batch_size': 16, 'patience': 8}\n",
      "Epoch 23/60, Loss: 0.0918, Val Loss: 0.0887\n",
      "Epoch 31/60, Loss: 0.0952, Val Loss: 0.0901\n",
      "Epoch 60/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 15/60, Loss: 0.1013, Val Loss: 0.0905\n",
      "Epoch 19/60, Loss: 0.1035, Val Loss: 0.0885\n",
      "[Trial 66] Validation Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:11:13,623] Trial 66 finished with value: 0.08919715285301208 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.00010183556995112552, 'batch_size': 32, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 83] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 6.197467541025706e-05, 'batch_size': 8, 'patience': 8}\n",
      "Epoch 8/60, Loss: 0.1337, Val Loss: 0.0902\n",
      "Epoch 1/60, Loss: 1.3024, Val Loss: 0.2060\n",
      "Epoch 57/60, Loss: 0.0874, Val Loss: 0.0909\n",
      "Epoch 4/60, Loss: 0.4339, Val Loss: 0.1025\n",
      "Epoch 5/60, Loss: 0.1646, Val Loss: 0.0941\n",
      "Epoch 18/60, Loss: 0.1042, Val Loss: 0.0893\n",
      "Epoch 7/60, Loss: 0.1549, Val Loss: 0.0918\n",
      "Epoch 59/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 51/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 32/60, Loss: 0.0943, Val Loss: 0.0902\n",
      "Epoch 24/60, Loss: 0.0915, Val Loss: 0.0887\n",
      "Epoch 20/60, Loss: 0.1017, Val Loss: 0.0883\n",
      "Epoch 16/60, Loss: 0.0997, Val Loss: 0.0904\n",
      "Epoch 37/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 2/60, Loss: 0.7162, Val Loss: 0.1457\n",
      "Epoch 9/60, Loss: 0.1253, Val Loss: 0.0898\n",
      "Epoch 58/60, Loss: 0.0873, Val Loss: 0.0908\n",
      "Epoch 5/60, Loss: 0.3433, Val Loss: 0.0975\n",
      "Epoch 6/60, Loss: 0.1446, Val Loss: 0.0936\n",
      "Epoch 8/60, Loss: 0.1416, Val Loss: 0.0913\n",
      "Epoch 19/60, Loss: 0.1022, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0939, Val Loss: 0.0901\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 52/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 21/60, Loss: 0.1003, Val Loss: 0.0882\n",
      "Epoch 25/60, Loss: 0.0913, Val Loss: 0.0887\n",
      "[Trial 61] Validation Loss: 0.0875\n",
      "Epoch 1/60, Loss: 1.1340, Val Loss: 0.1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:12:43,113] Trial 61 finished with value: 0.08746497705578804 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.000716115827994906, 'batch_size': 32, 'patience': 9}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 84] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.0295100050346404e-05, 'batch_size': 8, 'patience': 8}\n",
      "Epoch 17/60, Loss: 0.0982, Val Loss: 0.0903\n",
      "Epoch 3/60, Loss: 0.5254, Val Loss: 0.1257\n",
      "Epoch 59/60, Loss: 0.0875, Val Loss: 0.0908\n",
      "Epoch 10/60, Loss: 0.1182, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Early stopping triggered\n",
      "Epoch 6/60, Loss: 0.2798, Val Loss: 0.0949\n",
      "[Trial 71] Validation Loss: 0.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:13:00,001] Trial 71 finished with value: 0.08708357637127241 and parameters: {'hidden_dim': 320, 'latent_dim': 32, 'lr': 0.0008596724037215931, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 85] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.229796049951665e-05, 'batch_size': 16, 'patience': 8}\n",
      "Epoch 7/60, Loss: 0.1306, Val Loss: 0.0928\n",
      "Epoch 9/60, Loss: 0.1311, Val Loss: 0.0908\n",
      "Epoch 34/60, Loss: 0.0934, Val Loss: 0.0900\n",
      "Epoch 20/60, Loss: 0.1012, Val Loss: 0.0891\n",
      "Epoch 22/60, Loss: 0.0992, Val Loss: 0.0881\n",
      "Epoch 26/60, Loss: 0.0910, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.0971, Val Loss: 0.0902\n",
      "Epoch 60/60, Loss: 0.0873, Val Loss: 0.0908\n",
      "Epoch 4/60, Loss: 0.4053, Val Loss: 0.1077\n",
      "Epoch 53/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "[Trial 70] Validation Loss: 0.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:13:33,516] Trial 70 finished with value: 0.09083348289132118 and parameters: {'hidden_dim': 64, 'latent_dim': 32, 'lr': 0.000651709835410296, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 86] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00197129406763158, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 7/60, Loss: 0.2383, Val Loss: 0.0938\n",
      "Epoch 11/60, Loss: 0.1133, Val Loss: 0.0891\n",
      "Epoch 35/60, Loss: 0.0930, Val Loss: 0.0900\n",
      "Epoch 10/60, Loss: 0.1239, Val Loss: 0.0905\n",
      "Epoch 8/60, Loss: 0.1209, Val Loss: 0.0924\n",
      "Epoch 1/60, Loss: 0.9254, Val Loss: 0.1179\n",
      "Epoch 2/60, Loss: 0.5819, Val Loss: 0.1195\n",
      "Epoch 21/60, Loss: 0.0996, Val Loss: 0.0891\n",
      "Epoch 23/60, Loss: 0.0980, Val Loss: 0.0881\n",
      "Epoch 27/60, Loss: 0.0907, Val Loss: 0.0886\n",
      "Epoch 5/60, Loss: 0.3239, Val Loss: 0.0997\n",
      "Epoch 19/60, Loss: 0.0962, Val Loss: 0.0901\n",
      "Epoch 8/60, Loss: 0.2068, Val Loss: 0.0930\n",
      "Epoch 54/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 12/60, Loss: 0.1090, Val Loss: 0.0889\n",
      "Epoch 36/60, Loss: 0.0927, Val Loss: 0.0899\n",
      "Epoch 11/60, Loss: 0.1179, Val Loss: 0.0901\n",
      "Epoch 9/60, Loss: 0.1142, Val Loss: 0.0920\n",
      "Epoch 22/60, Loss: 0.0985, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 1.1992, Val Loss: 0.1552\n",
      "Epoch 24/60, Loss: 0.0971, Val Loss: 0.0880\n",
      "Epoch 6/60, Loss: 0.2714, Val Loss: 0.0960\n",
      "Epoch 28/60, Loss: 0.0905, Val Loss: 0.0886\n",
      "Epoch 20/60, Loss: 0.0953, Val Loss: 0.0900\n",
      "Epoch 9/60, Loss: 0.1842, Val Loss: 0.0924\n",
      "Epoch 3/60, Loss: 0.3824, Val Loss: 0.1059\n",
      "Epoch 13/60, Loss: 0.1063, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0924, Val Loss: 0.0899\n",
      "Epoch 55/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Early stopping triggered\n",
      "Epoch 12/60, Loss: 0.1132, Val Loss: 0.0898\n",
      "[Trial 64] Validation Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:15:20,200] Trial 64 finished with value: 0.08666378334164619 and parameters: {'hidden_dim': 256, 'latent_dim': 32, 'lr': 0.0001197966165019995, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 87] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.530746301123239e-05, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 23/60, Loss: 0.0976, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.1091, Val Loss: 0.0920\n",
      "Epoch 1/60, Loss: 0.9018, Val Loss: 0.1336\n",
      "Epoch 25/60, Loss: 0.0963, Val Loss: 0.0880\n",
      "Epoch 7/60, Loss: 0.2345, Val Loss: 0.0942\n",
      "Epoch 29/60, Loss: 0.0905, Val Loss: 0.0885\n",
      "Epoch 10/60, Loss: 0.1678, Val Loss: 0.0919\n",
      "Epoch 21/60, Loss: 0.0947, Val Loss: 0.0900\n",
      "Epoch 14/60, Loss: 0.1037, Val Loss: 0.0886\n",
      "Epoch 38/60, Loss: 0.0919, Val Loss: 0.0899\n",
      "Epoch 13/60, Loss: 0.1099, Val Loss: 0.0894\n",
      "Epoch 2/60, Loss: 0.6377, Val Loss: 0.1166\n",
      "Epoch 24/60, Loss: 0.0966, Val Loss: 0.0890\n",
      "Epoch 11/60, Loss: 0.1055, Val Loss: 0.0917\n",
      "Epoch 1/60, Loss: 0.1469, Val Loss: 0.0927\n",
      "Epoch 26/60, Loss: 0.0956, Val Loss: 0.0879\n",
      "Epoch 8/60, Loss: 0.2074, Val Loss: 0.0930\n",
      "Epoch 2/60, Loss: 0.3358, Val Loss: 0.0977\n",
      "Epoch 30/60, Loss: 0.0903, Val Loss: 0.0886\n",
      "Epoch 11/60, Loss: 0.1543, Val Loss: 0.0915\n",
      "Epoch 4/60, Loss: 0.2742, Val Loss: 0.1000\n",
      "Epoch 22/60, Loss: 0.0940, Val Loss: 0.0900\n",
      "Epoch 39/60, Loss: 0.0918, Val Loss: 0.0899\n",
      "Epoch 15/60, Loss: 0.1015, Val Loss: 0.0885\n",
      "Epoch 14/60, Loss: 0.1067, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0959, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.1028, Val Loss: 0.0916\n",
      "Epoch 27/60, Loss: 0.0951, Val Loss: 0.0878\n",
      "Epoch 9/60, Loss: 0.1860, Val Loss: 0.0922\n",
      "Epoch 12/60, Loss: 0.1438, Val Loss: 0.0912\n",
      "Epoch 31/60, Loss: 0.0902, Val Loss: 0.0886\n",
      "Epoch 23/60, Loss: 0.0935, Val Loss: 0.0899\n",
      "Epoch 3/60, Loss: 0.4093, Val Loss: 0.1039\n",
      "Epoch 40/60, Loss: 0.0916, Val Loss: 0.0899\n",
      "Epoch 16/60, Loss: 0.0999, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.1042, Val Loss: 0.0890\n",
      "Epoch 26/60, Loss: 0.0953, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.1006, Val Loss: 0.0915\n",
      "Epoch 10/60, Loss: 0.1702, Val Loss: 0.0916\n",
      "Epoch 28/60, Loss: 0.0945, Val Loss: 0.0878\n",
      "Epoch 5/60, Loss: 0.2162, Val Loss: 0.0960\n",
      "Epoch 13/60, Loss: 0.1355, Val Loss: 0.0908\n",
      "Epoch 2/60, Loss: 0.3603, Val Loss: 0.1029\n",
      "Epoch 32/60, Loss: 0.0900, Val Loss: 0.0887\n",
      "Epoch 24/60, Loss: 0.0931, Val Loss: 0.0899\n",
      "Epoch 41/60, Loss: 0.0913, Val Loss: 0.0899\n",
      "Epoch 17/60, Loss: 0.0987, Val Loss: 0.0884\n",
      "Epoch 16/60, Loss: 0.1025, Val Loss: 0.0888\n",
      "Epoch 1/60, Loss: 0.8582, Val Loss: 0.1256\n",
      "Epoch 27/60, Loss: 0.0947, Val Loss: 0.0889\n",
      "Epoch 14/60, Loss: 0.0987, Val Loss: 0.0915\n",
      "Epoch 11/60, Loss: 0.1580, Val Loss: 0.0912\n",
      "Epoch 29/60, Loss: 0.0940, Val Loss: 0.0878\n",
      "Epoch 14/60, Loss: 0.1290, Val Loss: 0.0906\n",
      "Epoch 2/60, Loss: 0.0888, Val Loss: 0.0929\n",
      "Epoch 4/60, Loss: 0.2838, Val Loss: 0.0982\n",
      "Epoch 33/60, Loss: 0.0899, Val Loss: 0.0885\n",
      "Epoch 25/60, Loss: 0.0927, Val Loss: 0.0899\n",
      "Epoch 3/60, Loss: 0.1813, Val Loss: 0.0922\n",
      "Epoch 42/60, Loss: 0.0911, Val Loss: 0.0898\n",
      "Epoch 17/60, Loss: 0.1009, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.0976, Val Loss: 0.0883\n",
      "Epoch 6/60, Loss: 0.1785, Val Loss: 0.0946\n",
      "Epoch 28/60, Loss: 0.0941, Val Loss: 0.0888\n",
      "Epoch 12/60, Loss: 0.1482, Val Loss: 0.0907\n",
      "Epoch 15/60, Loss: 0.0972, Val Loss: 0.0914\n",
      "Epoch 30/60, Loss: 0.0937, Val Loss: 0.0878\n",
      "Epoch 15/60, Loss: 0.1243, Val Loss: 0.0904\n",
      "Epoch 34/60, Loss: 0.0899, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0922, Val Loss: 0.0898\n",
      "Epoch 43/60, Loss: 0.0909, Val Loss: 0.0898\n",
      "Epoch 18/60, Loss: 0.0994, Val Loss: 0.0886\n",
      "Epoch 19/60, Loss: 0.0967, Val Loss: 0.0882\n",
      "Epoch 29/60, Loss: 0.0938, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.1392, Val Loss: 0.0903\n",
      "Epoch 16/60, Loss: 0.0963, Val Loss: 0.0913\n",
      "Epoch 5/60, Loss: 0.2155, Val Loss: 0.0949\n",
      "Epoch 16/60, Loss: 0.1192, Val Loss: 0.0903\n",
      "Epoch 31/60, Loss: 0.0931, Val Loss: 0.0877\n",
      "Epoch 35/60, Loss: 0.0896, Val Loss: 0.0885\n",
      "Epoch 44/60, Loss: 0.0906, Val Loss: 0.0898\n",
      "Epoch 27/60, Loss: 0.0917, Val Loss: 0.0898\n",
      "Epoch 19/60, Loss: 0.0982, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.1542, Val Loss: 0.0938\n",
      "Epoch 3/60, Loss: 0.2063, Val Loss: 0.0954\n",
      "Epoch 20/60, Loss: 0.0958, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.1330, Val Loss: 0.0902\n",
      "Epoch 30/60, Loss: 0.0932, Val Loss: 0.0888\n",
      "Epoch 2/60, Loss: 0.3175, Val Loss: 0.0983\n",
      "Epoch 17/60, Loss: 0.1154, Val Loss: 0.0900\n",
      "Epoch 17/60, Loss: 0.0951, Val Loss: 0.0912\n",
      "Epoch 32/60, Loss: 0.0929, Val Loss: 0.0877\n",
      "Epoch 36/60, Loss: 0.0894, Val Loss: 0.0884\n",
      "Epoch 45/60, Loss: 0.0906, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.0883, Val Loss: 0.0923\n",
      "Epoch 28/60, Loss: 0.0917, Val Loss: 0.0898\n",
      "Epoch 20/60, Loss: 0.0971, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.0950, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.1767, Val Loss: 0.0938\n",
      "Epoch 4/60, Loss: 0.1351, Val Loss: 0.0909\n",
      "Epoch 15/60, Loss: 0.1268, Val Loss: 0.0897\n",
      "Epoch 31/60, Loss: 0.0928, Val Loss: 0.0888\n",
      "Epoch 18/60, Loss: 0.1122, Val Loss: 0.0898\n",
      "Epoch 33/60, Loss: 0.0925, Val Loss: 0.0876\n",
      "Epoch 18/60, Loss: 0.0943, Val Loss: 0.0912\n",
      "Epoch 8/60, Loss: 0.1388, Val Loss: 0.0933\n",
      "Epoch 37/60, Loss: 0.0894, Val Loss: 0.0883\n",
      "Epoch 46/60, Loss: 0.0904, Val Loss: 0.0897\n",
      "Epoch 29/60, Loss: 0.0913, Val Loss: 0.0897\n",
      "Epoch 21/60, Loss: 0.0963, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0945, Val Loss: 0.0881\n",
      "Epoch 16/60, Loss: 0.1224, Val Loss: 0.0896\n",
      "Epoch 19/60, Loss: 0.1093, Val Loss: 0.0897\n",
      "Epoch 32/60, Loss: 0.0924, Val Loss: 0.0887\n",
      "Epoch 34/60, Loss: 0.0923, Val Loss: 0.0876\n",
      "Epoch 19/60, Loss: 0.0936, Val Loss: 0.0912\n",
      "Epoch 38/60, Loss: 0.0893, Val Loss: 0.0883\n",
      "Epoch 47/60, Loss: 0.0902, Val Loss: 0.0897\n",
      "Epoch 22/60, Loss: 0.0954, Val Loss: 0.0884\n",
      "Epoch 7/60, Loss: 0.1514, Val Loss: 0.0931\n",
      "Epoch 30/60, Loss: 0.0910, Val Loss: 0.0898\n",
      "Epoch 23/60, Loss: 0.0939, Val Loss: 0.0881\n",
      "Epoch 17/60, Loss: 0.1185, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.1071, Val Loss: 0.0895\n",
      "Epoch 33/60, Loss: 0.0922, Val Loss: 0.0888\n",
      "Epoch 4/60, Loss: 0.1510, Val Loss: 0.0938\n",
      "Epoch 35/60, Loss: 0.0920, Val Loss: 0.0876\n",
      "Epoch 9/60, Loss: 0.1271, Val Loss: 0.0926\n",
      "Epoch 20/60, Loss: 0.0929, Val Loss: 0.0911\n",
      "Epoch 3/60, Loss: 0.1854, Val Loss: 0.0949\n",
      "Epoch 48/60, Loss: 0.0902, Val Loss: 0.0898\n",
      "Epoch 39/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0948, Val Loss: 0.0884\n",
      "Epoch 31/60, Loss: 0.0909, Val Loss: 0.0897\n",
      "Epoch 18/60, Loss: 0.1149, Val Loss: 0.0891\n",
      "Epoch 24/60, Loss: 0.0932, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.0884, Val Loss: 0.0922\n",
      "Epoch 21/60, Loss: 0.1055, Val Loss: 0.0893\n",
      "Epoch 34/60, Loss: 0.0920, Val Loss: 0.0887\n",
      "Epoch 36/60, Loss: 0.0918, Val Loss: 0.0876\n",
      "Epoch 21/60, Loss: 0.0924, Val Loss: 0.0911\n",
      "Epoch 5/60, Loss: 0.1151, Val Loss: 0.0898\n",
      "Epoch 8/60, Loss: 0.1363, Val Loss: 0.0925\n",
      "Epoch 49/60, Loss: 0.0899, Val Loss: 0.0897\n",
      "Epoch 40/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0943, Val Loss: 0.0883\n",
      "Epoch 32/60, Loss: 0.0904, Val Loss: 0.0897\n",
      "Epoch 19/60, Loss: 0.1121, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0931, Val Loss: 0.0880\n",
      "Epoch 22/60, Loss: 0.1034, Val Loss: 0.0891\n",
      "Epoch 10/60, Loss: 0.1195, Val Loss: 0.0923\n",
      "Epoch 35/60, Loss: 0.0916, Val Loss: 0.0887\n",
      "Epoch 37/60, Loss: 0.0916, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0920, Val Loss: 0.0911\n",
      "Epoch 50/60, Loss: 0.0900, Val Loss: 0.0897\n",
      "Epoch 41/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 25/60, Loss: 0.0938, Val Loss: 0.0883\n",
      "Epoch 20/60, Loss: 0.1099, Val Loss: 0.0887\n",
      "Epoch 33/60, Loss: 0.0903, Val Loss: 0.0897\n",
      "Epoch 23/60, Loss: 0.1020, Val Loss: 0.0890\n",
      "Epoch 26/60, Loss: 0.0926, Val Loss: 0.0880\n",
      "Epoch 36/60, Loss: 0.0915, Val Loss: 0.0887\n",
      "Epoch 38/60, Loss: 0.0914, Val Loss: 0.0876\n",
      "Epoch 9/60, Loss: 0.1255, Val Loss: 0.0922\n",
      "Epoch 23/60, Loss: 0.0917, Val Loss: 0.0911\n",
      "Epoch 5/60, Loss: 0.1261, Val Loss: 0.0926\n",
      "Epoch 51/60, Loss: 0.0898, Val Loss: 0.0897\n",
      "Epoch 42/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0934, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.1388, Val Loss: 0.0934\n",
      "Epoch 21/60, Loss: 0.1076, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.1131, Val Loss: 0.0919\n",
      "Epoch 34/60, Loss: 0.0904, Val Loss: 0.0896\n",
      "Epoch 24/60, Loss: 0.1006, Val Loss: 0.0888\n",
      "Epoch 27/60, Loss: 0.0923, Val Loss: 0.0880\n",
      "Epoch 37/60, Loss: 0.0911, Val Loss: 0.0887\n",
      "Epoch 39/60, Loss: 0.0912, Val Loss: 0.0875\n",
      "Epoch 5/60, Loss: 0.0880, Val Loss: 0.0918\n",
      "Epoch 24/60, Loss: 0.0912, Val Loss: 0.0910\n",
      "Epoch 52/60, Loss: 0.0898, Val Loss: 0.0897\n",
      "Epoch 27/60, Loss: 0.0928, Val Loss: 0.0882\n",
      "Epoch 43/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.1055, Val Loss: 0.0891\n",
      "Epoch 22/60, Loss: 0.1056, Val Loss: 0.0883\n",
      "Epoch 25/60, Loss: 0.0993, Val Loss: 0.0888\n",
      "Epoch 35/60, Loss: 0.0903, Val Loss: 0.0897\n",
      "Epoch 28/60, Loss: 0.0920, Val Loss: 0.0880\n",
      "Epoch 10/60, Loss: 0.1171, Val Loss: 0.0916\n",
      "Epoch 38/60, Loss: 0.0909, Val Loss: 0.0887\n",
      "Epoch 40/60, Loss: 0.0910, Val Loss: 0.0875\n",
      "Epoch 53/60, Loss: 0.0896, Val Loss: 0.0897\n",
      "Epoch 25/60, Loss: 0.0911, Val Loss: 0.0911\n",
      "Epoch 12/60, Loss: 0.1087, Val Loss: 0.0916\n",
      "Epoch 28/60, Loss: 0.0925, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.1042, Val Loss: 0.0882\n",
      "Epoch 44/60, Loss: 0.0890, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0983, Val Loss: 0.0887\n",
      "Epoch 36/60, Loss: 0.0901, Val Loss: 0.0896\n",
      "Epoch 29/60, Loss: 0.0917, Val Loss: 0.0880\n",
      "Epoch 39/60, Loss: 0.0909, Val Loss: 0.0887\n",
      "Epoch 41/60, Loss: 0.0908, Val Loss: 0.0875\n",
      "Epoch 54/60, Loss: 0.0895, Val Loss: 0.0896\n",
      "Epoch 26/60, Loss: 0.0907, Val Loss: 0.0911\n",
      "Epoch 29/60, Loss: 0.0923, Val Loss: 0.0882\n",
      "Epoch 24/60, Loss: 0.1026, Val Loss: 0.0880\n",
      "Epoch 27/60, Loss: 0.0974, Val Loss: 0.0887\n",
      "Epoch 11/60, Loss: 0.1117, Val Loss: 0.0912\n",
      "Epoch 45/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.1125, Val Loss: 0.0917\n",
      "Epoch 37/60, Loss: 0.0898, Val Loss: 0.0896\n",
      "Epoch 30/60, Loss: 0.0915, Val Loss: 0.0879\n",
      "Epoch 5/60, Loss: 0.1186, Val Loss: 0.0925\n",
      "Epoch 40/60, Loss: 0.0906, Val Loss: 0.0886\n",
      "Epoch 42/60, Loss: 0.0907, Val Loss: 0.0877\n",
      "Epoch 13/60, Loss: 0.1049, Val Loss: 0.0912\n",
      "Epoch 55/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 27/60, Loss: 0.0906, Val Loss: 0.0910\n",
      "Epoch 6/60, Loss: 0.0878, Val Loss: 0.0917\n",
      "Epoch 25/60, Loss: 0.1013, Val Loss: 0.0879\n",
      "Epoch 30/60, Loss: 0.0920, Val Loss: 0.0882\n",
      "Epoch 28/60, Loss: 0.0966, Val Loss: 0.0886\n",
      "Epoch 46/60, Loss: 0.0887, Val Loss: 0.0881\n",
      "Epoch 31/60, Loss: 0.0914, Val Loss: 0.0880\n",
      "Epoch 38/60, Loss: 0.0897, Val Loss: 0.0897\n",
      "Epoch 7/60, Loss: 0.1002, Val Loss: 0.0886\n",
      "Epoch 41/60, Loss: 0.0906, Val Loss: 0.0886\n",
      "Epoch 43/60, Loss: 0.0906, Val Loss: 0.0875\n",
      "Epoch 56/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 12/60, Loss: 0.1074, Val Loss: 0.0909\n",
      "Epoch 28/60, Loss: 0.0903, Val Loss: 0.0909\n",
      "Epoch 26/60, Loss: 0.1001, Val Loss: 0.0877\n",
      "Epoch 31/60, Loss: 0.0916, Val Loss: 0.0881\n",
      "Epoch 29/60, Loss: 0.0960, Val Loss: 0.0886\n",
      "Epoch 47/60, Loss: 0.0887, Val Loss: 0.0881\n",
      "Epoch 32/60, Loss: 0.0911, Val Loss: 0.0879\n",
      "Epoch 39/60, Loss: 0.0897, Val Loss: 0.0896\n",
      "Epoch 14/60, Loss: 0.1018, Val Loss: 0.0909\n",
      "Epoch 44/60, Loss: 0.0904, Val Loss: 0.0875\n",
      "Epoch 42/60, Loss: 0.0904, Val Loss: 0.0886\n",
      "Epoch 57/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 27/60, Loss: 0.0992, Val Loss: 0.0877\n",
      "Epoch 32/60, Loss: 0.0915, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0955, Val Loss: 0.0886\n",
      "Epoch 29/60, Loss: 0.0900, Val Loss: 0.0910\n",
      "Epoch 33/60, Loss: 0.0908, Val Loss: 0.0879\n",
      "Epoch 48/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 7/60, Loss: 0.1041, Val Loss: 0.0909\n",
      "Epoch 40/60, Loss: 0.0896, Val Loss: 0.0897\n",
      "Epoch 45/60, Loss: 0.0904, Val Loss: 0.0875\n",
      "Epoch 13/60, Loss: 0.1037, Val Loss: 0.0905\n",
      "Epoch 43/60, Loss: 0.0903, Val Loss: 0.0886\n",
      "Epoch 6/60, Loss: 0.1079, Val Loss: 0.0919\n",
      "Epoch 58/60, Loss: 0.0892, Val Loss: 0.0896\n",
      "Epoch 28/60, Loss: 0.0984, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0948, Val Loss: 0.0885\n",
      "Epoch 33/60, Loss: 0.0913, Val Loss: 0.0881\n",
      "Epoch 30/60, Loss: 0.0898, Val Loss: 0.0910\n",
      "Epoch 7/60, Loss: 0.0877, Val Loss: 0.0916\n",
      "Epoch 15/60, Loss: 0.0997, Val Loss: 0.0907\n",
      "Epoch 34/60, Loss: 0.0907, Val Loss: 0.0879\n",
      "Epoch 41/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 46/60, Loss: 0.0902, Val Loss: 0.0874\n",
      "Epoch 49/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 44/60, Loss: 0.0902, Val Loss: 0.0885\n",
      "Epoch 8/60, Loss: 0.0968, Val Loss: 0.0883\n",
      "Epoch 59/60, Loss: 0.0893, Val Loss: 0.0896\n",
      "Epoch 29/60, Loss: 0.0975, Val Loss: 0.0875\n",
      "Epoch 32/60, Loss: 0.0942, Val Loss: 0.0885\n",
      "Epoch 34/60, Loss: 0.0911, Val Loss: 0.0882\n",
      "Epoch 31/60, Loss: 0.0899, Val Loss: 0.0910\n",
      "Epoch 35/60, Loss: 0.0906, Val Loss: 0.0879\n",
      "Epoch 14/60, Loss: 0.1010, Val Loss: 0.0902\n",
      "Epoch 47/60, Loss: 0.0902, Val Loss: 0.0874\n",
      "Epoch 42/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 45/60, Loss: 0.0900, Val Loss: 0.0886\n",
      "Epoch 60/60, Loss: 0.0892, Val Loss: 0.0896\n",
      "[Trial 72] Validation Loss: 0.0896\n",
      "Epoch 30/60, Loss: 0.0969, Val Loss: 0.0875\n",
      "Epoch 33/60, Loss: 0.0938, Val Loss: 0.0884\n",
      "Epoch 50/60, Loss: 0.0886, Val Loss: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:30:51,278] Trial 72 finished with value: 0.08958107978105545 and parameters: {'hidden_dim': 128, 'latent_dim': 32, 'lr': 5.687210714100786e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 88] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00202778456898668, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 35/60, Loss: 0.0908, Val Loss: 0.0882\n",
      "Epoch 16/60, Loss: 0.0980, Val Loss: 0.0906\n",
      "Epoch 32/60, Loss: 0.0896, Val Loss: 0.0909\n",
      "Epoch 36/60, Loss: 0.0904, Val Loss: 0.0878\n",
      "Epoch 48/60, Loss: 0.0901, Val Loss: 0.0874\n",
      "Epoch 43/60, Loss: 0.0894, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.0993, Val Loss: 0.0905\n",
      "Epoch 46/60, Loss: 0.0898, Val Loss: 0.0885\n",
      "Epoch 31/60, Loss: 0.0961, Val Loss: 0.0874\n",
      "Epoch 34/60, Loss: 0.0933, Val Loss: 0.0884\n",
      "Epoch 7/60, Loss: 0.1017, Val Loss: 0.0914\n",
      "Epoch 1/60, Loss: 0.3688, Val Loss: 0.0988\n",
      "Epoch 36/60, Loss: 0.0907, Val Loss: 0.0881\n",
      "Epoch 51/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 15/60, Loss: 0.0986, Val Loss: 0.0899\n",
      "Epoch 37/60, Loss: 0.0902, Val Loss: 0.0878\n",
      "Epoch 33/60, Loss: 0.0893, Val Loss: 0.0909\n",
      "Epoch 8/60, Loss: 0.0878, Val Loss: 0.0919\n",
      "Epoch 2/60, Loss: 0.1046, Val Loss: 0.0899\n",
      "Epoch 49/60, Loss: 0.0899, Val Loss: 0.0874\n",
      "Epoch 44/60, Loss: 0.0892, Val Loss: 0.0895\n",
      "Epoch 17/60, Loss: 0.0963, Val Loss: 0.0904\n",
      "Epoch 47/60, Loss: 0.0899, Val Loss: 0.0885\n",
      "Epoch 35/60, Loss: 0.0931, Val Loss: 0.0884\n",
      "Epoch 32/60, Loss: 0.0956, Val Loss: 0.0874\n",
      "Epoch 9/60, Loss: 0.0944, Val Loss: 0.0882\n",
      "Epoch 37/60, Loss: 0.0906, Val Loss: 0.0881\n",
      "Epoch 3/60, Loss: 0.0945, Val Loss: 0.0889\n",
      "Epoch 52/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 38/60, Loss: 0.0902, Val Loss: 0.0878\n",
      "Epoch 34/60, Loss: 0.0893, Val Loss: 0.0910\n",
      "Epoch 50/60, Loss: 0.0900, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.0922, Val Loss: 0.0880\n",
      "Epoch 36/60, Loss: 0.0928, Val Loss: 0.0884\n",
      "Epoch 33/60, Loss: 0.0951, Val Loss: 0.0873\n",
      "Epoch 45/60, Loss: 0.0892, Val Loss: 0.0895\n",
      "Epoch 48/60, Loss: 0.0896, Val Loss: 0.0885\n",
      "Epoch 16/60, Loss: 0.0970, Val Loss: 0.0898\n",
      "Epoch 38/60, Loss: 0.0905, Val Loss: 0.0880\n",
      "Epoch 39/60, Loss: 0.0901, Val Loss: 0.0878\n",
      "Epoch 5/60, Loss: 0.0909, Val Loss: 0.0876\n",
      "Epoch 53/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 35/60, Loss: 0.0892, Val Loss: 0.0909\n",
      "Epoch 18/60, Loss: 0.0951, Val Loss: 0.0905\n",
      "Epoch 37/60, Loss: 0.0925, Val Loss: 0.0883\n",
      "Epoch 34/60, Loss: 0.0947, Val Loss: 0.0873\n",
      "Epoch 51/60, Loss: 0.0899, Val Loss: 0.0874\n",
      "Epoch 46/60, Loss: 0.0892, Val Loss: 0.0895\n",
      "Epoch 49/60, Loss: 0.0897, Val Loss: 0.0885\n",
      "Epoch 6/60, Loss: 0.0904, Val Loss: 0.0877\n",
      "Epoch 39/60, Loss: 0.0903, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.0962, Val Loss: 0.0903\n",
      "Epoch 8/60, Loss: 0.0978, Val Loss: 0.0909\n",
      "Epoch 40/60, Loss: 0.0901, Val Loss: 0.0878\n",
      "Epoch 7/60, Loss: 0.0900, Val Loss: 0.0874\n",
      "Epoch 36/60, Loss: 0.0891, Val Loss: 0.0909\n",
      "Epoch 17/60, Loss: 0.0957, Val Loss: 0.0897\n",
      "Epoch 38/60, Loss: 0.0922, Val Loss: 0.0883\n",
      "Epoch 35/60, Loss: 0.0942, Val Loss: 0.0872\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 9/60, Loss: 0.0875, Val Loss: 0.0916\n",
      "Epoch 52/60, Loss: 0.0900, Val Loss: 0.0874\n",
      "Epoch 47/60, Loss: 0.0890, Val Loss: 0.0895\n",
      "Epoch 50/60, Loss: 0.0894, Val Loss: 0.0884\n",
      "Epoch 40/60, Loss: 0.0901, Val Loss: 0.0880\n",
      "Epoch 8/60, Loss: 0.0898, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.0930, Val Loss: 0.0879\n",
      "Epoch 41/60, Loss: 0.0899, Val Loss: 0.0878\n",
      "Epoch 19/60, Loss: 0.0942, Val Loss: 0.0903\n",
      "Epoch 39/60, Loss: 0.0920, Val Loss: 0.0883\n",
      "Epoch 36/60, Loss: 0.0938, Val Loss: 0.0872\n",
      "Epoch 37/60, Loss: 0.0889, Val Loss: 0.0908\n",
      "Epoch 9/60, Loss: 0.0898, Val Loss: 0.0875\n",
      "Epoch 53/60, Loss: 0.0898, Val Loss: 0.0874\n",
      "Epoch 55/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 48/60, Loss: 0.0889, Val Loss: 0.0895\n",
      "Epoch 51/60, Loss: 0.0895, Val Loss: 0.0883\n",
      "Epoch 41/60, Loss: 0.0902, Val Loss: 0.0881\n",
      "Epoch 42/60, Loss: 0.0899, Val Loss: 0.0878\n",
      "Epoch 18/60, Loss: 0.0947, Val Loss: 0.0898\n",
      "Epoch 10/60, Loss: 0.0895, Val Loss: 0.0873\n",
      "Epoch 40/60, Loss: 0.0917, Val Loss: 0.0883\n",
      "Epoch 37/60, Loss: 0.0935, Val Loss: 0.0872\n",
      "Epoch 38/60, Loss: 0.0888, Val Loss: 0.0909\n",
      "Epoch 54/60, Loss: 0.0897, Val Loss: 0.0874\n",
      "Epoch 42/60, Loss: 0.0900, Val Loss: 0.0880\n",
      "Epoch 49/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.0895, Val Loss: 0.0874\n",
      "Epoch 52/60, Loss: 0.0893, Val Loss: 0.0884\n",
      "Epoch 20/60, Loss: 0.0934, Val Loss: 0.0903\n",
      "Epoch 43/60, Loss: 0.0898, Val Loss: 0.0878\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 9/60, Loss: 0.0949, Val Loss: 0.0907\n",
      "Epoch 10/60, Loss: 0.0941, Val Loss: 0.0902\n",
      "Epoch 41/60, Loss: 0.0915, Val Loss: 0.0883\n",
      "Epoch 12/60, Loss: 0.0895, Val Loss: 0.0873\n",
      "Epoch 38/60, Loss: 0.0931, Val Loss: 0.0872\n",
      "Epoch 39/60, Loss: 0.0888, Val Loss: 0.0907\n",
      "Epoch 44/60, Loss: 0.0897, Val Loss: 0.0878\n",
      "Epoch 55/60, Loss: 0.0897, Val Loss: 0.0874\n",
      "Epoch 43/60, Loss: 0.0899, Val Loss: 0.0880\n",
      "Epoch 10/60, Loss: 0.0875, Val Loss: 0.0916\n",
      "Epoch 50/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 53/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 19/60, Loss: 0.0938, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.0893, Val Loss: 0.0873\n",
      "Epoch 57/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 11/60, Loss: 0.0918, Val Loss: 0.0879\n",
      "Epoch 42/60, Loss: 0.0913, Val Loss: 0.0882\n",
      "Epoch 39/60, Loss: 0.0928, Val Loss: 0.0872\n",
      "Epoch 45/60, Loss: 0.0897, Val Loss: 0.0877\n",
      "Epoch 14/60, Loss: 0.0893, Val Loss: 0.0873\n",
      "Epoch 21/60, Loss: 0.0924, Val Loss: 0.0902\n",
      "Epoch 40/60, Loss: 0.0887, Val Loss: 0.0906\n",
      "Epoch 56/60, Loss: 0.0896, Val Loss: 0.0874\n",
      "Epoch 44/60, Loss: 0.0899, Val Loss: 0.0880\n",
      "Epoch 51/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 54/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 15/60, Loss: 0.0892, Val Loss: 0.0871\n",
      "Epoch 43/60, Loss: 0.0911, Val Loss: 0.0883\n",
      "Epoch 58/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 46/60, Loss: 0.0895, Val Loss: 0.0877\n",
      "Epoch 40/60, Loss: 0.0926, Val Loss: 0.0871\n",
      "Epoch 20/60, Loss: 0.0930, Val Loss: 0.0895\n",
      "Epoch 41/60, Loss: 0.0885, Val Loss: 0.0907\n",
      "Epoch 16/60, Loss: 0.0890, Val Loss: 0.0871\n",
      "Epoch 45/60, Loss: 0.0897, Val Loss: 0.0880\n",
      "Epoch 57/60, Loss: 0.0896, Val Loss: 0.0874\n",
      "Epoch 52/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 55/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "Epoch 47/60, Loss: 0.0894, Val Loss: 0.0877\n",
      "Epoch 44/60, Loss: 0.0910, Val Loss: 0.0883\n",
      "Epoch 10/60, Loss: 0.0931, Val Loss: 0.0905\n",
      "Epoch 11/60, Loss: 0.0925, Val Loss: 0.0901\n",
      "Epoch 41/60, Loss: 0.0923, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0920, Val Loss: 0.0902\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0871\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0906\n",
      "Epoch 46/60, Loss: 0.0897, Val Loss: 0.0879\n",
      "Epoch 58/60, Loss: 0.0895, Val Loss: 0.0874\n",
      "Epoch 53/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0889, Val Loss: 0.0870\n",
      "Epoch 56/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "Epoch 48/60, Loss: 0.0894, Val Loss: 0.0877\n",
      "Epoch 11/60, Loss: 0.0877, Val Loss: 0.0916\n",
      "Epoch 45/60, Loss: 0.0907, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0923, Val Loss: 0.0895\n",
      "Epoch 42/60, Loss: 0.0921, Val Loss: 0.0870\n",
      "Epoch 12/60, Loss: 0.0912, Val Loss: 0.0877\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0869\n",
      "Epoch 60/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Early stopping triggered\n",
      "[Trial 73] Validation Loss: 0.0878\n",
      "Epoch 47/60, Loss: 0.0898, Val Loss: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:39:16,811] Trial 73 finished with value: 0.08782617350419362 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 7.198406973830452e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 89] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0019337994485620672, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0906\n",
      "Epoch 49/60, Loss: 0.0892, Val Loss: 0.0876\n",
      "Epoch 59/60, Loss: 0.0894, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0885, Val Loss: 0.0892\n",
      "Epoch 57/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 23/60, Loss: 0.0916, Val Loss: 0.0901\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 46/60, Loss: 0.0907, Val Loss: 0.0882\n",
      "Epoch 43/60, Loss: 0.0919, Val Loss: 0.0870\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 50/60, Loss: 0.0893, Val Loss: 0.0876\n",
      "Epoch 48/60, Loss: 0.0895, Val Loss: 0.0879\n",
      "Epoch 44/60, Loss: 0.0885, Val Loss: 0.0905\n",
      "Epoch 60/60, Loss: 0.0894, Val Loss: 0.0874\n",
      "Epoch 55/60, Loss: 0.0884, Val Loss: 0.0893\n",
      "Epoch 22/60, Loss: 0.0917, Val Loss: 0.0894\n",
      "Epoch 58/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "[Trial 75] Validation Loss: 0.0874\n",
      "Epoch 47/60, Loss: 0.0905, Val Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:40:11,166] Trial 75 finished with value: 0.08737023547291756 and parameters: {'hidden_dim': 128, 'latent_dim': 96, 'lr': 6.696492767998545e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 90] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0018616633211972157, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0867\n",
      "Epoch 44/60, Loss: 0.0915, Val Loss: 0.0870\n",
      "Epoch 11/60, Loss: 0.0921, Val Loss: 0.0904\n",
      "Epoch 12/60, Loss: 0.0918, Val Loss: 0.0900\n",
      "Epoch 51/60, Loss: 0.0891, Val Loss: 0.0876\n",
      "Epoch 49/60, Loss: 0.0894, Val Loss: 0.0879\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 24/60, Loss: 0.0913, Val Loss: 0.0901\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0905\n",
      "Epoch 59/60, Loss: 0.0888, Val Loss: 0.0883\n",
      "Epoch 48/60, Loss: 0.0904, Val Loss: 0.0882\n",
      "Epoch 56/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 45/60, Loss: 0.0914, Val Loss: 0.0871\n",
      "Epoch 12/60, Loss: 0.0876, Val Loss: 0.0913\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0869\n",
      "Epoch 52/60, Loss: 0.0892, Val Loss: 0.0876\n",
      "Epoch 13/60, Loss: 0.0905, Val Loss: 0.0879\n",
      "Epoch 23/60, Loss: 0.0915, Val Loss: 0.0893\n",
      "Epoch 50/60, Loss: 0.0893, Val Loss: 0.0879\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0905\n",
      "Epoch 49/60, Loss: 0.0903, Val Loss: 0.0881\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 60/60, Loss: 0.0888, Val Loss: 0.0882\n",
      "[Trial 74] Validation Loss: 0.0882\n",
      "Epoch 57/60, Loss: 0.0883, Val Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:41:36,090] Trial 74 finished with value: 0.08822662929693857 and parameters: {'hidden_dim': 256, 'latent_dim': 96, 'lr': 4.028660222497338e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 91] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.001955006270993221, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 46/60, Loss: 0.0913, Val Loss: 0.0870\n",
      "Epoch 53/60, Loss: 0.0890, Val Loss: 0.0875\n",
      "Epoch 1/60, Loss: 0.1383, Val Loss: 0.0907\n",
      "Epoch 25/60, Loss: 0.0909, Val Loss: 0.0901\n",
      "Epoch 26/60, Loss: 0.0885, Val Loss: 0.0867\n",
      "Epoch 51/60, Loss: 0.0894, Val Loss: 0.0878\n",
      "Epoch 50/60, Loss: 0.0902, Val Loss: 0.0882\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0905\n",
      "Epoch 47/60, Loss: 0.0912, Val Loss: 0.0870\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0869\n",
      "Epoch 58/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 54/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 24/60, Loss: 0.0912, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0912, Val Loss: 0.0907\n",
      "Epoch 52/60, Loss: 0.0892, Val Loss: 0.0877\n",
      "Epoch 13/60, Loss: 0.0905, Val Loss: 0.0900\n",
      "Epoch 1/60, Loss: 0.1439, Val Loss: 0.0889\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 51/60, Loss: 0.0900, Val Loss: 0.0881\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0905\n",
      "Epoch 48/60, Loss: 0.0909, Val Loss: 0.0869\n",
      "Epoch 55/60, Loss: 0.0889, Val Loss: 0.0874\n",
      "Epoch 26/60, Loss: 0.0904, Val Loss: 0.0900\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0875, Val Loss: 0.0914\n",
      "Epoch 53/60, Loss: 0.0892, Val Loss: 0.0877\n",
      "Epoch 52/60, Loss: 0.0900, Val Loss: 0.0881\n",
      "Epoch 14/60, Loss: 0.0903, Val Loss: 0.0877\n",
      "Epoch 49/60, Loss: 0.0910, Val Loss: 0.0870\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0904\n",
      "Epoch 25/60, Loss: 0.0906, Val Loss: 0.0893\n",
      "Epoch 56/60, Loss: 0.0887, Val Loss: 0.0873\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 60/60, Loss: 0.0882, Val Loss: 0.0890\n",
      "Epoch 2/60, Loss: 0.0893, Val Loss: 0.0905\n",
      "Epoch 1/60, Loss: 0.1433, Val Loss: 0.0888\n",
      "Epoch 53/60, Loss: 0.0899, Val Loss: 0.0881\n",
      "Epoch 54/60, Loss: 0.0891, Val Loss: 0.0877\n",
      "[Trial 76] Validation Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:44:07,435] Trial 76 finished with value: 0.08904657910267512 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 5.1254233548958216e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 92] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0017556303730770096, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 50/60, Loss: 0.0908, Val Loss: 0.0870\n",
      "Epoch 27/60, Loss: 0.0900, Val Loss: 0.0900\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0865\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0903\n",
      "Epoch 57/60, Loss: 0.0888, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0898, Val Loss: 0.0881\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0865\n",
      "Epoch 55/60, Loss: 0.0892, Val Loss: 0.0876\n",
      "Epoch 13/60, Loss: 0.0908, Val Loss: 0.0903\n",
      "Epoch 26/60, Loss: 0.0907, Val Loss: 0.0894\n",
      "Epoch 51/60, Loss: 0.0907, Val Loss: 0.0869\n",
      "Epoch 2/60, Loss: 0.0899, Val Loss: 0.0874\n",
      "Epoch 14/60, Loss: 0.0902, Val Loss: 0.0899\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 51/60, Loss: 0.0879, Val Loss: 0.0903\n",
      "Epoch 58/60, Loss: 0.0888, Val Loss: 0.0873\n",
      "Epoch 55/60, Loss: 0.0898, Val Loss: 0.0881\n",
      "Epoch 28/60, Loss: 0.0897, Val Loss: 0.0901\n",
      "Epoch 56/60, Loss: 0.0889, Val Loss: 0.0877\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 52/60, Loss: 0.0906, Val Loss: 0.0869\n",
      "Epoch 14/60, Loss: 0.0908, Val Loss: 0.0935\n",
      "Epoch 15/60, Loss: 0.0900, Val Loss: 0.0876\n",
      "Epoch 52/60, Loss: 0.0879, Val Loss: 0.0904\n",
      "Epoch 59/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 36/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 56/60, Loss: 0.0896, Val Loss: 0.0880\n",
      "Epoch 27/60, Loss: 0.0902, Val Loss: 0.0893\n",
      "Epoch 57/60, Loss: 0.0889, Val Loss: 0.0876\n",
      "Epoch 2/60, Loss: 0.0896, Val Loss: 0.0886\n",
      "Epoch 53/60, Loss: 0.0905, Val Loss: 0.0869\n",
      "Epoch 3/60, Loss: 0.0887, Val Loss: 0.0904\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 1/60, Loss: 0.1463, Val Loss: 0.0883\n",
      "Epoch 60/60, Loss: 0.0887, Val Loss: 0.0873\n",
      "Epoch 29/60, Loss: 0.0898, Val Loss: 0.0899\n",
      "Epoch 53/60, Loss: 0.0879, Val Loss: 0.0903\n",
      "Epoch 57/60, Loss: 0.0895, Val Loss: 0.0880\n",
      "[Trial 77] Validation Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0884, Val Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:46:51,710] Trial 77 finished with value: 0.08735049615303675 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 5.376875364548665e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 93] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.001912517836444088, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 58/60, Loss: 0.0888, Val Loss: 0.0876\n",
      "Epoch 54/60, Loss: 0.0904, Val Loss: 0.0869\n",
      "Epoch 14/60, Loss: 0.0899, Val Loss: 0.0902\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0865\n",
      "Early stopping triggered\n",
      "Epoch 3/60, Loss: 0.0894, Val Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:47:20,102] Trial 88 finished with value: 0.08652963836987813 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00202778456898668, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 88] Validation Loss: 0.0865\n",
      "\n",
      "[Trial 94] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002204734961588676, 'batch_size': 64, 'patience': 8}\n",
      "Epoch 15/60, Loss: 0.0896, Val Loss: 0.0899\n",
      "Epoch 28/60, Loss: 0.0900, Val Loss: 0.0893\n",
      "Epoch 58/60, Loss: 0.0895, Val Loss: 0.0881\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0903\n",
      "Epoch 55/60, Loss: 0.0903, Val Loss: 0.0869\n",
      "Epoch 59/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 1/60, Loss: 0.3495, Val Loss: 0.1025\n",
      "Epoch 30/60, Loss: 0.0897, Val Loss: 0.0900\n",
      "Epoch 15/60, Loss: 0.0881, Val Loss: 0.0915\n",
      "Epoch 2/60, Loss: 0.1025, Val Loss: 0.0925\n",
      "Epoch 59/60, Loss: 0.0895, Val Loss: 0.0879\n",
      "Epoch 16/60, Loss: 0.0897, Val Loss: 0.0875\n",
      "Epoch 55/60, Loss: 0.0876, Val Loss: 0.0902\n",
      "Epoch 56/60, Loss: 0.0903, Val Loss: 0.0868\n",
      "Epoch 60/60, Loss: 0.0887, Val Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:48:37,744] Trial 78 finished with value: 0.08753162572781245 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 4.749241855750065e-05, 'batch_size': 32, 'patience': 5}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 78] Validation Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.0932, Val Loss: 0.0914\n",
      "\n",
      "[Trial 95] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0019956282404503564, 'batch_size': 64, 'patience': 8}\n",
      "Epoch 3/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 29/60, Loss: 0.0897, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.0885, Val Loss: 0.0902\n",
      "Epoch 60/60, Loss: 0.0894, Val Loss: 0.0879\n",
      "Epoch 4/60, Loss: 0.0912, Val Loss: 0.0904\n",
      "Epoch 2/60, Loss: 0.0900, Val Loss: 0.0884\n",
      "[Trial 80] Validation Loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:49:05,087] Trial 80 finished with value: 0.08791433349251747 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 6.01384511505037e-05, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 96] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0023879190376969255, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 1/60, Loss: 0.3808, Val Loss: 0.1029\n",
      "Epoch 57/60, Loss: 0.0902, Val Loss: 0.0869\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0902\n",
      "Epoch 31/60, Loss: 0.0896, Val Loss: 0.0900\n",
      "Epoch 1/60, Loss: 0.1432, Val Loss: 0.0865\n",
      "Epoch 5/60, Loss: 0.0901, Val Loss: 0.0901\n",
      "Epoch 2/60, Loss: 0.1028, Val Loss: 0.0929\n",
      "Epoch 15/60, Loss: 0.0896, Val Loss: 0.0901\n",
      "Epoch 1/60, Loss: 0.3498, Val Loss: 0.0998\n",
      "Epoch 4/60, Loss: 0.0892, Val Loss: 0.0871\n",
      "Epoch 16/60, Loss: 0.0895, Val Loss: 0.0898\n",
      "Epoch 6/60, Loss: 0.0896, Val Loss: 0.0900\n",
      "Epoch 58/60, Loss: 0.0901, Val Loss: 0.0868\n",
      "Epoch 3/60, Loss: 0.0941, Val Loss: 0.0919\n",
      "Epoch 2/60, Loss: 0.1008, Val Loss: 0.0903\n",
      "Epoch 30/60, Loss: 0.0897, Val Loss: 0.0892\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0902\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0900\n",
      "Epoch 4/60, Loss: 0.0917, Val Loss: 0.0909\n",
      "Epoch 3/60, Loss: 0.0934, Val Loss: 0.0896\n",
      "Epoch 16/60, Loss: 0.0875, Val Loss: 0.0915\n",
      "Epoch 32/60, Loss: 0.0894, Val Loss: 0.0900\n",
      "Epoch 59/60, Loss: 0.0900, Val Loss: 0.0868\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0900\n",
      "Epoch 5/60, Loss: 0.0904, Val Loss: 0.0905\n",
      "Epoch 17/60, Loss: 0.0895, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.0917, Val Loss: 0.0890\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0902\n",
      "Epoch 4/60, Loss: 0.0890, Val Loss: 0.0884\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0900\n",
      "Epoch 6/60, Loss: 0.0898, Val Loss: 0.0905\n",
      "Epoch 5/60, Loss: 0.0884, Val Loss: 0.0903\n",
      "Epoch 5/60, Loss: 0.0908, Val Loss: 0.0888\n",
      "Epoch 60/60, Loss: 0.0900, Val Loss: 0.0869\n",
      "Epoch 31/60, Loss: 0.0895, Val Loss: 0.0892\n",
      "[Trial 81] Validation Loss: 0.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:51:19,389] Trial 81 finished with value: 0.08686573182543118 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.288048041953943e-05, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 97] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0022704364433580983, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 3/60, Loss: 0.0894, Val Loss: 0.0878\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0904\n",
      "Epoch 6/60, Loss: 0.0902, Val Loss: 0.0883\n",
      "Epoch 59/60, Loss: 0.0877, Val Loss: 0.0902\n",
      "Epoch 2/60, Loss: 0.0902, Val Loss: 0.0859\n",
      "Epoch 33/60, Loss: 0.0892, Val Loss: 0.0899\n",
      "Epoch 1/60, Loss: 0.3627, Val Loss: 0.1013\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 16/60, Loss: 0.0895, Val Loss: 0.0900\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0905\n",
      "Epoch 7/60, Loss: 0.0899, Val Loss: 0.0885\n",
      "Epoch 5/60, Loss: 0.0890, Val Loss: 0.0870\n",
      "Epoch 17/60, Loss: 0.0894, Val Loss: 0.0899\n",
      "Epoch 2/60, Loss: 0.1057, Val Loss: 0.0937\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0904\n",
      "Epoch 60/60, Loss: 0.0876, Val Loss: 0.0902\n",
      "Epoch 8/60, Loss: 0.0896, Val Loss: 0.0883\n",
      "[Trial 79] Validation Loss: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:52:32,445] Trial 79 finished with value: 0.09015663613875707 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 6.585730619223292e-05, 'batch_size': 32, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 98] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0024468705493102165, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 32/60, Loss: 0.0892, Val Loss: 0.0892\n",
      "Epoch 3/60, Loss: 0.0947, Val Loss: 0.0898\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0903\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 17/60, Loss: 0.0876, Val Loss: 0.0915\n",
      "Epoch 4/60, Loss: 0.0922, Val Loss: 0.0889\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 34/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0904\n",
      "Epoch 18/60, Loss: 0.0894, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0882\n",
      "Epoch 1/60, Loss: 0.3537, Val Loss: 0.1006\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0908, Val Loss: 0.0885\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0903\n",
      "Epoch 6/60, Loss: 0.0882, Val Loss: 0.0901\n",
      "Epoch 11/60, Loss: 0.0893, Val Loss: 0.0882\n",
      "Epoch 2/60, Loss: 0.1013, Val Loss: 0.0919\n",
      "Epoch 4/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "Epoch 6/60, Loss: 0.0902, Val Loss: 0.0882\n",
      "Epoch 33/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0887, Val Loss: 0.0903\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0898\n",
      "Epoch 12/60, Loss: 0.0893, Val Loss: 0.0882\n",
      "Epoch 3/60, Loss: 0.0900, Val Loss: 0.0862\n",
      "Epoch 3/60, Loss: 0.0932, Val Loss: 0.0908\n",
      "Epoch 7/60, Loss: 0.0900, Val Loss: 0.0882\n",
      "Epoch 17/60, Loss: 0.0893, Val Loss: 0.0900\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0903\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 35/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 6/60, Loss: 0.0889, Val Loss: 0.0869\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0898\n",
      "Epoch 8/60, Loss: 0.0897, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.0913, Val Loss: 0.0898\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0902\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 14/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.0895, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0903, Val Loss: 0.0896\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0902\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 34/60, Loss: 0.0894, Val Loss: 0.0893\n",
      "Epoch 15/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 18/60, Loss: 0.0873, Val Loss: 0.0915\n",
      "Early stopping triggered\n",
      "[Trial 86] Validation Loss: 0.0915\n",
      "Epoch 10/60, Loss: 0.0894, Val Loss: 0.0880\n",
      "Epoch 6/60, Loss: 0.0898, Val Loss: 0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 14:55:15,202] Trial 86 finished with value: 0.0914665804244578 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00197129406763158, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 99] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002179830913619954, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0901\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 19/60, Loss: 0.0894, Val Loss: 0.0875\n",
      "Epoch 16/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 36/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 11/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0900\n",
      "Epoch 7/60, Loss: 0.0882, Val Loss: 0.0900\n",
      "Epoch 21/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 12/60, Loss: 0.0892, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0877\n",
      "Epoch 1/60, Loss: 0.3796, Val Loss: 0.1004\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0899\n",
      "Epoch 8/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0858\n",
      "Epoch 35/60, Loss: 0.0892, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0893, Val Loss: 0.0881\n",
      "Epoch 2/60, Loss: 0.1030, Val Loss: 0.0906\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0899\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0894\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 7/60, Loss: 0.0889, Val Loss: 0.0869\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "Epoch 14/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 37/60, Loss: 0.0889, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.0938, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0879\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 15/60, Loss: 0.0892, Val Loss: 0.0880\n",
      "Epoch 4/60, Loss: 0.0919, Val Loss: 0.0888\n",
      "Epoch 22/60, Loss: 0.0881, Val Loss: 0.0899\n",
      "Epoch 11/60, Loss: 0.0890, Val Loss: 0.0893\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 36/60, Loss: 0.0891, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.0891, Val Loss: 0.0879\n",
      "Epoch 5/60, Loss: 0.0909, Val Loss: 0.0886\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0897\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0892, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 7/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0880\n",
      "Epoch 6/60, Loss: 0.0901, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0897\n",
      "Epoch 8/60, Loss: 0.0881, Val Loss: 0.0899\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0891\n",
      "Epoch 38/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0895, Val Loss: 0.0854\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0880\n",
      "Epoch 6/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0882\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0897\n",
      "Epoch 14/60, Loss: 0.0889, Val Loss: 0.0891\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0878\n",
      "Epoch 8/60, Loss: 0.0896, Val Loss: 0.0883\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "Epoch 37/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0897\n",
      "Epoch 15/60, Loss: 0.0889, Val Loss: 0.0891\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0869\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0878\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "Epoch 9/60, Loss: 0.0896, Val Loss: 0.0881\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Epoch 16/60, Loss: 0.0887, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 39/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0876\n",
      "Epoch 10/60, Loss: 0.0895, Val Loss: 0.0880\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0896\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0888\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 11/60, Loss: 0.0893, Val Loss: 0.0881\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Epoch 18/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 21/60, Loss: 0.0892, Val Loss: 0.0875\n",
      "Epoch 38/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 23/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 12/60, Loss: 0.0893, Val Loss: 0.0880\n",
      "Epoch 9/60, Loss: 0.0879, Val Loss: 0.0900\n",
      "Epoch 30/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 6/60, Loss: 0.0893, Val Loss: 0.0855\n",
      "Epoch 24/60, Loss: 0.0887, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0887, Val Loss: 0.0898\n",
      "Epoch 13/60, Loss: 0.0893, Val Loss: 0.0880\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0873\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 20/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 14/60, Loss: 0.0891, Val Loss: 0.0879\n",
      "Epoch 32/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0899\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0887, Val Loss: 0.0869\n",
      "Epoch 39/60, Loss: 0.0890, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0890, Val Loss: 0.0878\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0897\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 22/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 27/60, Loss: 0.0886, Val Loss: 0.0874\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 41/60, Loss: 0.0885, Val Loss: 0.0897\n",
      "Epoch 33/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 37/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 17/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0887\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0874\n",
      "Epoch 7/60, Loss: 0.0893, Val Loss: 0.0853\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 18/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 40/60, Loss: 0.0889, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0886\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 10/60, Loss: 0.0881, Val Loss: 0.0897\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 37/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0873\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0898\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0898\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 10/60, Loss: 0.0887, Val Loss: 0.0868\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0888, Val Loss: 0.0897\n",
      "Epoch 39/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 41/60, Loss: 0.0887, Val Loss: 0.0890\n",
      "Epoch 42/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0854\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 43/60, Loss: 0.0885, Val Loss: 0.0897\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 40/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 23/60, Loss: 0.0890, Val Loss: 0.0874\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0891Epoch 24/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 10/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 11/60, Loss: 0.0881, Val Loss: 0.0899\n",
      "Epoch 25/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 42/60, Loss: 0.0890, Val Loss: 0.0890\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 43/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 42/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 37/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 44/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0898\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0870\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0896\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0856\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 46/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0888, Val Loss: 0.0889\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 47/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0873\n",
      "Epoch 48/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 37/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 12/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Epoch 49/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 44/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 10/60, Loss: 0.0892, Val Loss: 0.0853\n",
      "Epoch 51/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0898\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0895\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0869\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0896\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 41/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0898\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 53/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 45/60, Loss: 0.0887, Val Loss: 0.0889\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 56/60, Loss: 0.0937, Val Loss: 0.0901\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 54/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0873\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0872\n",
      "Epoch 57/60, Loss: 0.0885, Val Loss: 0.0895\n",
      "Epoch 48/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 55/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 44/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 13/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 38/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 12/60, Loss: 0.0902, Val Loss: 0.0879\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 56/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0852\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Early stopping triggered\n",
      "[Trial 98] Validation Loss: 0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:10:03,190] Trial 98 finished with value: 0.0884063442548116 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0024468705493102165, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 100] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.009660946184511443, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 11/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 59/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 57/60, Loss: 0.0917, Val Loss: 0.0931\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 40/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 1/60, Loss: 0.2331, Val Loss: 0.1011\n",
      "[Trial 94] Validation Loss: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:10:38,274] Trial 94 finished with value: 0.08909047593673071 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002204734961588676, 'batch_size': 64, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 101] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0035857961173957342, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 51/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 58/60, Loss: 0.0887, Val Loss: 0.0898\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 48/60, Loss: 0.0880, Val Loss: 0.0895\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 2/60, Loss: 0.0978, Val Loss: 0.0921\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 59/60, Loss: 0.0880, Val Loss: 0.0896\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 1/60, Loss: 0.2776, Val Loss: 0.0974\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 3/60, Loss: 0.0922, Val Loss: 0.0907\n",
      "Epoch 47/60, Loss: 0.0887, Val Loss: 0.0889\n",
      "Epoch 53/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "[Trial 95] Validation Loss: 0.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:11:33,606] Trial 95 finished with value: 0.08950393150250117 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0019956282404503564, 'batch_size': 64, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 102] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004070220565707142, 'batch_size': 64, 'patience': 6}\n",
      "Epoch 2/60, Loss: 0.0957, Val Loss: 0.0897\n",
      "Epoch 4/60, Loss: 0.0907, Val Loss: 0.0902\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "[Trial 96] Validation Loss: 0.0873\n",
      "Epoch 3/60, Loss: 0.0918, Val Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:12:00,030] Trial 96 finished with value: 0.0873106782635053 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0023879190376969255, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 103] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.00374238377098403, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 14/60, Loss: 0.0905, Val Loss: 0.0896\n",
      "Epoch 5/60, Loss: 0.0898, Val Loss: 0.0887\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0853\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 1/60, Loss: 0.3563, Val Loss: 0.1009\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 4/60, Loss: 0.0905, Val Loss: 0.0879\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0886\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0874\n",
      "Epoch 2/60, Loss: 0.1057, Val Loss: 0.0952\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0888\n",
      "Epoch 5/60, Loss: 0.0899, Val Loss: 0.0880\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 7/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 3/60, Loss: 0.0970, Val Loss: 0.0895\n",
      "Epoch 57/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0895\n",
      "Epoch 6/60, Loss: 0.0899, Val Loss: 0.0879\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0866\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 4/60, Loss: 0.0929, Val Loss: 0.0880\n",
      "Epoch 1/60, Loss: 0.1816, Val Loss: 0.0923\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 58/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0878\n",
      "Epoch 5/60, Loss: 0.0918, Val Loss: 0.0874\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0887\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 49/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0878\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.0910, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0889\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 60/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "[Trial 97] Validation Loss: 0.0873\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:14:15,286] Trial 97 finished with value: 0.08729331294695536 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0022704364433580983, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 104] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0038476956262656716, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0851\n",
      "Epoch 7/60, Loss: 0.0906, Val Loss: 0.0869\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 2/60, Loss: 0.0910, Val Loss: 0.0891\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0879\n",
      "Epoch 8/60, Loss: 0.0902, Val Loss: 0.0869\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 13/60, Loss: 0.0908, Val Loss: 0.0875\n",
      "Epoch 51/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 11/60, Loss: 0.0894, Val Loss: 0.0878\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 9/60, Loss: 0.0900, Val Loss: 0.0868\n",
      "Epoch 50/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 27/60, Loss: 0.0883, Val Loss: 0.0895\n",
      "Epoch 12/60, Loss: 0.0893, Val Loss: 0.0878\n",
      "Epoch 10/60, Loss: 0.0899, Val Loss: 0.0868\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0867\n",
      "Epoch 3/60, Loss: 0.0899, Val Loss: 0.0890\n",
      "Epoch 14/60, Loss: 0.0889, Val Loss: 0.0886\n",
      "Epoch 53/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 11/60, Loss: 0.0898, Val Loss: 0.0866\n",
      "Epoch 13/60, Loss: 0.0892, Val Loss: 0.0878\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 1/60, Loss: 0.1342, Val Loss: 0.0897\n",
      "Epoch 15/60, Loss: 0.0889, Val Loss: 0.0886\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 12/60, Loss: 0.0897, Val Loss: 0.0866\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Epoch 14/60, Loss: 0.0892, Val Loss: 0.0878\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 13/60, Loss: 0.0897, Val Loss: 0.0866\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 16/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 15/60, Loss: 0.0891, Val Loss: 0.0876\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0851\n",
      "Epoch 4/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 17/60, Loss: 0.0887, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0896, Val Loss: 0.0866\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 16/60, Loss: 0.0890, Val Loss: 0.0877\n",
      "Epoch 2/60, Loss: 0.0900, Val Loss: 0.0878\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0895\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0871\n",
      "Epoch 18/60, Loss: 0.0887, Val Loss: 0.0884\n",
      "Epoch 15/60, Loss: 0.0897, Val Loss: 0.0866\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 17/60, Loss: 0.0889, Val Loss: 0.0874\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 52/60, Loss: 0.0886, Val Loss: 0.0886\n",
      "Epoch 16/60, Loss: 0.0895, Val Loss: 0.0865\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0884\n",
      "Epoch 18/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 16/60, Loss: 0.0901, Val Loss: 0.0866\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0884\n",
      "Epoch 17/60, Loss: 0.0896, Val Loss: 0.0865\n",
      "Epoch 19/60, Loss: 0.0888, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.0896, Val Loss: 0.0885\n",
      "Epoch 59/60, Loss: 0.0926, Val Loss: 0.0887\n",
      "Epoch 54/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0883\n",
      "Epoch 18/60, Loss: 0.0895, Val Loss: 0.0866\n",
      "Epoch 29/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0872\n",
      "Epoch 60/60, Loss: 0.0890, Val Loss: 0.0875\n",
      "[Trial 99] Validation Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:18:30,867] Trial 99 finished with value: 0.08750553727149964 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002179830913619954, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 105] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.003647875037196721, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 19/60, Loss: 0.0895, Val Loss: 0.0865\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 6/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 17/60, Loss: 0.0887, Val Loss: 0.0898\n",
      "Epoch 15/60, Loss: 0.0891, Val Loss: 0.0852\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0872\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 20/60, Loss: 0.0894, Val Loss: 0.0865\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0882\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 4/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0872\n",
      "Epoch 21/60, Loss: 0.0894, Val Loss: 0.0862\n",
      "Epoch 28/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0870\n",
      "Epoch 22/60, Loss: 0.0893, Val Loss: 0.0862\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 7/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 25/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 17/60, Loss: 0.0888, Val Loss: 0.0866\n",
      "Epoch 1/60, Loss: 0.1856, Val Loss: 0.0905\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 23/60, Loss: 0.0893, Val Loss: 0.0862\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 25/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 24/60, Loss: 0.0892, Val Loss: 0.0862\n",
      "Epoch 5/60, Loss: 0.0892, Val Loss: 0.0881\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 30/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 25/60, Loss: 0.0892, Val Loss: 0.0860\n",
      "Epoch 16/60, Loss: 0.0891, Val Loss: 0.0852\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 2/60, Loss: 0.0905, Val Loss: 0.0891\n",
      "Epoch 18/60, Loss: 0.0881, Val Loss: 0.0900\n",
      "Epoch 27/60, Loss: 0.0886, Val Loss: 0.0870\n",
      "Epoch 26/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 17/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 29/60, Loss: 0.0883, Val Loss: 0.0880\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0873\n",
      "Epoch 27/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 16/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 6/60, Loss: 0.0892, Val Loss: 0.0875\n",
      "Epoch 28/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 29/60, Loss: 0.0885, Val Loss: 0.0870\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0883\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 3/60, Loss: 0.0897, Val Loss: 0.0888\n",
      "Epoch 29/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Epoch 18/60, Loss: 0.0889, Val Loss: 0.0865\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0881\n",
      "Epoch 30/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Epoch 17/60, Loss: 0.0942, Val Loss: 0.0852\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 31/60, Loss: 0.0891, Val Loss: 0.0861\n",
      "Early stopping triggered\n",
      "[Trial 102] Validation Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:22:43,914] Trial 102 finished with value: 0.08607684224843978 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.004070220565707142, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 106] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0033646023475789244, 'batch_size': 64, 'patience': 7}\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0871\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0870\n",
      "Epoch 7/60, Loss: 0.0889, Val Loss: 0.0873\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0882\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0893\n",
      "Epoch 4/60, Loss: 0.0894, Val Loss: 0.0889\n",
      "Epoch 34/60, Loss: 0.1270, Val Loss: 0.1228\n",
      "Early stopping triggered\n",
      "[Trial 100] Validation Loss: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:23:05,916] Trial 100 finished with value: 0.1227777823805809 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.009660946184511443, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 107] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.003735243668583108, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0870\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0899\n",
      "Epoch 1/60, Loss: 0.4317, Val Loss: 0.1029\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 57/60, Loss: 0.0883, Val Loss: 0.0885\n",
      "Epoch 34/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 2/60, Loss: 0.1074, Val Loss: 0.0975\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0871\n",
      "Epoch 3/60, Loss: 0.0978, Val Loss: 0.0926\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 5/60, Loss: 0.0892, Val Loss: 0.0889\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0875\n",
      "Epoch 59/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0854\n",
      "Epoch 4/60, Loss: 0.0930, Val Loss: 0.0904\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 1/60, Loss: 0.1799, Val Loss: 0.0909\n",
      "Epoch 5/60, Loss: 0.0912, Val Loss: 0.0898\n",
      "Epoch 58/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0870\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0898\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0887\n",
      "Epoch 38/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 6/60, Loss: 0.0891, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0899, Val Loss: 0.0897\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0874\n",
      "Epoch 60/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "[Trial 82] Validation Loss: 0.0893\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:25:29,606] Trial 82 finished with value: 0.08928355680157742 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 4.814986678449057e-05, 'batch_size': 16, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 108] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.003889135292360695, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 2/60, Loss: 0.0906, Val Loss: 0.0889\n",
      "Epoch 8/60, Loss: 0.0896, Val Loss: 0.0894\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0850\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0894\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0883\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0891\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0870\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0894\n",
      "Epoch 10/60, Loss: 0.0887, Val Loss: 0.0872\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0866\n",
      "Epoch 42/60, Loss: 0.0889, Val Loss: 0.0872\n",
      "Epoch 11/60, Loss: 0.0893, Val Loss: 0.0893\n",
      "Epoch 3/60, Loss: 0.0898, Val Loss: 0.0888\n",
      "Epoch 1/60, Loss: 0.1843, Val Loss: 0.0899\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 60/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 43/60, Loss: 0.0892, Val Loss: 0.0875\n",
      "Epoch 33/60, Loss: 0.0885, Val Loss: 0.0870\n",
      "[Trial 85] Validation Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:27:09,556] Trial 85 finished with value: 0.08846285703281562 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.229796049951665e-05, 'batch_size': 16, 'patience': 8}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 109] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0038530817188234296, 'batch_size': 64, 'patience': 7}\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0886\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 44/60, Loss: 0.0926, Val Loss: 0.0876\n",
      "Early stopping triggered\n",
      "[Trial 101] Validation Loss: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:27:33,578] Trial 101 finished with value: 0.08761772761742274 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0035857961173957342, 'batch_size': 64, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 110] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.00480103410703769, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 21/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 20/60, Loss: 0.0891, Val Loss: 0.0851\n",
      "Epoch 14/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.0893, Val Loss: 0.0888\n",
      "Epoch 1/60, Loss: 0.3967, Val Loss: 0.1008\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0873\n",
      "Epoch 2/60, Loss: 0.0907, Val Loss: 0.0887\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 15/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0872\n",
      "Epoch 2/60, Loss: 0.1041, Val Loss: 0.0927\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.0890, Val Loss: 0.0884\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0894\n",
      "Epoch 3/60, Loss: 0.0940, Val Loss: 0.0909\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0894\n",
      "Epoch 21/60, Loss: 0.0889, Val Loss: 0.0873\n",
      "Epoch 5/60, Loss: 0.0893, Val Loss: 0.0887\n",
      "Epoch 4/60, Loss: 0.0915, Val Loss: 0.0900\n",
      "Epoch 1/60, Loss: 0.1870, Val Loss: 0.0919\n",
      "Epoch 18/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 3/60, Loss: 0.0896, Val Loss: 0.0888\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0875\n",
      "Epoch 5/60, Loss: 0.0904, Val Loss: 0.0896\n",
      "Epoch 34/60, Loss: 0.0886, Val Loss: 0.0869\n",
      "Epoch 16/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0885\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 6/60, Loss: 0.0899, Val Loss: 0.0895\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0899\n",
      "Early stopping triggered\n",
      "Epoch 20/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Epoch 21/60, Loss: 0.0889, Val Loss: 0.0851\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "[Trial 89] Validation Loss: 0.0899\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0896, Val Loss: 0.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:29:56,194] Trial 89 finished with value: 0.08986450086037318 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0019337994485620672, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 111] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0057280334163466035, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 2/60, Loss: 0.0900, Val Loss: 0.0908\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0893\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0885\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0893\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 22/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0888\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0884\n",
      "Epoch 9/60, Loss: 0.0893, Val Loss: 0.0893\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0867\n",
      "Epoch 10/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.0892, Val Loss: 0.0900\n",
      "Epoch 24/60, Loss: 0.0887, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.0894, Val Loss: 0.0884\n",
      "Epoch 1/60, Loss: 0.1616, Val Loss: 0.0930\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0870\n",
      "Epoch 25/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0881\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0871\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0850\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 13/60, Loss: 0.0890, Val Loss: 0.0893\n",
      "Epoch 8/60, Loss: 0.0893, Val Loss: 0.0889\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0901\n",
      "Epoch 27/60, Loss: 0.0886, Val Loss: 0.0888\n",
      "Epoch 34/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.0904, Val Loss: 0.0909\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0872\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0905\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 19/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.0978, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 5/60, Loss: 0.0890, Val Loss: 0.0902\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0887\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 7/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 3/60, Loss: 0.0893, Val Loss: 0.0903\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0884\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 16/60, Loss: 0.0899, Val Loss: 0.0877\n",
      "Epoch 23/60, Loss: 0.0889, Val Loss: 0.0849\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Early stopping triggered\n",
      "Epoch 6/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0883\n",
      "Epoch 33/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "[Trial 91] Validation Loss: 0.0876\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:34:19,541] Trial 91 finished with value: 0.08755005616694689 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.001955006270993221, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 112] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0061436388138226645, 'batch_size': 16, 'patience': 7}\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0890\n",
      "Epoch 8/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0909\n",
      "Epoch 34/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0884\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0881\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 35/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 22/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 17/60, Loss: 0.0892, Val Loss: 0.0877\n",
      "Epoch 7/60, Loss: 0.0889, Val Loss: 0.0904\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0866\n",
      "Early stopping triggered\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0886\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "[Trial 90] Validation Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:35:28,662] Trial 90 finished with value: 0.08659873999034365 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0018616633211972157, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 113] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.005648225440458782, 'batch_size': 8, 'patience': 7}\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0903\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0889\n",
      "Epoch 1/60, Loss: 0.1557, Val Loss: 0.0959\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0883\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 24/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 38/60, Loss: 0.0883, Val Loss: 0.0886\n",
      "Epoch 24/60, Loss: 0.0888, Val Loss: 0.0852\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0888\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0902\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.0891, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0904\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0888\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 40/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 2/60, Loss: 0.0902, Val Loss: 0.0915\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0883\n",
      "Epoch 37/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.1018, Val Loss: 0.0884\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Early stopping triggered\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0888\n",
      "[Trial 92] Validation Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:37:03,717] Trial 92 finished with value: 0.08719194664930303 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0017556303730770096, 'batch_size': 8, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 114] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0011898784578709062, 'batch_size': 8, 'patience': 7}\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 28/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 9/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0887, Val Loss: 0.0910\n",
      "Epoch 29/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0871\n",
      "Epoch 3/60, Loss: 0.0890, Val Loss: 0.0920\n",
      "Epoch 43/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0882\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "Epoch 1/60, Loss: 0.1234, Val Loss: 0.0912\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 25/60, Loss: 0.0891, Val Loss: 0.0850\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0902\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0889, Val Loss: 0.0902\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0878\n",
      "Epoch 4/60, Loss: 0.0885, Val Loss: 0.0915\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0898\n",
      "Epoch 1/60, Loss: 0.1455, Val Loss: 0.0901\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.0908, Val Loss: 0.0892\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0904\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 5/60, Loss: 0.0884, Val Loss: 0.0913\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "Epoch 49/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0892, Val Loss: 0.0883\n",
      "Epoch 2/60, Loss: 0.0896, Val Loss: 0.0905\n",
      "Epoch 36/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0869\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0887, Val Loss: 0.0851\n",
      "Epoch 12/60, Loss: 0.0884, Val Loss: 0.0899\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0885\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0904\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 6/60, Loss: 0.0883, Val Loss: 0.0911\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 14/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0918, Val Loss: 0.0910\n",
      "Epoch 27/60, Loss: 0.0887, Val Loss: 0.0888\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 40/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0873\n",
      "Epoch 2/60, Loss: 0.0895, Val Loss: 0.0905\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0910\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0909\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 7/60, Loss: 0.0883, Val Loss: 0.0914\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0882\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0881\n",
      "Early stopping triggered\n",
      "Epoch 3/60, Loss: 0.0889, Val Loss: 0.0911\n",
      "[Trial 103] Validation Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:42:12,773] Trial 103 finished with value: 0.08812281948824724 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.00374238377098403, 'batch_size': 16, 'patience': 6}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 115] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012419737327539284, 'batch_size': 8, 'patience': 7}\n",
      "Epoch 42/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 43/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 27/60, Loss: 0.0889, Val Loss: 0.0854\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0897\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 23/60, Loss: 0.0888, Val Loss: 0.0870\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0909\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Early stopping triggered\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0881\n",
      "[Trial 109] Validation Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:43:00,259] Trial 109 finished with value: 0.0885389730334282 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0038530817188234296, 'batch_size': 64, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 116] Starting with parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.005653380083906164, 'batch_size': 8, 'patience': 7}\n",
      "Epoch 8/60, Loss: 0.0881, Val Loss: 0.0918\n",
      "Epoch 58/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0886\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 60/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 3/60, Loss: 0.0887, Val Loss: 0.0898\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0898\n",
      "[Trial 106] Validation Loss: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:43:46,720] Trial 106 finished with value: 0.08855796903371811 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0033646023475789244, 'batch_size': 64, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 117] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.005048899195372302, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0902\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 9/60, Loss: 0.0883, Val Loss: 0.0916\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0870\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0868\n",
      "Epoch 24/60, Loss: 0.0885, Val Loss: 0.0882\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0880\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0908\n",
      "Epoch 1/60, Loss: 0.1453, Val Loss: 0.0900\n",
      "Epoch 28/60, Loss: 0.0891, Val Loss: 0.0851\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0896\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0903\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0916\n",
      "Epoch 25/60, Loss: 0.0886, Val Loss: 0.0881\n",
      "Epoch 1/60, Loss: 0.1279, Val Loss: 0.0913\n",
      "Epoch 18/60, Loss: 0.0890, Val Loss: 0.0882\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0897\n",
      "Epoch 4/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 1/60, Loss: 0.1183, Val Loss: 0.0876\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0903\n",
      "Early stopping triggered\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0910\n",
      "Epoch 11/60, Loss: 0.0884, Val Loss: 0.0912\n",
      "[Trial 111] Validation Loss: 0.0903\n",
      "Epoch 42/60, Loss: 0.0883, Val Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:46:13,647] Trial 111 finished with value: 0.09033225700259209 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0057280334163466035, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 118] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0011040208294715308, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 26/60, Loss: 0.0890, Val Loss: 0.0882\n",
      "Early stopping triggered\n",
      "[Trial 105] Validation Loss: 0.0882\n",
      "Epoch 19/60, Loss: 0.0914, Val Loss: 0.0883\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:46:21,086] Trial 105 finished with value: 0.08822464620073636 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.003647875037196721, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 119] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0011245119283398723, 'batch_size': 8, 'patience': 6}\n",
      "[Trial 108] Validation Loss: 0.0884\n",
      "Epoch 5/60, Loss: 0.0887, Val Loss: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:46:29,031] Trial 108 finished with value: 0.08835790840288003 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.003889135292360695, 'batch_size': 16, 'patience': 7}. Best is trial 5 with value: 0.08564341689149539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 120] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0014057250054804694, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 2/60, Loss: 0.0894, Val Loss: 0.0898\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0873\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0854\n",
      "Early stopping triggered\n",
      "Epoch 41/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "[Trial 93] Validation Loss: 0.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:46:56,240] Trial 93 finished with value: 0.08537403478597601 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.001912517836444088, 'batch_size': 8, 'patience': 6}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 121] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012330689450189439, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0898\n",
      "Epoch 2/60, Loss: 0.0894, Val Loss: 0.0911\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0919\n",
      "Epoch 22/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 19/60, Loss: 0.0943, Val Loss: 0.0902\n",
      "Epoch 5/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 2/60, Loss: 0.0899, Val Loss: 0.0869\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0912\n",
      "Early stopping triggered\n",
      "Epoch 43/60, Loss: 0.0882, Val Loss: 0.0868\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0884\n",
      "[Trial 112] Validation Loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:48:27,434] Trial 112 finished with value: 0.09119553963343302 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.0061436388138226645, 'batch_size': 16, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 122] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012589907254044416, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 3/60, Loss: 0.0890, Val Loss: 0.0895\n",
      "Epoch 1/60, Loss: 0.1518, Val Loss: 0.0906\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0904\n",
      "Epoch 1/60, Loss: 0.1494, Val Loss: 0.0889\n",
      "Epoch 1/60, Loss: 0.1373, Val Loss: 0.0906\n",
      "Epoch 42/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Early stopping triggered\n",
      "Epoch 3/60, Loss: 0.0887, Val Loss: 0.0911\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "[Trial 104] Validation Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:49:15,200] Trial 104 finished with value: 0.0871849981447061 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0038476956262656716, 'batch_size': 16, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 123] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0013014921466614408, 'batch_size': 8, 'patience': 6}\n",
      "Epoch 1/60, Loss: 0.1447, Val Loss: 0.0878\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 24/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 3/60, Loss: 0.0896, Val Loss: 0.0867\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0882, Val Loss: 0.0892\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 2/60, Loss: 0.0895, Val Loss: 0.0903\n",
      "Epoch 2/60, Loss: 0.0902, Val Loss: 0.0879\n",
      "Epoch 4/60, Loss: 0.0887, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 0.1426, Val Loss: 0.0863\n",
      "Epoch 7/60, Loss: 0.0889, Val Loss: 0.0904\n",
      "Epoch 2/60, Loss: 0.0892, Val Loss: 0.0902\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.0887, Val Loss: 0.0907\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0900\n",
      "Epoch 2/60, Loss: 0.0898, Val Loss: 0.0877\n",
      "Epoch 1/60, Loss: 0.1460, Val Loss: 0.0889\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0869\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0897\n",
      "Early stopping triggered\n",
      "Epoch 7/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "[Trial 110] Validation Loss: 0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:52:27,766] Trial 110 finished with value: 0.08969459397097429 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.00480103410703769, 'batch_size': 16, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 124] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.001181153859425261, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 3/60, Loss: 0.0891, Val Loss: 0.0902\n",
      "Epoch 3/60, Loss: 0.0894, Val Loss: 0.0875\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 2/60, Loss: 0.0905, Val Loss: 0.0860\n",
      "Epoch 8/60, Loss: 0.0928, Val Loss: 0.0908\n",
      "Epoch 3/60, Loss: 0.0887, Val Loss: 0.0901\n",
      "Epoch 5/60, Loss: 0.0886, Val Loss: 0.0908\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 3/60, Loss: 0.0893, Val Loss: 0.0877\n",
      "Epoch 2/60, Loss: 0.0897, Val Loss: 0.0884\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0897, Val Loss: 0.0879\n",
      "Epoch 8/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0868\n",
      "Epoch 4/60, Loss: 0.0888, Val Loss: 0.0872\n",
      "Epoch 1/60, Loss: 0.1476, Val Loss: 0.0918\n",
      "Epoch 4/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 3/60, Loss: 0.0899, Val Loss: 0.0861\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0883\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0934\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0907\n",
      "Epoch 4/60, Loss: 0.0885, Val Loss: 0.0901\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0883\n",
      "Epoch 6/60, Loss: 0.0895, Val Loss: 0.0873\n",
      "Epoch 9/60, Loss: 0.0879, Val Loss: 0.0894\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 5/60, Loss: 0.0891, Val Loss: 0.0871\n",
      "Epoch 2/60, Loss: 0.0892, Val Loss: 0.0913\n",
      "Epoch 7/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 5/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 7/60, Loss: 0.0887, Val Loss: 0.0905\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0855\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0884\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0903\n",
      "Epoch 5/60, Loss: 0.0880, Val Loss: 0.0899\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 5/60, Loss: 0.0888, Val Loss: 0.0870\n",
      "Epoch 4/60, Loss: 0.0892, Val Loss: 0.0888\n",
      "Epoch 47/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0885\n",
      "Early stopping triggered\n",
      "[Trial 107] Validation Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 15:58:06,475] Trial 107 finished with value: 0.08850412492950757 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.003735243668583108, 'batch_size': 16, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 125] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0014717255620366912, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0868\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0868\n",
      "Epoch 10/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0907\n",
      "Epoch 6/60, Loss: 0.0886, Val Loss: 0.0871\n",
      "Epoch 3/60, Loss: 0.0885, Val Loss: 0.0916\n",
      "Epoch 8/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 6/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 5/60, Loss: 0.0898, Val Loss: 0.0850\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0871\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0900\n",
      "Epoch 6/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "Epoch 48/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 1/60, Loss: 0.1350, Val Loss: 0.0873\n",
      "Epoch 8/60, Loss: 0.0896, Val Loss: 0.0867\n",
      "Epoch 9/60, Loss: 0.0977, Val Loss: 0.0918\n",
      "Epoch 49/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 11/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 7/60, Loss: 0.0887, Val Loss: 0.0869\n",
      "Epoch 9/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0880, Val Loss: 0.0896\n",
      "Epoch 4/60, Loss: 0.0885, Val Loss: 0.0911\n",
      "Epoch 7/60, Loss: 0.0886, Val Loss: 0.0868\n",
      "Epoch 6/60, Loss: 0.0896, Val Loss: 0.0853\n",
      "Epoch 48/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 7/60, Loss: 0.0880, Val Loss: 0.0897\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0904\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.0901, Val Loss: 0.0872\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0907\n",
      "Epoch 9/60, Loss: 0.0895, Val Loss: 0.0873\n",
      "Epoch 50/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0869\n",
      "Epoch 8/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Epoch 12/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 10/60, Loss: 0.0881, Val Loss: 0.0886\n",
      "Epoch 8/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 5/60, Loss: 0.0883, Val Loss: 0.0907\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0850\n",
      "Epoch 49/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0901\n",
      "Epoch 7/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0895, Val Loss: 0.0905\n",
      "Epoch 3/60, Loss: 0.0898, Val Loss: 0.0869\n",
      "Epoch 51/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0867\n",
      "Epoch 10/60, Loss: 0.0895, Val Loss: 0.0867\n",
      "Epoch 9/60, Loss: 0.0887, Val Loss: 0.0869\n",
      "Epoch 11/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 9/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 13/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 6/60, Loss: 0.0880, Val Loss: 0.0908\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0849\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 8/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 14/60, Loss: 0.0914, Val Loss: 0.0900\n",
      "Epoch 51/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0906\n",
      "Epoch 4/60, Loss: 0.0895, Val Loss: 0.0868\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0867\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 11/60, Loss: 0.0895, Val Loss: 0.0866\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 12/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 7/60, Loss: 0.0879, Val Loss: 0.0907\n",
      "Epoch 14/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0851\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 10/60, Loss: 0.0880, Val Loss: 0.0895\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0901\n",
      "Epoch 52/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.0887, Val Loss: 0.0905\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0867\n",
      "Epoch 5/60, Loss: 0.0888, Val Loss: 0.0867\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0869\n",
      "Epoch 12/60, Loss: 0.0966, Val Loss: 0.0869\n",
      "Epoch 11/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 13/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.0881, Val Loss: 0.0917\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0850\n",
      "Epoch 15/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 53/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0877, Val Loss: 0.0897\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0906\n",
      "Epoch 16/60, Loss: 0.0887, Val Loss: 0.0907\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0870\n",
      "Epoch 12/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 13/60, Loss: 0.0899, Val Loss: 0.0866\n",
      "Epoch 12/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 14/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 53/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0878, Val Loss: 0.0906\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0846\n",
      "Epoch 16/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.0889, Val Loss: 0.0907\n",
      "Epoch 54/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 12/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 17/60, Loss: 0.0906, Val Loss: 0.0901\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0866\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 7/60, Loss: 0.0889, Val Loss: 0.0866\n",
      "Epoch 13/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0879, Val Loss: 0.0894\n",
      "Epoch 15/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 14/60, Loss: 0.0895, Val Loss: 0.0866\n",
      "Epoch 10/60, Loss: 0.0878, Val Loss: 0.0910\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0905\n",
      "Epoch 12/60, Loss: 0.0892, Val Loss: 0.0848\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 55/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 13/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0895, Val Loss: 0.0905\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 56/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 8/60, Loss: 0.0889, Val Loss: 0.0862\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 17/60, Loss: 0.0889, Val Loss: 0.0911\n",
      "Epoch 14/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 16/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 15/60, Loss: 0.0894, Val Loss: 0.0865\n",
      "Epoch 11/60, Loss: 0.0878, Val Loss: 0.0904\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.0891, Val Loss: 0.0847\n",
      "Epoch 18/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 14/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 19/60, Loss: 0.0888, Val Loss: 0.0901\n",
      "Epoch 57/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 18/60, Loss: 0.0891, Val Loss: 0.0918\n",
      "Epoch 56/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0862\n",
      "Epoch 17/60, Loss: 0.0901, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0876, Val Loss: 0.0904\n",
      "Epoch 16/60, Loss: 0.0896, Val Loss: 0.0866\n",
      "Epoch 57/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 14/60, Loss: 0.0889, Val Loss: 0.0847\n",
      "Epoch 19/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0894, Val Loss: 0.0872\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0880\n",
      "Epoch 15/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0867\n",
      "Epoch 20/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "Epoch 19/60, Loss: 0.0893, Val Loss: 0.0905\n",
      "Epoch 57/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Early stopping triggered\n",
      "Epoch 18/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Early stopping triggered\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0865\n",
      "Epoch 16/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "[Trial 119] Validation Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:19:33,950] Trial 119 finished with value: 0.08670395103593667 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0011245119283398723, 'batch_size': 8, 'patience': 6}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 126] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0014017929815347376, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 58/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "[Trial 115] Validation Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:19:37,944] Trial 115 finished with value: 0.08870569265757998 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012419737327539284, 'batch_size': 8, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 127] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00015793117120305216, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 17/60, Loss: 0.0894, Val Loss: 0.0866\n",
      "Epoch 13/60, Loss: 0.0878, Val Loss: 0.0905\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0866\n",
      "Epoch 15/60, Loss: 0.0890, Val Loss: 0.0846\n",
      "Epoch 15/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 20/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 16/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0885, Val Loss: 0.0906\n",
      "Early stopping triggered\n",
      "Epoch 21/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "[Trial 116] Validation Loss: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:20:53,752] Trial 116 finished with value: 0.09058132969463865 and parameters: {'hidden_dim': 64, 'latent_dim': 64, 'lr': 0.005653380083906164, 'batch_size': 8, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 128] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0001681076919282509, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 58/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Early stopping triggered\n",
      "[Trial 87] Validation Loss: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:21:17,416] Trial 87 finished with value: 0.08912707992518941 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.530746301123239e-05, 'batch_size': 8, 'patience': 6}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 129] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.5841794712597655e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0864\n",
      "Epoch 1/60, Loss: 0.1425, Val Loss: 0.0890\n",
      "Epoch 1/60, Loss: 0.4022, Val Loss: 0.0927\n",
      "Epoch 18/60, Loss: 0.0893, Val Loss: 0.0867\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 14/60, Loss: 0.0875, Val Loss: 0.0902\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0846\n",
      "Epoch 16/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0867\n",
      "[Trial 83] Validation Loss: 0.0867\n",
      "Epoch 17/60, Loss: 0.0878, Val Loss: 0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:22:46,918] Trial 83 finished with value: 0.08666707904388507 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 6.197467541025706e-05, 'batch_size': 8, 'patience': 8}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 130] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0001730520099972918, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 22/60, Loss: 0.0888, Val Loss: 0.0901\n",
      "Epoch 1/60, Loss: 0.3574, Val Loss: 0.0949\n",
      "Epoch 1/60, Loss: 0.9745, Val Loss: 0.1398\n",
      "Epoch 2/60, Loss: 0.0898, Val Loss: 0.0880\n",
      "Epoch 60/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.1119, Val Loss: 0.0901\n",
      "[Trial 84] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:23:47,233] Trial 84 finished with value: 0.0888533467737337 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 5.0295100050346404e-05, 'batch_size': 8, 'patience': 8}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 131] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0015184920808745763, 'batch_size': 32, 'patience': 10}\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0865\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0892\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0863\n",
      "Epoch 19/60, Loss: 0.0895, Val Loss: 0.0865\n",
      "Epoch 15/60, Loss: 0.0876, Val Loss: 0.0912\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0847\n",
      "Epoch 17/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 1/60, Loss: 0.2607, Val Loss: 0.0911\n",
      "Epoch 22/60, Loss: 0.0888, Val Loss: 0.0890\n",
      "Epoch 18/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 1/60, Loss: 0.3421, Val Loss: 0.0934\n",
      "Epoch 2/60, Loss: 0.1072, Val Loss: 0.0924\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0901\n",
      "Epoch 2/60, Loss: 0.0931, Val Loss: 0.0896\n",
      "Epoch 3/60, Loss: 0.0895, Val Loss: 0.0883\n",
      "Epoch 3/60, Loss: 0.0966, Val Loss: 0.0891\n",
      "Epoch 2/60, Loss: 0.4535, Val Loss: 0.1048\n",
      "Epoch 20/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 3/60, Loss: 0.0904, Val Loss: 0.0894\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0935, Val Loss: 0.0866\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0862\n",
      "Epoch 16/60, Loss: 0.0875, Val Loss: 0.0903\n",
      "Epoch 4/60, Loss: 0.0898, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0934, Val Loss: 0.0849\n",
      "Epoch 18/60, Loss: 0.0916, Val Loss: 0.0879\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 5/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 3/60, Loss: 0.0946, Val Loss: 0.0923\n",
      "Epoch 19/60, Loss: 0.0913, Val Loss: 0.0893\n",
      "Epoch 2/60, Loss: 0.1055, Val Loss: 0.0911\n",
      "Epoch 24/60, Loss: 0.0887, Val Loss: 0.0911\n",
      "Epoch 4/60, Loss: 0.0889, Val Loss: 0.0878\n",
      "Epoch 6/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 4/60, Loss: 0.0925, Val Loss: 0.0889\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 3/60, Loss: 0.2699, Val Loss: 0.0955\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0892\n",
      "Epoch 21/60, Loss: 0.0895, Val Loss: 0.0871\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 17/60, Loss: 0.0899, Val Loss: 0.0903\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0846\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 4/60, Loss: 0.0914, Val Loss: 0.0922\n",
      "Epoch 3/60, Loss: 0.0946, Val Loss: 0.0908\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 5/60, Loss: 0.0888, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.0910, Val Loss: 0.0887\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 25/60, Loss: 0.0936, Val Loss: 0.0931\n",
      "Epoch 4/60, Loss: 0.1932, Val Loss: 0.0930\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0887\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0896, Val Loss: 0.0865\n",
      "Epoch 11/60, Loss: 0.0883, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0862\n",
      "Epoch 18/60, Loss: 0.0876, Val Loss: 0.0903\n",
      "Epoch 20/60, Loss: 0.0890, Val Loss: 0.0846\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 5/60, Loss: 0.0900, Val Loss: 0.0917\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 4/60, Loss: 0.0915, Val Loss: 0.0906\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 6/60, Loss: 0.0900, Val Loss: 0.0886\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0873\n",
      "Epoch 21/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0901, Val Loss: 0.0903\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 5/60, Loss: 0.1559, Val Loss: 0.0917\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 23/60, Loss: 0.0893, Val Loss: 0.0867\n",
      "Epoch 19/60, Loss: 0.0874, Val Loss: 0.0903\n",
      "Epoch 16/60, Loss: 0.0885, Val Loss: 0.0861\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0846\n",
      "Epoch 21/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0916\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0886\n",
      "Epoch 26/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0902, Val Loss: 0.0902\n",
      "Epoch 7/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 6/60, Loss: 0.1346, Val Loss: 0.0910\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 24/60, Loss: 0.0904, Val Loss: 0.0867\n",
      "Epoch 18/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 20/60, Loss: 0.0876, Val Loss: 0.0904\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0917\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0862\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0846\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 8/60, Loss: 0.0894, Val Loss: 0.0887\n",
      "Epoch 19/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 8/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.0897, Val Loss: 0.0901\n",
      "Epoch 27/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.0893, Val Loss: 0.0894\n",
      "Epoch 20/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0904\n",
      "Epoch 7/60, Loss: 0.1214, Val Loss: 0.0902\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0914\n",
      "Epoch 25/60, Loss: 0.0896, Val Loss: 0.0866\n",
      "Early stopping triggered\n",
      "[Trial 117] Validation Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:37:11,095] Trial 117 finished with value: 0.08657611239080627 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.005048899195372302, 'batch_size': 8, 'patience': 10}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 132] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00816951543788565, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 26/60, Loss: 0.0891, Val Loss: 0.0866\n",
      "Epoch 21/60, Loss: 0.0874, Val Loss: 0.0904\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Early stopping triggered\n",
      "Epoch 23/60, Loss: 0.0887, Val Loss: 0.0845\n",
      "Epoch 18/60, Loss: 0.0930, Val Loss: 0.0869\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0884\n",
      "[Trial 123] Validation Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:37:35,758] Trial 123 finished with value: 0.08765801256522536 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0013014921466614408, 'batch_size': 8, 'patience': 6}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 133] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00018665033962420925, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0872\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0902\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.1120, Val Loss: 0.0894\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 9/60, Loss: 0.0883, Val Loss: 0.0913\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0865\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 1/60, Loss: 0.1258, Val Loss: 0.0936\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0875, Val Loss: 0.0903\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0846\n",
      "Epoch 19/60, Loss: 0.0886, Val Loss: 0.0861\n",
      "Epoch 10/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 1/60, Loss: 0.3312, Val Loss: 0.0936\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0902\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.1060, Val Loss: 0.0891\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0908, Val Loss: 0.0901\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 10/60, Loss: 0.0882, Val Loss: 0.0911\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 2/60, Loss: 0.0896, Val Loss: 0.0925\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0875, Val Loss: 0.0901\n",
      "Epoch 25/60, Loss: 0.0890, Val Loss: 0.0845\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 11/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 2/60, Loss: 0.1036, Val Loss: 0.0913\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0859\n",
      "Epoch 9/60, Loss: 0.0887, Val Loss: 0.0900\n",
      "Epoch 30/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Early stopping triggered\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 10/60, Loss: 0.1014, Val Loss: 0.0890\n",
      "[Trial 114] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:42:38,297] Trial 114 finished with value: 0.08892913047845165 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0011898784578709062, 'batch_size': 8, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 134] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.726962754513822e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 31/60, Loss: 0.0909, Val Loss: 0.0901\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 11/60, Loss: 0.0879, Val Loss: 0.0913\n",
      "Epoch 3/60, Loss: 0.0887, Val Loss: 0.0921\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 27/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 24/60, Loss: 0.0876, Val Loss: 0.0902\n",
      "Epoch 12/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 26/60, Loss: 0.0891, Val Loss: 0.0849\n",
      "Epoch 3/60, Loss: 0.0935, Val Loss: 0.0910\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0860\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0898\n",
      "Epoch 11/60, Loss: 0.0983, Val Loss: 0.0886\n",
      "Epoch 1/60, Loss: 0.9481, Val Loss: 0.1327\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 32/60, Loss: 0.0889, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0868\n",
      "Epoch 12/60, Loss: 0.0879, Val Loss: 0.0911\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0881\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 4/60, Loss: 0.0890, Val Loss: 0.0917\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 4/60, Loss: 0.0907, Val Loss: 0.0905\n",
      "Epoch 25/60, Loss: 0.0875, Val Loss: 0.0904\n",
      "Epoch 27/60, Loss: 0.0891, Val Loss: 0.0846\n",
      "Epoch 36/60, Loss: 0.0906, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0861\n",
      "Epoch 12/60, Loss: 0.0960, Val Loss: 0.0884\n",
      "Epoch 11/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 37/60, Loss: 0.0885, Val Loss: 0.0883\n",
      "Epoch 2/60, Loss: 0.4307, Val Loss: 0.1035\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 28/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 33/60, Loss: 0.0903, Val Loss: 0.0903\n",
      "Epoch 13/60, Loss: 0.0876, Val Loss: 0.0908\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0880\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 5/60, Loss: 0.0890, Val Loss: 0.0928\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.0897, Val Loss: 0.0880\n",
      "Epoch 5/60, Loss: 0.0901, Val Loss: 0.0904\n",
      "Epoch 28/60, Loss: 0.0888, Val Loss: 0.0845\n",
      "Epoch 26/60, Loss: 0.0875, Val Loss: 0.0904\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0861\n",
      "Epoch 13/60, Loss: 0.0943, Val Loss: 0.0884\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0865\n",
      "Epoch 3/60, Loss: 0.2508, Val Loss: 0.0960\n",
      "Epoch 29/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 34/60, Loss: 0.0888, Val Loss: 0.0900\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0877, Val Loss: 0.0908\n",
      "Epoch 15/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 6/60, Loss: 0.0889, Val Loss: 0.0917\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0892\n",
      "Epoch 15/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0906\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0845\n",
      "Epoch 27/60, Loss: 0.0874, Val Loss: 0.0901\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Early stopping triggered\n",
      "[Trial 131] Validation Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:50:51,840] Trial 131 finished with value: 0.08822419742743175 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0015184920808745763, 'batch_size': 32, 'patience': 10}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 135] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.8603334622845543e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 14/60, Loss: 0.0929, Val Loss: 0.0884\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 24/60, Loss: 0.0885, Val Loss: 0.0861\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0897\n",
      "Epoch 4/60, Loss: 0.1788, Val Loss: 0.0939\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 15/60, Loss: 0.0875, Val Loss: 0.0907\n",
      "Epoch 30/60, Loss: 0.0883, Val Loss: 0.0900\n",
      "Epoch 35/60, Loss: 0.0887, Val Loss: 0.0900\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0912\n",
      "Epoch 31/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 7/60, Loss: 0.0891, Val Loss: 0.0903\n",
      "Epoch 30/60, Loss: 0.0887, Val Loss: 0.0845\n",
      "Epoch 28/60, Loss: 0.0875, Val Loss: 0.0902\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0866\n",
      "Epoch 1/60, Loss: 1.0558, Val Loss: 0.1381\n",
      "Epoch 15/60, Loss: 0.0921, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0885, Val Loss: 0.0895\n",
      "Epoch 5/60, Loss: 0.1462, Val Loss: 0.0929\n",
      "Epoch 14/60, Loss: 0.0881, Val Loss: 0.0896\n",
      "Epoch 16/60, Loss: 0.0876, Val Loss: 0.0907\n",
      "Epoch 31/60, Loss: 0.0876, Val Loss: 0.0893\n",
      "Early stopping triggered\n",
      "Epoch 36/60, Loss: 0.0891, Val Loss: 0.0908\n",
      "Early stopping triggered\n",
      "[Trial 113] Validation Loss: 0.0909\n",
      "[Trial 120] Validation Loss: 0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:54:05,228] Trial 113 finished with value: 0.09086110076556603 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.005648225440458782, 'batch_size': 8, 'patience': 7}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 136] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0001528921180947403, 'batch_size': 8, 'patience': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:54:05,601] Trial 120 finished with value: 0.08931019802888235 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0014057250054804694, 'batch_size': 8, 'patience': 6}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 137] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0001754744627898067, 'batch_size': 32, 'patience': 10}\n",
      "Epoch 8/60, Loss: 0.0885, Val Loss: 0.0916\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0870\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0901\n",
      "Epoch 1/60, Loss: 0.6839, Val Loss: 0.1069\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 31/60, Loss: 0.0889, Val Loss: 0.0846\n",
      "Epoch 29/60, Loss: 0.0875, Val Loss: 0.0902\n",
      "Epoch 2/60, Loss: 0.4872, Val Loss: 0.1041\n",
      "Epoch 16/60, Loss: 0.0913, Val Loss: 0.0883\n",
      "Epoch 2/60, Loss: 0.2272, Val Loss: 0.0938\n",
      "Epoch 18/60, Loss: 0.0879, Val Loss: 0.0879\n",
      "Epoch 6/60, Loss: 0.1266, Val Loss: 0.0922\n",
      "Epoch 17/60, Loss: 0.0874, Val Loss: 0.0907\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 26/60, Loss: 0.0900, Val Loss: 0.0860\n",
      "Epoch 3/60, Loss: 0.1481, Val Loss: 0.0915\n",
      "Epoch 1/60, Loss: 0.4149, Val Loss: 0.0922\n",
      "Epoch 4/60, Loss: 0.1225, Val Loss: 0.0906\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0913\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 18/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0902\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 5/60, Loss: 0.1105, Val Loss: 0.0899\n",
      "Epoch 32/60, Loss: 0.0897, Val Loss: 0.0846\n",
      "Epoch 3/60, Loss: 0.2796, Val Loss: 0.0951\n",
      "Epoch 17/60, Loss: 0.0910, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0874, Val Loss: 0.0901\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 6/60, Loss: 0.1036, Val Loss: 0.0891\n",
      "Epoch 7/60, Loss: 0.1152, Val Loss: 0.0914\n",
      "Epoch 18/60, Loss: 0.0874, Val Loss: 0.0907\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0860\n",
      "Epoch 2/60, Loss: 0.1127, Val Loss: 0.0898\n",
      "Epoch 7/60, Loss: 0.0997, Val Loss: 0.0888\n",
      "Epoch 10/60, Loss: 0.1009, Val Loss: 0.1495\n",
      "Epoch 8/60, Loss: 0.0971, Val Loss: 0.0887\n",
      "Epoch 19/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 34/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 10/60, Loss: 0.0885, Val Loss: 0.0899\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0865\n",
      "Early stopping triggered\n",
      "[Trial 121] Validation Loss: 0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 16:59:25,984] Trial 121 finished with value: 0.08650824998815855 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012330689450189439, 'batch_size': 8, 'patience': 10}. Best is trial 93 with value: 0.08537403478597601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 138] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.1116966725239616e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 18/60, Loss: 0.0905, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.1898, Val Loss: 0.0928\n",
      "Epoch 9/60, Loss: 0.0952, Val Loss: 0.0886\n",
      "Epoch 33/60, Loss: 0.0889, Val Loss: 0.0845\n",
      "Epoch 20/60, Loss: 0.0880, Val Loss: 0.0878\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0901\n",
      "Epoch 8/60, Loss: 0.1080, Val Loss: 0.0909\n",
      "Epoch 19/60, Loss: 0.0873, Val Loss: 0.0906\n",
      "Epoch 10/60, Loss: 0.0941, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0859\n",
      "Epoch 3/60, Loss: 0.0970, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0930, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0995, Val Loss: 0.0946\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0896\n",
      "Epoch 11/60, Loss: 0.0882, Val Loss: 0.0900\n",
      "Epoch 12/60, Loss: 0.0923, Val Loss: 0.0884\n",
      "Epoch 1/60, Loss: 1.0314, Val Loss: 0.1554\n",
      "Epoch 19/60, Loss: 0.0900, Val Loss: 0.0880\n",
      "Epoch 5/60, Loss: 0.1528, Val Loss: 0.0916\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 34/60, Loss: 0.0889, Val Loss: 0.0845\n",
      "Epoch 13/60, Loss: 0.0918, Val Loss: 0.0884\n",
      "Epoch 32/60, Loss: 0.0875, Val Loss: 0.0902\n",
      "Epoch 9/60, Loss: 0.1026, Val Loss: 0.0903\n",
      "Epoch 20/60, Loss: 0.0872, Val Loss: 0.0907\n",
      "Epoch 4/60, Loss: 0.0930, Val Loss: 0.0888\n",
      "Epoch 18/60, Loss: 0.0879, Val Loss: 0.0893\n",
      "Epoch 14/60, Loss: 0.0914, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.0888, Val Loss: 0.0859\n",
      "Epoch 15/60, Loss: 0.0909, Val Loss: 0.0884\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0870\n",
      "Epoch 12/60, Loss: 0.0913, Val Loss: 0.0940\n",
      "Epoch 12/60, Loss: 0.0878, Val Loss: 0.0898\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 2/60, Loss: 0.5158, Val Loss: 0.1122\n",
      "Epoch 16/60, Loss: 0.0907, Val Loss: 0.0883\n",
      "Epoch 20/60, Loss: 0.0898, Val Loss: 0.0881\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 6/60, Loss: 0.1304, Val Loss: 0.0907\n",
      "Epoch 35/60, Loss: 0.0889, Val Loss: 0.0848\n",
      "Early stopping triggered\n",
      "[Trial 122] Validation Loss: 0.0848\n",
      "Epoch 33/60, Loss: 0.0875, Val Loss: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:04:12,751] Trial 122 finished with value: 0.08478449912120899 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012589907254044416, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60, Loss: 0.0993, Val Loss: 0.0902\n",
      "\n",
      "[Trial 139] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.9041887859969148e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 21/60, Loss: 0.0871, Val Loss: 0.0907\n",
      "Epoch 17/60, Loss: 0.0904, Val Loss: 0.0883\n",
      "Epoch 5/60, Loss: 0.0911, Val Loss: 0.0888\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 18/60, Loss: 0.0902, Val Loss: 0.0883\n",
      "Epoch 3/60, Loss: 0.3249, Val Loss: 0.1007\n",
      "Epoch 19/60, Loss: 0.0900, Val Loss: 0.0882\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 13/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Epoch 13/60, Loss: 0.0901, Val Loss: 0.0913\n",
      "Epoch 37/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Early stopping triggered\n",
      "[Trial 118] Validation Loss: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:05:51,889] Trial 118 finished with value: 0.08908500904217362 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0011040208294715308, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "\n",
      "[Trial 140] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00019329051613815206, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 21/60, Loss: 0.0896, Val Loss: 0.0880\n",
      "Epoch 7/60, Loss: 0.1173, Val Loss: 0.0900\n",
      "Epoch 20/60, Loss: 0.0898, Val Loss: 0.0883\n",
      "Epoch 11/60, Loss: 0.0964, Val Loss: 0.0901\n",
      "Epoch 22/60, Loss: 0.0873, Val Loss: 0.0906\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0884\n",
      "Epoch 34/60, Loss: 0.0876, Val Loss: 0.0902\n",
      "Epoch 1/60, Loss: 0.9058, Val Loss: 0.1364\n",
      "Epoch 21/60, Loss: 0.0898, Val Loss: 0.0881\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0860\n",
      "Epoch 22/60, Loss: 0.0896, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.2265, Val Loss: 0.0960\n",
      "Epoch 14/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 23/60, Loss: 0.0895, Val Loss: 0.0881\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0913\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0877\n",
      "Epoch 22/60, Loss: 0.0895, Val Loss: 0.0881\n",
      "Epoch 8/60, Loss: 0.1088, Val Loss: 0.0897\n",
      "Epoch 1/60, Loss: 0.3286, Val Loss: 0.0898\n",
      "Epoch 24/60, Loss: 0.0894, Val Loss: 0.0880\n",
      "Epoch 7/60, Loss: 0.0897, Val Loss: 0.0887\n",
      "Epoch 12/60, Loss: 0.0943, Val Loss: 0.0899\n",
      "Epoch 23/60, Loss: 0.0873, Val Loss: 0.0906\n",
      "Epoch 2/60, Loss: 0.3997, Val Loss: 0.1028\n",
      "Epoch 35/60, Loss: 0.0875, Val Loss: 0.0901\n",
      "Epoch 25/60, Loss: 0.0893, Val Loss: 0.0879\n",
      "Epoch 21/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0859\n",
      "Epoch 5/60, Loss: 0.1787, Val Loss: 0.0946\n",
      "Epoch 26/60, Loss: 0.0892, Val Loss: 0.0879\n",
      "Epoch 15/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0871\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0878\n",
      "Epoch 15/60, Loss: 0.1013, Val Loss: 0.0932\n",
      "Epoch 2/60, Loss: 0.1034, Val Loss: 0.0876\n",
      "Epoch 23/60, Loss: 0.0894, Val Loss: 0.0879\n",
      "Epoch 27/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 9/60, Loss: 0.1032, Val Loss: 0.0893\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0871, Val Loss: 0.0906\n",
      "Epoch 13/60, Loss: 0.0932, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.2349, Val Loss: 0.0948\n",
      "Epoch 28/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 36/60, Loss: 0.0875, Val Loss: 0.0903\n",
      "Epoch 6/60, Loss: 0.1521, Val Loss: 0.0934\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 29/60, Loss: 0.0889, Val Loss: 0.0879\n",
      "Epoch 33/60, Loss: 0.0885, Val Loss: 0.0861\n",
      "Epoch 16/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 30/60, Loss: 0.0889, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 3/60, Loss: 0.0940, Val Loss: 0.0870\n",
      "Epoch 10/60, Loss: 0.0994, Val Loss: 0.0893\n",
      "Epoch 16/60, Loss: 0.0903, Val Loss: 0.0916\n",
      "Epoch 24/60, Loss: 0.0893, Val Loss: 0.0879\n",
      "Epoch 9/60, Loss: 0.0892, Val Loss: 0.0882\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0872, Val Loss: 0.0907\n",
      "Epoch 14/60, Loss: 0.0920, Val Loss: 0.0899\n",
      "Epoch 4/60, Loss: 0.1716, Val Loss: 0.0929\n",
      "Epoch 7/60, Loss: 0.1345, Val Loss: 0.0927\n",
      "Epoch 37/60, Loss: 0.0875, Val Loss: 0.0901\n",
      "Early stopping triggered\n",
      "[Trial 124] Validation Loss: 0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:13:22,637] Trial 124 finished with value: 0.09014369028930863 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.001181153859425261, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 141] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 2.1930955129806902e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 32/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 23/60, Loss: 0.0876, Val Loss: 0.0893\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0860\n",
      "Epoch 33/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 17/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 27/60, Loss: 0.0877, Val Loss: 0.0877\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 4/60, Loss: 0.0917, Val Loss: 0.0869\n",
      "Epoch 11/60, Loss: 0.0968, Val Loss: 0.0890\n",
      "Epoch 25/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 17/60, Loss: 0.0892, Val Loss: 0.0913\n",
      "Early stopping triggered\n",
      "Epoch 34/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "[Trial 132] Validation Loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:14:47,530] Trial 132 finished with value: 0.09133645308514436 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00816951543788565, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 142] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00016436878475012688, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0880\n",
      "Epoch 5/60, Loss: 0.1414, Val Loss: 0.0917\n",
      "Epoch 26/60, Loss: 0.0873, Val Loss: 0.0906\n",
      "Epoch 15/60, Loss: 0.0912, Val Loss: 0.0897\n",
      "Epoch 8/60, Loss: 0.1222, Val Loss: 0.0920\n",
      "Epoch 35/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 1.0503, Val Loss: 0.1594\n",
      "Epoch 24/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 35/60, Loss: 0.0891, Val Loss: 0.0863\n",
      "Epoch 36/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 18/60, Loss: 0.0876, Val Loss: 0.0895\n",
      "Epoch 5/60, Loss: 0.0907, Val Loss: 0.0868\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0868\n",
      "Epoch 37/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 12/60, Loss: 0.0948, Val Loss: 0.0889\n",
      "Epoch 26/60, Loss: 0.0890, Val Loss: 0.0878\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 6/60, Loss: 0.1242, Val Loss: 0.0907\n",
      "Epoch 1/60, Loss: 0.3576, Val Loss: 0.0916\n",
      "Epoch 9/60, Loss: 0.1136, Val Loss: 0.0913\n",
      "Epoch 27/60, Loss: 0.0873, Val Loss: 0.0906\n",
      "Epoch 16/60, Loss: 0.0908, Val Loss: 0.0896\n",
      "Epoch 38/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 0.4858, Val Loss: 0.1111\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 25/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0860\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 19/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 40/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0868\n",
      "Epoch 28/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 13/60, Loss: 0.0934, Val Loss: 0.0888\n",
      "Epoch 27/60, Loss: 0.0890, Val Loss: 0.0878\n",
      "Epoch 2/60, Loss: 0.1081, Val Loss: 0.0899\n",
      "Epoch 10/60, Loss: 0.1073, Val Loss: 0.0910\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 7/60, Loss: 0.1129, Val Loss: 0.0900\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 17/60, Loss: 0.0901, Val Loss: 0.0896\n",
      "Epoch 28/60, Loss: 0.0872, Val Loss: 0.0906\n",
      "Epoch 3/60, Loss: 0.3031, Val Loss: 0.0984\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0861\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0866\n",
      "Epoch 14/60, Loss: 0.0923, Val Loss: 0.0888\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 3/60, Loss: 0.0958, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.1030, Val Loss: 0.0908\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 28/60, Loss: 0.0890, Val Loss: 0.0877\n",
      "Epoch 8/60, Loss: 0.1060, Val Loss: 0.0895\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 18/60, Loss: 0.0900, Val Loss: 0.0896\n",
      "Epoch 29/60, Loss: 0.0871, Val Loss: 0.0906\n",
      "Epoch 4/60, Loss: 0.2157, Val Loss: 0.0942\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 27/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 38/60, Loss: 0.0886, Val Loss: 0.0860\n",
      "Early stopping triggered\n",
      "Epoch 21/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "[Trial 125] Validation Loss: 0.0860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:22:55,506] Trial 125 finished with value: 0.086023157214125 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0014717255620366912, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 143] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00016496951547097192, 'batch_size': 64, 'patience': 10}\n",
      "Epoch 8/60, Loss: 0.0897, Val Loss: 0.0867\n",
      "Epoch 4/60, Loss: 0.0926, Val Loss: 0.0883\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 12/60, Loss: 0.0992, Val Loss: 0.0907\n",
      "Epoch 15/60, Loss: 0.0915, Val Loss: 0.0887\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 9/60, Loss: 0.1009, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 14/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 0.9124, Val Loss: 0.1429\n",
      "Epoch 19/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 30/60, Loss: 0.0873, Val Loss: 0.0906\n",
      "Epoch 5/60, Loss: 0.1713, Val Loss: 0.0930\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 2/60, Loss: 0.4207, Val Loss: 0.1038\n",
      "Epoch 3/60, Loss: 0.2594, Val Loss: 0.0957\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 4/60, Loss: 0.1939, Val Loss: 0.0935\n",
      "Epoch 28/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.1599, Val Loss: 0.0926\n",
      "Epoch 22/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 5/60, Loss: 0.0909, Val Loss: 0.0880\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 9/60, Loss: 0.0895, Val Loss: 0.0867\n",
      "Epoch 13/60, Loss: 0.0970, Val Loss: 0.0905\n",
      "Epoch 16/60, Loss: 0.0907, Val Loss: 0.0887\n",
      "Epoch 6/60, Loss: 0.1404, Val Loss: 0.0917\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 10/60, Loss: 0.0982, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 7/60, Loss: 0.1277, Val Loss: 0.0910\n",
      "Epoch 20/60, Loss: 0.0894, Val Loss: 0.0895\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.1477, Val Loss: 0.0917\n",
      "Epoch 31/60, Loss: 0.0872, Val Loss: 0.0906\n",
      "Epoch 8/60, Loss: 0.1193, Val Loss: 0.0907\n",
      "Epoch 9/60, Loss: 0.1134, Val Loss: 0.0904\n",
      "Epoch 52/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 10/60, Loss: 0.1089, Val Loss: 0.0900\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0876\n",
      "Epoch 29/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.1051, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0881\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 23/60, Loss: 0.0874, Val Loss: 0.0894\n",
      "Epoch 14/60, Loss: 0.0949, Val Loss: 0.0903\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0864\n",
      "Epoch 12/60, Loss: 0.1028, Val Loss: 0.0896\n",
      "Epoch 17/60, Loss: 0.0904, Val Loss: 0.0886\n",
      "Epoch 11/60, Loss: 0.0958, Val Loss: 0.0888\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 13/60, Loss: 0.1006, Val Loss: 0.0893\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 7/60, Loss: 0.1310, Val Loss: 0.0910\n",
      "Epoch 21/60, Loss: 0.0891, Val Loss: 0.0895\n",
      "Epoch 32/60, Loss: 0.0872, Val Loss: 0.0906\n",
      "Epoch 14/60, Loss: 0.0990, Val Loss: 0.0893\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 15/60, Loss: 0.0978, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0966, Val Loss: 0.0891\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 17/60, Loss: 0.0958, Val Loss: 0.0890\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0879\n",
      "Epoch 30/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0937, Val Loss: 0.0903\n",
      "Epoch 24/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 11/60, Loss: 0.0890, Val Loss: 0.0861\n",
      "Epoch 18/60, Loss: 0.0950, Val Loss: 0.0891\n",
      "Epoch 18/60, Loss: 0.0900, Val Loss: 0.0886\n",
      "Epoch 12/60, Loss: 0.0941, Val Loss: 0.0887\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 19/60, Loss: 0.0943, Val Loss: 0.0890\n",
      "Epoch 8/60, Loss: 0.1196, Val Loss: 0.0904\n",
      "Epoch 33/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 32/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0895\n",
      "Epoch 20/60, Loss: 0.0938, Val Loss: 0.0890\n",
      "Epoch 33/60, Loss: 0.0871, Val Loss: 0.0906\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 21/60, Loss: 0.0933, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0929, Val Loss: 0.0890\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0877\n",
      "Epoch 23/60, Loss: 0.0924, Val Loss: 0.0889\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0878\n",
      "Epoch 16/60, Loss: 0.0923, Val Loss: 0.0903\n",
      "Epoch 31/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 24/60, Loss: 0.0922, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0889, Val Loss: 0.0860\n",
      "Epoch 60/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "[Trial 137] Validation Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:32:02,443] Trial 137 finished with value: 0.08746084719896316 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0001754744627898067, 'batch_size': 32, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 144] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.355088274813288e-05, 'batch_size': 64, 'patience': 10}\n",
      "Epoch 13/60, Loss: 0.0926, Val Loss: 0.0886\n",
      "Epoch 19/60, Loss: 0.0897, Val Loss: 0.0885\n",
      "Epoch 9/60, Loss: 0.1118, Val Loss: 0.0899\n",
      "Epoch 25/60, Loss: 0.0920, Val Loss: 0.0889\n",
      "Epoch 18/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 34/60, Loss: 0.0889, Val Loss: 0.0869\n",
      "Epoch 33/60, Loss: 0.0887, Val Loss: 0.0875\n",
      "Epoch 26/60, Loss: 0.0917, Val Loss: 0.0889\n",
      "Epoch 23/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 1/60, Loss: 1.5788, Val Loss: 0.3309\n",
      "Epoch 34/60, Loss: 0.0872, Val Loss: 0.0906\n",
      "Epoch 27/60, Loss: 0.0913, Val Loss: 0.0888\n",
      "Epoch 2/60, Loss: 1.1561, Val Loss: 0.2568\n",
      "Epoch 28/60, Loss: 0.0913, Val Loss: 0.0888\n",
      "Epoch 3/60, Loss: 0.9483, Val Loss: 0.2005\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0877\n",
      "Epoch 29/60, Loss: 0.0910, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0915, Val Loss: 0.0902\n",
      "Epoch 4/60, Loss: 0.8066, Val Loss: 0.1710\n",
      "Epoch 26/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 30/60, Loss: 0.0908, Val Loss: 0.0888\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0860\n",
      "Epoch 5/60, Loss: 0.7079, Val Loss: 0.1517\n",
      "Epoch 10/60, Loss: 0.1065, Val Loss: 0.0894\n",
      "Epoch 14/60, Loss: 0.0917, Val Loss: 0.0886\n",
      "Epoch 20/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 31/60, Loss: 0.0907, Val Loss: 0.0889\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 6/60, Loss: 0.6399, Val Loss: 0.1389\n",
      "Epoch 35/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 34/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 32/60, Loss: 0.0906, Val Loss: 0.0888\n",
      "Epoch 7/60, Loss: 0.5799, Val Loss: 0.1284\n",
      "Epoch 24/60, Loss: 0.0888, Val Loss: 0.0894\n",
      "Epoch 35/60, Loss: 0.0871, Val Loss: 0.0906\n",
      "Epoch 33/60, Loss: 0.0905, Val Loss: 0.0888\n",
      "Epoch 8/60, Loss: 0.5274, Val Loss: 0.1194\n",
      "Epoch 34/60, Loss: 0.0904, Val Loss: 0.0888\n",
      "Epoch 9/60, Loss: 0.4802, Val Loss: 0.1131\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0909, Val Loss: 0.0901\n",
      "Epoch 35/60, Loss: 0.0902, Val Loss: 0.0888\n",
      "Epoch 10/60, Loss: 0.4416, Val Loss: 0.1096\n",
      "Epoch 27/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0860\n",
      "Epoch 36/60, Loss: 0.0901, Val Loss: 0.0887\n",
      "Epoch 33/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.1022, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.4056, Val Loss: 0.1065\n",
      "Epoch 15/60, Loss: 0.0911, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.0894, Val Loss: 0.0886\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 37/60, Loss: 0.0901, Val Loss: 0.0887\n",
      "Epoch 12/60, Loss: 0.3722, Val Loss: 0.1040\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 35/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0899, Val Loss: 0.0887\n",
      "Epoch 13/60, Loss: 0.3473, Val Loss: 0.1020\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0893\n",
      "Epoch 36/60, Loss: 0.0871, Val Loss: 0.0906\n",
      "Epoch 39/60, Loss: 0.0899, Val Loss: 0.0886\n",
      "Epoch 14/60, Loss: 0.3226, Val Loss: 0.1004\n",
      "Epoch 40/60, Loss: 0.0896, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.3037, Val Loss: 0.0992\n",
      "Epoch 19/60, Loss: 0.0904, Val Loss: 0.0900\n",
      "Epoch 11/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 41/60, Loss: 0.0897, Val Loss: 0.0886\n",
      "Epoch 16/60, Loss: 0.2879, Val Loss: 0.0979\n",
      "Epoch 12/60, Loss: 0.0992, Val Loss: 0.0888\n",
      "Epoch 28/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 15/60, Loss: 0.0883, Val Loss: 0.0858\n",
      "Epoch 42/60, Loss: 0.0897, Val Loss: 0.0886\n",
      "Epoch 17/60, Loss: 0.2718, Val Loss: 0.0974\n",
      "Epoch 16/60, Loss: 0.0905, Val Loss: 0.0884\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0896\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0885\n",
      "Epoch 43/60, Loss: 0.0895, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.2594, Val Loss: 0.0970\n",
      "Epoch 36/60, Loss: 0.0887, Val Loss: 0.0874\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Early stopping triggered\n",
      "Epoch 44/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 19/60, Loss: 0.2481, Val Loss: 0.0964\n",
      "[Trial 126] Validation Loss: 0.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:39:18,795] Trial 126 finished with value: 0.08690825949112574 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0014017929815347376, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 145] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.2180205755924384e-05, 'batch_size': 64, 'patience': 9}\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0905\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0893\n",
      "Epoch 45/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 20/60, Loss: 0.2365, Val Loss: 0.0960\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0874\n",
      "Epoch 1/60, Loss: 1.7210, Val Loss: 0.3765\n",
      "Epoch 20/60, Loss: 0.0903, Val Loss: 0.0900\n",
      "Epoch 46/60, Loss: 0.0893, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.2268, Val Loss: 0.0958\n",
      "Epoch 39/60, Loss: 0.0889, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 1.1952, Val Loss: 0.2670\n",
      "Epoch 22/60, Loss: 0.2174, Val Loss: 0.0954\n",
      "Epoch 47/60, Loss: 0.0893, Val Loss: 0.0885\n",
      "Epoch 13/60, Loss: 0.0964, Val Loss: 0.0886\n",
      "Epoch 3/60, Loss: 0.9403, Val Loss: 0.2065\n",
      "Epoch 29/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0858\n",
      "Epoch 23/60, Loss: 0.2100, Val Loss: 0.0950\n",
      "Epoch 48/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 17/60, Loss: 0.0902, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 35/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.8091, Val Loss: 0.1712\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 24/60, Loss: 0.2029, Val Loss: 0.0950\n",
      "Epoch 49/60, Loss: 0.0891, Val Loss: 0.0884\n",
      "Epoch 37/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 5/60, Loss: 0.7109, Val Loss: 0.1518\n",
      "Epoch 25/60, Loss: 0.1952, Val Loss: 0.0948\n",
      "Epoch 50/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "Epoch 38/60, Loss: 0.0873, Val Loss: 0.0905\n",
      "Epoch 27/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 6/60, Loss: 0.6419, Val Loss: 0.1374\n",
      "Epoch 26/60, Loss: 0.1903, Val Loss: 0.0946\n",
      "Epoch 51/60, Loss: 0.0890, Val Loss: 0.0884\n",
      "Epoch 21/60, Loss: 0.0899, Val Loss: 0.0900\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0873\n",
      "Epoch 7/60, Loss: 0.5835, Val Loss: 0.1274\n",
      "Epoch 27/60, Loss: 0.1845, Val Loss: 0.0943\n",
      "Epoch 52/60, Loss: 0.0890, Val Loss: 0.0884\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 8/60, Loss: 0.5266, Val Loss: 0.1199\n",
      "Epoch 28/60, Loss: 0.1787, Val Loss: 0.0941\n",
      "Epoch 53/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0949, Val Loss: 0.0885\n",
      "Epoch 9/60, Loss: 0.4857, Val Loss: 0.1132\n",
      "Epoch 17/60, Loss: 0.0884, Val Loss: 0.0860\n",
      "Epoch 30/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0900, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.1731, Val Loss: 0.0938\n",
      "Epoch 54/60, Loss: 0.0888, Val Loss: 0.0884\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 10/60, Loss: 0.4500, Val Loss: 0.1094\n",
      "Epoch 36/60, Loss: 0.0872, Val Loss: 0.0892\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0885\n",
      "Epoch 30/60, Loss: 0.1684, Val Loss: 0.0937\n",
      "Epoch 55/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 11/60, Loss: 0.4153, Val Loss: 0.1068\n",
      "Epoch 38/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 31/60, Loss: 0.1650, Val Loss: 0.0935\n",
      "Epoch 56/60, Loss: 0.0889, Val Loss: 0.0884\n",
      "Epoch 12/60, Loss: 0.3860, Val Loss: 0.1036\n",
      "Epoch 39/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0892\n",
      "Epoch 32/60, Loss: 0.1607, Val Loss: 0.0934\n",
      "Epoch 57/60, Loss: 0.0888, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0894, Val Loss: 0.0900\n",
      "Epoch 13/60, Loss: 0.3592, Val Loss: 0.1018\n",
      "Epoch 33/60, Loss: 0.1574, Val Loss: 0.0932\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0876\n",
      "Epoch 58/60, Loss: 0.0887, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.3368, Val Loss: 0.0996\n",
      "Epoch 15/60, Loss: 0.0935, Val Loss: 0.0884\n",
      "Epoch 34/60, Loss: 0.1523, Val Loss: 0.0931\n",
      "Epoch 59/60, Loss: 0.0888, Val Loss: 0.0882\n",
      "Epoch 15/60, Loss: 0.3156, Val Loss: 0.0980\n",
      "Epoch 35/60, Loss: 0.1493, Val Loss: 0.0930\n",
      "Epoch 19/60, Loss: 0.0897, Val Loss: 0.0883\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0858\n",
      "Epoch 31/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 60/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "[Trial 143] Validation Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:45:44,405] Trial 143 finished with value: 0.08818933814764023 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00016496951547097192, 'batch_size': 64, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60, Loss: 0.2988, Val Loss: 0.0966\n",
      "\n",
      "[Trial 146] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.8733023735111828e-05, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 36/60, Loss: 0.1464, Val Loss: 0.0928\n",
      "Epoch 25/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 37/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 17/60, Loss: 0.2822, Val Loss: 0.0958\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 37/60, Loss: 0.1435, Val Loss: 0.0927\n",
      "Epoch 18/60, Loss: 0.2718, Val Loss: 0.0950\n",
      "Epoch 40/60, Loss: 0.0872, Val Loss: 0.0906\n",
      "Epoch 38/60, Loss: 0.1410, Val Loss: 0.0926\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0872\n",
      "Epoch 19/60, Loss: 0.2561, Val Loss: 0.0942\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0900\n",
      "Epoch 39/60, Loss: 0.1383, Val Loss: 0.0924\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 20/60, Loss: 0.2468, Val Loss: 0.0939\n",
      "Epoch 16/60, Loss: 0.0925, Val Loss: 0.0883\n",
      "Epoch 40/60, Loss: 0.1359, Val Loss: 0.0923\n",
      "Epoch 21/60, Loss: 0.2385, Val Loss: 0.0937\n",
      "Epoch 20/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 41/60, Loss: 0.1337, Val Loss: 0.0923\n",
      "Epoch 19/60, Loss: 0.0886, Val Loss: 0.0858\n",
      "Epoch 32/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 22/60, Loss: 0.2286, Val Loss: 0.0932\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 1/60, Loss: 1.0081, Val Loss: 0.1448\n",
      "Epoch 42/60, Loss: 0.1316, Val Loss: 0.0921\n",
      "Epoch 26/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 23/60, Loss: 0.2197, Val Loss: 0.0930\n",
      "Epoch 38/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0887, Val Loss: 0.0873\n",
      "Epoch 43/60, Loss: 0.1294, Val Loss: 0.0920\n",
      "Epoch 24/60, Loss: 0.2119, Val Loss: 0.0926\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 41/60, Loss: 0.0872, Val Loss: 0.0905\n",
      "Epoch 44/60, Loss: 0.1276, Val Loss: 0.0919\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.2037, Val Loss: 0.0924\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0900\n",
      "Epoch 45/60, Loss: 0.1258, Val Loss: 0.0917\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 17/60, Loss: 0.0917, Val Loss: 0.0883\n",
      "Epoch 26/60, Loss: 0.1996, Val Loss: 0.0921\n",
      "Epoch 46/60, Loss: 0.1240, Val Loss: 0.0917\n",
      "Epoch 27/60, Loss: 0.1922, Val Loss: 0.0920\n",
      "Epoch 21/60, Loss: 0.0892, Val Loss: 0.0884\n",
      "Epoch 47/60, Loss: 0.1228, Val Loss: 0.0916\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0859\n",
      "Epoch 33/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 28/60, Loss: 0.1869, Val Loss: 0.0917\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 0.4495, Val Loss: 0.1079\n",
      "Epoch 48/60, Loss: 0.1207, Val Loss: 0.0915\n",
      "Epoch 29/60, Loss: 0.1819, Val Loss: 0.0915\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0883\n",
      "Epoch 39/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 49/60, Loss: 0.1197, Val Loss: 0.0914\n",
      "Epoch 30/60, Loss: 0.1763, Val Loss: 0.0914\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 50/60, Loss: 0.1180, Val Loss: 0.0913\n",
      "Epoch 31/60, Loss: 0.1724, Val Loss: 0.0912\n",
      "Epoch 25/60, Loss: 0.0889, Val Loss: 0.0899\n",
      "Epoch 42/60, Loss: 0.0871, Val Loss: 0.0907\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 18/60, Loss: 0.0912, Val Loss: 0.0883\n",
      "Epoch 51/60, Loss: 0.1171, Val Loss: 0.0912\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.1685, Val Loss: 0.0910\n",
      "Epoch 52/60, Loss: 0.1154, Val Loss: 0.0911\n",
      "Epoch 33/60, Loss: 0.1627, Val Loss: 0.0909\n",
      "Epoch 53/60, Loss: 0.1141, Val Loss: 0.0910\n",
      "Epoch 22/60, Loss: 0.0893, Val Loss: 0.0883\n",
      "Epoch 34/60, Loss: 0.1605, Val Loss: 0.0907\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0858\n",
      "Epoch 34/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.2566, Val Loss: 0.0983\n",
      "Epoch 54/60, Loss: 0.1135, Val Loss: 0.0909\n",
      "Epoch 35/60, Loss: 0.1557, Val Loss: 0.0906\n",
      "Epoch 28/60, Loss: 0.0888, Val Loss: 0.0884\n",
      "Epoch 55/60, Loss: 0.1118, Val Loss: 0.0909\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 36/60, Loss: 0.1527, Val Loss: 0.0905\n",
      "Epoch 42/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 56/60, Loss: 0.1110, Val Loss: 0.0909\n",
      "Epoch 37/60, Loss: 0.1499, Val Loss: 0.0904\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 43/60, Loss: 0.0870, Val Loss: 0.0905\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0907, Val Loss: 0.0882\n",
      "Epoch 57/60, Loss: 0.1101, Val Loss: 0.0908\n",
      "Epoch 38/60, Loss: 0.1467, Val Loss: 0.0903\n",
      "Epoch 45/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 58/60, Loss: 0.1093, Val Loss: 0.0907\n",
      "Epoch 39/60, Loss: 0.1441, Val Loss: 0.0901\n",
      "Epoch 59/60, Loss: 0.1085, Val Loss: 0.0907\n",
      "Epoch 40/60, Loss: 0.1413, Val Loss: 0.0900\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0882\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0859\n",
      "Epoch 35/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 28/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.1784, Val Loss: 0.0940\n",
      "Epoch 60/60, Loss: 0.1077, Val Loss: 0.0906\n",
      "Epoch 41/60, Loss: 0.1388, Val Loss: 0.0899\n",
      "[Trial 144] Validation Loss: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:54:45,001] Trial 144 finished with value: 0.09063905080159505 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.355088274813288e-05, 'batch_size': 64, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 147] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00046839884122149255, 'batch_size': 8, 'patience': 9}\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 42/60, Loss: 0.1364, Val Loss: 0.0897\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 41/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 19/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 43/60, Loss: 0.1341, Val Loss: 0.0897\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 20/60, Loss: 0.0900, Val Loss: 0.0882\n",
      "Epoch 44/60, Loss: 0.0872, Val Loss: 0.0905\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0890\n",
      "Epoch 44/60, Loss: 0.1319, Val Loss: 0.0895\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.1304, Val Loss: 0.0894\n",
      "Epoch 46/60, Loss: 0.1286, Val Loss: 0.0894\n",
      "Epoch 24/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0858\n",
      "Epoch 36/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 5/60, Loss: 0.1436, Val Loss: 0.0927\n",
      "Epoch 47/60, Loss: 0.1269, Val Loss: 0.0893\n",
      "Epoch 1/60, Loss: 0.1960, Val Loss: 0.0909\n",
      "Epoch 48/60, Loss: 0.1252, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 44/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 42/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 49/60, Loss: 0.1236, Val Loss: 0.0891\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 21/60, Loss: 0.0899, Val Loss: 0.0881\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0898\n",
      "Epoch 50/60, Loss: 0.1218, Val Loss: 0.0890\n",
      "Epoch 45/60, Loss: 0.0874, Val Loss: 0.0905\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 51/60, Loss: 0.1210, Val Loss: 0.0889\n",
      "Epoch 52/60, Loss: 0.1194, Val Loss: 0.0888\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0858\n",
      "Epoch 53/60, Loss: 0.1183, Val Loss: 0.0887\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.1254, Val Loss: 0.0919\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 37/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 54/60, Loss: 0.1170, Val Loss: 0.0886\n",
      "Epoch 2/60, Loss: 0.0914, Val Loss: 0.0897\n",
      "Epoch 31/60, Loss: 0.0886, Val Loss: 0.0881\n",
      "Epoch 55/60, Loss: 0.1158, Val Loss: 0.0886\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 21/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 22/60, Loss: 0.0898, Val Loss: 0.0881\n",
      "Epoch 43/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 29/60, Loss: 0.0885, Val Loss: 0.0898\n",
      "Epoch 56/60, Loss: 0.1146, Val Loss: 0.0884\n",
      "Epoch 46/60, Loss: 0.0870, Val Loss: 0.0905\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 57/60, Loss: 0.1137, Val Loss: 0.0884\n",
      "Epoch 48/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 58/60, Loss: 0.1124, Val Loss: 0.0883\n",
      "Epoch 59/60, Loss: 0.1113, Val Loss: 0.0883\n",
      "Epoch 7/60, Loss: 0.1142, Val Loss: 0.0910\n",
      "Epoch 25/60, Loss: 0.0886, Val Loss: 0.0857\n",
      "Epoch 26/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 60/60, Loss: 0.1108, Val Loss: 0.0882\n",
      "[Trial 145] Validation Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:01:11,093] Trial 145 finished with value: 0.08820479611555736 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.2180205755924384e-05, 'batch_size': 64, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 148] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00044883270836008573, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 3/60, Loss: 0.0897, Val Loss: 0.0895\n",
      "Epoch 32/60, Loss: 0.0886, Val Loss: 0.0881\n",
      "Epoch 23/60, Loss: 0.0895, Val Loss: 0.0882\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0873\n",
      "Epoch 30/60, Loss: 0.0883, Val Loss: 0.0898\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 47/60, Loss: 0.0872, Val Loss: 0.0905\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 8/60, Loss: 0.1067, Val Loss: 0.0907\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "Epoch 32/60, Loss: 0.0877, Val Loss: 0.0874\n",
      "Epoch 39/60, Loss: 0.0874, Val Loss: 0.0894\n",
      "Epoch 1/60, Loss: 0.2245, Val Loss: 0.0884\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0896\n",
      "Epoch 24/60, Loss: 0.0894, Val Loss: 0.0881\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 33/60, Loss: 0.0883, Val Loss: 0.0880\n",
      "Epoch 31/60, Loss: 0.0886, Val Loss: 0.0898\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 48/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 37/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.1016, Val Loss: 0.0903\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0857\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 2/60, Loss: 0.0926, Val Loss: 0.0878\n",
      "Epoch 40/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 5/60, Loss: 0.0888, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0892, Val Loss: 0.0881\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 34/60, Loss: 0.0885, Val Loss: 0.0881\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 46/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 49/60, Loss: 0.0872, Val Loss: 0.0905\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 10/60, Loss: 0.0982, Val Loss: 0.0900\n",
      "Epoch 3/60, Loss: 0.0900, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 29/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 41/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0883, Val Loss: 0.0897\n",
      "Epoch 26/60, Loss: 0.0890, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 35/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 52/60, Loss: 0.0875, Val Loss: 0.0875\n",
      "Epoch 47/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 50/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0889\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0878\n",
      "Epoch 11/60, Loss: 0.0960, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0858\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 34/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 42/60, Loss: 0.0874, Val Loss: 0.0894\n",
      "Epoch 27/60, Loss: 0.0890, Val Loss: 0.0880\n",
      "Epoch 26/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 7/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 36/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 48/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 51/60, Loss: 0.0869, Val Loss: 0.0905\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 5/60, Loss: 0.0893, Val Loss: 0.0876\n",
      "Epoch 12/60, Loss: 0.0941, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0896\n",
      "Epoch 36/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0857\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 43/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 8/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 52/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 49/60, Loss: 0.0873, Val Loss: 0.0890\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0888\n",
      "Epoch 6/60, Loss: 0.0891, Val Loss: 0.0873\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 13/60, Loss: 0.0928, Val Loss: 0.0897\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0857\n",
      "Epoch 29/60, Loss: 0.0889, Val Loss: 0.0880\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 44/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 9/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 52/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 53/60, Loss: 0.0872, Val Loss: 0.0905\n",
      "Epoch 50/60, Loss: 0.0873, Val Loss: 0.0891\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0871\n",
      "Epoch 14/60, Loss: 0.0917, Val Loss: 0.0896\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 30/60, Loss: 0.0889, Val Loss: 0.0879\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 10/60, Loss: 0.0882, Val Loss: 0.0887\n",
      "Epoch 56/60, Loss: 0.0875, Val Loss: 0.0875\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 54/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 51/60, Loss: 0.0873, Val Loss: 0.0891\n",
      "Epoch 43/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0869\n",
      "Epoch 15/60, Loss: 0.0911, Val Loss: 0.0896\n",
      "Epoch 31/60, Loss: 0.0886, Val Loss: 0.0879\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0858\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 46/60, Loss: 0.0874, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.0881, Val Loss: 0.0891\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0905\n",
      "Epoch 9/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 52/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 44/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 16/60, Loss: 0.0906, Val Loss: 0.0894\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0874\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 34/60, Loss: 0.0890, Val Loss: 0.0858\n",
      "Epoch 35/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 47/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 58/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 56/60, Loss: 0.0873, Val Loss: 0.0905\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 53/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 17/60, Loss: 0.0902, Val Loss: 0.0895\n",
      "Epoch 33/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0857\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 48/60, Loss: 0.0872, Val Loss: 0.0893\n",
      "Epoch 59/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 13/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 57/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 11/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 18/60, Loss: 0.0899, Val Loss: 0.0894\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 54/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 34/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 36/60, Loss: 0.0884, Val Loss: 0.0857\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 49/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "[Trial 127] Validation Loss: 0.0875\n",
      "Epoch 14/60, Loss: 0.0876, Val Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:25:05,299] Trial 127 finished with value: 0.08745293049141764 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00015793117120305216, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 149] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0029040187492946554, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 43/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 58/60, Loss: 0.0873, Val Loss: 0.0905\n",
      "Epoch 19/60, Loss: 0.0896, Val Loss: 0.0894\n",
      "Epoch 35/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 55/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 37/60, Loss: 0.0883, Val Loss: 0.0858\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 50/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 15/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 1/60, Loss: 0.1205, Val Loss: 0.0909\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 13/60, Loss: 0.0885, Val Loss: 0.0869\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 59/60, Loss: 0.0871, Val Loss: 0.0906\n",
      "Epoch 36/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 20/60, Loss: 0.0894, Val Loss: 0.0894\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 56/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 51/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 2/60, Loss: 0.0891, Val Loss: 0.0905\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0869\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0879\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 60/60, Loss: 0.0871, Val Loss: 0.0905\n",
      "Epoch 37/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "[Trial 128] Validation Loss: 0.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:30:08,483] Trial 128 finished with value: 0.09054428481807311 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0001681076919282509, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 150] Starting with parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0003993374751132642, 'batch_size': 8, 'patience': 9}\n",
      "Epoch 21/60, Loss: 0.0892, Val Loss: 0.0894\n",
      "Epoch 36/60, Loss: 0.0884, Val Loss: 0.0869\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0894\n",
      "Epoch 49/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 57/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 45/60, Loss: 0.0905, Val Loss: 0.0874\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 52/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 3/60, Loss: 0.0890, Val Loss: 0.0900\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 60/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 38/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "[Trial 129] Validation Loss: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:32:17,502] Trial 129 finished with value: 0.08701415018488963 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.5841794712597655e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 151] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'lr': 0.0004367738109156613, 'batch_size': 8, 'patience': 10}\n",
      "Epoch 22/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 1/60, Loss: 0.2242, Val Loss: 0.0889\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0874\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.0888, Val Loss: 0.0902\n",
      "Epoch 53/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 18/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 23/60, Loss: 0.0888, Val Loss: 0.0893\n",
      "Epoch 2/60, Loss: 0.0932, Val Loss: 0.0881\n",
      "Epoch 1/60, Loss: 0.1719, Val Loss: 0.0902\n",
      "Epoch 47/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 59/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 42/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.0888, Val Loss: 0.0906\n",
      "Epoch 54/60, Loss: 0.0872, Val Loss: 0.0892\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 19/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 40/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 3/60, Loss: 0.0905, Val Loss: 0.0879\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Epoch 2/60, Loss: 0.0905, Val Loss: 0.0897\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 52/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 60/60, Loss: 0.0875, Val Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:37:20,865] Trial 130 finished with value: 0.08899535223220785 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0001730520099972918, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 130] Validation Loss: 0.0890\n",
      "\n",
      "[Trial 152] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 64, 'lr': 0.0004310434626930156, 'batch_size': 8, 'patience': 9}\n",
      "Epoch 42/60, Loss: 0.0884, Val Loss: 0.0857\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0899\n",
      "Epoch 55/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 41/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 49/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 40/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0880\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 3/60, Loss: 0.0894, Val Loss: 0.0898\n",
      "Epoch 49/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0886, Val Loss: 0.0896\n",
      "Epoch 1/60, Loss: 0.1844, Val Loss: 0.0910\n",
      "Epoch 43/60, Loss: 0.0881, Val Loss: 0.0856\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 56/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 19/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 42/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 21/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0869\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 26/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0891, Val Loss: 0.0876\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0874\n",
      "Epoch 4/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0896\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 2/60, Loss: 0.0906, Val Loss: 0.0905\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 57/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 51/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Epoch 6/60, Loss: 0.0890, Val Loss: 0.0876\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 5/60, Loss: 0.0884, Val Loss: 0.0893\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0897\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 3/60, Loss: 0.0891, Val Loss: 0.0900\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 44/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 58/60, Loss: 0.0872, Val Loss: 0.0892\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 23/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0890\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0874\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0874\n",
      "Epoch 53/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 6/60, Loss: 0.0880, Val Loss: 0.0895\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 22/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0856\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 4/60, Loss: 0.0886, Val Loss: 0.0900\n",
      "Epoch 59/60, Loss: 0.0872, Val Loss: 0.0892\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 24/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0890\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0877\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0873\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 7/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 11/60, Loss: 0.0883, Val Loss: 0.0897\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 47/60, Loss: 0.0883, Val Loss: 0.0856\n",
      "Epoch 48/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 60/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 5/60, Loss: 0.0882, Val Loss: 0.0897\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "[Trial 133] Validation Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:49:01,947] Trial 133 finished with value: 0.08917298202092448 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00018665033962420925, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 153] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 64, 'lr': 1.603934740295883e-05, 'batch_size': 8, 'patience': 9}\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0886\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0872\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0873\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0867\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 58/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 8/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0856\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 6/60, Loss: 0.0882, Val Loss: 0.0896\n",
      "Epoch 1/60, Loss: 1.0283, Val Loss: 0.1277\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 31/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 55/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0873\n",
      "Epoch 55/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 9/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 7/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Epoch 2/60, Loss: 0.4824, Val Loss: 0.1011\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 27/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0873\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0872\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 60/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0857\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "[Trial 134] Validation Loss: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 18:55:18,760] Trial 134 finished with value: 0.08861075726648172 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.726962754513822e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 154] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 1.6549848751377882e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 10/60, Loss: 0.0875, Val Loss: 0.0887\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 58/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 3/60, Loss: 0.2698, Val Loss: 0.0945\n",
      "Epoch 8/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0873\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 57/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 1.2797, Val Loss: 0.2164\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0873\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 51/60, Loss: 0.0882, Val Loss: 0.0857\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 2/60, Loss: 0.7322, Val Loss: 0.1495\n",
      "Epoch 11/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0873\n",
      "Epoch 34/60, Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 4/60, Loss: 0.1819, Val Loss: 0.0924\n",
      "Epoch 9/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 29/60, Loss: 0.0875, Val Loss: 0.0886\n",
      "Epoch 51/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 3/60, Loss: 0.5270, Val Loss: 0.1179\n",
      "Epoch 28/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 16/60, Loss: 0.0996, Val Loss: 0.0900\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0856\n",
      "Epoch 60/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "[Trial 138] Validation Loss: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:00:02,279] Trial 138 finished with value: 0.08909378368407488 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.1116966725239616e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 155] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 128, 'lr': 1.5887588515264224e-05, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 4/60, Loss: 0.3953, Val Loss: 0.1050\n",
      "Epoch 12/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 59/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 5/60, Loss: 0.1450, Val Loss: 0.0915\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0870\n",
      "Epoch 10/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 59/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.3073, Val Loss: 0.0989\n",
      "Epoch 1/60, Loss: 1.1509, Val Loss: 0.1620\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 53/60, Loss: 0.0891, Val Loss: 0.0856\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.2488, Val Loss: 0.0962\n",
      "Epoch 2/60, Loss: 0.6032, Val Loss: 0.1151\n",
      "Epoch 60/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 13/60, Loss: 0.0876, Val Loss: 0.0887\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "[Trial 136] Validation Loss: 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:02:47,989] Trial 136 finished with value: 0.08732947319125135 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0001528921180947403, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 156] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002834255526171394, 'batch_size': 8, 'patience': 9}\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 6/60, Loss: 0.1264, Val Loss: 0.0908\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0876, Val Loss: 0.0894\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0867\n",
      "[Trial 135] Validation Loss: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:03:42,585] Trial 135 finished with value: 0.0875747165021797 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.8603334622845543e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 157] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0004964592970743144, 'batch_size': 8, 'patience': 9}\n",
      "Epoch 7/60, Loss: 0.2134, Val Loss: 0.0949\n",
      "Epoch 52/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 3/60, Loss: 0.3904, Val Loss: 0.1010\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0856\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 8/60, Loss: 0.1881, Val Loss: 0.0941\n",
      "Epoch 1/60, Loss: 0.1276, Val Loss: 0.0886\n",
      "Epoch 14/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 4/60, Loss: 0.2680, Val Loss: 0.0961\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 7/60, Loss: 0.1144, Val Loss: 0.0903\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 12/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 1/60, Loss: 0.2486, Val Loss: 0.0887\n",
      "Epoch 9/60, Loss: 0.1703, Val Loss: 0.0935\n",
      "Epoch 5/60, Loss: 0.1989, Val Loss: 0.0941\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0894\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0856\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0874\n",
      "Epoch 2/60, Loss: 0.0894, Val Loss: 0.0882\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 10/60, Loss: 0.1568, Val Loss: 0.0928\n",
      "Epoch 15/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 6/60, Loss: 0.1647, Val Loss: 0.0929\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 8/60, Loss: 0.1074, Val Loss: 0.0900\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 2/60, Loss: 0.0945, Val Loss: 0.0870\n",
      "Epoch 54/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 13/60, Loss: 0.0876, Val Loss: 0.0896\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.1463, Val Loss: 0.0922\n",
      "Epoch 7/60, Loss: 0.1454, Val Loss: 0.0923\n",
      "Epoch 56/60, Loss: 0.0883, Val Loss: 0.0856\n",
      "Epoch 3/60, Loss: 0.0892, Val Loss: 0.0885\n",
      "Epoch 57/60, Loss: 0.0880, Val Loss: 0.0874\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 12/60, Loss: 0.1370, Val Loss: 0.0919\n",
      "Epoch 16/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 18/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 8/60, Loss: 0.1333, Val Loss: 0.0916\n",
      "Epoch 3/60, Loss: 0.0909, Val Loss: 0.0864\n",
      "Epoch 9/60, Loss: 0.1027, Val Loss: 0.0899\n",
      "Epoch 34/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Early stopping triggered\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "[Trial 142] Validation Loss: 0.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:10:27,755] Trial 142 finished with value: 0.08689234297101696 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00016436878475012688, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 158] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0004038323036485432, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 14/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 21/60, Loss: 0.0895, Val Loss: 0.0897\n",
      "Epoch 4/60, Loss: 0.0891, Val Loss: 0.0885\n",
      "Epoch 13/60, Loss: 0.1297, Val Loss: 0.0915\n",
      "Epoch 57/60, Loss: 0.0880, Val Loss: 0.0856\n",
      "Epoch 9/60, Loss: 0.1241, Val Loss: 0.0911\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 1/60, Loss: 0.4102, Val Loss: 0.0941\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 4/60, Loss: 0.0903, Val Loss: 0.0866\n",
      "Epoch 19/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 14/60, Loss: 0.1237, Val Loss: 0.0912\n",
      "Epoch 17/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0993, Val Loss: 0.0898\n",
      "Epoch 10/60, Loss: 0.1173, Val Loss: 0.0907\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0866\n",
      "Epoch 2/60, Loss: 0.1115, Val Loss: 0.0913\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 5/60, Loss: 0.0891, Val Loss: 0.0900\n",
      "Epoch 15/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 58/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 15/60, Loss: 0.1187, Val Loss: 0.0908\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 11/60, Loss: 0.1121, Val Loss: 0.0904\n",
      "Epoch 59/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 3/60, Loss: 0.0962, Val Loss: 0.0905\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 5/60, Loss: 0.0899, Val Loss: 0.0862\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 16/60, Loss: 0.1146, Val Loss: 0.0906\n",
      "Epoch 18/60, Loss: 0.0875, Val Loss: 0.0888\n",
      "Epoch 11/60, Loss: 0.0965, Val Loss: 0.0896\n",
      "Epoch 12/60, Loss: 0.1082, Val Loss: 0.0903\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0867\n",
      "Epoch 4/60, Loss: 0.0925, Val Loss: 0.0901\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0883\n",
      "Epoch 36/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0873, Val Loss: 0.0895\n",
      "Epoch 59/60, Loss: 0.0885, Val Loss: 0.0856\n",
      "Epoch 59/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 17/60, Loss: 0.1107, Val Loss: 0.0904\n",
      "Epoch 60/60, Loss: 0.0879, Val Loss: 0.0874\n",
      "Epoch 5/60, Loss: 0.0910, Val Loss: 0.0902\n",
      "Epoch 13/60, Loss: 0.1051, Val Loss: 0.0901\n",
      "[Trial 139] Validation Loss: 0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:16:05,299] Trial 139 finished with value: 0.08739269288877646 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.9041887859969148e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 159] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.000916824578997601, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 6/60, Loss: 0.0896, Val Loss: 0.0860\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 7/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 18/60, Loss: 0.1081, Val Loss: 0.0903\n",
      "Epoch 6/60, Loss: 0.0900, Val Loss: 0.0901\n",
      "Epoch 12/60, Loss: 0.0946, Val Loss: 0.0895\n",
      "Epoch 19/60, Loss: 0.0874, Val Loss: 0.0887\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 14/60, Loss: 0.1026, Val Loss: 0.0900\n",
      "Epoch 37/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Early stopping triggered\n",
      "Epoch 1/60, Loss: 0.2545, Val Loss: 0.0907\n",
      "[Trial 149] Validation Loss: 0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:17:31,370] Trial 149 finished with value: 0.08931717338661353 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0029040187492946554, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 160] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00035911530171601444, 'batch_size': 16, 'patience': 9}\n",
      "Epoch 60/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 60/60, Loss: 0.0883, Val Loss: 0.0857\n",
      "Epoch 17/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "[Trial 141] Validation Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:17:59,201] Trial 141 finished with value: 0.08724433699001868 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 2.1930955129806902e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 161] Starting with parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.0005794687810049903, 'batch_size': 16, 'patience': 9}\n",
      "[Trial 140] Validation Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:18:05,766] Trial 140 finished with value: 0.08567457189783453 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00019329051613815206, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 162] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.000560616589264733, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 7/60, Loss: 0.0897, Val Loss: 0.0899\n",
      "Epoch 19/60, Loss: 0.1055, Val Loss: 0.0902\n",
      "Epoch 7/60, Loss: 0.0893, Val Loss: 0.0859\n",
      "Epoch 2/60, Loss: 0.0941, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.1006, Val Loss: 0.0898\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 1/60, Loss: 0.4625, Val Loss: 0.0939\n",
      "Epoch 22/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 8/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "Epoch 8/60, Loss: 0.0895, Val Loss: 0.0899\n",
      "Epoch 13/60, Loss: 0.0933, Val Loss: 0.0895\n",
      "Epoch 20/60, Loss: 0.1035, Val Loss: 0.0901\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 1/60, Loss: 0.1831, Val Loss: 0.0927\n",
      "Epoch 20/60, Loss: 0.0875, Val Loss: 0.0886\n",
      "Epoch 1/60, Loss: 0.2347, Val Loss: 0.0882\n",
      "Epoch 3/60, Loss: 0.0906, Val Loss: 0.0889\n",
      "Epoch 38/60, Loss: 0.0875, Val Loss: 0.0884\n",
      "Epoch 16/60, Loss: 0.0989, Val Loss: 0.0899\n",
      "Epoch 2/60, Loss: 0.1188, Val Loss: 0.0911\n",
      "Epoch 18/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0898\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0860\n",
      "Epoch 21/60, Loss: 0.1014, Val Loss: 0.0899\n",
      "Epoch 2/60, Loss: 0.0905, Val Loss: 0.0919\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0891\n",
      "Epoch 2/60, Loss: 0.0942, Val Loss: 0.0865\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 17/60, Loss: 0.0971, Val Loss: 0.0897\n",
      "Epoch 3/60, Loss: 0.0988, Val Loss: 0.0902\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0877\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0899\n",
      "Epoch 14/60, Loss: 0.0922, Val Loss: 0.0895\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0887\n",
      "Epoch 22/60, Loss: 0.0997, Val Loss: 0.0898\n",
      "Epoch 3/60, Loss: 0.0894, Val Loss: 0.0922\n",
      "Epoch 3/60, Loss: 0.0910, Val Loss: 0.0869\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 4/60, Loss: 0.0940, Val Loss: 0.0904\n",
      "Epoch 39/60, Loss: 0.0882, Val Loss: 0.0892\n",
      "Epoch 18/60, Loss: 0.0960, Val Loss: 0.0898\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0858\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0897\n",
      "Epoch 19/60, Loss: 0.0876, Val Loss: 0.0893\n",
      "Epoch 6/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 23/60, Loss: 0.0982, Val Loss: 0.0898\n",
      "Epoch 45/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 4/60, Loss: 0.0885, Val Loss: 0.0908\n",
      "Epoch 4/60, Loss: 0.0905, Val Loss: 0.0862\n",
      "Epoch 5/60, Loss: 0.0920, Val Loss: 0.0898\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0883\n",
      "Epoch 19/60, Loss: 0.0952, Val Loss: 0.0896\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 12/60, Loss: 0.0884, Val Loss: 0.0896\n",
      "Epoch 15/60, Loss: 0.0914, Val Loss: 0.0894\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 7/60, Loss: 0.0890, Val Loss: 0.0885\n",
      "Epoch 6/60, Loss: 0.0906, Val Loss: 0.0898\n",
      "Epoch 24/60, Loss: 0.0974, Val Loss: 0.0898\n",
      "Epoch 5/60, Loss: 0.0883, Val Loss: 0.0906\n",
      "Epoch 5/60, Loss: 0.0900, Val Loss: 0.0860\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0859\n",
      "Epoch 20/60, Loss: 0.0943, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "Epoch 7/60, Loss: 0.0902, Val Loss: 0.0895\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 20/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0964, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0899, Val Loss: 0.0859\n",
      "Epoch 6/60, Loss: 0.0882, Val Loss: 0.0910\n",
      "Epoch 21/60, Loss: 0.0932, Val Loss: 0.0896\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 8/60, Loss: 0.0898, Val Loss: 0.0894\n",
      "Epoch 9/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 16/60, Loss: 0.0907, Val Loss: 0.0893\n",
      "Epoch 22/60, Loss: 0.0930, Val Loss: 0.0895\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0857\n",
      "Epoch 26/60, Loss: 0.0953, Val Loss: 0.0896\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0868\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0885\n",
      "Epoch 7/60, Loss: 0.0881, Val Loss: 0.0948\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0898\n",
      "Epoch 23/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 23/60, Loss: 0.0924, Val Loss: 0.0898\n",
      "Epoch 9/60, Loss: 0.0893, Val Loss: 0.0897\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0882\n",
      "Epoch 12/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 21/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 27/60, Loss: 0.0944, Val Loss: 0.0896\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 24/60, Loss: 0.0920, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0856\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 8/60, Loss: 0.0879, Val Loss: 0.0901\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0894\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0867\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0881\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 17/60, Loss: 0.0902, Val Loss: 0.0893\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0893\n",
      "Epoch 28/60, Loss: 0.0935, Val Loss: 0.0896\n",
      "Epoch 42/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0915, Val Loss: 0.0895\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0893\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 9/60, Loss: 0.0888, Val Loss: 0.0857\n",
      "Epoch 24/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0881\n",
      "Epoch 9/60, Loss: 0.0880, Val Loss: 0.0902\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0909, Val Loss: 0.0895\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0930, Val Loss: 0.0895\n",
      "Epoch 27/60, Loss: 0.0897, Val Loss: 0.0869\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0854\n",
      "Epoch 22/60, Loss: 0.0872, Val Loss: 0.0893\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0881\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0862\n",
      "Epoch 10/60, Loss: 0.0877, Val Loss: 0.0908\n",
      "Epoch 27/60, Loss: 0.0908, Val Loss: 0.0895\n",
      "Epoch 18/60, Loss: 0.0898, Val Loss: 0.0893\n",
      "Epoch 19/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 43/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 30/60, Loss: 0.0925, Val Loss: 0.0895\n",
      "Epoch 14/60, Loss: 0.0884, Val Loss: 0.0881\n",
      "Epoch 28/60, Loss: 0.0904, Val Loss: 0.0895\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0856\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 25/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 11/60, Loss: 0.0877, Val Loss: 0.0900\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0854\n",
      "Epoch 14/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0903, Val Loss: 0.0894\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0869\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0866\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 31/60, Loss: 0.0921, Val Loss: 0.0895\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0902, Val Loss: 0.0895\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0853\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0898, Val Loss: 0.0894\n",
      "Epoch 12/60, Loss: 0.0876, Val Loss: 0.0905\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 31/60, Loss: 0.0898, Val Loss: 0.0894\n",
      "Epoch 44/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0916, Val Loss: 0.0894\n",
      "Epoch 22/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 50/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0854\n",
      "Epoch 16/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0854\n",
      "Epoch 32/60, Loss: 0.0897, Val Loss: 0.0895\n",
      "Epoch 26/60, Loss: 0.0873, Val Loss: 0.0885\n",
      "Epoch 44/60, Loss: 0.0879, Val Loss: 0.0866\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0879\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 13/60, Loss: 0.0878, Val Loss: 0.0901\n",
      "Epoch 16/60, Loss: 0.0940, Val Loss: 0.0876\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 33/60, Loss: 0.0915, Val Loss: 0.0894\n",
      "Epoch 33/60, Loss: 0.0896, Val Loss: 0.0894\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0893, Val Loss: 0.0893\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0853\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 34/60, Loss: 0.0894, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0855\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 14/60, Loss: 0.0877, Val Loss: 0.0899\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 34/60, Loss: 0.0911, Val Loss: 0.0894\n",
      "Epoch 35/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0854\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 27/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 36/60, Loss: 0.0892, Val Loss: 0.0893\n",
      "Epoch 15/60, Loss: 0.0876, Val Loss: 0.0900\n",
      "Epoch 35/60, Loss: 0.0905, Val Loss: 0.0894\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0854\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 21/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 25/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 37/60, Loss: 0.0890, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0852\n",
      "Epoch 46/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 16/60, Loss: 0.0874, Val Loss: 0.0899\n",
      "Epoch 36/60, Loss: 0.0905, Val Loss: 0.0893\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 38/60, Loss: 0.0890, Val Loss: 0.0895\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0868\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 27/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0889\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0854\n",
      "Epoch 28/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 39/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Epoch 18/60, Loss: 0.0886, Val Loss: 0.0857\n",
      "Epoch 37/60, Loss: 0.0902, Val Loss: 0.0893\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0878\n",
      "Epoch 17/60, Loss: 0.0876, Val Loss: 0.0901\n",
      "Epoch 28/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 53/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 18/60, Loss: 0.0888, Val Loss: 0.0852\n",
      "Epoch 29/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 41/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 38/60, Loss: 0.0899, Val Loss: 0.0893\n",
      "Epoch 23/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 18/60, Loss: 0.0871, Val Loss: 0.0898\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 19/60, Loss: 0.0886, Val Loss: 0.0855\n",
      "Epoch 42/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 30/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0853\n",
      "Epoch 29/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0879\n",
      "Epoch 24/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 39/60, Loss: 0.0900, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 23/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0877, Val Loss: 0.0898\n",
      "Epoch 43/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Epoch 54/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 48/60, Loss: 0.0874, Val Loss: 0.0884\n",
      "Epoch 31/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 48/60, Loss: 0.0883, Val Loss: 0.0866\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 27/60, Loss: 0.0875, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0857\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0854\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0898, Val Loss: 0.0893\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 20/60, Loss: 0.0874, Val Loss: 0.0899\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0878\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 21/60, Loss: 0.0886, Val Loss: 0.0876\n",
      "Epoch 30/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0851\n",
      "Epoch 41/60, Loss: 0.0896, Val Loss: 0.0893\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 24/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 49/60, Loss: 0.0879, Val Loss: 0.0865\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0853\n",
      "Epoch 21/60, Loss: 0.0874, Val Loss: 0.0899\n",
      "Epoch 46/60, Loss: 0.0884, Val Loss: 0.0890\n",
      "Epoch 28/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0888, Val Loss: 0.0851\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0868\n",
      "Epoch 42/60, Loss: 0.0895, Val Loss: 0.0893\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 28/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 22/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 28/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 47/60, Loss: 0.0882, Val Loss: 0.0888\n",
      "Epoch 22/60, Loss: 0.0875, Val Loss: 0.0901\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0890\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 31/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0889, Val Loss: 0.0859\n",
      "Epoch 43/60, Loss: 0.0892, Val Loss: 0.0894\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 23/60, Loss: 0.0888, Val Loss: 0.0851\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 25/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 50/60, Loss: 0.0875, Val Loss: 0.0884\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 30/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 23/60, Loss: 0.0875, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 23/60, Loss: 0.0890, Val Loss: 0.0877\n",
      "Epoch 49/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 44/60, Loss: 0.0893, Val Loss: 0.0894\n",
      "Epoch 29/60, Loss: 0.0874, Val Loss: 0.0893\n",
      "Epoch 30/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0851\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 23/60, Loss: 0.0890, Val Loss: 0.0853\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0888\n",
      "Epoch 57/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0881\n",
      "Epoch 24/60, Loss: 0.0875, Val Loss: 0.0897\n",
      "Epoch 45/60, Loss: 0.0892, Val Loss: 0.0892\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0889\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0854\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 51/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 19:56:08,562] Trial 159 finished with value: 0.08777026434739431 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.000916824578997601, 'batch_size': 16, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 159] Validation Loss: 0.0878\n",
      "\n",
      "[Trial 163] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0005452722920895833, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 46/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0854\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0898\n",
      "Epoch 30/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0852\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 1/60, Loss: 0.3587, Val Loss: 0.0912\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0866\n",
      "Epoch 52/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 25/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 47/60, Loss: 0.0891, Val Loss: 0.0892\n",
      "Epoch 2/60, Loss: 0.1043, Val Loss: 0.0891\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 33/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0874, Val Loss: 0.0897\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 27/60, Loss: 0.0886, Val Loss: 0.0851\n",
      "Epoch 3/60, Loss: 0.0948, Val Loss: 0.0884\n",
      "Epoch 37/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0853\n",
      "Epoch 53/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 48/60, Loss: 0.0888, Val Loss: 0.0893\n",
      "Epoch 4/60, Loss: 0.0923, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 27/60, Loss: 0.0874, Val Loss: 0.0898\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0850\n",
      "Epoch 5/60, Loss: 0.0911, Val Loss: 0.0882\n",
      "Epoch 42/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 36/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 49/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0881\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0854\n",
      "Epoch 34/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0889\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0912\n",
      "Epoch 43/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 29/60, Loss: 0.0889, Val Loss: 0.0851\n",
      "Epoch 37/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 7/60, Loss: 0.0900, Val Loss: 0.0881\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 50/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0866\n",
      "Epoch 8/60, Loss: 0.0898, Val Loss: 0.0881\n",
      "Epoch 60/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 44/60, Loss: 0.0875, Val Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:03:07,287] Trial 146 finished with value: 0.0884421695334216 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 2.8733023735111828e-05, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 146] Validation Loss: 0.0884\n",
      "\n",
      "[Trial 164] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 8.898734156090751e-05, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0873, Val Loss: 0.0893\n",
      "Epoch 29/60, Loss: 0.0876, Val Loss: 0.0898\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0851\n",
      "Epoch 56/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 27/60, Loss: 0.0884, Val Loss: 0.0854\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0881\n",
      "Epoch 54/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Epoch 1/60, Loss: 0.9325, Val Loss: 0.1282\n",
      "Epoch 51/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 45/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 39/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 10/60, Loss: 0.0895, Val Loss: 0.0878\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 35/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 2/60, Loss: 0.3542, Val Loss: 0.0989\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 28/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 30/60, Loss: 0.0872, Val Loss: 0.0897\n",
      "Epoch 31/60, Loss: 0.0886, Val Loss: 0.0854\n",
      "Epoch 57/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0881\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 3/60, Loss: 0.2075, Val Loss: 0.0944\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 52/60, Loss: 0.0889, Val Loss: 0.0891\n",
      "Epoch 28/60, Loss: 0.0884, Val Loss: 0.0853\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 4/60, Loss: 0.1580, Val Loss: 0.0931\n",
      "Epoch 33/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 55/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 31/60, Loss: 0.0873, Val Loss: 0.0897\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0850\n",
      "Epoch 47/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0876\n",
      "Epoch 5/60, Loss: 0.1338, Val Loss: 0.0921\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 53/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0869\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0877\n",
      "Epoch 6/60, Loss: 0.1209, Val Loss: 0.0915\n",
      "Epoch 36/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Early stopping triggered\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 59/60, Loss: 0.0878, Val Loss: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:08:43,230] Trial 151 finished with value: 0.0885443842659394 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'lr': 0.0004367738109156613, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 151] Validation Loss: 0.0885\n",
      "\n",
      "[Trial 165] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 1.6361664666242988e-05, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 42/60, Loss: 0.0874, Val Loss: 0.0886\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0866\n",
      "Epoch 29/60, Loss: 0.0885, Val Loss: 0.0854\n",
      "Epoch 33/60, Loss: 0.0891, Val Loss: 0.0851\n",
      "Epoch 32/60, Loss: 0.0889, Val Loss: 0.0904\n",
      "Epoch 7/60, Loss: 0.1127, Val Loss: 0.0909\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 54/60, Loss: 0.0887, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 1.4623, Val Loss: 0.2702\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 43/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 8/60, Loss: 0.1071, Val Loss: 0.0905\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:10:22,989] Trial 155 finished with value: 0.08855962753295898 and parameters: {'hidden_dim': 448, 'latent_dim': 128, 'lr': 1.5887588515264224e-05, 'batch_size': 16, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 155] Validation Loss: 0.0886\n",
      "\n",
      "[Trial 166] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00028498881045985, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0873\n",
      "Epoch 2/60, Loss: 0.9884, Val Loss: 0.1876\n",
      "Epoch 34/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 34/60, Loss: 0.0887, Val Loss: 0.0850\n",
      "Epoch 1/60, Loss: 0.8631, Val Loss: 0.1048\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0897\n",
      "Epoch 9/60, Loss: 0.1029, Val Loss: 0.0903\n",
      "Epoch 41/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 55/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 3/60, Loss: 0.7891, Val Loss: 0.1510\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 2/60, Loss: 0.2623, Val Loss: 0.0943\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 30/60, Loss: 0.0889, Val Loss: 0.0854\n",
      "Epoch 57/60, Loss: 0.0879, Val Loss: 0.0865\n",
      "Epoch 3/60, Loss: 0.1484, Val Loss: 0.0929\n",
      "Epoch 10/60, Loss: 0.1004, Val Loss: 0.0901\n",
      "Epoch 31/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 4/60, Loss: 0.6718, Val Loss: 0.1321\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 4/60, Loss: 0.1189, Val Loss: 0.0920\n",
      "Epoch 35/60, Loss: 0.0888, Val Loss: 0.0850\n",
      "Epoch 31/60, Loss: 0.0902, Val Loss: 0.0877\n",
      "Epoch 45/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 51/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.1067, Val Loss: 0.0913\n",
      "Epoch 11/60, Loss: 0.0983, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.0872, Val Loss: 0.0897\n",
      "Epoch 5/60, Loss: 0.5660, Val Loss: 0.1193\n",
      "Epoch 56/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0873\n",
      "Epoch 6/60, Loss: 0.1005, Val Loss: 0.0906\n",
      "Epoch 57/60, Loss: 0.0876, Val Loss: 0.0885\n",
      "Epoch 12/60, Loss: 0.0968, Val Loss: 0.0899\n",
      "Epoch 7/60, Loss: 0.0968, Val Loss: 0.0909\n",
      "Epoch 6/60, Loss: 0.4916, Val Loss: 0.1115\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0852\n",
      "Epoch 35/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 8/60, Loss: 0.0948, Val Loss: 0.0903\n",
      "Epoch 52/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0868\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0874\n",
      "Epoch 58/60, Loss: 0.0880, Val Loss: 0.0867\n",
      "Epoch 36/60, Loss: 0.0888, Val Loss: 0.0850\n",
      "Epoch 13/60, Loss: 0.0954, Val Loss: 0.0899\n",
      "Epoch 9/60, Loss: 0.0934, Val Loss: 0.0902\n",
      "Epoch 7/60, Loss: 0.4257, Val Loss: 0.1059\n",
      "Epoch 57/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0874, Val Loss: 0.0897\n",
      "Epoch 10/60, Loss: 0.0923, Val Loss: 0.0901\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 14/60, Loss: 0.0943, Val Loss: 0.0898\n",
      "Epoch 53/60, Loss: 0.0873, Val Loss: 0.0888\n",
      "Epoch 11/60, Loss: 0.0917, Val Loss: 0.0902\n",
      "Epoch 8/60, Loss: 0.3729, Val Loss: 0.1026\n",
      "Epoch 12/60, Loss: 0.0911, Val Loss: 0.0900\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 37/60, Loss: 0.0886, Val Loss: 0.0850\n",
      "Epoch 15/60, Loss: 0.0936, Val Loss: 0.0898\n",
      "Epoch 58/60, Loss: 0.0875, Val Loss: 0.0884\n",
      "Epoch 13/60, Loss: 0.0909, Val Loss: 0.0900\n",
      "Epoch 9/60, Loss: 0.3296, Val Loss: 0.0997\n",
      "Epoch 32/60, Loss: 0.0889, Val Loss: 0.0854\n",
      "Epoch 58/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 14/60, Loss: 0.0903, Val Loss: 0.0900\n",
      "Epoch 54/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 36/60, Loss: 0.0873, Val Loss: 0.0898\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0873\n",
      "Epoch 16/60, Loss: 0.0930, Val Loss: 0.0897\n",
      "Epoch 43/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 15/60, Loss: 0.0900, Val Loss: 0.0900\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0865\n",
      "Early stopping triggered\n",
      "Epoch 10/60, Loss: 0.2913, Val Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:17:13,201] Trial 148 finished with value: 0.08654943285509945 and parameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.00044883270836008573, 'batch_size': 8, 'patience': 10}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 148] Validation Loss: 0.0865\n",
      "\n",
      "[Trial 167] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0005629517458953209, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 36/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.0897, Val Loss: 0.0900\n",
      "Epoch 33/60, Loss: 0.0886, Val Loss: 0.0875\n",
      "Epoch 17/60, Loss: 0.0924, Val Loss: 0.0896\n",
      "Epoch 49/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 17/60, Loss: 0.0897, Val Loss: 0.0901\n",
      "Epoch 24/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 38/60, Loss: 0.0885, Val Loss: 0.0850\n",
      "Epoch 55/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 11/60, Loss: 0.2630, Val Loss: 0.0968\n",
      "Epoch 59/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 1/60, Loss: 0.3499, Val Loss: 0.0931\n",
      "Epoch 18/60, Loss: 0.0894, Val Loss: 0.0900\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 37/60, Loss: 0.0872, Val Loss: 0.0897\n",
      "Epoch 18/60, Loss: 0.0920, Val Loss: 0.0896\n",
      "Epoch 19/60, Loss: 0.0895, Val Loss: 0.0900\n",
      "Epoch 12/60, Loss: 0.2386, Val Loss: 0.0960\n",
      "Epoch 33/60, Loss: 0.0884, Val Loss: 0.0853\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 2/60, Loss: 0.1032, Val Loss: 0.0910\n",
      "Epoch 20/60, Loss: 0.0892, Val Loss: 0.0899\n",
      "Epoch 50/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 59/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Early stopping triggered\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:19:26,122] Trial 147 finished with value: 0.08842741030578812 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.00046839884122149255, 'batch_size': 8, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 147] Validation Loss: 0.0884\n",
      "\n",
      "[Trial 168] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0003650723648149555, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 21/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 19/60, Loss: 0.0916, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.2232, Val Loss: 0.0954\n",
      "Epoch 39/60, Loss: 0.0883, Val Loss: 0.0850\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 60/60, Loss: 0.0884, Val Loss: 0.0889\n",
      "Epoch 3/60, Loss: 0.0940, Val Loss: 0.0903\n",
      "Epoch 44/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "[Trial 154] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:20:00,652] Trial 154 finished with value: 0.08891006459792455 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 1.6549848751377882e-05, 'batch_size': 16, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 169] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0003728172968337625, 'batch_size': 32, 'patience': 9}\n",
      "Epoch 22/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 34/60, Loss: 0.0885, Val Loss: 0.0877\n",
      "Epoch 1/60, Loss: 0.4394, Val Loss: 0.0940\n",
      "Epoch 20/60, Loss: 0.0912, Val Loss: 0.0896\n",
      "Epoch 23/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 38/60, Loss: 0.0875, Val Loss: 0.0898\n",
      "Epoch 51/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 14/60, Loss: 0.2062, Val Loss: 0.0949\n",
      "Epoch 57/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 4/60, Loss: 0.0916, Val Loss: 0.0900\n",
      "Epoch 27/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 37/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 24/60, Loss: 0.0889, Val Loss: 0.0898\n",
      "Epoch 1/60, Loss: 0.4575, Val Loss: 0.0929\n",
      "Epoch 25/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 2/60, Loss: 0.1189, Val Loss: 0.0918\n",
      "Epoch 34/60, Loss: 0.0885, Val Loss: 0.0853\n",
      "Epoch 21/60, Loss: 0.0908, Val Loss: 0.0895\n",
      "Epoch 15/60, Loss: 0.1934, Val Loss: 0.0944\n",
      "Epoch 40/60, Loss: 0.0885, Val Loss: 0.0850\n",
      "Early stopping triggered\n",
      "Epoch 5/60, Loss: 0.0905, Val Loss: 0.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:21:44,660] Trial 162 finished with value: 0.08495766663302978 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.000560616589264733, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 162] Validation Loss: 0.0850\n",
      "\n",
      "[Trial 170] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.00033421797437379534, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0898\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.1185, Val Loss: 0.0909\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 27/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "Epoch 3/60, Loss: 0.0999, Val Loss: 0.0908\n",
      "Epoch 22/60, Loss: 0.0907, Val Loss: 0.0895\n",
      "Epoch 16/60, Loss: 0.1831, Val Loss: 0.0939\n",
      "Epoch 39/60, Loss: 0.0872, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0898, Val Loss: 0.0900\n",
      "Epoch 28/60, Loss: 0.0885, Val Loss: 0.0897\n",
      "Epoch 35/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 3/60, Loss: 0.1004, Val Loss: 0.0896\n",
      "Epoch 29/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 17/60, Loss: 0.1749, Val Loss: 0.0937\n",
      "Epoch 4/60, Loss: 0.0946, Val Loss: 0.0904\n",
      "Epoch 23/60, Loss: 0.0904, Val Loss: 0.0895\n",
      "Epoch 59/60, Loss: 0.0875, Val Loss: 0.0888\n",
      "Epoch 53/60, Loss: 0.0874, Val Loss: 0.0885\n",
      "Epoch 30/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0901\n",
      "Epoch 1/60, Loss: 0.3267, Val Loss: 0.0920\n",
      "Epoch 4/60, Loss: 0.0949, Val Loss: 0.0895\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 35/60, Loss: 0.0885, Val Loss: 0.0855\n",
      "Epoch 18/60, Loss: 0.1656, Val Loss: 0.0934\n",
      "Epoch 24/60, Loss: 0.0901, Val Loss: 0.0896\n",
      "Epoch 5/60, Loss: 0.0923, Val Loss: 0.0901\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0899\n",
      "Epoch 40/60, Loss: 0.0870, Val Loss: 0.0897\n",
      "Epoch 38/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0926, Val Loss: 0.0892\n",
      "Epoch 31/60, Loss: 0.0882, Val Loss: 0.0872\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 54/60, Loss: 0.0883, Val Loss: 0.0887\n",
      "Epoch 60/60, Loss: 0.0873, Val Loss: 0.0888\n",
      "[Trial 158] Validation Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:24:51,555] Trial 158 finished with value: 0.08882946930825711 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0004038323036485432, 'batch_size': 16, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 171] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0005577583750410123, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 19/60, Loss: 0.1602, Val Loss: 0.0931\n",
      "Epoch 34/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 2/60, Loss: 0.1010, Val Loss: 0.0896\n",
      "Epoch 6/60, Loss: 0.0912, Val Loss: 0.0901\n",
      "Epoch 25/60, Loss: 0.0901, Val Loss: 0.0895\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 36/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 6/60, Loss: 0.0916, Val Loss: 0.0893\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.1528, Val Loss: 0.0929\n",
      "Epoch 26/60, Loss: 0.0899, Val Loss: 0.0894\n",
      "Epoch 7/60, Loss: 0.0904, Val Loss: 0.0900\n",
      "Epoch 55/60, Loss: 0.0875, Val Loss: 0.0885\n",
      "Epoch 10/60, Loss: 0.0889, Val Loss: 0.0897\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 41/60, Loss: 0.0875, Val Loss: 0.0897\n",
      "Epoch 7/60, Loss: 0.0906, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 1/60, Loss: 0.2417, Val Loss: 0.0898\n",
      "Epoch 36/60, Loss: 0.0884, Val Loss: 0.0853\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0893\n",
      "Epoch 3/60, Loss: 0.0931, Val Loss: 0.0898\n",
      "Epoch 21/60, Loss: 0.1475, Val Loss: 0.0928\n",
      "Epoch 27/60, Loss: 0.0898, Val Loss: 0.0894\n",
      "Epoch 8/60, Loss: 0.0901, Val Loss: 0.0899\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0893\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0895\n",
      "Epoch 8/60, Loss: 0.0903, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 34/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 22/60, Loss: 0.1422, Val Loss: 0.0924\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 28/60, Loss: 0.0895, Val Loss: 0.0894\n",
      "Epoch 9/60, Loss: 0.0896, Val Loss: 0.0899\n",
      "Epoch 37/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0895\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 9/60, Loss: 0.0900, Val Loss: 0.0890\n",
      "Epoch 2/60, Loss: 0.0943, Val Loss: 0.0878\n",
      "Epoch 42/60, Loss: 0.0873, Val Loss: 0.0896\n",
      "Epoch 4/60, Loss: 0.0911, Val Loss: 0.0895\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 23/60, Loss: 0.1372, Val Loss: 0.0924\n",
      "Epoch 29/60, Loss: 0.0895, Val Loss: 0.0892\n",
      "Epoch 10/60, Loss: 0.0894, Val Loss: 0.0899\n",
      "Epoch 57/60, Loss: 0.0876, Val Loss: 0.0884\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 10/60, Loss: 0.0897, Val Loss: 0.0888\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 45/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 37/60, Loss: 0.0884, Val Loss: 0.0854\n",
      "Epoch 24/60, Loss: 0.1335, Val Loss: 0.0922\n",
      "Epoch 47/60, Loss: 0.0879, Val Loss: 0.0868\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0892, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.0890, Val Loss: 0.0897\n",
      "Epoch 3/60, Loss: 0.0912, Val Loss: 0.0872\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 11/60, Loss: 0.0895, Val Loss: 0.0888\n",
      "Epoch 5/60, Loss: 0.0903, Val Loss: 0.0891\n",
      "Epoch 43/60, Loss: 0.0874, Val Loss: 0.0897\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.1299, Val Loss: 0.0920\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 38/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 31/60, Loss: 0.0891, Val Loss: 0.0892\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0897\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 15/60, Loss: 0.0881, Val Loss: 0.0895\n",
      "Epoch 50/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.1259, Val Loss: 0.0918\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.0902, Val Loss: 0.0881\n",
      "Epoch 32/60, Loss: 0.0894, Val Loss: 0.0891\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 6/60, Loss: 0.0896, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0896\n",
      "Epoch 59/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 13/60, Loss: 0.0890, Val Loss: 0.0885\n",
      "Epoch 52/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0873, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 38/60, Loss: 0.0894, Val Loss: 0.0853\n",
      "Epoch 27/60, Loss: 0.1230, Val Loss: 0.0916\n",
      "Epoch 44/60, Loss: 0.0873, Val Loss: 0.0898\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0892\n",
      "Epoch 33/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 54/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 14/60, Loss: 0.0886, Val Loss: 0.0900\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0885\n",
      "Epoch 17/60, Loss: 0.0880, Val Loss: 0.0893\n",
      "Epoch 48/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:33:28,810] Trial 166 finished with value: 0.0891158235569795 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00028498881045985, 'batch_size': 32, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 166] Validation Loss: 0.0891\n",
      "\n",
      "[Trial 172] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0005459037951835143, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 28/60, Loss: 0.1211, Val Loss: 0.0915\n",
      "Epoch 60/60, Loss: 0.0875, Val Loss: 0.0884\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0877\n",
      "Epoch 39/60, Loss: 0.0895, Val Loss: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:33:50,691] Trial 160 finished with value: 0.08838871022065481 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.00035911530171601444, 'batch_size': 16, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 160] Validation Loss: 0.0884\n",
      "\n",
      "[Trial 173] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0028704659500548265, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 7/60, Loss: 0.0892, Val Loss: 0.0891\n",
      "Epoch 34/60, Loss: 0.0889, Val Loss: 0.0892\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 1/60, Loss: 0.2429, Val Loss: 0.0907\n",
      "Epoch 15/60, Loss: 0.0885, Val Loss: 0.0895\n",
      "Epoch 15/60, Loss: 0.0886, Val Loss: 0.0885\n",
      "Epoch 18/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 29/60, Loss: 0.1184, Val Loss: 0.0914\n",
      "Epoch 45/60, Loss: 0.0886, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0888, Val Loss: 0.0891\n",
      "Epoch 2/60, Loss: 0.0937, Val Loss: 0.0898\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 16/60, Loss: 0.0888, Val Loss: 0.0884\n",
      "Epoch 39/60, Loss: 0.0885, Val Loss: 0.0853\n",
      "Epoch 19/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.1159, Val Loss: 0.0912\n",
      "Epoch 3/60, Loss: 0.0906, Val Loss: 0.0894\n",
      "Epoch 6/60, Loss: 0.0893, Val Loss: 0.0869\n",
      "Epoch 1/60, Loss: 0.1389, Val Loss: 0.0873\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0892\n",
      "Epoch 36/60, Loss: 0.0887, Val Loss: 0.0890\n",
      "Epoch 41/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0891\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0882\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0893\n",
      "Epoch 31/60, Loss: 0.1137, Val Loss: 0.0911\n",
      "Epoch 40/60, Loss: 0.0891, Val Loss: 0.0878\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 37/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 46/60, Loss: 0.0874, Val Loss: 0.0897\n",
      "Epoch 5/60, Loss: 0.0894, Val Loss: 0.0892\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0894\n",
      "Epoch 32/60, Loss: 0.1124, Val Loss: 0.0910\n",
      "Epoch 2/60, Loss: 0.0899, Val Loss: 0.0877\n",
      "Epoch 7/60, Loss: 0.0893, Val Loss: 0.0871\n",
      "Epoch 6/60, Loss: 0.0889, Val Loss: 0.0888\n",
      "Epoch 38/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 40/60, Loss: 0.0885, Val Loss: 0.0852\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 44/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 33/60, Loss: 0.1106, Val Loss: 0.0909\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 19/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0889\n",
      "Epoch 39/60, Loss: 0.0886, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.0887, Val Loss: 0.0888\n",
      "Epoch 47/60, Loss: 0.0875, Val Loss: 0.0899\n",
      "Epoch 3/60, Loss: 0.0896, Val Loss: 0.0870\n",
      "Epoch 34/60, Loss: 0.1091, Val Loss: 0.0908\n",
      "Epoch 41/60, Loss: 0.0886, Val Loss: 0.0879\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0884, Val Loss: 0.0886\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0868\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0894\n",
      "Epoch 20/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 40/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0892\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 35/60, Loss: 0.1075, Val Loss: 0.0907\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 21/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0887\n",
      "Epoch 41/60, Loss: 0.0884, Val Loss: 0.0852\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 39/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 4/60, Loss: 0.0896, Val Loss: 0.0873\n",
      "Epoch 48/60, Loss: 0.0875, Val Loss: 0.0898\n",
      "Epoch 36/60, Loss: 0.1060, Val Loss: 0.0907\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 9/60, Loss: 0.0890, Val Loss: 0.0866\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 42/60, Loss: 0.0885, Val Loss: 0.0889\n",
      "Epoch 42/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 11/60, Loss: 0.0884, Val Loss: 0.0885\n",
      "Epoch 37/60, Loss: 0.1047, Val Loss: 0.0906\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0882\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0896, Val Loss: 0.0870\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0888\n",
      "Epoch 12/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 38/60, Loss: 0.1037, Val Loss: 0.0906\n",
      "Epoch 49/60, Loss: 0.0872, Val Loss: 0.0897\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0866\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 27/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 42/60, Loss: 0.0884, Val Loss: 0.0854\n",
      "Epoch 49/60, Loss: 0.0879, Val Loss: 0.0873\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 51/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 44/60, Loss: 0.0883, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.1025, Val Loss: 0.0905\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 28/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 6/60, Loss: 0.0893, Val Loss: 0.0869\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 25/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0883, Val Loss: 0.0888\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 40/60, Loss: 0.1016, Val Loss: 0.0905\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0867\n",
      "Epoch 50/60, Loss: 0.0872, Val Loss: 0.0897\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 29/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 41/60, Loss: 0.1006, Val Loss: 0.0904\n",
      "Epoch 14/60, Loss: 0.0881, Val Loss: 0.0884\n",
      "Epoch 43/60, Loss: 0.0884, Val Loss: 0.0852\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0868\n",
      "Epoch 30/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0888\n",
      "Epoch 42/60, Loss: 0.0999, Val Loss: 0.0903\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0864\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 51/60, Loss: 0.0875, Val Loss: 0.0897\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:49:34,239] Trial 161 finished with value: 0.08971245139837265 and parameters: {'hidden_dim': 448, 'latent_dim': 64, 'lr': 0.0005794687810049903, 'batch_size': 16, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 161] Validation Loss: 0.0897\n",
      "\n",
      "[Trial 174] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 8.748821395689341e-05, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 28/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Epoch 44/60, Loss: 0.0885, Val Loss: 0.0877\n",
      "Epoch 31/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 43/60, Loss: 0.0991, Val Loss: 0.0903\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 44/60, Loss: 0.0874, Val Loss: 0.0892\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0883\n",
      "Epoch 8/60, Loss: 0.0891, Val Loss: 0.0871\n",
      "Epoch 1/60, Loss: 0.9068, Val Loss: 0.1216\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 32/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 44/60, Loss: 0.0984, Val Loss: 0.0902\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0863\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 44/60, Loss: 0.0883, Val Loss: 0.0853\n",
      "Epoch 2/60, Loss: 0.3838, Val Loss: 0.0976\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 45/60, Loss: 0.0978, Val Loss: 0.0903\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 18/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 30/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 3/60, Loss: 0.2220, Val Loss: 0.0942\n",
      "Epoch 45/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 9/60, Loss: 0.0893, Val Loss: 0.0868\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 51/60, Loss: 0.0881, Val Loss: 0.0887\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 46/60, Loss: 0.0971, Val Loss: 0.0902\n",
      "Epoch 53/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0866\n",
      "Epoch 31/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 56/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 4/60, Loss: 0.1653, Val Loss: 0.0926\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Epoch 35/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 47/60, Loss: 0.0966, Val Loss: 0.0902\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 45/60, Loss: 0.0872, Val Loss: 0.0892\n",
      "Early stopping triggered\n",
      "Epoch 45/60, Loss: 0.0885, Val Loss: 0.0854\n",
      "Epoch 5/60, Loss: 0.1394, Val Loss: 0.0920\n",
      "Epoch 32/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 57/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0865\n",
      "[Trial 152] Validation Loss: 0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:54:14,780] Trial 152 finished with value: 0.08925165071462592 and parameters: {'hidden_dim': 320, 'latent_dim': 64, 'lr': 0.0004310434626930156, 'batch_size': 8, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 175] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0028008263729738343, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 53/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 42/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 48/60, Loss: 0.0960, Val Loss: 0.0902\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0867\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 6/60, Loss: 0.1237, Val Loss: 0.0914\n",
      "Epoch 46/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Early stopping triggered\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 58/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 1/60, Loss: 0.1741, Val Loss: 0.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:55:18,470] Trial 156 finished with value: 0.08746572298308214 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.002834255526171394, 'batch_size': 8, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 156] Validation Loss: 0.0875\n",
      "\n",
      "[Trial 176] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 8.636219782426374e-05, 'batch_size': 32, 'patience': 6}\n",
      "Epoch 49/60, Loss: 0.0956, Val Loss: 0.0901\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 37/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 18/60, Loss: 0.0881, Val Loss: 0.0885\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.1145, Val Loss: 0.0910\n",
      "Epoch 11/60, Loss: 0.0891, Val Loss: 0.0867\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 59/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 2/60, Loss: 0.0899, Val Loss: 0.0908\n",
      "Epoch 1/60, Loss: 0.8973, Val Loss: 0.1200\n",
      "Epoch 50/60, Loss: 0.0951, Val Loss: 0.0902\n",
      "Epoch 56/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0864\n",
      "Epoch 38/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 8/60, Loss: 0.1080, Val Loss: 0.0905\n",
      "Epoch 46/60, Loss: 0.0883, Val Loss: 0.0854\n",
      "Epoch 35/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 60/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Early stopping triggered\n",
      "Epoch 3/60, Loss: 0.0889, Val Loss: 0.0909\n",
      "Epoch 2/60, Loss: 0.3744, Val Loss: 0.0965\n",
      "Epoch 57/60, Loss: 0.0879, Val Loss: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:57:24,489] Trial 163 finished with value: 0.08706503013769785 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0005452722920895833, 'batch_size': 32, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 163] Validation Loss: 0.0871\n",
      "\n",
      "[Trial 177] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 8.508084018592605e-05, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 51/60, Loss: 0.0947, Val Loss: 0.0901\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 9/60, Loss: 0.1043, Val Loss: 0.0903\n",
      "Epoch 39/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0866\n",
      "Epoch 58/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 36/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.0888, Val Loss: 0.0908\n",
      "Epoch 3/60, Loss: 0.2169, Val Loss: 0.0931\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 52/60, Loss: 0.0943, Val Loss: 0.0901\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0864\n",
      "Epoch 10/60, Loss: 0.1012, Val Loss: 0.0903\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 59/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.1639, Val Loss: 0.0917\n",
      "Epoch 5/60, Loss: 0.0886, Val Loss: 0.0907\n",
      "Epoch 1/60, Loss: 0.6299, Val Loss: 0.1029\n",
      "Epoch 53/60, Loss: 0.0939, Val Loss: 0.0900\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 11/60, Loss: 0.0990, Val Loss: 0.0901\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 47/60, Loss: 0.0889, Val Loss: 0.0852\n",
      "Epoch 41/60, Loss: 0.0875, Val Loss: 0.0892\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 20:59:59,263] Trial 164 finished with value: 0.08861076136430104 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 8.898734156090751e-05, 'batch_size': 32, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 164] Validation Loss: 0.0886\n",
      "\n",
      "[Trial 178] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00023380203837370064, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.1387, Val Loss: 0.0909\n",
      "Epoch 54/60, Loss: 0.0935, Val Loss: 0.0901\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0912\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0863\n",
      "Epoch 12/60, Loss: 0.0970, Val Loss: 0.0901\n",
      "Epoch 23/60, Loss: 0.0876, Val Loss: 0.0882\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 42/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 55/60, Loss: 0.0932, Val Loss: 0.0901\n",
      "Epoch 2/60, Loss: 0.1876, Val Loss: 0.0942\n",
      "Epoch 6/60, Loss: 0.1242, Val Loss: 0.0903\n",
      "Epoch 39/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 21/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 7/60, Loss: 0.0885, Val Loss: 0.0905\n",
      "Epoch 13/60, Loss: 0.0957, Val Loss: 0.0900\n",
      "Epoch 40/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 43/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 14/60, Loss: 0.0889, Val Loss: 0.0864\n",
      "Epoch 1/60, Loss: 0.3954, Val Loss: 0.0904\n",
      "Epoch 44/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 56/60, Loss: 0.0931, Val Loss: 0.0900\n",
      "Epoch 7/60, Loss: 0.1152, Val Loss: 0.0897\n",
      "Epoch 14/60, Loss: 0.0947, Val Loss: 0.0900\n",
      "Epoch 40/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0864\n",
      "Early stopping triggered\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0906\n",
      "[Trial 171] Validation Loss: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:02:05,445] Trial 171 finished with value: 0.08636653212209543 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0005577583750410123, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 179] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0006941157005633638, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 48/60, Loss: 0.0901, Val Loss: 0.0854\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 44/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 56/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 3/60, Loss: 0.1306, Val Loss: 0.0922\n",
      "Epoch 57/60, Loss: 0.0926, Val Loss: 0.0900\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 15/60, Loss: 0.0938, Val Loss: 0.0899\n",
      "Epoch 8/60, Loss: 0.1089, Val Loss: 0.0893\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0907\n",
      "Epoch 2/60, Loss: 0.1111, Val Loss: 0.0882\n",
      "Epoch 42/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 15/60, Loss: 0.0890, Val Loss: 0.0868\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0893\n",
      "Epoch 58/60, Loss: 0.0922, Val Loss: 0.0900\n",
      "Epoch 16/60, Loss: 0.0932, Val Loss: 0.0899\n",
      "Epoch 9/60, Loss: 0.1046, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 10/60, Loss: 0.0884, Val Loss: 0.0903\n",
      "Epoch 42/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 1/60, Loss: 0.2178, Val Loss: 0.0912\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 46/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.1121, Val Loss: 0.0912\n",
      "Epoch 59/60, Loss: 0.0923, Val Loss: 0.0900\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 17/60, Loss: 0.0926, Val Loss: 0.0900\n",
      "Epoch 10/60, Loss: 0.1013, Val Loss: 0.0889\n",
      "Epoch 11/60, Loss: 0.0882, Val Loss: 0.0902\n",
      "Epoch 43/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 3/60, Loss: 0.0972, Val Loss: 0.0878\n",
      "Epoch 49/60, Loss: 0.0884, Val Loss: 0.0852\n",
      "Epoch 44/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 16/60, Loss: 0.0918, Val Loss: 0.0870\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 60/60, Loss: 0.0919, Val Loss: 0.0900\n",
      "Epoch 18/60, Loss: 0.0920, Val Loss: 0.0898\n",
      "Epoch 47/60, Loss: 0.0875, Val Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:05:00,637] Trial 165 finished with value: 0.0899480327963829 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 1.6361664666242988e-05, 'batch_size': 32, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 165] Validation Loss: 0.0899\n",
      "\n",
      "[Trial 180] Starting with parameters: {'hidden_dim': 384, 'latent_dim': 128, 'lr': 0.00024378282690024045, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 11/60, Loss: 0.0992, Val Loss: 0.0887\n",
      "Epoch 2/60, Loss: 0.0918, Val Loss: 0.0900\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 57/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 12/60, Loss: 0.0880, Val Loss: 0.0905\n",
      "Epoch 5/60, Loss: 0.1036, Val Loss: 0.0916\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "Epoch 19/60, Loss: 0.0918, Val Loss: 0.0898\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 12/60, Loss: 0.0974, Val Loss: 0.0887\n",
      "Epoch 48/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.0936, Val Loss: 0.0874\n",
      "Epoch 45/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0883, Val Loss: 0.0904\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0866\n",
      "Epoch 20/60, Loss: 0.0913, Val Loss: 0.0898\n",
      "Epoch 46/60, Loss: 0.0878, Val Loss: 0.0879\n",
      "Epoch 13/60, Loss: 0.0961, Val Loss: 0.0886\n",
      "Epoch 3/60, Loss: 0.0899, Val Loss: 0.0894\n",
      "Epoch 49/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0881\n",
      "Epoch 1/60, Loss: 0.2487, Val Loss: 0.0913\n",
      "Epoch 46/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 50/60, Loss: 0.0884, Val Loss: 0.0853\n",
      "Early stopping triggered\n",
      "Epoch 6/60, Loss: 0.0987, Val Loss: 0.0910\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0902\n",
      "Epoch 21/60, Loss: 0.0908, Val Loss: 0.0898\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0951, Val Loss: 0.0888\n",
      "[Trial 157] Validation Loss: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:07:25,465] Trial 157 finished with value: 0.08533250863353412 and parameters: {'hidden_dim': 128, 'latent_dim': 64, 'lr': 0.0004964592970743144, 'batch_size': 8, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 181] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00022310859679582158, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0879\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.0917, Val Loss: 0.0871\n",
      "Epoch 47/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 22/60, Loss: 0.0906, Val Loss: 0.0897\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 15/60, Loss: 0.0940, Val Loss: 0.0884\n",
      "Epoch 4/60, Loss: 0.0894, Val Loss: 0.0897\n",
      "Epoch 18/60, Loss: 0.0888, Val Loss: 0.0864\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0904\n",
      "Epoch 58/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 48/60, Loss: 0.0879, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 51/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.0982, Val Loss: 0.0894\n",
      "Epoch 7/60, Loss: 0.0959, Val Loss: 0.0906\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 23/60, Loss: 0.0905, Val Loss: 0.0897\n",
      "Epoch 16/60, Loss: 0.0934, Val Loss: 0.0884\n",
      "Epoch 48/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 1/60, Loss: 0.3990, Val Loss: 0.0933\n",
      "Epoch 16/60, Loss: 0.0879, Val Loss: 0.0900\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0880\n",
      "Epoch 6/60, Loss: 0.0911, Val Loss: 0.0872\n",
      "Epoch 52/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 5/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 17/60, Loss: 0.0929, Val Loss: 0.0884\n",
      "Epoch 24/60, Loss: 0.0903, Val Loss: 0.0897\n",
      "Epoch 49/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0888, Val Loss: 0.0862\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Epoch 17/60, Loss: 0.0878, Val Loss: 0.0899\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 3/60, Loss: 0.0923, Val Loss: 0.0894\n",
      "Epoch 53/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Epoch 18/60, Loss: 0.0924, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0901, Val Loss: 0.0897\n",
      "Epoch 8/60, Loss: 0.0937, Val Loss: 0.0903\n",
      "Epoch 2/60, Loss: 0.1117, Val Loss: 0.0904\n",
      "Epoch 50/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 7/60, Loss: 0.0904, Val Loss: 0.0869\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 18/60, Loss: 0.0878, Val Loss: 0.0901\n",
      "Epoch 54/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 59/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0897\n",
      "Epoch 26/60, Loss: 0.0899, Val Loss: 0.0896\n",
      "Epoch 19/60, Loss: 0.0919, Val Loss: 0.0884\n",
      "Epoch 47/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 20/60, Loss: 0.0948, Val Loss: 0.0871\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0880\n",
      "Epoch 19/60, Loss: 0.0879, Val Loss: 0.0899\n",
      "Epoch 4/60, Loss: 0.0906, Val Loss: 0.0890\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 55/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 27/60, Loss: 0.0898, Val Loss: 0.0896\n",
      "Epoch 9/60, Loss: 0.0925, Val Loss: 0.0901\n",
      "Epoch 20/60, Loss: 0.0915, Val Loss: 0.0883\n",
      "Epoch 8/60, Loss: 0.0901, Val Loss: 0.0869\n",
      "Epoch 3/60, Loss: 0.0974, Val Loss: 0.0891\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0879\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0901\n",
      "Epoch 7/60, Loss: 0.0885, Val Loss: 0.0890\n",
      "Epoch 28/60, Loss: 0.0896, Val Loss: 0.0896\n",
      "Epoch 56/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 21/60, Loss: 0.0913, Val Loss: 0.0884\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0893, Val Loss: 0.0866\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 5/60, Loss: 0.0899, Val Loss: 0.0888\n",
      "Epoch 29/60, Loss: 0.0894, Val Loss: 0.0895\n",
      "Epoch 21/60, Loss: 0.0877, Val Loss: 0.0898\n",
      "Epoch 10/60, Loss: 0.0918, Val Loss: 0.0903\n",
      "Epoch 22/60, Loss: 0.0910, Val Loss: 0.0883\n",
      "Epoch 57/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0896, Val Loss: 0.0867\n",
      "Epoch 4/60, Loss: 0.0932, Val Loss: 0.0897\n",
      "Epoch 60/60, Loss: 0.0879, Val Loss: 0.0868\n",
      "[Trial 150] Validation Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:14:19,744] Trial 150 finished with value: 0.086824882371972 and parameters: {'hidden_dim': 192, 'latent_dim': 96, 'lr': 0.0003993374751132642, 'batch_size': 8, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 182] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0016344092864480477, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 54/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 30/60, Loss: 0.0893, Val Loss: 0.0895\n",
      "Epoch 55/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "Epoch 8/60, Loss: 0.0884, Val Loss: 0.0895\n",
      "Epoch 48/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0878, Val Loss: 0.0900\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0907, Val Loss: 0.0883\n",
      "Epoch 58/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 22/60, Loss: 0.0890, Val Loss: 0.0870\n",
      "Epoch 55/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 30/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0891, Val Loss: 0.0895\n",
      "Epoch 11/60, Loss: 0.0912, Val Loss: 0.0902\n",
      "Epoch 6/60, Loss: 0.0894, Val Loss: 0.0890\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Early stopping triggered\n",
      "Epoch 10/60, Loss: 0.0896, Val Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:15:43,261] Trial 169 finished with value: 0.08796039894223213 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0003728172968337625, 'batch_size': 32, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 169] Validation Loss: 0.0880\n",
      "\n",
      "[Trial 183] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0009780046463119107, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 5/60, Loss: 0.0915, Val Loss: 0.0888\n",
      "Epoch 24/60, Loss: 0.0905, Val Loss: 0.0884\n",
      "Epoch 59/60, Loss: 0.0874, Val Loss: 0.0889\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Epoch 1/60, Loss: 0.1523, Val Loss: 0.0938\n",
      "Epoch 56/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 32/60, Loss: 0.0891, Val Loss: 0.0893\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0897\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:16:37,946] Trial 172 finished with value: 0.08816147372126579 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0005459037951835143, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 172] Validation Loss: 0.0882\n",
      "\n",
      "[Trial 184] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.000262252199666924, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 25/60, Loss: 0.0904, Val Loss: 0.0883\n",
      "Epoch 60/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0877, Val Loss: 0.0901\n",
      "[Trial 167] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:16:47,691] Trial 167 finished with value: 0.08891682376464208 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0005629517458953209, 'batch_size': 32, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 185] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00024391056421664526, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 31/60, Loss: 0.0876, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0892, Val Loss: 0.0866\n",
      "Epoch 57/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 33/60, Loss: 0.0889, Val Loss: 0.0893\n",
      "Epoch 12/60, Loss: 0.0904, Val Loss: 0.0902\n",
      "Epoch 11/60, Loss: 0.0896, Val Loss: 0.0866\n",
      "Epoch 6/60, Loss: 0.0908, Val Loss: 0.0890\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0888\n",
      "Epoch 1/60, Loss: 0.1870, Val Loss: 0.0890\n",
      "Epoch 26/60, Loss: 0.0902, Val Loss: 0.0883\n",
      "Epoch 2/60, Loss: 0.0894, Val Loss: 0.0913\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0899\n",
      "Epoch 34/60, Loss: 0.0887, Val Loss: 0.0893\n",
      "Epoch 58/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 10/60, Loss: 0.0882, Val Loss: 0.0887\n",
      "Epoch 1/60, Loss: 0.3496, Val Loss: 0.0933\n",
      "Epoch 27/60, Loss: 0.0901, Val Loss: 0.0882\n",
      "Epoch 1/60, Loss: 0.3686, Val Loss: 0.0916\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0876, Val Loss: 0.0899\n",
      "Epoch 24/60, Loss: 0.0891, Val Loss: 0.0865\n",
      "Epoch 35/60, Loss: 0.0888, Val Loss: 0.0894\n",
      "Epoch 13/60, Loss: 0.0903, Val Loss: 0.0900\n",
      "Epoch 12/60, Loss: 0.0892, Val Loss: 0.0863\n",
      "Epoch 7/60, Loss: 0.0899, Val Loss: 0.0889\n",
      "Epoch 59/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 2/60, Loss: 0.0909, Val Loss: 0.0903\n",
      "Epoch 28/60, Loss: 0.0900, Val Loss: 0.0882\n",
      "Epoch 3/60, Loss: 0.0887, Val Loss: 0.0914\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0887\n",
      "Epoch 27/60, Loss: 0.0876, Val Loss: 0.0899\n",
      "Epoch 2/60, Loss: 0.1057, Val Loss: 0.0904\n",
      "Epoch 36/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 11/60, Loss: 0.0880, Val Loss: 0.0887\n",
      "Epoch 60/60, Loss: 0.0875, Val Loss: 0.0889\n",
      "[Trial 168] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:19:55,981] Trial 168 finished with value: 0.08892252544562022 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.0003650723648149555, 'batch_size': 32, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 186] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.000237308339279024, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 2/60, Loss: 0.1081, Val Loss: 0.0908\n",
      "Epoch 29/60, Loss: 0.0899, Val Loss: 0.0882\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Early stopping triggered\n",
      "[Trial 170] Validation Loss: 0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:20:15,439] Trial 170 finished with value: 0.088397612174352 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 0.00033421797437379534, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 187] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.00023392210880049624, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 14/60, Loss: 0.0899, Val Loss: 0.0900\n",
      "Epoch 37/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 25/60, Loss: 0.0890, Val Loss: 0.0862\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0898\n",
      "Epoch 13/60, Loss: 0.0889, Val Loss: 0.0863\n",
      "Epoch 8/60, Loss: 0.0898, Val Loss: 0.0886\n",
      "Epoch 3/60, Loss: 0.0897, Val Loss: 0.0883\n",
      "Epoch 4/60, Loss: 0.0889, Val Loss: 0.0906\n",
      "Epoch 30/60, Loss: 0.0897, Val Loss: 0.0881\n",
      "Epoch 3/60, Loss: 0.0952, Val Loss: 0.0905\n",
      "Epoch 9/60, Loss: 0.0888, Val Loss: 0.0886\n",
      "Epoch 38/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 50/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 12/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 29/60, Loss: 0.0875, Val Loss: 0.0897\n",
      "Epoch 1/60, Loss: 0.5086, Val Loss: 0.0956\n",
      "Epoch 3/60, Loss: 0.0961, Val Loss: 0.0888\n",
      "Epoch 31/60, Loss: 0.0896, Val Loss: 0.0881\n",
      "Epoch 1/60, Loss: 0.6500, Val Loss: 0.0952\n",
      "Epoch 15/60, Loss: 0.0896, Val Loss: 0.0899\n",
      "Epoch 39/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.0895, Val Loss: 0.0887\n",
      "Epoch 14/60, Loss: 0.0890, Val Loss: 0.0863\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0862\n",
      "Epoch 5/60, Loss: 0.0886, Val Loss: 0.0913\n",
      "Epoch 30/60, Loss: 0.1097, Val Loss: 0.0911\n",
      "Epoch 32/60, Loss: 0.0895, Val Loss: 0.0880\n",
      "Epoch 4/60, Loss: 0.0921, Val Loss: 0.0898\n",
      "Epoch 4/60, Loss: 0.0925, Val Loss: 0.0887\n",
      "Epoch 2/60, Loss: 0.1436, Val Loss: 0.0920\n",
      "Epoch 40/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 10/60, Loss: 0.0886, Val Loss: 0.0889\n",
      "Epoch 2/60, Loss: 0.1638, Val Loss: 0.0917\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0907\n",
      "Epoch 16/60, Loss: 0.0891, Val Loss: 0.0899\n",
      "Epoch 33/60, Loss: 0.0893, Val Loss: 0.0881\n",
      "Epoch 41/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0892, Val Loss: 0.0881\n",
      "Epoch 15/60, Loss: 0.0890, Val Loss: 0.0864\n",
      "Epoch 10/60, Loss: 0.0891, Val Loss: 0.0884\n",
      "Epoch 27/60, Loss: 0.0889, Val Loss: 0.0863\n",
      "Epoch 5/60, Loss: 0.0906, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0885, Val Loss: 0.0902\n",
      "Epoch 3/60, Loss: 0.1090, Val Loss: 0.0901\n",
      "Epoch 5/60, Loss: 0.0910, Val Loss: 0.0889\n",
      "Epoch 34/60, Loss: 0.0891, Val Loss: 0.0879\n",
      "Epoch 32/60, Loss: 0.0885, Val Loss: 0.0905\n",
      "Epoch 3/60, Loss: 0.1140, Val Loss: 0.0901\n",
      "Epoch 42/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 51/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0887\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0888\n",
      "Epoch 6/60, Loss: 0.0899, Val Loss: 0.0901\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0898\n",
      "Epoch 35/60, Loss: 0.0892, Val Loss: 0.0879\n",
      "Epoch 33/60, Loss: 0.0885, Val Loss: 0.0907\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 43/60, Loss: 0.0883, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.0987, Val Loss: 0.0896\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0862\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 28/60, Loss: 0.0888, Val Loss: 0.0863\n",
      "Epoch 7/60, Loss: 0.0882, Val Loss: 0.0907\n",
      "Epoch 4/60, Loss: 0.1010, Val Loss: 0.0893\n",
      "Epoch 6/60, Loss: 0.0903, Val Loss: 0.0887\n",
      "Epoch 36/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 7/60, Loss: 0.0895, Val Loss: 0.0897\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0885\n",
      "Epoch 34/60, Loss: 0.0883, Val Loss: 0.0903\n",
      "Epoch 18/60, Loss: 0.0891, Val Loss: 0.0897\n",
      "Epoch 5/60, Loss: 0.0950, Val Loss: 0.0897\n",
      "Epoch 12/60, Loss: 0.0884, Val Loss: 0.0882\n",
      "Epoch 37/60, Loss: 0.0890, Val Loss: 0.0879\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0891\n",
      "Epoch 5/60, Loss: 0.0963, Val Loss: 0.0889\n",
      "Epoch 7/60, Loss: 0.0888, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0885, Val Loss: 0.0865\n",
      "Epoch 12/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0892, Val Loss: 0.0896\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0904\n",
      "Early stopping triggered\n",
      "[Trial 175] Validation Loss: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:27:32,776] Trial 175 finished with value: 0.09036325464646021 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0028008263729738343, 'batch_size': 32, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 188] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.0002278872895148489, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 29/60, Loss: 0.0889, Val Loss: 0.0867\n",
      "Epoch 8/60, Loss: 0.0883, Val Loss: 0.0907\n",
      "Epoch 7/60, Loss: 0.0898, Val Loss: 0.0884\n",
      "Epoch 38/60, Loss: 0.0890, Val Loss: 0.0880\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0886\n",
      "Epoch 52/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 6/60, Loss: 0.0928, Val Loss: 0.0891\n",
      "Epoch 19/60, Loss: 0.0890, Val Loss: 0.0897\n",
      "Epoch 6/60, Loss: 0.0937, Val Loss: 0.0887\n",
      "Epoch 9/60, Loss: 0.0891, Val Loss: 0.0892\n",
      "Epoch 39/60, Loss: 0.0889, Val Loss: 0.0878\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0881\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0863\n",
      "Epoch 1/60, Loss: 0.5667, Val Loss: 0.0957\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0882\n",
      "Epoch 13/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0897, Val Loss: 0.0883\n",
      "Epoch 30/60, Loss: 0.0887, Val Loss: 0.0863\n",
      "Epoch 9/60, Loss: 0.0881, Val Loss: 0.0902\n",
      "Epoch 7/60, Loss: 0.0917, Val Loss: 0.0893\n",
      "Epoch 40/60, Loss: 0.0888, Val Loss: 0.0878\n",
      "Epoch 48/60, Loss: 0.0881, Val Loss: 0.0890\n",
      "Epoch 17/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0923, Val Loss: 0.0888\n",
      "Epoch 10/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0896\n",
      "Epoch 2/60, Loss: 0.1508, Val Loss: 0.0926\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0861\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0890\n",
      "Epoch 41/60, Loss: 0.0889, Val Loss: 0.0877\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0878\n",
      "Epoch 14/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0909, Val Loss: 0.0891\n",
      "Epoch 9/60, Loss: 0.0890, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 11/60, Loss: 0.0886, Val Loss: 0.0892\n",
      "Epoch 10/60, Loss: 0.0882, Val Loss: 0.0902\n",
      "Epoch 31/60, Loss: 0.0887, Val Loss: 0.0862\n",
      "Early stopping triggered\n",
      "Epoch 8/60, Loss: 0.0913, Val Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:31:31,549] Trial 173 finished with value: 0.08621402308344842 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0028704659500548265, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 173] Validation Loss: 0.0862\n",
      "\n",
      "[Trial 189] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0015947568713005967, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 50/60, Loss: 0.0878, Val Loss: 0.0890\n",
      "Epoch 18/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 53/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 42/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 3/60, Loss: 0.1117, Val Loss: 0.0906\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0895\n",
      "Epoch 12/60, Loss: 0.0884, Val Loss: 0.0891\n",
      "Epoch 20/60, Loss: 0.0887, Val Loss: 0.0861\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 9/60, Loss: 0.0903, Val Loss: 0.0889\n",
      "Epoch 10/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 43/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 9/60, Loss: 0.0908, Val Loss: 0.0887\n",
      "Epoch 10/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 11/60, Loss: 0.0880, Val Loss: 0.0900\n",
      "Epoch 1/60, Loss: 0.1519, Val Loss: 0.0893\n",
      "Epoch 13/60, Loss: 0.0880, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 4/60, Loss: 0.1004, Val Loss: 0.0899\n",
      "Epoch 19/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 52/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 44/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0895\n",
      "Epoch 10/60, Loss: 0.0901, Val Loss: 0.0889\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 21/60, Loss: 0.0884, Val Loss: 0.0861\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0890\n",
      "Epoch 10/60, Loss: 0.0903, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 45/60, Loss: 0.0886, Val Loss: 0.0877\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0880\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 5/60, Loss: 0.0957, Val Loss: 0.0897\n",
      "Epoch 2/60, Loss: 0.0900, Val Loss: 0.0916\n",
      "Epoch 12/60, Loss: 0.0881, Val Loss: 0.0899\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 54/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 54/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0889\n",
      "Epoch 16/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 11/60, Loss: 0.0895, Val Loss: 0.0889\n",
      "Epoch 46/60, Loss: 0.0885, Val Loss: 0.0876\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 11/60, Loss: 0.0899, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 6/60, Loss: 0.0932, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0879, Val Loss: 0.0889\n",
      "Epoch 3/60, Loss: 0.0897, Val Loss: 0.0885\n",
      "Epoch 47/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0880\n",
      "Epoch 12/60, Loss: 0.0888, Val Loss: 0.0880\n",
      "Epoch 13/60, Loss: 0.0878, Val Loss: 0.0898\n",
      "Epoch 21/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 56/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0893, Val Loss: 0.0888\n",
      "Epoch 12/60, Loss: 0.0899, Val Loss: 0.0886\n",
      "Epoch 48/60, Loss: 0.0884, Val Loss: 0.0876\n",
      "Epoch 17/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 17/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 7/60, Loss: 0.0919, Val Loss: 0.0893\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 4/60, Loss: 0.0894, Val Loss: 0.0896\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 18/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 49/60, Loss: 0.0885, Val Loss: 0.0875\n",
      "Epoch 18/60, Loss: 0.0881, Val Loss: 0.0891\n",
      "Epoch 13/60, Loss: 0.0893, Val Loss: 0.0888\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0885\n",
      "Epoch 14/60, Loss: 0.0879, Val Loss: 0.0900\n",
      "Epoch 13/60, Loss: 0.0896, Val Loss: 0.0885\n",
      "Epoch 58/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 55/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0911, Val Loss: 0.0892\n",
      "Epoch 50/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0894\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 59/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0862\n",
      "Epoch 5/60, Loss: 0.0889, Val Loss: 0.0883\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 14/60, Loss: 0.0891, Val Loss: 0.0887\n",
      "Epoch 14/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 19/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 14/60, Loss: 0.0894, Val Loss: 0.0884\n",
      "Epoch 51/60, Loss: 0.0884, Val Loss: 0.0875\n",
      "Epoch 23/60, Loss: 0.0875, Val Loss: 0.0887\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0889\n",
      "Epoch 20/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 9/60, Loss: 0.0905, Val Loss: 0.0891\n",
      "Epoch 15/60, Loss: 0.0877, Val Loss: 0.0897\n",
      "[Trial 174] Validation Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:41:26,241] Trial 174 finished with value: 0.08890709877014161 and parameters: {'hidden_dim': 256, 'latent_dim': 64, 'lr': 8.748821395689341e-05, 'batch_size': 32, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 190] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.0015975980872770992, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 26/60, Loss: 0.0881, Val Loss: 0.0892\n",
      "Epoch 52/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 6/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0861\n",
      "Epoch 15/60, Loss: 0.0891, Val Loss: 0.0890\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0882\n",
      "Epoch 19/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 15/60, Loss: 0.0890, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 20/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "Epoch 10/60, Loss: 0.0900, Val Loss: 0.0894\n",
      "Epoch 1/60, Loss: 0.1768, Val Loss: 0.0907\n",
      "Epoch 24/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 53/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 56/60, Loss: 0.0877, Val Loss: 0.0884\n",
      "Epoch 16/60, Loss: 0.0879, Val Loss: 0.0897\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 16/60, Loss: 0.0889, Val Loss: 0.0885\n",
      "Epoch 54/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 7/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0892, Val Loss: 0.0883\n",
      "Epoch 26/60, Loss: 0.0885, Val Loss: 0.0865\n",
      "Early stopping triggered\n",
      "Epoch 16/60, Loss: 0.0885, Val Loss: 0.0874\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:44:18,260] Trial 178 finished with value: 0.08649431218703588 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00023380203837370064, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 178] Validation Loss: 0.0865\n",
      "\n",
      "[Trial 191] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00020927986019040747, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 2/60, Loss: 0.0905, Val Loss: 0.0897\n",
      "Epoch 11/60, Loss: 0.0900, Val Loss: 0.0891\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0880\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 25/60, Loss: 0.0877, Val Loss: 0.0885\n",
      "Epoch 55/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 17/60, Loss: 0.0877, Val Loss: 0.0914\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0888\n",
      "Epoch 17/60, Loss: 0.0886, Val Loss: 0.0886\n",
      "Epoch 17/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 3/60, Loss: 0.0894, Val Loss: 0.0897\n",
      "Epoch 8/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 12/60, Loss: 0.0898, Val Loss: 0.0890\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 1/60, Loss: 0.3906, Val Loss: 0.0914\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0882\n",
      "Epoch 57/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0887, Val Loss: 0.0885\n",
      "Epoch 57/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 18/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.0893, Val Loss: 0.0899\n",
      "Epoch 18/60, Loss: 0.0878, Val Loss: 0.0899\n",
      "Epoch 13/60, Loss: 0.0893, Val Loss: 0.0891\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 2/60, Loss: 0.1151, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0883, Val Loss: 0.0876\n",
      "Epoch 58/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0886\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 19/60, Loss: 0.0885, Val Loss: 0.0884\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 5/60, Loss: 0.0890, Val Loss: 0.0897\n",
      "Epoch 59/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 22/60, Loss: 0.0876, Val Loss: 0.0879\n",
      "Epoch 14/60, Loss: 0.0893, Val Loss: 0.0890\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0906\n",
      "Epoch 26/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 30/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 3/60, Loss: 0.0986, Val Loss: 0.0892\n",
      "Epoch 19/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:49:45,173] Trial 176 finished with value: 0.08741753771901131 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 8.636219782426374e-05, 'batch_size': 32, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 176] Validation Loss: 0.0874\n",
      "\n",
      "[Trial 192] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.0016370173028743703, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 20/60, Loss: 0.0884, Val Loss: 0.0884\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0896\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 15/60, Loss: 0.0893, Val Loss: 0.0889\n",
      "Epoch 58/60, Loss: 0.0875, Val Loss: 0.0883\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Epoch 20/60, Loss: 0.0909, Val Loss: 0.0898\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 4/60, Loss: 0.0943, Val Loss: 0.0887\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0897\n",
      "Epoch 7/60, Loss: 0.0885, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0883\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 0.1461, Val Loss: 0.0907\n",
      "Epoch 29/60, Loss: 0.0886, Val Loss: 0.0885\n",
      "Epoch 16/60, Loss: 0.0891, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Epoch 8/60, Loss: 0.0884, Val Loss: 0.0892\n",
      "Epoch 5/60, Loss: 0.0921, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0883\n",
      "Epoch 21/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 22/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 24/60, Loss: 0.0877, Val Loss: 0.0879\n",
      "Epoch 12/60, Loss: 0.0885, Val Loss: 0.0882\n",
      "Epoch 32/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 21/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 2/60, Loss: 0.0896, Val Loss: 0.0905\n",
      "Epoch 17/60, Loss: 0.0891, Val Loss: 0.0889\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0878\n",
      "Epoch 59/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0891\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0887\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0885, Val Loss: 0.0878\n",
      "Epoch 6/60, Loss: 0.0909, Val Loss: 0.0884\n",
      "Epoch 13/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 22/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 25/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0878\n",
      "Epoch 18/60, Loss: 0.0889, Val Loss: 0.0886\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Early stopping triggered\n",
      "Epoch 3/60, Loss: 0.0891, Val Loss: 0.0910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:54:54,590] Trial 183 finished with value: 0.08747450845936934 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0009780046463119107, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 183] Validation Loss: 0.0875\n",
      "\n",
      "[Trial 193] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.00023242147154546336, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 31/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 10/60, Loss: 0.0885, Val Loss: 0.0893\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 24/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0878, Val Loss: 0.0886\n",
      "Epoch 7/60, Loss: 0.0906, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0886\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 23/60, Loss: 0.0877, Val Loss: 0.0897\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 11/60, Loss: 0.0884, Val Loss: 0.0890\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 4/60, Loss: 0.0889, Val Loss: 0.0901\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0882\n",
      "Epoch 1/60, Loss: 0.3079, Val Loss: 0.0920\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0886\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0878\n",
      "Epoch 60/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0875, Val Loss: 0.0886\n",
      "Epoch 8/60, Loss: 0.0897, Val Loss: 0.0883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 21:57:14,927] Trial 153 finished with value: 0.08827876417587201 and parameters: {'hidden_dim': 384, 'latent_dim': 64, 'lr': 1.603934740295883e-05, 'batch_size': 8, 'patience': 9}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 153] Validation Loss: 0.0883\n",
      "\n",
      "[Trial 194] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00023764721058076808, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 20/60, Loss: 0.0888, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 12/60, Loss: 0.0881, Val Loss: 0.0889\n",
      "Epoch 24/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 24/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0883\n",
      "Epoch 5/60, Loss: 0.0890, Val Loss: 0.0906\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "Epoch 2/60, Loss: 0.1025, Val Loss: 0.0901\n",
      "Epoch 33/60, Loss: 0.0878, Val Loss: 0.0885\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0879\n",
      "Epoch 9/60, Loss: 0.0898, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0887, Val Loss: 0.0885\n",
      "Epoch 32/60, Loss: 0.0875, Val Loss: 0.0886\n",
      "Epoch 1/60, Loss: 0.3113, Val Loss: 0.0910\n",
      "Epoch 13/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 36/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 27/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 25/60, Loss: 0.0881, Val Loss: 0.0879\n",
      "Epoch 25/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0887\n",
      "Epoch 3/60, Loss: 0.0940, Val Loss: 0.0903\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Early stopping triggered\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:00:09,807] Trial 179 finished with value: 0.08834066105385621 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0006941157005633638, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 179] Validation Loss: 0.0883\n",
      "\n",
      "[Trial 195] Starting with parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00021585697558040932, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 10/60, Loss: 0.0895, Val Loss: 0.0880\n",
      "Epoch 14/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 2/60, Loss: 0.1068, Val Loss: 0.0888\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 37/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 23/60, Loss: 0.0884, Val Loss: 0.0886\n",
      "Epoch 26/60, Loss: 0.0876, Val Loss: 0.0899\n",
      "Epoch 15/60, Loss: 0.0883, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.0917, Val Loss: 0.0893\n",
      "Epoch 1/60, Loss: 0.3708, Val Loss: 0.0923\n",
      "Epoch 7/60, Loss: 0.0887, Val Loss: 0.0899\n",
      "Epoch 11/60, Loss: 0.0892, Val Loss: 0.0880\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 3/60, Loss: 0.0960, Val Loss: 0.0894\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0878\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 34/60, Loss: 0.0875, Val Loss: 0.0886\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 18/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 24/60, Loss: 0.0886, Val Loss: 0.0885\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0891\n",
      "Epoch 27/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 30/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 2/60, Loss: 0.1114, Val Loss: 0.0901\n",
      "Epoch 5/60, Loss: 0.0904, Val Loss: 0.0891\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 4/60, Loss: 0.0926, Val Loss: 0.0881\n",
      "Epoch 12/60, Loss: 0.0891, Val Loss: 0.0878\n",
      "Epoch 35/60, Loss: 0.0876, Val Loss: 0.0886\n",
      "Epoch 8/60, Loss: 0.0885, Val Loss: 0.0895\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0878\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 19/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0884\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 39/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 28/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 31/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 3/60, Loss: 0.0971, Val Loss: 0.0897\n",
      "Epoch 31/60, Loss: 0.0883, Val Loss: 0.0880\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0904\n",
      "Epoch 5/60, Loss: 0.0915, Val Loss: 0.0880\n",
      "Epoch 36/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 6/60, Loss: 0.0898, Val Loss: 0.0892\n",
      "Epoch 13/60, Loss: 0.0887, Val Loss: 0.0878\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0879\n",
      "Epoch 18/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0884\n",
      "Epoch 9/60, Loss: 0.0885, Val Loss: 0.0900\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 31/60, Loss: 0.0877, Val Loss: 0.0879\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 40/60, Loss: 0.0874, Val Loss: 0.0891\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 4/60, Loss: 0.0934, Val Loss: 0.0894\n",
      "Epoch 37/60, Loss: 0.0876, Val Loss: 0.0887\n",
      "Early stopping triggered\n",
      "Epoch 6/60, Loss: 0.0905, Val Loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:06:38,925] Trial 184 finished with value: 0.08872610479593276 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.000262252199666924, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 184] Validation Loss: 0.0887\n",
      "\n",
      "[Trial 196] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.00020681883385739668, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 29/60, Loss: 0.0878, Val Loss: 0.0906\n",
      "Epoch 14/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 7/60, Loss: 0.0894, Val Loss: 0.0889\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0878\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:07:11,019] Trial 181 finished with value: 0.08777674045413733 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00022310859679582158, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 181] Validation Loss: 0.0878\n",
      "\n",
      "[Trial 197] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.0017140466131633106, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 10/60, Loss: 0.0883, Val Loss: 0.0901\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 41/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0879\n",
      "Epoch 5/60, Loss: 0.0915, Val Loss: 0.0895\n",
      "Epoch 1/60, Loss: 0.5079, Val Loss: 0.0982\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0891\n",
      "Epoch 7/60, Loss: 0.0902, Val Loss: 0.0878\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0883\n",
      "Epoch 15/60, Loss: 0.0887, Val Loss: 0.0877\n",
      "Epoch 30/60, Loss: 0.0878, Val Loss: 0.0896\n",
      "Epoch 8/60, Loss: 0.0890, Val Loss: 0.0886\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 1/60, Loss: 0.1855, Val Loss: 0.0881\n",
      "Epoch 34/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 2/60, Loss: 0.1505, Val Loss: 0.0921\n",
      "Epoch 11/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 6/60, Loss: 0.0905, Val Loss: 0.0895\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0891\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0888\n",
      "Epoch 33/60, Loss: 0.0877, Val Loss: 0.0878\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 8/60, Loss: 0.0897, Val Loss: 0.0881\n",
      "Epoch 35/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 2/60, Loss: 0.0917, Val Loss: 0.0865\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 3/60, Loss: 0.1132, Val Loss: 0.0903\n",
      "Epoch 31/60, Loss: 0.0877, Val Loss: 0.0895\n",
      "Epoch 9/60, Loss: 0.0886, Val Loss: 0.0891\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 7/60, Loss: 0.0899, Val Loss: 0.0892\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 32/60, Loss: 0.0879, Val Loss: 0.0878\n",
      "Epoch 43/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 12/60, Loss: 0.0879, Val Loss: 0.0896\n",
      "Epoch 4/60, Loss: 0.1015, Val Loss: 0.0894\n",
      "Epoch 9/60, Loss: 0.0896, Val Loss: 0.0876\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 3/60, Loss: 0.0899, Val Loss: 0.0865\n",
      "Epoch 34/60, Loss: 0.0876, Val Loss: 0.0880\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 17/60, Loss: 0.0887, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 10/60, Loss: 0.0887, Val Loss: 0.0887\n",
      "Epoch 5/60, Loss: 0.0962, Val Loss: 0.0891\n",
      "Epoch 23/60, Loss: 0.0876, Val Loss: 0.0888\n",
      "Epoch 31/60, Loss: 0.0882, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0898, Val Loss: 0.0892\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 24/60, Loss: 0.0948, Val Loss: 0.0893\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 44/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 4/60, Loss: 0.0897, Val Loss: 0.0866\n",
      "Epoch 10/60, Loss: 0.0893, Val Loss: 0.0877\n",
      "Epoch 13/60, Loss: 0.0882, Val Loss: 0.0893\n",
      "Epoch 37/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.0940, Val Loss: 0.0889\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0879\n",
      "Epoch 24/60, Loss: 0.0922, Val Loss: 0.0900\n",
      "Epoch 38/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0882\n",
      "Epoch 33/60, Loss: 0.0887, Val Loss: 0.0908\n",
      "Epoch 5/60, Loss: 0.0897, Val Loss: 0.0863\n",
      "Epoch 9/60, Loss: 0.0894, Val Loss: 0.0890\n",
      "Epoch 11/60, Loss: 0.0888, Val Loss: 0.0888\n",
      "Epoch 7/60, Loss: 0.0922, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0874, Val Loss: 0.0890\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 11/60, Loss: 0.0890, Val Loss: 0.0875\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 14/60, Loss: 0.0881, Val Loss: 0.0894\n",
      "Epoch 25/60, Loss: 0.0891, Val Loss: 0.0888\n",
      "Epoch 19/60, Loss: 0.0886, Val Loss: 0.0878\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 8/60, Loss: 0.0917, Val Loss: 0.0888\n",
      "Epoch 6/60, Loss: 0.0898, Val Loss: 0.0863\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0879\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0889\n",
      "Epoch 34/60, Loss: 0.0881, Val Loss: 0.0897\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0883\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 26/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Early stopping triggered\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0875\n",
      "Epoch 46/60, Loss: 0.0877, Val Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:15:55,976] Trial 189 finished with value: 0.08765501491725444 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0015947568713005967, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 189] Validation Loss: 0.0877\n",
      "\n",
      "[Trial 198] Starting with parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.00023080480199399217, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 9/60, Loss: 0.0911, Val Loss: 0.0888\n",
      "Epoch 12/60, Loss: 0.0889, Val Loss: 0.0874\n",
      "Epoch 26/60, Loss: 0.0879, Val Loss: 0.0888\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 7/60, Loss: 0.0896, Val Loss: 0.0862\n",
      "Epoch 20/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0899\n",
      "Epoch 10/60, Loss: 0.0905, Val Loss: 0.0886\n",
      "Epoch 11/60, Loss: 0.0890, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 41/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0897\n",
      "Epoch 37/60, Loss: 0.0875, Val Loss: 0.0879\n",
      "Epoch 1/60, Loss: 0.5127, Val Loss: 0.0964\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 13/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 47/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Epoch 35/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 13/60, Loss: 0.0886, Val Loss: 0.0873\n",
      "Epoch 8/60, Loss: 0.0893, Val Loss: 0.0860\n",
      "Epoch 11/60, Loss: 0.0898, Val Loss: 0.0886\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0875\n",
      "Epoch 42/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 16/60, Loss: 0.0880, Val Loss: 0.0892\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 2/60, Loss: 0.1487, Val Loss: 0.0914\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0887\n",
      "Epoch 28/60, Loss: 0.0876, Val Loss: 0.0889\n",
      "Epoch 12/60, Loss: 0.0897, Val Loss: 0.0885\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 36/60, Loss: 0.0875, Val Loss: 0.0894\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0878\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 9/60, Loss: 0.0893, Val Loss: 0.0861\n",
      "Epoch 14/60, Loss: 0.0889, Val Loss: 0.0874\n",
      "Epoch 48/60, Loss: 0.0875, Val Loss: 0.0891\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 3/60, Loss: 0.1107, Val Loss: 0.0900\n",
      "Epoch 22/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 42/60, Loss: 0.0881, Val Loss: 0.0881\n",
      "Epoch 13/60, Loss: 0.0894, Val Loss: 0.0886\n",
      "Epoch 29/60, Loss: 0.0877, Val Loss: 0.0886\n",
      "Epoch 13/60, Loss: 0.0887, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0893\n",
      "Epoch 10/60, Loss: 0.0890, Val Loss: 0.0857\n",
      "Epoch 37/60, Loss: 0.0878, Val Loss: 0.0895\n",
      "Epoch 38/60, Loss: 0.0878, Val Loss: 0.0875\n",
      "Epoch 14/60, Loss: 0.0896, Val Loss: 0.0884\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0873\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 4/60, Loss: 0.1000, Val Loss: 0.0894\n",
      "Epoch 39/60, Loss: 0.0874, Val Loss: 0.0878\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0876\n",
      "Epoch 15/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 30/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 14/60, Loss: 0.0885, Val Loss: 0.0884\n",
      "Epoch 15/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0889, Val Loss: 0.0861\n",
      "Epoch 5/60, Loss: 0.0955, Val Loss: 0.0894\n",
      "Epoch 18/60, Loss: 0.0877, Val Loss: 0.0891\n",
      "Epoch 39/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0894\n",
      "Epoch 16/60, Loss: 0.0884, Val Loss: 0.0871\n",
      "Epoch 50/60, Loss: 0.0873, Val Loss: 0.0890\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0880\n",
      "Epoch 31/60, Loss: 0.0896, Val Loss: 0.0890\n",
      "Epoch 16/60, Loss: 0.0895, Val Loss: 0.0885\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0878\n",
      "Epoch 39/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 16/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 24/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 12/60, Loss: 0.0890, Val Loss: 0.0857\n",
      "Epoch 15/60, Loss: 0.0884, Val Loss: 0.0885\n",
      "Epoch 6/60, Loss: 0.0934, Val Loss: 0.0889\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Early stopping triggered\n",
      "Epoch 17/60, Loss: 0.0892, Val Loss: 0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:24:23,026] Trial 187 finished with value: 0.08751710454622905 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.00023392210880049624, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 187] Validation Loss: 0.0875\n",
      "\n",
      "[Trial 199] Starting with parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.0017902645754506146, 'batch_size': 16, 'patience': 6}\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0880\n",
      "Epoch 40/60, Loss: 0.0877, Val Loss: 0.0875\n",
      "Epoch 19/60, Loss: 0.0880, Val Loss: 0.0894\n",
      "Epoch 32/60, Loss: 0.0880, Val Loss: 0.0888\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 39/60, Loss: 0.0873, Val Loss: 0.0894\n",
      "Epoch 51/60, Loss: 0.0876, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 13/60, Loss: 0.0888, Val Loss: 0.0860\n",
      "Epoch 7/60, Loss: 0.0919, Val Loss: 0.0888\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0893, Val Loss: 0.0885\n",
      "Epoch 41/60, Loss: 0.0877, Val Loss: 0.0878\n",
      "Epoch 17/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 16/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0887\n",
      "Epoch 1/60, Loss: 0.1449, Val Loss: 0.0904\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 19/60, Loss: 0.0887, Val Loss: 0.0882\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0875\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0871\n",
      "Epoch 8/60, Loss: 0.0908, Val Loss: 0.0887\n",
      "Epoch 14/60, Loss: 0.0887, Val Loss: 0.0857\n",
      "Epoch 20/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0890\n",
      "Epoch 40/60, Loss: 0.0875, Val Loss: 0.0895\n",
      "Epoch 26/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 17/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 18/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 42/60, Loss: 0.0876, Val Loss: 0.0878\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0879\n",
      "Epoch 20/60, Loss: 0.0886, Val Loss: 0.0881\n",
      "Epoch 34/60, Loss: 0.0877, Val Loss: 0.0889\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 9/60, Loss: 0.0908, Val Loss: 0.0886\n",
      "Epoch 15/60, Loss: 0.0888, Val Loss: 0.0856\n",
      "Epoch 2/60, Loss: 0.0900, Val Loss: 0.0903\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0875\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0884\n",
      "Epoch 53/60, Loss: 0.0875, Val Loss: 0.0890\n",
      "Early stopping triggered\n",
      "[Trial 177] Validation Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:28:38,060] Trial 177 finished with value: 0.08899097380538781 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 8.508084018592605e-05, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60, Loss: 0.0879, Val Loss: 0.0891\n",
      "Epoch 41/60, Loss: 0.0898, Val Loss: 0.0896\n",
      "Epoch 27/60, Loss: 0.0882, Val Loss: 0.0873\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0885\n",
      "Epoch 48/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0887\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:29:02,120] Trial 190 finished with value: 0.08868094508846601 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.0015975980872770992, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 190] Validation Loss: 0.0887\n",
      "Epoch 10/60, Loss: 0.0903, Val Loss: 0.0887\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 19/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 16/60, Loss: 0.0886, Val Loss: 0.0857\n",
      "Epoch 3/60, Loss: 0.0893, Val Loss: 0.0888\n",
      "Epoch 20/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 43/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:30:02,418] Trial 185 finished with value: 0.08757316979269186 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00024391056421664526, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 185] Validation Loss: 0.0876\n",
      "Epoch 49/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 23/60, Loss: 0.0886, Val Loss: 0.0880\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0875\n",
      "Epoch 19/60, Loss: 0.0883, Val Loss: 0.0885\n",
      "Epoch 11/60, Loss: 0.0900, Val Loss: 0.0886\n",
      "Epoch 22/60, Loss: 0.0877, Val Loss: 0.0892\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0897\n",
      "Early stopping triggered\n",
      "Epoch 44/60, Loss: 0.0880, Val Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:30:35,760] Trial 182 finished with value: 0.0896752721319596 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.0016344092864480477, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 182] Validation Loss: 0.0897\n",
      "Epoch 17/60, Loss: 0.0887, Val Loss: 0.0858\n",
      "Epoch 20/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 24/60, Loss: 0.0887, Val Loss: 0.0879\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0879\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:31:13,274] Trial 180 finished with value: 0.08788830780734619 and parameters: {'hidden_dim': 384, 'latent_dim': 128, 'lr': 0.00024378282690024045, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 180] Validation Loss: 0.0879\n",
      "Epoch 4/60, Loss: 0.0889, Val Loss: 0.0887\n",
      "Epoch 50/60, Loss: 0.0880, Val Loss: 0.0880\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 12/60, Loss: 0.0897, Val Loss: 0.0887\n",
      "Epoch 45/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 25/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 20/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0885, Val Loss: 0.0858\n",
      "Epoch 23/60, Loss: 0.0878, Val Loss: 0.0891\n",
      "Epoch 26/60, Loss: 0.0886, Val Loss: 0.0879\n",
      "Epoch 51/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 21/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 13/60, Loss: 0.0893, Val Loss: 0.0892\n",
      "Epoch 5/60, Loss: 0.0887, Val Loss: 0.0885\n",
      "Epoch 22/60, Loss: 0.0883, Val Loss: 0.0871\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Epoch 19/60, Loss: 0.0888, Val Loss: 0.0856\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0874\n",
      "Epoch 27/60, Loss: 0.0885, Val Loss: 0.0880\n",
      "Epoch 24/60, Loss: 0.0879, Val Loss: 0.0892\n",
      "Early stopping triggered\n",
      "Epoch 52/60, Loss: 0.0880, Val Loss: 0.0879\n",
      "[Trial 192] Validation Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:33:18,266] Trial 192 finished with value: 0.0891566793123881 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.0016370173028743703, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60, Loss: 0.0894, Val Loss: 0.0885\n",
      "Epoch 47/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 22/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 6/60, Loss: 0.0887, Val Loss: 0.0892\n",
      "Epoch 20/60, Loss: 0.0890, Val Loss: 0.0858\n",
      "Epoch 23/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 22/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0873\n",
      "Epoch 28/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 15/60, Loss: 0.0893, Val Loss: 0.0884\n",
      "Epoch 53/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:34:09,651] Trial 186 finished with value: 0.08805682150026163 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.000237308339279024, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 186] Validation Loss: 0.0881\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0890, Val Loss: 0.0856\n",
      "Epoch 23/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 16/60, Loss: 0.0893, Val Loss: 0.0884\n",
      "Epoch 29/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 24/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 23/60, Loss: 0.0880, Val Loss: 0.0883\n",
      "Epoch 7/60, Loss: 0.0885, Val Loss: 0.0896\n",
      "Epoch 32/60, Loss: 0.0883, Val Loss: 0.0872\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:35:07,436] Trial 188 finished with value: 0.08813485881934563 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.0002278872895148489, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 188] Validation Loss: 0.0881\n",
      "Epoch 22/60, Loss: 0.0886, Val Loss: 0.0855\n",
      "Epoch 17/60, Loss: 0.0890, Val Loss: 0.0882\n",
      "Epoch 30/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0884\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 33/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 24/60, Loss: 0.0880, Val Loss: 0.0889\n",
      "Epoch 8/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 23/60, Loss: 0.0933, Val Loss: 0.0861\n",
      "Epoch 18/60, Loss: 0.0886, Val Loss: 0.0882\n",
      "Epoch 31/60, Loss: 0.0885, Val Loss: 0.0879\n",
      "Epoch 25/60, Loss: 0.0879, Val Loss: 0.0884\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 26/60, Loss: 0.0882, Val Loss: 0.0870\n",
      "Epoch 24/60, Loss: 0.0891, Val Loss: 0.0857\n",
      "Epoch 25/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 19/60, Loss: 0.0889, Val Loss: 0.0882\n",
      "Epoch 32/60, Loss: 0.0884, Val Loss: 0.0877\n",
      "Epoch 9/60, Loss: 0.0884, Val Loss: 0.0882\n",
      "Epoch 26/60, Loss: 0.0876, Val Loss: 0.0883\n",
      "Epoch 25/60, Loss: 0.0889, Val Loss: 0.0856\n",
      "Epoch 35/60, Loss: 0.0878, Val Loss: 0.0872\n",
      "Epoch 20/60, Loss: 0.0889, Val Loss: 0.0881\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 27/60, Loss: 0.0880, Val Loss: 0.0871\n",
      "Epoch 26/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 10/60, Loss: 0.0880, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 26/60, Loss: 0.0888, Val Loss: 0.0861\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 27/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 36/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 28/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 22/60, Loss: 0.0887, Val Loss: 0.0880\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 27/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 27/60, Loss: 0.0888, Val Loss: 0.0855\n",
      "Epoch 11/60, Loss: 0.0882, Val Loss: 0.0884\n",
      "Epoch 28/60, Loss: 0.0878, Val Loss: 0.0884\n",
      "Epoch 37/60, Loss: 0.0877, Val Loss: 0.0872\n",
      "Epoch 29/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 23/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 28/60, Loss: 0.0886, Val Loss: 0.0856\n",
      "Epoch 28/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 29/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 12/60, Loss: 0.0883, Val Loss: 0.0886\n",
      "Epoch 37/60, Loss: 0.0883, Val Loss: 0.0877\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 24/60, Loss: 0.0884, Val Loss: 0.0879\n",
      "Epoch 29/60, Loss: 0.0887, Val Loss: 0.0856\n",
      "Epoch 30/60, Loss: 0.0882, Val Loss: 0.0871\n",
      "Epoch 38/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 25/60, Loss: 0.0883, Val Loss: 0.0880\n",
      "Epoch 30/60, Loss: 0.0877, Val Loss: 0.0882\n",
      "Epoch 29/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 30/60, Loss: 0.0889, Val Loss: 0.0857\n",
      "Epoch 13/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 26/60, Loss: 0.0883, Val Loss: 0.0879\n",
      "Epoch 31/60, Loss: 0.0879, Val Loss: 0.0883\n",
      "Epoch 31/60, Loss: 0.0890, Val Loss: 0.0855\n",
      "Epoch 40/60, Loss: 0.0880, Val Loss: 0.0872\n",
      "Epoch 30/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 27/60, Loss: 0.0883, Val Loss: 0.0878\n",
      "Epoch 14/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0870\n",
      "Epoch 32/60, Loss: 0.0888, Val Loss: 0.0856\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0883\n",
      "Epoch 41/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 41/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 28/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 31/60, Loss: 0.0881, Val Loss: 0.0880\n",
      "Epoch 33/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 15/60, Loss: 0.0882, Val Loss: 0.0879\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 33/60, Loss: 0.0886, Val Loss: 0.0856\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:42:54,386] Trial 197 finished with value: 0.08562414466092984 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.0017140466131633106, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 197] Validation Loss: 0.0856\n",
      "Epoch 33/60, Loss: 0.0876, Val Loss: 0.0882\n",
      "Epoch 29/60, Loss: 0.0884, Val Loss: 0.0878\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0878\n",
      "Epoch 32/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 34/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 30/60, Loss: 0.0884, Val Loss: 0.0880\n",
      "Epoch 16/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 34/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 44/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0873\n",
      "Epoch 31/60, Loss: 0.0880, Val Loss: 0.0878\n",
      "Epoch 45/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 35/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 33/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 35/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 17/60, Loss: 0.0883, Val Loss: 0.0881\n",
      "Epoch 44/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 32/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 46/60, Loss: 0.0882, Val Loss: 0.0877\n",
      "Epoch 36/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 34/60, Loss: 0.0879, Val Loss: 0.0880\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Early stopping triggered\n",
      "Epoch 36/60, Loss: 0.0878, Val Loss: 0.0883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:45:21,975] Trial 196 finished with value: 0.08778461627662182 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.00020681883385739668, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 196] Validation Loss: 0.0878\n",
      "Epoch 33/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0874\n",
      "Epoch 18/60, Loss: 0.0882, Val Loss: 0.0881\n",
      "Epoch 37/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 34/60, Loss: 0.0882, Val Loss: 0.0878\n",
      "Epoch 37/60, Loss: 0.0877, Val Loss: 0.0883\n",
      "Epoch 35/60, Loss: 0.0875, Val Loss: 0.0881\n",
      "Epoch 46/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 35/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 19/60, Loss: 0.0941, Val Loss: 0.0897\n",
      "Epoch 38/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 38/60, Loss: 0.0877, Val Loss: 0.0881\n",
      "Epoch 36/60, Loss: 0.0876, Val Loss: 0.0880\n",
      "Epoch 47/60, Loss: 0.0881, Val Loss: 0.0872\n",
      "Epoch 36/60, Loss: 0.0880, Val Loss: 0.0878\n",
      "Epoch 39/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 20/60, Loss: 0.0890, Val Loss: 0.0885\n",
      "Epoch 39/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 48/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 37/60, Loss: 0.0880, Val Loss: 0.0881\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:47:44,117] Trial 193 finished with value: 0.0880751047283411 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.00023242147154546336, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 193] Validation Loss: 0.0881\n",
      "Epoch 40/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 38/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 40/60, Loss: 0.0876, Val Loss: 0.0882\n",
      "Epoch 21/60, Loss: 0.0888, Val Loss: 0.0881\n",
      "Epoch 49/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 39/60, Loss: 0.0881, Val Loss: 0.0878\n",
      "Epoch 41/60, Loss: 0.0878, Val Loss: 0.0869\n",
      "Epoch 41/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 40/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 50/60, Loss: 0.0881, Val Loss: 0.0871\n",
      "Epoch 22/60, Loss: 0.0882, Val Loss: 0.0880\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:48:58,937] Trial 199 finished with value: 0.08805457390844822 and parameters: {'hidden_dim': 320, 'latent_dim': 128, 'lr': 0.0017902645754506146, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 199] Validation Loss: 0.0881\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 41/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 42/60, Loss: 0.0878, Val Loss: 0.0882\n",
      "Epoch 51/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 42/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 43/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 43/60, Loss: 0.0876, Val Loss: 0.0882\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0872\n",
      "Epoch 43/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 44/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 44/60, Loss: 0.0878, Val Loss: 0.0877\n",
      "Epoch 44/60, Loss: 0.0876, Val Loss: 0.0882\n",
      "Epoch 53/60, Loss: 0.0878, Val Loss: 0.0873\n",
      "Epoch 45/60, Loss: 0.0881, Val Loss: 0.0869\n",
      "Epoch 45/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 45/60, Loss: 0.0879, Val Loss: 0.0881\n",
      "Epoch 54/60, Loss: 0.0877, Val Loss: 0.0871\n",
      "Epoch 46/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 46/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 46/60, Loss: 0.0879, Val Loss: 0.0882\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0877\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0872\n",
      "Epoch 47/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 48/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 47/60, Loss: 0.0878, Val Loss: 0.0883\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:51:35,628] Trial 195 finished with value: 0.08827390012641748 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00021585697558040932, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 195] Validation Loss: 0.0883\n",
      "Epoch 56/60, Loss: 0.0889, Val Loss: 0.0871\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:51:40,941] Trial 191 finished with value: 0.087142022823294 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00020927986019040747, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 191] Validation Loss: 0.0871\n",
      "Epoch 49/60, Loss: 0.0880, Val Loss: 0.0876\n",
      "Epoch 48/60, Loss: 0.0879, Val Loss: 0.0871\n",
      "Epoch 50/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 51/60, Loss: 0.0878, Val Loss: 0.0877\n",
      "Epoch 49/60, Loss: 0.0878, Val Loss: 0.0868\n",
      "Epoch 52/60, Loss: 0.0877, Val Loss: 0.0876\n",
      "Epoch 50/60, Loss: 0.0882, Val Loss: 0.0868\n",
      "Epoch 53/60, Loss: 0.0879, Val Loss: 0.0877\n",
      "Epoch 54/60, Loss: 0.0878, Val Loss: 0.0876\n",
      "Epoch 51/60, Loss: 0.0880, Val Loss: 0.0869\n",
      "Epoch 55/60, Loss: 0.0879, Val Loss: 0.0876\n",
      "Epoch 56/60, Loss: 0.0882, Val Loss: 0.0876\n",
      "Epoch 52/60, Loss: 0.0881, Val Loss: 0.0868\n",
      "Epoch 57/60, Loss: 0.0881, Val Loss: 0.0877\n",
      "Epoch 58/60, Loss: 0.0877, Val Loss: 0.0878\n",
      "Epoch 53/60, Loss: 0.0888, Val Loss: 0.0870\n",
      "Epoch 59/60, Loss: 0.0877, Val Loss: 0.0876\n",
      "Epoch 60/60, Loss: 0.0881, Val Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:53:28,275] Trial 198 finished with value: 0.08767610726257165 and parameters: {'hidden_dim': 128, 'latent_dim': 128, 'lr': 0.00023080480199399217, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 198] Validation Loss: 0.0877\n",
      "Epoch 54/60, Loss: 0.0880, Val Loss: 0.0868\n",
      "Epoch 55/60, Loss: 0.0878, Val Loss: 0.0868\n",
      "Epoch 56/60, Loss: 0.0879, Val Loss: 0.0870\n",
      "Epoch 57/60, Loss: 0.0879, Val Loss: 0.0869\n",
      "Epoch 58/60, Loss: 0.0878, Val Loss: 0.0868\n",
      "Epoch 59/60, Loss: 0.0880, Val Loss: 0.0870\n",
      "Epoch 60/60, Loss: 0.0878, Val Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 22:54:44,971] Trial 194 finished with value: 0.08682398398717245 and parameters: {'hidden_dim': 256, 'latent_dim': 128, 'lr': 0.00023764721058076808, 'batch_size': 16, 'patience': 6}. Best is trial 122 with value: 0.08478449912120899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 194] Validation Loss: 0.0868\n",
      "Best hyperparameters: {'hidden_dim': 192, 'latent_dim': 64, 'lr': 0.0012589907254044416, 'batch_size': 8, 'patience': 10}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to search\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 512, step=64)\n",
    "    latent_dim = trial.suggest_int(\"latent_dim\", 32, 128, step=32)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Print the current trial's hyperparameters\n",
    "    print(f\"\\n[Trial {trial.number}] Starting with parameters: {trial.params}\")\n",
    "\n",
    "    # Prepare dataset loaders\n",
    "    pyg_dataset = torch.load('../../data/curated dataset/cleaned_frag_pyg_dataset.pth')\n",
    "    train_ratio = 0.8\n",
    "    num_train = int(len(pyg_dataset) * train_ratio)\n",
    "    num_valid = len(pyg_dataset) - num_train\n",
    "\n",
    "    train_dataset, valid_dataset = random_split(pyg_dataset, [num_train, num_valid])\n",
    "    train_loader = PyGDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = PyGDataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    node_features = pyg_dataset[0].x.size(1)\n",
    "    edge_features = pyg_dataset[0].edge_attr.size(1)\n",
    "    model = ARGA(node_features, edge_features, hidden_dim, latent_dim)\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = train_arga_with_early_stopping(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=60,\n",
    "        lr=lr,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        patience=patience\n",
    "    )\n",
    "\n",
    "    # Calculate validation loss or other metrics\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            reconstructed_x, reconstructed_edge_attr, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            val_loss += (F.mse_loss(reconstructed_x, batch.x) + \n",
    "                        F.mse_loss(reconstructed_edge_attr, batch.edge_attr)).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"[Trial {trial.number}] Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Return validation loss as the optimization metric\n",
    "    return avg_val_loss\n",
    "\n",
    "\n",
    "# Define and run the Optuna study\n",
    "if __name__ == \"__main__\":\n",
    "    num_cores = multiprocessing.cpu_count()  # Use all available cores\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=200, n_jobs=num_cores)  # Set n_jobs to the number of CPU cores\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
